<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Differentiable Augmentation for Data-Efficient GAN Training | Seoyeon Choi</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Differentiable Augmentation for Data-Efficient GAN Training" />
<meta name="author" content="최서연" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Shengyu Zhao(IIIS, Tsinghua University and MIT), Zhijian Liu(MIT), Ji Lin(MIT), Jun-Yan Zhu(Adobe and CMU), Song Han(MIT)" />
<meta property="og:description" content="Shengyu Zhao(IIIS, Tsinghua University and MIT), Zhijian Liu(MIT), Ji Lin(MIT), Jun-Yan Zhu(Adobe and CMU), Song Han(MIT)" />
<link rel="canonical" href="https://seoyeonc.github.io/chch/gan/%EB%85%BC%EB%AC%B8%EB%A6%AC%EB%B7%B0/2022/02/02/Data-Efficient-GAN.html" />
<meta property="og:url" content="https://seoyeonc.github.io/chch/gan/%EB%85%BC%EB%AC%B8%EB%A6%AC%EB%B7%B0/2022/02/02/Data-Efficient-GAN.html" />
<meta property="og:site_name" content="Seoyeon Choi" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-02-02T00:00:00-06:00" />
<script type="application/ld+json">
{"description":"Shengyu Zhao(IIIS, Tsinghua University and MIT), Zhijian Liu(MIT), Ji Lin(MIT), Jun-Yan Zhu(Adobe and CMU), Song Han(MIT)","url":"https://seoyeonc.github.io/chch/gan/%EB%85%BC%EB%AC%B8%EB%A6%AC%EB%B7%B0/2022/02/02/Data-Efficient-GAN.html","@type":"BlogPosting","headline":"Differentiable Augmentation for Data-Efficient GAN Training","dateModified":"2022-02-02T00:00:00-06:00","datePublished":"2022-02-02T00:00:00-06:00","author":{"@type":"Person","name":"최서연"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://seoyeonc.github.io/chch/gan/%EB%85%BC%EB%AC%B8%EB%A6%AC%EB%B7%B0/2022/02/02/Data-Efficient-GAN.html"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/chch/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://seoyeonc.github.io/chch/feed.xml" title="Seoyeon Choi" /><link rel="shortcut icon" type="image/x-icon" href="/chch/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/chch/">Seoyeon Choi</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/chch/about/">About Me</a><a class="page-link" href="/chch/search/">Search</a><a class="page-link" href="/chch/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Differentiable Augmentation for Data-Efficient GAN Training</h1><p class="page-description">Shengyu Zhao(IIIS, Tsinghua University and MIT), Zhijian Liu(MIT), Ji Lin(MIT), Jun-Yan Zhu(Adobe and CMU), Song Han(MIT)</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2022-02-02T00:00:00-06:00" itemprop="datePublished">
        Feb 2, 2022
      </time>• 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">최서연</span></span>
       • <span class="read-time" title="Estimated read time">
    
    
      17 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/chch/categories/#GAN">GAN</a>
        &nbsp;
      
        <a class="category-tags-link" href="/chch/categories/#논문리뷰">논문리뷰</a>
        
      
      </p>
    

    
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#Abstract">Abstract </a></li>
<li class="toc-entry toc-h2"><a href="#Method">Method </a></li>
<li class="toc-entry toc-h2"><a href="#Revisiting-Data-Augmentation">Revisiting Data Augmentation </a></li>
<li class="toc-entry toc-h2"><a href="#Differentiable-Augmentation-for-GANs">Differentiable Augmentation for GANs </a></li>
<li class="toc-entry toc-h2"><a href="#Experiments">Experiments </a>
<ul>
<li class="toc-entry toc-h3"><a href="#ImageNet">ImageNet </a></li>
<li class="toc-entry toc-h3"><a href="#FFHQ-and-LSUN-Cat">FFHQ and LSUN-Cat </a></li>
<li class="toc-entry toc-h3"><a href="#CIFAR-10-and-CIFAR-100">CIFAR-10 and CIFAR-100 </a></li>
<li class="toc-entry toc-h3"><a href="#Low-Shot-Generation">Low-Shot Generation </a></li>
<li class="toc-entry toc-h3"><a href="#Analysis">Analysis </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Conclusion">Conclusion </a></li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2022-02-02-Data-Efficient GAN.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>ref: <a href="https://proceedings.neurips.cc/paper/2020/file/55479c55ebd1efd3ff125f1337100388-Paper.pdf">https://proceedings.neurips.cc/paper/2020/file/55479c55ebd1efd3ff125f1337100388-Paper.pdf</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>ref: <a href="https://github.com/mit-han-lab/data-efficient-gans">https://github.com/mit-han-lab/data-efficient-gans</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>
</p>
<center class="youtube-iframe-wrapper">
    <iframe width="730" height="315" src="https://www.youtube.com/embed/SsqcjS6SVM0" frameborder="0" allowfullscreen=""></iframe>
</center>


</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Abstract">
<a class="anchor" href="#Abstract" aria-hidden="true"><span class="octicon octicon-link"></span></a>Abstract<a class="anchor-link" href="#Abstract"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>The performance of generative adversarial networks (GANs) heavily deteriorates given a limited amount of training data. <ul>
<li>제한된 양의 학습 데이터가 주어지면 성능 나빠짐</li>
<li>discriminator가 정확한 training set 기억하는 주된 이유</li>
</ul>
</li>
<li>To combat it, we propose Differentiable Augmentation (DiffAugment), a simple method that improves the data efficiency of GANs by imposing various types of differentiable augmentations on both real and fake samples. <ul>
<li>실제/가짜 sample에 differentiable augmentations의 다양한 type 부과해서 GAN의 data 효율성을 증진하는 DiffAugment(Differentiable Augmentation) 제시</li>
<li>일반화된 sample에서 differentiable augmentation 차별화된 확대 수용하면 training이 효율적으로 안정화하고 더 나은 convergence를 이끔</li>
<li>only 20% training data, we can match the top performance on CIFAR-10 and CIFAR-100</li>
<li>our method can generate high-fidelity images using only 100 images without pre-training, while being on par with existing transfer learning algorithms. </li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Method">
<a class="anchor" href="#Method" aria-hidden="true"><span class="octicon octicon-link"></span></a>Method<a class="anchor-link" href="#Method"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>GANs(Generative Adversarial Networks)는 generator G와 discriminator D로 target dataset의 분포를 모델링하는 것이 목적</p>
<p>genorator G는 typically 가우시안 분포에서 나온 입력 latent 벡터 z에서 출력 G(z)에 mapping한다.</p>
<p>discriminator D는 실제 관측치 x에서 generated sample G(z)를 구별해내는 것을 배움</p>
<p>The standard GANs training algorithm alternately optimizes the discriminator’s loss $L_D$ and the generator’s loss $L_G$ given loss functions $f_D$ and $f_G$:

$$L_D = E_{x~p_{data}(x)}|f_D (-D(x))| + E_{x~p(x)}|f_D (D(G(z)))|, \dots(1)$$


$$L_G = E_{x~p(x)} |f_G (-D(G(z)))|, \dots(2)$$
</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="data:image/png;base64,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" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Figure 4: Overview of DiffAugment for updating D (left) and G (right)</p>
<ul>
<li>DiffAugment는 실제 smaple x와 generated 출력 G(z)에 augmentation T를 적용</li>
<li>G를 업데이트하면 기울기는 T로 역전파되어야 하며 T는 입력으로 미분할 수 있어야 함</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Here, different loss functions can be used, such as the non-saturating loss, where $f_D(x) = f_G(x) = log (1 + e^x)$, and the hinge loss, where $f_D(x) = max(0, 1 + x)$ and $f_G(x) = x$.</p>
<p>the discriminator tends to memorize the observations as the training progresses.</p>
<ul>
<li>discrminator는 training 한 관찰을 기억하는 경향이 있음</li>
</ul>
<p>An overfitted discriminator penalizes any generated samples other than the exact training data points, provides uninformative gradients due to poor generalization, and usually leads to training instability.</p>
<ul>
<li>과적합 discriminator는 정확한 training data point 외의 generated sample에 penalize하고, poor generation 따문에 정보 없는 gradient를 제공하지 않으며 training 불안정성을 이끈다.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Challenge: Discriminator Overfitting</strong></p>
<ul>
<li>CIFAR-10 사용하여 BigGAN 성능 분석</li>
<li>figure 1 미루어보아 데이터가 100% 주어져도 genarator과 discriminator 사이의 격차 계속 증가<ul>
<li>discriminator가 단순하게 training image를 기억하고 있다는 뜻</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Revisiting-Data-Augmentation">
<a class="anchor" href="#Revisiting-Data-Augmentation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Revisiting Data Augmentation<a class="anchor-link" href="#Revisiting-Data-Augmentation"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Data augmentation is a commonly-used strategy to reduce overfitting in many recognition tasks.</p>
<ul>
<li>it has an irreplaceable role and can also be applied in conjunction with other regularization techniques: e.g., weight decay.</li>
</ul>
<p>the discriminator suffers from a similar overfitting problem as the binary classifier.</p>
<ul>
<li>data augmentation is seldom used in the GAN literature compared to the explicit regularizations on the discriminator</li>
<li>In fact, a recent work [50] observes that directly applying data augmentation to GANs does not improve the baseline. </li>
</ul>
<p>ask the questions:</p>
<ul>
<li>what prevents us from simply applying data augmentation to GANs? </li>
<li>Why is augmenting GANs not as effective as augmenting classifiers?</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Augment reals only</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The most straightforward way of augmenting GANs would be directly applying augmentation T to the real observations x, which we call “Augment reals only”: GAN 확대 혹은 증가를 위한 간단한 방법, Augment reals only라 부르는 실제 관측치 x를 T에 직접 적용시키기

$$L_D = E_{x~p_{data}(x)}|f_D (-D(T(x))))| + E_{x~p(x)}|f_D(D(G((z))))|, \dots (3)$$
</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQrxZ_1odR9kZuceLJYnEX3HRBwC5GY7R_H9Q&amp;usqp=CAU" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Figure 5. Understanding why vanilla augmentation strategies fail:</p>
<ul>
<li>(a) “Augment reals only” 는 확대augmentation와 동일한 데이터 왜곡 의미, </li>
<li>(b)“Augment D only” 는 augment된 T(x)와 T(G(z))를 완벽하게 분리하지만 G(z)(Augmentation없는 가짜 이미지)를 거의 인지하지 못함.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>“Augment reals only”</strong>는 generative modeling의 원래 목적에서 벗어남.</p>
<ul>
<li>모델이 x대신에 T(x)의 다른 data distribution에서 learning하고 있기 때문이다.</li>
<li>이는 실제 이미지의 분포가 크게 변화하여 어느 augmentation이든 적용하는 것으로부터 막기 때문.<ul>
<li>This prevents us from applying any augmentation that significantly alters the distribution of the real images.</li>
</ul>
</li>
<li>비록 강하게 특정 dataset에 의존하지만, 이 요구 사항을 만족하는 선택은 대부분 case에서 수평 flip이 될 수 있다.<ul>
<li>The choices that meet this requirement, although strongly dependent on the specific dataset, can only be horizontal flips in most cases. </li>
</ul>
</li>
<li>임의의 수평 flip을 적용하는 것은 성능이 보통 상승하는 것을 알 수 있어 baseline 을 더 stronger하게 만들기 위해 모든 experiment에서 임의의 수평 플립 사용함<ul>
<li>We find that applying random horizontal flips does increase the performance moderately, and we use it in all our experiments to make our baselines stronger.</li>
</ul>
</li>
<li>모델은 augmentation으로 도입된 원치 않는 색과 기하학적 왜곡을 생성하는 방법을 학습하여 성능이 크게 저하됨.<ul>
<li>As expected, the model learns to produce unwanted color and geometric distortion (e.g., unnatural color, cutout holes) as introduced by these augmentations, resulting in a significantly worse performance</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Augment D only</strong></p>
<ul>
<li>Augment reals only 은 실제 sample에 one-sided augmentation을 적용했던 것은 generated 분포가 manupulated 실제 분포와 일치한는 경우에만 convergence수렴이 achive될 수 있었다.<ul>
<li>Previously, “Augment reals only” applies one-sided augmentation to the real samples, and hence the convergence can be achieved only if the generated distribution matches the manipulated real distribution.</li>
</ul>
</li>
<li>discriminator의 관점에서 D를 업데이트할 때 진짜와 가짜 sample 모두 augment 하는 것이 temp할 수 있음.<ul>
<li>From the discriminator’s perspective, it may be tempting to augment both real and fake samples when we update D:

$$L_D = E_{x~p_{data}(z)}|f_D(-D(T(x)))| + E_{x~p(x)}|f_D(D(T(G(z))))|, \dots (5)$$


$$L_G = E_{x~p(x)}|f_G (-D(G(z)))|, \dots (6)$$
</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>실제 sample x와 가짜 sample G(z)가 같은 함수 T에 적용됨.</li>
<li>generator가 x의 분포를 성공적을 모델링한다면, G(z)와 x  뿐만 아니라 T(G(z)와 T(x)도 discriminator에 의해 판별될 수 없어야 한다.<ul>
<li>If the generator successfully models the distribution of x, T(G(z)) and T(x) should be indistinguishable to the discriminator as well as G(z) and x.</li>
</ul>
</li>
<li>하지만 이 strategy는 worse result를 이끔(Table 1에서 “Augment D only” 부분)</li>
<li>Figure 5 (b)“Augment D only” 에서는 Translatopnn이 적용된 training dynamics plot임<ul>
<li>Figure 5 b plots the training dynamics of “Augment D only” with Translation applied. </li>
</ul>
</li>
<li>비록 D는 90% 이상의 정확도로 완벽하게 augmenteg image들인 T(G(z))와 T(x)를 분류해내지만, 10% 이하의 정확도로 augmentation 없이 generated image인 G(z)를 인식하는 데 실패함<ul>
<li>Although D classifies the augmented images (both T(G(z)) and T(x)) perfectly with an accuracy of above 90%, it fails to recognize G(z), the generated images without augmentation, with an accuracy of lower than 10%.</li>
</ul>
</li>
<li>결과적으로, generator는 G(z)에 의해 discriminator를 완전히 fool하고 discriminator로부터 유용한 정보를 얻릉 수 없다.<ul>
<li>As a result, the generator completely fools the discriminator by G(z) and cannot obtain useful information from the discriminator.</li>
</ul>
</li>
<li>generator G와 discriminator D 사이의 delicate한 균형을 깨는 시도가 실패하기 쉽다는 것을 나타냄.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Differentiable-Augmentation-for-GANs">
<a class="anchor" href="#Differentiable-Augmentation-for-GANs" aria-hidden="true"><span class="octicon octicon-link"></span></a>Differentiable Augmentation for GANs<a class="anchor-link" href="#Differentiable-Augmentation-for-GANs"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Augment reals only의 실패는 실제와 가짜 sample을 augment하도록 동기부여 하지만, Augment D only의 실패는 generator가 augmented sample을 놔둬서는 안 된다고 경고한다.</p>
<ul>
<li>The failure of “Augment reals only” motivates us to augment both real and fake samples, while the failure of “Augment D only” warns us that the generator should not neglect the augmented samples.</li>
<li>augmented sample 을 통해 G로 gradient를 전파하기 위해 augmentation T 는 구별될 수 있어야함.<ul>
<li>이게 바로 Differentiable Augmentation (DiffAugment)

$$L_D = E_{x~p_{data}}(x)[f_D (-D(T(x)))] + E_{x~p(x)}[f_D(D(T(G(z))))], \dots (7)$$


$$L_g = E_{z~p(z)}[f_G(-D(T(G(z))))], \dots (8)$$
</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>T는 동일한 임의의 함수, 하지만 세 위치에 거쳐 꼭 동일한 임의의 seed를 가질 필요는 없음<ul>
<li>Note that T is required to be the same (random) function but not necessarily the same random seed across the three places illustrated in Figure 4.</li>
</ul>
</li>
<li>As shown in Table 1, BigGAN can be improved using the simple Translation policy and further boosted using a composition of Cutout and Translation; it is also robust to the strongest policy when Color is used in combined.</li>
<li>Figue 6에서 stronger한 DiffAugment policy가 일반적으로 더 낮은 training 정확도의 cost애서 더 높은 discriminator의 검증 정확도를 유지하고, overfitting을 완화하며, 결과적으로 더 나은 수렴convergence를 성취achieve했다고 분석한다.<ul>
<li>Figure 6 analyzes that stronger DiffAugment policies generally maintain a higher discriminator’s validation accuracy at the cost of a lower training accuracy, alleviate the overfitting problem, and eventually achieve better convergence.</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSyl7x7gcXynJl30VgC2_x7cIS-EXMZ-dfioZCGfvsY1sxVVja47qBjZUFCdHWhgY2oNYo&amp;usqp=CAU" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Figure 6: Analysis of different types of DiffAugment on CIFAR-10 with 100% training data.</p>
<ul>
<li>stronger한 DiffAugment가 극적으로 discriminator의 training 정확도(중간)와 validation 정확도(오른쪽) 차이를 감소할 수 있어 더 나은 수렴convergence에(왼쪽) 이르게 할 수 있다.<ul>
<li>A stronger DiffAugment can dramatically reduce the gap between the discriminator’s training accuracy (middle) and validation accuracy (right), leading to a better convergence (left)</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Experiments">
<a class="anchor" href="#Experiments" aria-hidden="true"><span class="octicon octicon-link"></span></a>Experiments<a class="anchor-link" href="#Experiments"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="ImageNet">
<a class="anchor" href="#ImageNet" aria-hidden="true"><span class="octicon octicon-link"></span></a>ImageNet<a class="anchor-link" href="#ImageNet"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>We follow the top-performing model BigGAN [2] on ImageNet dataset at 128×128 resolution. </li>
<li>Additionally, we augment real images with random horizontal flips, yielding the best reimplementation of BigGAN to our knowledge (FID: ours 7.6 vs. 8.7 in the original paper [2]). </li>
<li>We use the simple Translation DiffAugment for all the data percentage settings. </li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="FFHQ-and-LSUN-Cat">
<a class="anchor" href="#FFHQ-and-LSUN-Cat" aria-hidden="true"><span class="octicon octicon-link"></span></a>FFHQ and LSUN-Cat<a class="anchor-link" href="#FFHQ-and-LSUN-Cat"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>We further experiment with StyleGAN2 [18] on the FFHQ portrait dataset [17] and the LSUN-Cat dataset [46] at 256×256 resolution.</li>
<li>We investigate different limited data settings, with 1k, 5k, 10k, and 30k training images available.</li>
<li>We apply the strongest Color + Translation + Cutout DiffAugment to all the StyleGAN2 baselines without any hyperparameter changes. </li>
<li>The real images are also augmented with random horizontal flips as commonly applied in StyleGAN2 [18].</li>
<li>성능이 모든 데이터 백분율 설정에서 고려할만했음!</li>
<li>게다가 DiffAugment에 사용되는 고정 정책으로 성능이 adoptive augmentation strategy에 기반한 동시작업인 ADA와 동등함.<ul>
<li>Moreover, with the fixed policies used in DiffAugment, our performance is on par with ADA [16], a concurrent work based on the adaptive augmentation strategy.</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="CIFAR-10-and-CIFAR-100">
<a class="anchor" href="#CIFAR-10-and-CIFAR-100" aria-hidden="true"><span class="octicon octicon-link"></span></a>CIFAR-10 and CIFAR-100<a class="anchor-link" href="#CIFAR-10-and-CIFAR-100"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>experiment on the class-conditional BigGAN [2] and CR-BigGAN [50] and unconditional StyleGAN2 [18] models.</li>
<li>For a fair comparison, augment real images with random horizontal flips for all the baselines. </li>
</ul>
<p>For DiffAugment, we adopt <strong>Translation + Cutout</strong> for the BigGAN models, <strong>Color + Cutout</strong> for StyleGAN2 with 100% data, and <strong>Color + Translation + Cutout</strong> for StyleGAN2 with 10% or 20% data.</p>
<ul>
<li>Table 4로 미루어 보아 our method improves all the baselines independently of the baseline architectures, regularizations, and loss functions (hinge loss in BigGAN and non-saturating loss in StyleGAN2) without any hyperparameter changes.<ul>
<li>The improvements are considerable especially when limited data is available. </li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Low-Shot-Generation">
<a class="anchor" href="#Low-Shot-Generation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Low-Shot Generation<a class="anchor-link" href="#Low-Shot-Generation"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>image data가 제대로 수집이 되지 않았을때.</p>
<ul>
<li>fine-tunre을 통해 사전 훈련된 모델을 적용 시키기도 하고<ul>
<li>Wang et al. [45] use fine-tuning to transfer the knowledge of models pre-trained on external large-scale datasets.</li>
</ul>
</li>
<li>모델의 일부만을 fine-tune하기도 함<ul>
<li>Several works propose to fine-tune only part of the model [30,31,44]. </li>
</ul>
</li>
</ul>
<p>논문에서 제안하는 것은 image data가 제대로 수집되지 않았을 때 외부 데이터셋이나 모델을 사용하지 않고 결쟁력있는 결과를 제공할 수 있을 뿐만 아니라 기존 전송 학습 방법과 직교한다는 것을 보여준다.</p>
<ul>
<li>Below, we show that our method not only produces competitive results without using external datasets or models but also is orthogonal to the existing transfer learning methods. </li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRFlqOukMAm5H9aJxZJ3M0DRN-kST79NJeffw&amp;usqp=CAU" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Figure 7: Style space interpolation of our method for low-shot generation without pre-training.</p>
<ul>
<li>The smooth interpolation results suggest little overfitting of our method even given small datasets.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>For DiffAugment, we adopt Color + Translation + Cutout for StyleGAN2, Color + Cutout for both the vanilla fine-tuning algorithm TransferGAN [45] and FreezeD [30] that freezes the first several layers of the discriminator.</p>
<p>Without any pre-training, we still achieve results on par with the existing transfer learning algorithms that require tens of thousands of images, with an exception on the 100-shot Obama dataset where pre-training with human faces clearly leads to better generalization.</p>
<p>tiny dataset에서는 과적합의 문제가 있을 수 있지만 figure7은 style space의 선형 보간법을 통한 방법의 과적합이 적다는 것을 보여줌.</p>
<ul>
<li>While there might be a concern that the generator is likely to overfit the tiny datasets (i.e., generating identical training images), Figure 7 suggests little overfitting of our method via linear interpolation in the style space [17]; please refer to the supplementary material for the nearest neighbor tests.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Analysis">
<a class="anchor" href="#Analysis" aria-hidden="true"><span class="octicon octicon-link"></span></a>Analysis<a class="anchor-link" href="#Analysis"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>smaller model 이나 stronger regularization이 비슷하게 과접합을 줄일 수 있는지.또 DiffAugment 가 여전히 도움이 되는지 보기</p>
<ul>
<li>Below, we investigate whether smaller model or stronger regularization would similarly reduce overfitting and whether DiffAugment still helps. </li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="https://d3i71xaburhd42.cloudfront.net/dac89790fb29d5ddac521927f2fdbabc6d6cf3ab/12-Figure10-1.png" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Figure 8: Analysis of smaller models or stronger regularization on CIFAR-10 with 10% training data.</p>
<ul>
<li>(a) Smaller models reduce overfitting for the BigGAN baseline, while our method dominates its performance at all model capacities. 작은 모델은 BigGAN 기준선에 대한 과적합을 줄이지만 모든 model capacities에서 성능이 지배적이다.</li>
<li>(b) Over a wide sweep of the R1 regularization γ for the baseline StyleGAN2, its best FID (26.87) is still much worse than ours (14.50). 기준선 StyleGAN2에 대해 R1 정규화의 wide sweep에 걸쳐, best FID는 논문에서 제시한 것보다 여전히 별로다.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Model Size Matters</strong></p>
<ul>
<li>G,D의 채널 수를 점진적으로 절반으로 즐임으로서 model capacity 줄임<ul>
<li>We reduce the model capacity of BigGAN by progressively halving the number of channels for both G and D.</li>
</ul>
</li>
<li>As plotted in Figure 8a, the baseline heavily overfits on CIFAR-10 with 10% training data when using the full model and achieves a minimum FID of 29.02 at 1/4 channels.</li>
<li>However, it is surpassed by our method over all model capacities. </li>
<li>4분의 1 채널로 논문의 모델은 21.57의 훨씬 더 나은 FID를 성취했지만, 그 차이는 모델이 커지게 될 수록 단조롭게 증가한다.<ul>
<li>With 1/4 channels, our model achieves a significantly better FID of 21.57, while the gap is monotonically increasing as the model becomes larger.</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Stronger Regularization Matters</strong></p>
<ul>
<li>StyleGAN2는 training을 안정화하기 위해 R1 정규화를 선택하고, 강도를 10에서 10의 4제곱까지 증가시킨다.<ul>
<li>As StyleGAN2 adopts the R1 regularization [27] to stabilize training, we increase its strength from γ = 0.1 to up to 104 and plot the FID curves in Figure 8b. </li>
</ul>
</li>
<li>While we initially find that γ = 0.1 works best under the 100% data setting, the choice of γ = 103 boosts its performance from 34.05 to 26.87 under the 10% data setting. </li>
<li>When γ = 104 , within 750k iterations, we only observe a minimum FID of 29.14 at 440k iteration and the performance deteriorates after that. </li>
<li>Figure 8 (b)로 미루어보아 논문에서 제시한 DiffAugment가 정규화하는 것에 비해 효과적이라는 것을 알 수 있음<ul>
<li>However, its best FID is still 1.8× worse than ours (with the default γ = 0.1). This shows that DiffAugment is more effective compared to explicitly regularizing the discriminator.</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="https://img-blog.csdnimg.cn/2596d75bcb594621a8fd45f36e8f0996.JPG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNzk1ODI3Mg==,size_16,color_FFFFFF,t_70" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Figure 9: Various types of DiffAugment consistently outperform the baseline. We report StyleGAN2’s FID on CIFAR-10 with 10% training data.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Choice of DiffAugment Matters</strong></p>
<p>We investigate additional choices of DiffAugment in Figure 9, including random 90◦ rotations ({−90◦ , 0 ◦ , 90◦} each with 1/3 probability), Gaussian noise (with a standard deviation of 0.1), and general geometry transformations that involve bilinear interpolation, such as bilinear translation (within [−0.25, 0.25]), bilinear scaling (within [0.75, 1.25]), bilinear rotation (within [−30◦ , 30◦]), and bilinear shearing (within [−0.25, 0.25]). While all these policies consistently outperform the baseline, <strong>we find that the Color + Translation + Cutout DiffAugment is especially effective</strong>. The simplicity also makes it easier to deploy.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Conclusion">
<a class="anchor" href="#Conclusion" aria-hidden="true"><span class="octicon octicon-link"></span></a>Conclusion<a class="anchor-link" href="#Conclusion"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>present DiffAugment for data-efficient GAN training. </li>
<li>DiffAugment reveals valuable observations that augmenting both real and fake samples effectively prevents the discriminator from over-fitting, and that the augmentation must be differentiable to enable both generator and discriminator training. </li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>


<span class="k">def</span> <span class="nf">DiffAugment</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">policy</span><span class="o">=</span><span class="s1">''</span><span class="p">,</span> <span class="n">channels_first</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">policy</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">channels_first</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">policy</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">','</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">AUGMENT_FNS</span><span class="p">[</span><span class="n">p</span><span class="p">]:</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">channels_first</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">x</span>


<span class="k">def</span> <span class="nf">rand_brightness</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">magnitude</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">([</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span> <span class="o">-</span> <span class="mf">0.5</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">magnitude</span>
    <span class="k">return</span> <span class="n">x</span>


<span class="k">def</span> <span class="nf">rand_saturation</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">magnitude</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">([</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span> <span class="o">*</span> <span class="mi">2</span>
    <span class="n">x_mean</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">x_mean</span><span class="p">)</span> <span class="o">*</span> <span class="n">magnitude</span> <span class="o">+</span> <span class="n">x_mean</span>
    <span class="k">return</span> <span class="n">x</span>


<span class="k">def</span> <span class="nf">rand_contrast</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">magnitude</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">([</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span> <span class="o">+</span> <span class="mf">0.5</span>
    <span class="n">x_mean</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">x_mean</span><span class="p">)</span> <span class="o">*</span> <span class="n">magnitude</span> <span class="o">+</span> <span class="n">x_mean</span>
    <span class="k">return</span> <span class="n">x</span>


<span class="k">def</span> <span class="nf">rand_translation</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">ratio</span><span class="o">=</span><span class="mf">0.125</span><span class="p">):</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">image_size</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">]</span>
    <span class="n">shift</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">image_size</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="o">*</span> <span class="n">ratio</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="n">translation_x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">([</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="o">-</span><span class="n">shift</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">shift</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="n">translation_y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">([</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="o">-</span><span class="n">shift</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">shift</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="n">grid_x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">clip_by_value</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">image_size</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="n">translation_x</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">image_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">grid_y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">clip_by_value</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">image_size</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="n">translation_y</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">image_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gather_nd</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]),</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">grid_x</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">batch_dims</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">gather_nd</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]),</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">grid_y</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">batch_dims</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">x</span>


<span class="k">def</span> <span class="nf">rand_cutout</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">ratio</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">image_size</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">]</span>
    <span class="n">cutout_size</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">image_size</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="o">*</span> <span class="n">ratio</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="n">offset_x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">([</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">maxval</span><span class="o">=</span><span class="n">image_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">cutout_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">%</span> <span class="mi">2</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="n">offset_y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">([</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">maxval</span><span class="o">=</span><span class="n">image_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">cutout_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">%</span> <span class="mi">2</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="n">grid_batch</span><span class="p">,</span> <span class="n">grid_x</span><span class="p">,</span> <span class="n">grid_y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">cutout_size</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">cutout_size</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span> <span class="n">indexing</span><span class="o">=</span><span class="s1">'ij'</span><span class="p">)</span>
    <span class="n">cutout_grid</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">grid_batch</span><span class="p">,</span> <span class="n">grid_x</span> <span class="o">+</span> <span class="n">offset_x</span> <span class="o">-</span> <span class="n">cutout_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">grid_y</span> <span class="o">+</span> <span class="n">offset_y</span> <span class="o">-</span> <span class="n">cutout_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">mask_shape</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">image_size</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">image_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
    <span class="n">cutout_grid</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">cutout_grid</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">cutout_grid</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">minimum</span><span class="p">(</span><span class="n">cutout_grid</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">mask_shape</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">]))</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">tf</span><span class="o">.</span><span class="n">scatter_nd</span><span class="p">(</span><span class="n">cutout_grid</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">cutout_size</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">cutout_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">mask_shape</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span>


<span class="n">AUGMENT_FNS</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">'color'</span><span class="p">:</span> <span class="p">[</span><span class="n">rand_brightness</span><span class="p">,</span> <span class="n">rand_saturation</span><span class="p">,</span> <span class="n">rand_contrast</span><span class="p">],</span>
    <span class="s1">'translation'</span><span class="p">:</span> <span class="p">[</span><span class="n">rand_translation</span><span class="p">],</span>
    <span class="s1">'cutout'</span><span class="p">:</span> <span class="p">[</span><span class="n">rand_cutout</span><span class="p">],</span>
<span class="p">}</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>


<span class="k">def</span> <span class="nf">DiffAugment</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">policy</span><span class="o">=</span><span class="s1">''</span><span class="p">,</span> <span class="n">channels_first</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">policy</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">channels_first</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">policy</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">','</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">AUGMENT_FNS</span><span class="p">[</span><span class="n">p</span><span class="p">]:</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">channels_first</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">x</span>


<span class="k">def</span> <span class="nf">rand_brightness</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span>


<span class="k">def</span> <span class="nf">rand_saturation</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">x_mean</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">x_mean</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="n">x_mean</span>
    <span class="k">return</span> <span class="n">x</span>


<span class="k">def</span> <span class="nf">rand_contrast</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">x_mean</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">x_mean</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">+</span> <span class="n">x_mean</span>
    <span class="k">return</span> <span class="n">x</span>


<span class="k">def</span> <span class="nf">rand_translation</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">ratio</span><span class="o">=</span><span class="mf">0.125</span><span class="p">):</span>
    <span class="n">shift_x</span><span class="p">,</span> <span class="n">shift_y</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">ratio</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">),</span> <span class="nb">int</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span> <span class="o">*</span> <span class="n">ratio</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">)</span>
    <span class="n">translation_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="o">-</span><span class="n">shift_x</span><span class="p">,</span> <span class="n">shift_x</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="n">translation_y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="o">-</span><span class="n">shift_y</span><span class="p">,</span> <span class="n">shift_y</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="n">grid_batch</span><span class="p">,</span> <span class="n">grid_x</span><span class="p">,</span> <span class="n">grid_y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="n">grid_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">grid_x</span> <span class="o">+</span> <span class="n">translation_x</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">grid_y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">grid_y</span> <span class="o">+</span> <span class="n">translation_y</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">x_pad</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x_pad</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()[</span><span class="n">grid_batch</span><span class="p">,</span> <span class="n">grid_x</span><span class="p">,</span> <span class="n">grid_y</span><span class="p">]</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">x</span>


<span class="k">def</span> <span class="nf">rand_cutout</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">ratio</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
    <span class="n">cutout_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">ratio</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">),</span> <span class="nb">int</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span> <span class="o">*</span> <span class="n">ratio</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">)</span>
    <span class="n">offset_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">cutout_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">%</span> <span class="mi">2</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="n">offset_y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">cutout_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">%</span> <span class="mi">2</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="n">grid_batch</span><span class="p">,</span> <span class="n">grid_x</span><span class="p">,</span> <span class="n">grid_y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">cutout_size</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">cutout_size</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="n">grid_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">grid_x</span> <span class="o">+</span> <span class="n">offset_x</span> <span class="o">-</span> <span class="n">cutout_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">grid_y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">grid_y</span> <span class="o">+</span> <span class="n">offset_y</span> <span class="o">-</span> <span class="n">cutout_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="n">mask</span><span class="p">[</span><span class="n">grid_batch</span><span class="p">,</span> <span class="n">grid_x</span><span class="p">,</span> <span class="n">grid_y</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span>


<span class="n">AUGMENT_FNS</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">'color'</span><span class="p">:</span> <span class="p">[</span><span class="n">rand_brightness</span><span class="p">,</span> <span class="n">rand_saturation</span><span class="p">,</span> <span class="n">rand_contrast</span><span class="p">],</span>
    <span class="s1">'translation'</span><span class="p">:</span> <span class="p">[</span><span class="n">rand_translation</span><span class="p">],</span>
    <span class="s1">'cutout'</span><span class="p">:</span> <span class="p">[</span><span class="n">rand_cutout</span><span class="p">],</span>
<span class="p">}</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">DiffAugment_tf</span> <span class="kn">import</span> <span class="n">DiffAugment</span>
<span class="n">policy</span> <span class="o">=</span> <span class="s1">'color,translation,cutout'</span> <span class="c1"># If your dataset is as small as ours (e.g.,</span>
<span class="c1"># hundreds of images), we recommend using the strongest Color + Translation + Cutout.</span>
<span class="c1"># For large datasets, try using a subset of transformations in ['color', 'translation', 'cutout'].</span>
<span class="c1"># Welcome to discover more DiffAugment transformations!</span>

<span class="o">...</span>
<span class="c1"># Training loop: update D</span>
<span class="n">reals</span> <span class="o">=</span> <span class="n">sample_real_images</span><span class="p">()</span> <span class="c1"># a batch of real images</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">sample_latent_vectors</span><span class="p">()</span>
<span class="n">fakes</span> <span class="o">=</span> <span class="n">Generator</span><span class="p">(</span><span class="n">z</span><span class="p">)</span> <span class="c1"># a batch of fake images</span>
<span class="n">real_scores</span> <span class="o">=</span> <span class="n">Discriminator</span><span class="p">(</span><span class="n">DiffAugment</span><span class="p">(</span><span class="n">reals</span><span class="p">,</span> <span class="n">policy</span><span class="o">=</span><span class="n">policy</span><span class="p">))</span>
<span class="n">fake_scores</span> <span class="o">=</span> <span class="n">Discriminator</span><span class="p">(</span><span class="n">DiffAugment</span><span class="p">(</span><span class="n">fakes</span><span class="p">,</span> <span class="n">policy</span><span class="o">=</span><span class="n">policy</span><span class="p">))</span>
<span class="c1"># Calculating D's loss based on real_scores and fake_scores...</span>
<span class="o">...</span>

<span class="o">...</span>
<span class="c1"># Training loop: update G</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">sample_latent_vectors</span><span class="p">()</span>
<span class="n">fakes</span> <span class="o">=</span> <span class="n">Generator</span><span class="p">(</span><span class="n">z</span><span class="p">)</span> <span class="c1"># a batch of fake images</span>
<span class="n">fake_scores</span> <span class="o">=</span> <span class="n">Discriminator</span><span class="p">(</span><span class="n">DiffAugment</span><span class="p">(</span><span class="n">fakes</span><span class="p">,</span> <span class="n">policy</span><span class="o">=</span><span class="n">policy</span><span class="p">))</span>
<span class="c1"># Calculating G's loss based on fake_scores...</span>
<span class="o">...</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

</div>



  </div><a class="u-url" href="/chch/gan/%EB%85%BC%EB%AC%B8%EB%A6%AC%EB%B7%B0/2022/02/02/Data-Efficient-GAN.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/chch/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/chch/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/chch/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>An easy to use blogging platform with support for Jupyter Notebooks.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/seoyeonc" target="_blank" title="seoyeonc"><svg class="svg-icon grey"><use xlink:href="/chch/assets/minima-social-icons.svg#github"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
