{
  
    
        "post0": {
            "title": "빅데이터 분석 (3주차) 9월28일",
            "content": "import torch import numpy as np . Data . - model: $y_i= w_0+w_1 x_i + epsilon_i = 2.5 + 4x_i + epsilon_i, quad i=1,2, dots,n$ . - model: ${ bf y}={ bf X}{ bf W} + boldsymbol{ epsilon}$ . ${ bf y}= begin{bmatrix} y_1 y_2 dots y_n end{bmatrix}, quad { bf X}= begin{bmatrix} 1 &amp; x_1 1 &amp; x_2 dots 1 &amp; x_n end{bmatrix}, quad { bf W}= begin{bmatrix} 2.5 4 end{bmatrix}, quad boldsymbol{ epsilon}= begin{bmatrix} epsilon_1 dots epsilon_n end{bmatrix}$ | . torch.manual_seed(202150754) n=100 ones=torch.ones(n) x,_=torch.randn(n).sort() X=torch.vstack([ones,x]).T W=torch.tensor([2.5,4]) ϵ=torch.randn(n)*0.4 y=X@W+ϵ ytrue = X@W . - 지난 시간에 했던 for문을 보고 step 찾기 . What= torch.tensor([-5.0,10.0],requires_grad=True) for epoc in range(30): Whats=Whats+[What.data.tolist()] What.grad=None yhat=X@What # yhat을 계산하는 공식을 알고 있거나, 과정이 필요 yhats=yhats+[yhat.data.tolist()] loss=torch.sum((y-yhat)**2) # loss정의하는 과정이 필요! losses = losses + [loss.item()] loss.backward() # 미분을 하는 과정이 필요 What.data = What.data-alpha * What.grad.data # 미분한 값을 가지고 업데이트를 하는 과정 . &#51060;&#51204;&#48169;&#48277;&#50836;&#50557; . - step1: yhat . - step2: loss . - step3: derivation . - step4: update . step1: yhat . - feedforward 신경망을 설계하는 과정(딥러닝 용어!) . 입력층으로 데이터가 입력되고, 1개 이상으로 구성되는 은닉 층을 거쳐서 마지막에 있는 출력 층으로 출력 값을 내보내는 과정. | 이전 틍에서 나온 출력 값이, 층과 층 사이에 적용되는 가중치 영향을 받은 다음 다음 층의 입력 값으로 들어가는 것 | . - 이 단계가 잘 완료되었다면, 임의의 ${ bf hat{W}}$을 넣었을 때 $ bf hat{y}$를 계산할 수 있어야 함 . &#48169;&#48277;1: &#51649;&#51217;&#49440;&#50616;_&#51649;&#51217; &#44273;&#54616;&#45716; &#44163; (&#45236;&#44032; &#44277;&#49885;&#51012; &#50508;&#44256; &#51080;&#50612;&#50556; &#54620;&#45796;) . - model: ${ bf y}={ bf X}{ bf W} + boldsymbol{ epsilon}$ . What=torch.tensor([-5.0,10.0],requires_grad=True) . yhat1=X@What . yhat1 . tensor([-27.9716, -26.0391, -25.8951, -24.1830, -23.6405, -23.1161, -22.0441, -21.9913, -21.4959, -21.2860, -20.4771, -19.6991, -19.1434, -18.0758, -17.5390, -17.4888, -16.8212, -16.6630, -16.2503, -14.3326, -13.8527, -13.6397, -13.5228, -13.2096, -12.8514, -12.8461, -12.7527, -12.2431, -12.0267, -11.7990, -11.6495, -11.5587, -11.5497, -11.1709, -10.9643, -10.7969, -10.7696, -10.7324, -10.6567, -10.4404, -10.1049, -9.9527, -9.7916, -9.3899, -9.2762, -8.2773, -8.0850, -7.9550, -7.8498, -7.7767, -7.6419, -7.2295, -7.1686, -6.9773, -6.9454, -6.6435, -5.6597, -5.5200, -5.4562, -5.3640, -4.9588, -4.9111, -4.5447, -3.9894, -3.6367, -3.0762, -2.4928, -2.4512, -2.1695, -2.0062, -1.7060, 0.1909, 0.5915, 0.9467, 1.3453, 1.4359, 2.0752, 2.4723, 2.5368, 2.7189, 2.7902, 2.8337, 3.2249, 3.7238, 3.8636, 3.9170, 3.9852, 5.0601, 5.7496, 6.0569, 7.0621, 7.2674, 7.6805, 7.9669, 8.4266, 9.6044, 9.6791, 10.7418, 12.6324, 18.9507], grad_fn=&lt;MvBackward0&gt;) . &#48169;&#48277;2: torch.nn.Linear() &#49324;&#50857;_&#50864;&#47532;&#44032; &#51452;&#47196; &#49324;&#50857;&#54624; &#48169;&#48277;_Neural Network . torch.nn.Linear? . Init signature: torch.nn.Linear( in_features: int, out_features: int, bias: bool = True, device=None, dtype=None, ) -&gt; None Docstring: Applies a linear transformation to the incoming data: :math:`y = xA^T + b` This module supports :ref:`TensorFloat32&lt;tf32_on_ampere&gt;`. Args: in_features: size of each input sample out_features: size of each output sample bias: If set to ``False``, the layer will not learn an additive bias. Default: ``True`` Shape: - Input: :math:`(*, H_{in})` where :math:`*` means any number of dimensions including none and :math:`H_{in} = text{in _features}`. - Output: :math:`(*, H_{out})` where all but the last dimension are the same shape as the input and :math:`H_{out} = text{out _features}`. Attributes: weight: the learnable weights of the module of shape :math:`( text{out _features}, text{in _features})`. The values are initialized from :math:` mathcal{U}(- sqrt{k}, sqrt{k})`, where :math:`k = frac{1}{ text{in _features}}` bias: the learnable bias of the module of shape :math:`( text{out _features})`. If :attr:`bias` is ``True``, the values are initialized from :math:` mathcal{U}(- sqrt{k}, sqrt{k})` where :math:`k = frac{1}{ text{in _features}}` Examples:: &gt;&gt;&gt; m = nn.Linear(20, 30) &gt;&gt;&gt; input = torch.randn(128, 20) &gt;&gt;&gt; output = m(input) &gt;&gt;&gt; print(output.size()) torch.Size([128, 30]) Init docstring: Initializes internal Module state, shared by both nn.Module and ScriptModule. File: ~/anaconda3/envs/csy/lib/python3.8/site-packages/torch/nn/modules/linear.py Type: type Subclasses: NonDynamicallyQuantizableLinear, LazyLinear, Linear, Linear . ${ bf y}= begin{bmatrix} y_1 y_2 dots y_n end{bmatrix}, quad { bf X}= begin{bmatrix} 1 &amp; x_1 1 &amp; x_2 dots 1 &amp; x_n end{bmatrix}, quad { bf W}= begin{bmatrix} 2.5 4 end{bmatrix}, quad boldsymbol{ epsilon}= begin{bmatrix} epsilon_1 dots epsilon_n end{bmatrix}$ | . net=torch.nn.Linear(in_features=2,out_features=1,bias=False) . Linear라는 클래스를 사용하여, in_features입력차원이자 $X(1,x_i)$라서 2, outfeatures출력차원이자 $y{hat}$라서 1 | bias가 False 인 이유는 $X(1,x_i)$에서 1이 bias의 역할을 하고 있기 때문에 필요가 없어서 | . net.weight.data # 우리가 원하는 입력값이 아니야 . tensor([[-0.2626, 0.1274]]) . net.weight.data=torch.tensor([[-5.0,10.0]]) . net.weight.data . tensor([[-5., 10.]]) . net(X) . tensor([[-27.9716], [-26.0391], [-25.8951], [-24.1830], [-23.6405], [-23.1161], [-22.0441], [-21.9913], [-21.4959], [-21.2860], [-20.4771], [-19.6991], [-19.1434], [-18.0758], [-17.5390], [-17.4888], [-16.8212], [-16.6630], [-16.2503], [-14.3326], [-13.8527], [-13.6397], [-13.5228], [-13.2096], [-12.8514], [-12.8461], [-12.7527], [-12.2431], [-12.0267], [-11.7990], [-11.6495], [-11.5587], [-11.5497], [-11.1709], [-10.9643], [-10.7969], [-10.7696], [-10.7324], [-10.6567], [-10.4404], [-10.1049], [ -9.9527], [ -9.7916], [ -9.3899], [ -9.2762], [ -8.2773], [ -8.0850], [ -7.9550], [ -7.8498], [ -7.7767], [ -7.6419], [ -7.2295], [ -7.1686], [ -6.9773], [ -6.9454], [ -6.6435], [ -5.6597], [ -5.5200], [ -5.4562], [ -5.3640], [ -4.9588], [ -4.9111], [ -4.5447], [ -3.9894], [ -3.6367], [ -3.0762], [ -2.4928], [ -2.4512], [ -2.1695], [ -2.0062], [ -1.7060], [ 0.1909], [ 0.5915], [ 0.9467], [ 1.3453], [ 1.4359], [ 2.0752], [ 2.4723], [ 2.5368], [ 2.7189], [ 2.7902], [ 2.8337], [ 3.2249], [ 3.7238], [ 3.8636], [ 3.9170], [ 3.9852], [ 5.0601], [ 5.7496], [ 6.0569], [ 7.0621], [ 7.2674], [ 7.6805], [ 7.9669], [ 8.4266], [ 9.6044], [ 9.6791], [ 10.7418], [ 12.6324], [ 18.9507]], grad_fn=&lt;MmBackward0&gt;) . yhat2=net(X) . 네트워크에 X를 입력으로 넣음으로써 y를 구하는 법 | . &#48169;&#48277;3: torch.nn.Linear()&#49324;&#50857;, bias=True . - model: $y_i= w_0+w_1 x_i + epsilon_i = 2.5 + 4x_i + epsilon_i, quad i=1,2, dots,n$ . net=torch.nn.Linear(in_features=1,out_features=1,bias=True) . Linear라는 클래스를 사용하여, in_features입력차원이자 $x_i$라서 1, outfeatures출력차원이자 $y{hat}$라서 1 | bias가 True 인 이유는 bias term상수항이 존재하는 네트워크라 정의했기 때문 | . net.weight.data # 입력차원을 1로 했기 때문에 출력차원 1개만 값이 나온 것. . tensor([[-0.8488]]) . net.weight.data=torch.tensor([[10.0]]) # tensor 괄호 수 따라가.. . net.bias.data=torch.tensor([-5.0]) . net.weight,net.bias . (Parameter containing: tensor([[10.]], requires_grad=True), Parameter containing: tensor([-5.], requires_grad=True)) . $X$가 아니라 $x(즉, x_i)$를 넣어애 함 | net(x.reshape(100,1)) x.reshape은 100값이 나오지만, (100,1)로 차원 명시 해주기 | . net(x.reshape(100,1)) . tensor([[-27.9716], [-26.0391], [-25.8951], [-24.1830], [-23.6405], [-23.1161], [-22.0441], [-21.9913], [-21.4959], [-21.2860], [-20.4771], [-19.6991], [-19.1434], [-18.0758], [-17.5390], [-17.4888], [-16.8212], [-16.6630], [-16.2503], [-14.3326], [-13.8527], [-13.6397], [-13.5228], [-13.2096], [-12.8514], [-12.8461], [-12.7527], [-12.2431], [-12.0267], [-11.7990], [-11.6495], [-11.5587], [-11.5497], [-11.1709], [-10.9643], [-10.7969], [-10.7696], [-10.7324], [-10.6567], [-10.4404], [-10.1049], [ -9.9527], [ -9.7916], [ -9.3899], [ -9.2762], [ -8.2773], [ -8.0850], [ -7.9550], [ -7.8498], [ -7.7767], [ -7.6419], [ -7.2295], [ -7.1686], [ -6.9773], [ -6.9454], [ -6.6435], [ -5.6597], [ -5.5200], [ -5.4562], [ -5.3640], [ -4.9588], [ -4.9111], [ -4.5447], [ -3.9894], [ -3.6367], [ -3.0762], [ -2.4928], [ -2.4512], [ -2.1695], [ -2.0062], [ -1.7060], [ 0.1909], [ 0.5915], [ 0.9467], [ 1.3453], [ 1.4359], [ 2.0752], [ 2.4723], [ 2.5368], [ 2.7189], [ 2.7902], [ 2.8337], [ 3.2249], [ 3.7238], [ 3.8636], [ 3.9170], [ 3.9852], [ 5.0601], [ 5.7496], [ 6.0569], [ 7.0621], [ 7.2674], [ 7.6805], [ 7.9669], [ 8.4266], [ 9.6044], [ 9.6791], [ 10.7418], [ 12.6324], [ 18.9507]], grad_fn=&lt;AddmmBackward0&gt;) . 방법 2와 3의 결과가 같아서 방법 3의 yhat은 따로 변수화하지 않음 | . step2: loss . &#48169;&#48277;1: &#49552;&#49892;&#54632;&#49688;&#47484; &#51649;&#51217;&#51221;&#51032;&#54616;&#45716; &#48169;&#48277; . loss=torch.mean((y-yhat1)**2) loss . tensor(109.8145, grad_fn=&lt;MeanBackward0&gt;) . loss=torch.mean((y-yhat2)**2) loss . tensor(187.0950, grad_fn=&lt;MeanBackward0&gt;) . 두 값이 다르기도 하고, 187.0950는 잘못된 결과 | grad_fn= 주의깊게 보기&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; (y-yhat2).shape . torch.Size([100, 100]) . y.shape . torch.Size([100]) . yhat2.shape . torch.Size([100, 1]) . 차원에 대한 개념 파악 너무 중요 | . torch.mean((y-yhat2.flatten())**2) # yhat2를 벡터화시키는 방법 1 . tensor(109.8145, grad_fn=&lt;MeanBackward0&gt;) . loss=torch.mean((y.reshape(100,1)-yhat2)**2) # y의 dhape을 바꿔주는 방법 2 loss . tensor(109.8145, grad_fn=&lt;MeanBackward0&gt;) . &#48169;&#48277;2: torch.nn.MSELoss()&#47484; &#49324;&#50857;&#54616;&#50668; &#49552;&#49892;&#54632;&#49688;&#47484; &#51221;&#51032;&#54616;&#45716; &#48169;&#48277; . torch.nn.MSELoss? . Init signature: torch.nn.MSELoss(size_average=None, reduce=None, reduction: str = &#39;mean&#39;) -&gt; None Docstring: Creates a criterion that measures the mean squared error (squared L2 norm) between each element in the input :math:`x` and target :math:`y`. The unreduced (i.e. with :attr:`reduction` set to ``&#39;none&#39;``) loss can be described as: .. math:: ell(x, y) = L = {l_1, dots,l_N }^ top, quad l_n = left( x_n - y_n right)^2, where :math:`N` is the batch size. If :attr:`reduction` is not ``&#39;none&#39;`` (default ``&#39;mean&#39;``), then: .. math:: ell(x, y) = begin{cases} operatorname{mean}(L), &amp; text{if reduction} = text{`mean&#39;;} operatorname{sum}(L), &amp; text{if reduction} = text{`sum&#39;.} end{cases} :math:`x` and :math:`y` are tensors of arbitrary shapes with a total of :math:`n` elements each. The mean operation still operates over all the elements, and divides by :math:`n`. The division by :math:`n` can be avoided if one sets ``reduction = &#39;sum&#39;``. Args: size_average (bool, optional): Deprecated (see :attr:`reduction`). By default, the losses are averaged over each loss element in the batch. Note that for some losses, there are multiple elements per sample. If the field :attr:`size_average` is set to ``False``, the losses are instead summed for each minibatch. Ignored when :attr:`reduce` is ``False``. Default: ``True`` reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the losses are averaged or summed over observations for each minibatch depending on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per batch element instead and ignores :attr:`size_average`. Default: ``True`` reduction (string, optional): Specifies the reduction to apply to the output: ``&#39;none&#39;`` | ``&#39;mean&#39;`` | ``&#39;sum&#39;``. ``&#39;none&#39;``: no reduction will be applied, ``&#39;mean&#39;``: the sum of the output will be divided by the number of elements in the output, ``&#39;sum&#39;``: the output will be summed. Note: :attr:`size_average` and :attr:`reduce` are in the process of being deprecated, and in the meantime, specifying either of those two args will override :attr:`reduction`. Default: ``&#39;mean&#39;`` Shape: - Input: :math:`(*)`, where :math:`*` means any number of dimensions. - Target: :math:`(*)`, same shape as the input. Examples:: &gt;&gt;&gt; loss = nn.MSELoss() &gt;&gt;&gt; input = torch.randn(3, 5, requires_grad=True) &gt;&gt;&gt; target = torch.randn(3, 5) &gt;&gt;&gt; output = loss(input, target) &gt;&gt;&gt; output.backward() Init docstring: Initializes internal Module state, shared by both nn.Module and ScriptModule. File: ~/anaconda3/envs/csy/lib/python3.8/site-packages/torch/nn/modules/loss.py Type: type Subclasses: . lossfn=torch.nn.MSELoss() # 단지 입력만하면 loss funxtion이 만들어짐 . loss=lossfn(y,yhat1) loss . tensor(109.8145, grad_fn=&lt;MseLossBackward0&gt;) . loss=lossfn(y.reshape(100,1),yhat2) loss . tensor(109.8145, grad_fn=&lt;MseLossBackward0&gt;) . 미분 꼬리표 붙은 모습! grad_fn=&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; 총 6가지 조합으로 loss를 구할 수 있다. | . &#49689;&#51228; . - model: $y_i= w_0+w_1 x_{i1}+w_2 x_{i2} + epsilon_i = 2.5 + 4x_{1i} + -2x_{2i}+ epsilon_i, quad i=1,2, dots,n$ . torch.manual_seed(202150754) n=100 ones=torch.ones(n) x1,_=torch.randn(n).sort() x2,_=torch.randn(n).sort() X=torch.vstack([ones,x1,x2]).T W=torch.tensor([2.5,4.0,-2.0]) ϵ=torch.randn(n)*0.5 y=X@W+ϵ ytrue=X@W . net=torch.nn.Linear(in_features=3,out_features=1,bias=False) . net.weight.data . tensor([[0.1152, 0.4159, 0.3233]]) . net.weight.data=torch.tensor([[2.5,5.0,-2.0]]) . net.weight.data . tensor([[ 2.5000, 5.0000, -2.0000]]) . net(X) . tensor([[-2.6509], [-3.6075], [-3.5596], [-3.1381], [-3.3609], [-3.4499], [-3.2561], [-3.2889], [-3.2011], [-3.1503], [-2.7970], [-2.5058], [-2.3969], [-1.9746], [-1.7134], [-1.6971], [-1.4055], [-1.5425], [-1.4787], [-0.5325], [-0.5519], [-0.4983], [-0.5579], [-0.4252], [-0.3783], [-0.3975], [-0.4601], [-0.3162], [-0.2366], [-0.1835], [-0.1374], [-0.1168], [-0.1915], [-0.2164], [-0.1212], [-0.0441], [-0.0724], [-0.0834], [-0.0505], [-0.0193], [ 0.1136], [ 0.1171], [ 0.1026], [ 0.2901], [ 0.2309], [ 0.7120], [ 0.7832], [ 0.8135], [ 0.7912], [ 0.7812], [ 0.8180], [ 0.9363], [ 0.9441], [ 1.0259], [ 1.0002], [ 1.0770], [ 1.4815], [ 1.3693], [ 1.3779], [ 1.4225], [ 1.6098], [ 1.5941], [ 1.7537], [ 2.0001], [ 2.0957], [ 2.3735], [ 2.6115], [ 2.6187], [ 2.7009], [ 2.7603], [ 2.8919], [ 3.7759], [ 3.9732], [ 4.0655], [ 4.2620], [ 4.2635], [ 4.4946], [ 4.6567], [ 4.6651], [ 4.7379], [ 4.7674], [ 4.6795], [ 4.8486], [ 5.0364], [ 5.0838], [ 5.0771], [ 5.0922], [ 5.5662], [ 5.8656], [ 5.8907], [ 6.3554], [ 6.4389], [ 6.4179], [ 6.2463], [ 6.2930], [ 6.6489], [ 6.0923], [ 6.1693], [ 6.9698], [ 9.9439]], grad_fn=&lt;MmBackward0&gt;) . yhat=net(X) . lossfn=torch.nn.MSELoss() . loss=lossfn(y,yhat) . /home/cgb4/anaconda3/envs/csy/lib/python3.8/site-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([100, 1])) that is different to the input size (torch.Size([100])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size. return F.mse_loss(input, target, reduction=self.reduction) . loss . tensor(14.1640, grad_fn=&lt;MseLossBackward0&gt;) . &lt;/div&gt; | . | .",
            "url": "https://seoyeonc.github.io/chch/2021/11/19/_bd_3%EC%A3%BC%EC%B0%A8.html",
            "relUrl": "/2021/11/19/_bd_3%EC%A3%BC%EC%B0%A8.html",
            "date": " • Nov 19, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "빅데이터 분석 (2주차) 9월14일, 9월16일",
            "content": "&#54028;&#51060;&#53664;&#52824;&#47484; &#51060;&#50857;&#54616;&#50668; &#54924;&#44480;&#47784;&#54805; &#54617;&#49845;&#54616;&#44592; . - (1/5) 회귀모형 소개, 손실 함수 . - (2/5) 경사하강법, 경사하강법을 이용하여 회귀계수 1회 업데이트 . - (3/5) 회귀계수 반복 업데이트 . - (4/5) 학습률 . - (5/5) 사과영상 . import torch import numpy as np import matplotlib.pyplot as plt . 로드맵 . 회귀분석 $ to$ 로지스틱 $ to$ 심층신경망(DNN) $ to$ 합성곱신경망(CNN) | . - model: $y_i= w_0+w_1 x_i + epsilon_i = 2.5 + 4x_i + epsilon_i, quad i=1,2, dots,n$ . w라는 로테이션을 많이 사용하는 딥러닝 | . - model: ${ bf y}={ bf X}{ bf W} + boldsymbol{ epsilon}$ . ${ bf y}= begin{bmatrix} y_1 y_2 dots y_n end{bmatrix}, quad { bf X}= begin{bmatrix} 1 &amp; x_1 1 &amp; x_2 dots 1 &amp; x_n end{bmatrix}, quad { bf W}= begin{bmatrix} 2.5 4 end{bmatrix}, quad boldsymbol{ epsilon}= begin{bmatrix} epsilon_1 dots epsilon_n end{bmatrix}$ | . torch.manual_seed(202150754) n=100 ones=torch.ones(n) x,_ = torch.randn(n).sort() # 배열하면 tendor,index가 반환됨. 필요한 x만 반환 X = torch.vstack([ones,x]).T W = torch.tensor([2.5,4]) ϵ = torch.randn(n)*0.5 y = X@W + ϵ #@는 벡터를 곱하라는 뜻..! ytrue = X@W # 우리가 알고 싶은 것은 평균 직선 . plt.plot(x,y,&#39;o&#39;) #우리가 관측한 값 plt.plot(x,ytrue,&#39;--&#39;) # 우리가 추론하고 싶은 값 . [&lt;matplotlib.lines.Line2D at 0x7f14326a1f10&gt;] . &#54617;&#49845; . - 파란점만 주어졌을때, 주황색 점선을 추론하는것. . - 좀 더 정확하게 말하면 given data로 $ begin{bmatrix} hat{w}_0 hat{w}_1 end{bmatrix}$를 최대한 $ begin{bmatrix} 2.5 4 end{bmatrix}$와 비슷하게 찾는것. (2.5와 4는 true의 값) . given data : $ big {(x_i,y_i) big }_{i=1}^{n}$ . | parameter: ${ bf W}= begin{bmatrix} w_0 w_1 end{bmatrix}$ . | estimated parameter: ${ bf hat{W}}= begin{bmatrix} hat{w}_0 hat{w}_1 end{bmatrix}$ . | . plt.plot(x,y,&#39;o&#39;) # 그림을 보고 &#39;적당한&#39; 추세를 찾는 과정 . [&lt;matplotlib.lines.Line2D at 0x7f1432614970&gt;] . - 시도: $( hat{w}_0, hat{w}_1)=(-5,10)$을 선택하여 선을 그려보고 적당한지 판단. . $ hat{y}_i=-5 +10 x_i$ 와 같이 $y_i$의 값을 적합시키겠다는 의미 | . plt.plot(x,y,&#39;o&#39;) plt.plot(x,-5+10*x,&#39;--&#39;) # 그림을 보고 판단해보는 단계 . [&lt;matplotlib.lines.Line2D at 0x7f14325f38b0&gt;] . - 벡터 표현으로주황색 추세선을 계산 . What = torch.tensor([-5.0,10.0]) # float으로 선언해야 함!!! plt.plot(x,y,&#39;o&#39;) plt.plot(x,X@What,&#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f1432546c10&gt;] . &#54028;&#46972;&#48120;&#53552;&#47484; &#54617;&#49845;&#54616;&#45716; &#48169;&#48277;, &#51593; &#51201;&#45817;&#54620; &#49440;&#50640; &#47582;&#52656;&#44032;&#45716; &#44284;&#51221; . - 이론적으로 추론 (회귀 분석) . - 컴퓨터의 반복계산을 이용하여 추론(경사하강법) . (1) initial value: 임의의 선을 그어봄 . What = torch.tensor([-5.0,10.0],requires_grad=True) What . tensor([-5., 10.], requires_grad=True) . 처음에는 ${ bf hat{W}}= begin{bmatrix} hat{w}_0 hat{w}_1 end{bmatrix}= begin{bmatrix} -5 10 end{bmatrix} $ 를 대입해서 주황색 점선을 적당히 그려보자는 의미 . | 끝에 requires_grad=True는 나중에 미분에 사용되기 위함. . | . yhat=X@What # yhat을 구하면 단지 X(미분X)*What(미분O) = 미분 옵션이 있는 텐션이 되어버린다. yhat.data # 미분 옵션이 사라짐. . tensor([-27.9716, -26.0391, -25.8951, -24.1830, -23.6405, -23.1161, -22.0441, -21.9913, -21.4959, -21.2860, -20.4771, -19.6991, -19.1434, -18.0758, -17.5390, -17.4888, -16.8212, -16.6630, -16.2503, -14.3326, -13.8527, -13.6397, -13.5228, -13.2096, -12.8514, -12.8461, -12.7527, -12.2431, -12.0267, -11.7990, -11.6495, -11.5587, -11.5497, -11.1709, -10.9643, -10.7969, -10.7696, -10.7324, -10.6567, -10.4404, -10.1049, -9.9527, -9.7916, -9.3899, -9.2762, -8.2773, -8.0850, -7.9550, -7.8498, -7.7767, -7.6419, -7.2295, -7.1686, -6.9773, -6.9454, -6.6435, -5.6597, -5.5200, -5.4562, -5.3640, -4.9588, -4.9111, -4.5447, -3.9894, -3.6367, -3.0762, -2.4928, -2.4512, -2.1695, -2.0062, -1.7060, 0.1909, 0.5915, 0.9467, 1.3453, 1.4359, 2.0752, 2.4723, 2.5368, 2.7189, 2.7902, 2.8337, 3.2249, 3.7238, 3.8636, 3.9170, 3.9852, 5.0601, 5.7496, 6.0569, 7.0621, 7.2674, 7.6805, 7.9669, 8.4266, 9.6044, 9.6791, 10.7418, 12.6324, 18.9507]) . plt.plot(x,y,&#39;o&#39;) plt.plot(x,yhat.data,&#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f143277e040&gt;] . (2) 첫 번째 수정: 추세선의 적당한 정도를 판단하여 적당한 선으로 업데이트 . - &#39;적당한 정도&#39;를 판단하기 위하 장치로서 loss function 도입 . $loss= sum_{i=1}^{n}(y_i- hat{y}_i)^2= sum_{i=1}^{n}(y_i-( hat{w}_0+ hat{w}_1x_i))^2$ . $=({ bf y}-{ bf hat{y}})^ top({ bf y}-{ bf hat{y}})=({ bf y}-{ bf X}{ bf hat{W}})^ top({ bf y}-{ bf X}{ bf hat{W}})$ . 구현하기 편하게 하기 위해 벡터로 구현 . - loss 함수의 특징 . $y_i approx hat{y}_i$ 일수록 loss값이 작다. | $y_i approx hat{y}_i$ 이 되도록 $( hat{w}_0, hat{w}_1)$을 잘 찍으면 loss값이 작다. | (중요) 주황색 점선이 적당할수록 loss값이 작다. | . loss = torch.sum((y-yhat)**2) # = (y-yhat)@(y-yhat) loss . tensor(11003.1260, grad_fn=&lt;SumBackward0&gt;) . - $loss(=11003.1260)$을 줄이는, 혹은 없애는 것이 목표 $ to$ 아예 모든 조합 $( hat{w}_0, hat{w}_1)$에 대하여 가장 작은 $loss$ 찾기 . - 문제의 치환 . 적당해 보이는 주황색 선을 찾자 $ to$ $loss(w_0,w_1)$을 최소로 하는 $(w_0,w_1$의 값을 찾기 | . - $loss(w_0,w_1)$를 최소로 하는 $(w_0,w_1)$ 구하는 것으로 수정된 목표 . 단순한 수학문제가 되었다. 마치 $loss(w)=w^2-2w+3$ 을 최소화하는 $w$를 찾으라는 것과 같음. | . - 경사하강법, 벡터미분 사용! . &#44221;&#49324;&#54616;&#44053;&#48277; . 경사하강법 아이디어(1차원) . (step 1) 임의의 점을 찍는다. . (step 2) 그 점에서 순간기울기를 구한다. (접선) &lt;-- 미분 . (step 3) 순간기울기(= 미분계수)의 부호를 살펴보고 부호와 반대방향으로 움직인다. (순간기울기와 같은 방향으로 움직이면 점점 커질테니까.) . (Tip) 기울기의 절대값 크기와 비례하여 보폭(= 움직이는 정도)을 조절한다. . 경사하강법 아이디어(2차원) . (step 1) 임의의 점을 찍는다. . (step 2) 그 점에서 순간기울기를 구한다. (접평면) &lt;-- 편미분 . (step 3) 순간기울기(= 여러개의 미분계수)의 부호를 살펴보고 부호와 반대방향으로 각각 움직인다. (순간기울기와 같은 방향으로 움직이면 점점 커질테니까.) . (Tip) 기울기의 절대값 크기와 비례하여 보폭(= 움직이는 정도)을 각각 조절한다. . loss를 줄이도록 $W$를 개선하는 방법 . - $수정값 leftarrow 원래값 - 기울어진 크기(= 미분계수) times alpha$ . 여기에서 $ alpha$는 전체적인 보폭의 크기를 결정한다. 즉, $ alpha$값이 클수록 한 번의 update에 움직이는 양이 크다. | . - ${ bf W} leftarrow { bf W} - alpha times frac{ partial}{ partial { bf W}}loss(w_0,w_1)$ . 마이너스의 의미 기울기의 부호를 보고 반대방향으로 움직여라 . | $ frac{ partial}{ partial { bf W}}loss(w_0,w_1):$ 기울기의 절대값 크기와 비례하여 움직이는 정도를 조정하라. (속도의 조절) . | $ alpha$의 의미: 전체적인 보폭의 속도를 조절, $ alpha$가 크면 전체적으로 빠르게 움직인다. 다리의 길이로 비유할 수 있다. . | . . - 목표: $loss(=11003.1260)$ 값을 줄이는 것. . - 방법: 경사하강법 . - 경사하강법으로 loss를 줄이기 위해서는 $ frac{ partial}{ partial { bf W}}loss(w_0,w_1)$의 계산이 필요한데, 이를 위해서 벡터미분이 필요하다. . requires_grad=True를 가진 텐서로 미분. | . loss=torch.sum((y-yhat)**2)= torch.sum((y-X@What)**2) # 이었고 What=torch.tensor([-5.0,10.0],requires_grad=True) # 이므로 결국 What으로 미분하라는 의미. # 미분한 식이 나오는 것이 아니고, # 그 식에 (-5.0, 10.0)을 대입한 계수값이 계산됨. . loss.backward() # requires_grad=True를 가진 텐서로 미분하라는 의미 # 단지 미분 계수가 계산되어 있음 # 정확하게 말하면 미분을 활용하여 $(-5,10)$에서의 순간기울기를 구했다는 의미임. . What.grad.data . tensor([-1730.4250, 1485.8135]) . 이것이 의미하는 건 $(-5,10)$에서의 순간기울기가 $([-1730.4250, 1485.8135])$ 이라는 의미 (각각 (양수, 음수)로 움직여야 함) | . - 직접 계산하여 검증 . $loss(w_0,w_1)=(y- hat{y})^ top (y- hat{y})=(y-XW)^ top (y-XW)$ . | $ frac{ partial}{ partial W}loss(w_0,w_1)=-2X^ top y+2X^ top X W$ . | . -2 * X.T @ y + 2 * X.T @ X @ What # = What.grad.data . tensor([-1730.4250, 1485.8135], grad_fn=&lt;AddBackward0&gt;) . alpha=0.001 print(&#39;수정 전: &#39; + str(What.data)) # 미분 옵션 없애기! print(&#39;수정하는 폭: &#39; + str(-alpha*What.grad.data)) print(&#39;수정 후: &#39; + str(What.data-alpha*What.grad.data)) print(&#39;*참값: (2.5,4)&#39;) . 수정 전: tensor([-5., 10.]) 수정하는 폭: tensor([ 1.7304, -1.4858]) 수정 후: tensor([-3.2696, 8.5142]) *참값: (2.5,4) . Wbefore = What.data Wafter = What.data-alpha*What.grad.data Wbefore, Wafter . (tensor([-5., 10.]), tensor([-3.2696, 8.5142])) . plt.plot(x,y,&#39;o&#39;) plt.plot(x,X@Wbefore,&#39;--b&#39;) # 수정 전 파란 점선 plt.plot(x,X@Wafter,&#39;--r&#39;) # 수정 후 빨간 점선 plt.title(&quot;before: blue // after: red&quot;) . Text(0.5, 1.0, &#39;before: blue // after: red&#39;) . (3) Learn (=estimate $ bf hat{W})$: . What= torch.tensor([-5.0,10.0],requires_grad=True) . alpha=0.001 for epoc in range(30): What.grad=None yhat=X@What loss=torch.sum((y-yhat)**2) loss.backward() # What으로 미분하는 과정 What.data = What.data-alpha * What.grad.data # 적정한 선으로 Update! . What.data # true 값은 2.5,4 . tensor([2.5248, 3.9898]) . plt.plot(x,y,&#39;o&#39;) plt.plot(x,(X@What.data),&#39;--&#39;) # 순수 데이터만 뽑기 위해 .data꼭 붙이기 plt.plot(x,(X@np.array([2.5,4])),&#39;-&#39;) # 거의 비슷해서 한 선으로 보임 . [&lt;matplotlib.lines.Line2D at 0x7f14329ed7f0&gt;] . &#54028;&#46972;&#47700;&#53552;&#51032; &#49688;&#51221; &#44284;&#51221;&#51012; &#44288;&#52272;&#54624; &#49688; &#50630;&#45208;.(&#54617;&#49845;&#44284;&#51221; &#47784;&#45768;&#53552;&#47553;) . - 기록 해보기 . losses=[] # 기록하고 싶은 것 1 yhats = [] # 기록하고 싶은 것 2 Whats = [] # 기록하고 싶은 것 3 . What= torch.tensor([-5.0,10.0],requires_grad=True) alpha=0.001 for epoc in range(30): Whats=Whats+[What.data.tolist()] # What을 list화 해서 저장 What.grad=None yhat=X@What yhats=yhats+[yhat.data.tolist()] loss=torch.sum((y-yhat)**2) losses=losses+[loss.item()] loss.backward() # What으로 미분하는 과정 What.data = What.data-alpha * What.grad.data # 적정한 선으로 Update! . - $ hat{y}$ 관찰 . plt.plot(x,y,&#39;o&#39;) plt.plot(x,yhats[5],&#39;--&#39;) # 5번 업데이트된 추세선 . [&lt;matplotlib.lines.Line2D at 0x7f14324f35b0&gt;] . plt.plot(x,y,&#39;o&#39;) plt.plot(x,yhats[10],&#39;--&#39;) # 10번 업데이트된 추세선 . [&lt;matplotlib.lines.Line2D at 0x7f143244d340&gt;] . - $ hat{ bf{W}}$ . losses . [11003.1259765625, 6417.849609375, 3748.93798828125, 2195.045166015625, 1290.041015625, 762.7489624023438, 455.38189697265625, 276.1114196777344, 171.48153686523438, 110.3656005859375, 74.63228607177734, 53.71556854248047, 41.45503234863281, 34.25670623779297, 30.02236557006836, 27.52593421936035, 26.050209045410156, 25.175155639648438, 24.654428482055664, 24.34327507019043, 24.156478881835938, 24.043743133544922, 23.975299835205078, 23.93347930908203, 23.907733917236328, 23.891769409179688, 23.881786346435547, 23.8754940032959, 23.871488571166992, 23.868919372558594] . plt.plot(losses) . [&lt;matplotlib.lines.Line2D at 0x7f14324200d0&gt;] . Animation . plt.rcParams[&#39;figure.figsize&#39;] = (10,4) # 크기 plt.rcParams[&quot;animation.html&quot;] = &quot;jshtml&quot; # 애니메이션 나오게 하는 옵션 . from matplotlib import animation fig = plt.figure() ax1 = fig.add_subplot(1, 2, 1) ax2 = fig.add_subplot(1, 2, 2, projection=&#39;3d&#39;) ## ax1: 왼쪽그림 ax1.plot(x,y,&#39;o&#39;) line, = ax1.plot(x,yhats[0]) ## ax2: 오른쪽그림 _w0 = np.arange(-6, 11, 0.5) ## 파란색곡면을 그리는 코드 (시작) _w1 = np.arange(-6, 11, 0.5) w1,w0 = np.meshgrid(_w1,_w0) l=w0*0 for i in range(len(_w0)): for j in range(len(_w1)): l[i,j]=torch.sum((y-_w0[i]-_w1[j]*x)**2) ax2.plot_surface(w0, w1, l, rstride=1, cstride=1, color=&#39;b&#39;,alpha=0.35) ## 파란색곡면을 그리는 코드(끝) ax2.scatter(2.5,4,torch.sum((y-2.5-4*x)**2),s=200,color=&#39;red&#39;,marker=&#39;*&#39;) ## 최소점을 표시하는 코드 (붉은색 별) ax2.scatter(np.array(Whats)[0,0],np.array(Whats)[0,1],losses[0],color=&#39;b&#39;) ## 업데이트되는 What을 표시하는 점 (파란색 동그라미) ax2.azim = 40 ## 3d plot의 view 조절 ax2.dist = 8 ## 3d plot의 view 조절 ax2.elev = 5 ## 3d plot의 view 조절 def animate(epoc): line.set_ydata(yhats[epoc]) ax2.scatter(np.array(Whats)[epoc,0],np.array(Whats)[epoc,1],losses[epoc],color=&#39;grey&#39;) return line ani = animation.FuncAnimation(fig, animate, frames=30) plt.close() ani . . &lt;/input&gt; Once Loop Reflect $ alpha$&#50640; &#45824;&#54616;&#50668; ($ alpha$&#45716; &#54617;&#49845;&#47456;) . (1) $ alpha$가 너무 작다면?$ to$ 비효율적이다. . losses = [] # 기록하고 싶은것 1 yhats = [] # 기록하고 싶은것 2 Whats = [] # 기록하고 싶은것 3 . . alpha=0.0001 What= torch.tensor([-5.0,10.0],requires_grad=True) for epoc in range(30): Whats=Whats+[What.data.tolist()] What.grad=None yhat=X@What yhats=yhats+[yhat.data.tolist()] loss=torch.sum((y-yhat)**2) losses = losses + [loss.item()] loss.backward() What.data = What.data-alpha * What.grad.data . . fig = plt.figure() ax1 = fig.add_subplot(1, 2, 1) ax2 = fig.add_subplot(1, 2, 2, projection=&#39;3d&#39;) ## ax1: 왼쪽그림 ax1.plot(x,y,&#39;o&#39;) line, = ax1.plot(x,yhats[0]) ## ax2: 오른쪽그림 _w0 = np.arange(-6, 11, 0.5) ## 파란색곡면을 그리는 코드 (시작) _w1 = np.arange(-6, 11, 0.5) w1,w0 = np.meshgrid(_w1,_w0) l=w0*0 for i in range(len(_w0)): for j in range(len(_w1)): l[i,j]=torch.sum((y-_w0[i]-_w1[j]*x)**2) ax2.plot_surface(w0, w1, l, rstride=1, cstride=1, color=&#39;b&#39;,alpha=0.35) ## 파란색곡면을 그리는 코드(끝) ax2.scatter(2.5,4,torch.sum((y-2.5-4*x)**2),s=200,color=&#39;red&#39;,marker=&#39;*&#39;) ## 최소점을 표시하는 코드 (붉은색 별) ax2.scatter(np.array(Whats)[0,0],np.array(Whats)[0,1],losses[0],color=&#39;b&#39;) ## 업데이트되는 What을 표시하는 점 (파란색 동그라미) ax2.azim = 40 ## 3d plot의 view 조절 ax2.dist = 8 ## 3d plot의 view 조절 ax2.elev = 5 ## 3d plot의 view 조절 def animate(epoc): line.set_ydata(yhats[epoc]) ax2.scatter(np.array(Whats)[epoc,0],np.array(Whats)[epoc,1],losses[epoc],color=&#39;grey&#39;) return line ani = animation.FuncAnimation(fig, animate, frames=30) plt.close() ani . . &lt;/input&gt; Once Loop Reflect (1) $ alpha$가 너무 크다면? $ to$ 다른의미에서 비효율적이다 + 위험하다.. . losses = [] # 기록하고 싶은것 1 yhats = [] # 기록하고 싶은것 2 Whats = [] # 기록하고 싶은것 3 . . alpha=0.0083 What= torch.tensor([-5.0,10.0],requires_grad=True) for epoc in range(30): Whats=Whats+[What.data.tolist()] What.grad=None yhat=X@What yhats=yhats+[yhat.data.tolist()] loss=torch.sum((y-yhat)**2) losses = losses + [loss.item()] loss.backward() What.data = What.data-alpha * What.grad.data . . fig = plt.figure() ax1 = fig.add_subplot(1, 2, 1) ax2 = fig.add_subplot(1, 2, 2, projection=&#39;3d&#39;) ## ax1: 왼쪽그림 ax1.plot(x,y,&#39;o&#39;) line, = ax1.plot(x,yhats[0]) ## ax2: 오른쪽그림 _w0 = np.arange(-6, 11, 0.5) ## 파란색곡면을 그리는 코드 (시작) _w1 = np.arange(-6, 11, 0.5) w1,w0 = np.meshgrid(_w1,_w0) l=w0*0 for i in range(len(_w0)): for j in range(len(_w1)): l[i,j]=torch.sum((y-_w0[i]-_w1[j]*x)**2) ax2.plot_surface(w0, w1, l, rstride=1, cstride=1, color=&#39;b&#39;,alpha=0.35) ## 파란색곡면을 그리는 코드(끝) ax2.scatter(2.5,4,torch.sum((y-2.5-4*x)**2),s=200,color=&#39;red&#39;,marker=&#39;*&#39;) ## 최소점을 표시하는 코드 (붉은색 별) ax2.scatter(np.array(Whats)[0,0],np.array(Whats)[0,1],losses[0],color=&#39;b&#39;) ## 업데이트되는 What을 표시하는 점 (파란색 동그라미) ax2.azim = 40 ## 3d plot의 view 조절 ax2.dist = 8 ## 3d plot의 view 조절 ax2.elev = 5 ## 3d plot의 view 조절 def animate(epoc): line.set_ydata(yhats[epoc]) ax2.scatter(np.array(Whats)[epoc,0],np.array(Whats)[epoc,1],losses[epoc],color=&#39;grey&#39;) return line ani = animation.FuncAnimation(fig, animate, frames=30) plt.close() ani . . &lt;/input&gt; Once Loop Reflect (3) $ alpha=0.0085$ 아예 모형을 벗어나버린다. . losses = [] # 기록하고 싶은것 1 yhats = [] # 기록하고 싶은것 2 Whats = [] # 기록하고 싶은것 3 . . alpha=0.0085 What= torch.tensor([-5.0,10.0],requires_grad=True) for epoc in range(30): Whats=Whats+[What.data.tolist()] What.grad=None yhat=X@What yhats=yhats+[yhat.data.tolist()] loss=torch.sum((y-yhat)**2) losses = losses + [loss.item()] loss.backward() What.data = What.data-alpha * What.grad.data . . fig = plt.figure() ax1 = fig.add_subplot(1, 2, 1) ax2 = fig.add_subplot(1, 2, 2, projection=&#39;3d&#39;) ## ax1: 왼쪽그림 ax1.plot(x,y,&#39;o&#39;) line, = ax1.plot(x,yhats[0]) ## ax2: 오른쪽그림 _w0 = np.arange(-6, 11, 0.5) ## 파란색곡면을 그리는 코드 (시작) _w1 = np.arange(-6, 11, 0.5) w1,w0 = np.meshgrid(_w1,_w0) l=w0*0 for i in range(len(_w0)): for j in range(len(_w1)): l[i,j]=torch.sum((y-_w0[i]-_w1[j]*x)**2) ax2.plot_surface(w0, w1, l, rstride=1, cstride=1, color=&#39;b&#39;,alpha=0.35) ## 파란색곡면을 그리는 코드(끝) ax2.scatter(2.5,4,torch.sum((y-2.5-4*x)**2),s=200,color=&#39;red&#39;,marker=&#39;*&#39;) ## 최소점을 표시하는 코드 (붉은색 별) ax2.scatter(np.array(Whats)[0,0],np.array(Whats)[0,1],losses[0],color=&#39;b&#39;) ## 업데이트되는 What을 표시하는 점 (파란색 동그라미) ax2.azim = 40 ## 3d plot의 view 조절 ax2.dist = 8 ## 3d plot의 view 조절 ax2.elev = 5 ## 3d plot의 view 조절 def animate(epoc): line.set_ydata(yhats[epoc]) ax2.scatter(np.array(Whats)[epoc,0],np.array(Whats)[epoc,1],losses[epoc],color=&#39;grey&#39;) return line ani = animation.FuncAnimation(fig, animate, frames=30) plt.close() ani . . &lt;/input&gt; Once Loop Reflect (4) $ alpha=0.01$ . losses = [] # 기록하고 싶은것 1 yhats = [] # 기록하고 싶은것 2 Whats = [] # 기록하고 싶은것 3 . . alpha=0.01 What= torch.tensor([-5.0,10.0],requires_grad=True) for epoc in range(30): Whats=Whats+[What.data.tolist()] What.grad=None yhat=X@What yhats=yhats+[yhat.data.tolist()] loss=torch.sum((y-yhat)**2) losses = losses + [loss.item()] loss.backward() What.data = What.data-alpha * What.grad.data . . fig = plt.figure() ax1 = fig.add_subplot(1, 2, 1) ax2 = fig.add_subplot(1, 2, 2, projection=&#39;3d&#39;) ## ax1: 왼쪽그림 ax1.plot(x,y,&#39;o&#39;) line, = ax1.plot(x,yhats[0]) ## ax2: 오른쪽그림 _w0 = np.arange(-6, 11, 0.5) ## 파란색곡면을 그리는 코드 (시작) _w1 = np.arange(-6, 11, 0.5) w1,w0 = np.meshgrid(_w1,_w0) l=w0*0 for i in range(len(_w0)): for j in range(len(_w1)): l[i,j]=torch.sum((y-_w0[i]-_w1[j]*x)**2) ax2.plot_surface(w0, w1, l, rstride=1, cstride=1, color=&#39;b&#39;,alpha=0.35) ## 파란색곡면을 그리는 코드(끝) ax2.scatter(2.5,4,torch.sum((y-2.5-4*x)**2),s=200,color=&#39;red&#39;,marker=&#39;*&#39;) ## 최소점을 표시하는 코드 (붉은색 별) ax2.scatter(np.array(Whats)[0,0],np.array(Whats)[0,1],losses[0],color=&#39;b&#39;) ## 업데이트되는 What을 표시하는 점 (파란색 동그라미) ax2.azim = 40 ## 3d plot의 view 조절 ax2.dist = 8 ## 3d plot의 view 조절 ax2.elev = 5 ## 3d plot의 view 조절 def animate(epoc): line.set_ydata(yhats[epoc]) ax2.scatter(np.array(Whats)[epoc,0],np.array(Whats)[epoc,1],losses[epoc],color=&#39;grey&#39;) return line ani = animation.FuncAnimation(fig, animate, frames=30) plt.close() ani . . &lt;/input&gt; Once Loop Reflect (5) $ alpha=0.006$ 숙제 . losses = [] # 기록하고 싶은것 1 yhats = [] # 기록하고 싶은것 2 Whats = [] # 기록하고 싶은것 3 . . alpha=0.006 What= torch.tensor([-5.0,10.0],requires_grad=True) for epoc in range(30): Whats=Whats+[What.data.tolist()] What.grad=None yhat=X@What yhats=yhats+[yhat.data.tolist()] loss=torch.sum((y-yhat)**2) losses = losses + [loss.item()] loss.backward() What.data = What.data-alpha * What.grad.data . . fig = plt.figure() ax1 = fig.add_subplot(1, 2, 1) ax2 = fig.add_subplot(1, 2, 2, projection=&#39;3d&#39;) ## ax1: 왼쪽그림 ax1.plot(x,y,&#39;o&#39;) line, = ax1.plot(x,yhats[0]) ## ax2: 오른쪽그림 _w0 = np.arange(-6, 11, 0.5) ## 파란색곡면을 그리는 코드 (시작) _w1 = np.arange(-6, 11, 0.5) w1,w0 = np.meshgrid(_w1,_w0) l=w0*0 for i in range(len(_w0)): for j in range(len(_w1)): l[i,j]=torch.sum((y-_w0[i]-_w1[j]*x)**2) ax2.plot_surface(w0, w1, l, rstride=1, cstride=1, color=&#39;b&#39;,alpha=0.35) ## 파란색곡면을 그리는 코드(끝) ax2.scatter(2.5,4,torch.sum((y-2.5-4*x)**2),s=200,color=&#39;red&#39;,marker=&#39;*&#39;) ## 최소점을 표시하는 코드 (붉은색 별) ax2.scatter(np.array(Whats)[0,0],np.array(Whats)[0,1],losses[0],color=&#39;b&#39;) ## 업데이트되는 What을 표시하는 점 (파란색 동그라미) ax2.azim = 40 ## 3d plot의 view 조절 ax2.dist = 8 ## 3d plot의 view 조절 ax2.elev = 5 ## 3d plot의 view 조절 def animate(epoc): line.set_ydata(yhats[epoc]) ax2.scatter(np.array(Whats)[epoc,0],np.array(Whats)[epoc,1],losses[epoc],color=&#39;grey&#39;) return line ani = animation.FuncAnimation(fig, animate, frames=30) plt.close() ani . . &lt;/input&gt; Once Loop Reflect &#45796;&#47336;&#44592; &#49899;&#51648;&#47564; &#54644;&#50556;&#54616;&#45716; &#49324;&#49548;&#54620; &#47928;&#51228;&#46308; . (A1) &#49552;&#49892;&#54632;&#49688; . - $ sum_{i=1}^{n}(y_i- hat{y}_i)^2$ 대신에 . $ frac{1}{n} sum_{i=1}^{n}(y_i- hat{y}_i)^2$ 평균, 이 형태를 많이 쓴다. | . | $ frac{1}{2n} sum_{i=1}^{n}(y_i- hat{y}_i)^2$ 미분하면 2 사라짐 | . | . 중 하나를 사용하여도 상관없다. . (A2) &#48324;&#54364;&#47196; &#54364;&#49884;&#46108; &#51216;&#51060; &#51221;&#47568; $(2.5,4.0)$&#51068;&#44620;? $ Longleftrightarrow$ l&#51060; &#51221;&#47568; $w_0=2.5$, $w_1=4.0$&#50640;&#49436; &#52572;&#49548;&#54868; &#46104;&#45716;&#44032;? . - np.argmin 소개(최소화되는 인덱스 출력해주는 함수) . _a=np.array([1,2,0,2,3,4]) np.argmin(_a) # 인덱스 2(여기서는 0값)번이 최소값 . 2 . np.argmin(l) . 598 . -무슨 값인지 모름.이런 값이 나오는 이유. . _X=np.array([[1,2,3],[1,-5,-5]]) . _X . array([[ 1, 2, 3], [ 1, -5, -5]]) . np.argmin(_X) . 4 . l.shape # 34*34=1156개 있음 . (34, 34) . - array의 구조가 너무 컴퓨터 위주의 숫자임.. $ to$ np.unravel_index() 함수사용 . np.unravel_index(4,_X.shape) # index로 반환해 달라 4 말고 . (1, 1) . - 응용하면 . np.unravel_index(np.argmin(l),l.shape) . (17, 20) . _w0[17],_w1[20] # 우리가 바라던 값이 나왔다 . (2.5, 4.0) . - (2.5,4.0)에서 ;이 최소값을 가지는 것이 맞긴 함 . - 그런데 이론적으로 그래야 하는 것은 아님 . torch.sum((y-2.5-4.0*x)**2) . tensor(23.9743) . XX=np.matrix(X) yy=np.matrix(y).T # (100,1)로 치환 . yy.shape . (100, 1) . (XX.T*XX).I * XX.T * yy . matrix([[2.530568 ], [3.9915466]], dtype=float32) . torch.sum((y-2.530568-3.9915466*x)**2) # loss값이 더 작아진 모습 . tensor(23.8640) . 진짜로 (2.530568,3.9915466) 에서의 로스가 더 작음 | . - $n$이 커질수록 (2.530568, 3.9915466) 의 값은 점점 (2.5,4.0)의 값에 가까워 진다. . (A3) &#54665;&#48289;&#53552;&#50752; &#50676;&#48289;&#53552; . - 아래의 매트릭스를 관찰하자. . XX . matrix([[ 1. , -2.2971632 ], [ 1. , -2.1039104 ], [ 1. , -2.0895088 ], [ 1. , -1.9183004 ], [ 1. , -1.8640488 ], [ 1. , -1.8116142 ], [ 1. , -1.7044138 ], [ 1. , -1.699133 ], [ 1. , -1.6495895 ], [ 1. , -1.6286039 ], [ 1. , -1.5477134 ], [ 1. , -1.469909 ], [ 1. , -1.4143386 ], [ 1. , -1.3075817 ], [ 1. , -1.2539034 ], [ 1. , -1.2488844 ], [ 1. , -1.1821247 ], [ 1. , -1.1662971 ], [ 1. , -1.1250314 ], [ 1. , -0.93326014], [ 1. , -0.88526654], [ 1. , -0.8639698 ], [ 1. , -0.8522789 ], [ 1. , -0.82096314], [ 1. , -0.7851367 ], [ 1. , -0.7846103 ], [ 1. , -0.775272 ], [ 1. , -0.72431004], [ 1. , -0.7026662 ], [ 1. , -0.67990315], [ 1. , -0.6649538 ], [ 1. , -0.65587115], [ 1. , -0.6549699 ], [ 1. , -0.6170914 ], [ 1. , -0.5964267 ], [ 1. , -0.5796867 ], [ 1. , -0.576962 ], [ 1. , -0.573241 ], [ 1. , -0.5656716 ], [ 1. , -0.5440386 ], [ 1. , -0.51049155], [ 1. , -0.49526608], [ 1. , -0.4791573 ], [ 1. , -0.43899277], [ 1. , -0.42762285], [ 1. , -0.32772934], [ 1. , -0.30849513], [ 1. , -0.2955021 ], [ 1. , -0.28497764], [ 1. , -0.2776678 ], [ 1. , -0.26418892], [ 1. , -0.22294523], [ 1. , -0.21685947], [ 1. , -0.19773111], [ 1. , -0.19453613], [ 1. , -0.16434576], [ 1. , -0.06597225], [ 1. , -0.05200045], [ 1. , -0.04561628], [ 1. , -0.03639911], [ 1. , 0.00411945], [ 1. , 0.00889459], [ 1. , 0.0455331 ], [ 1. , 0.10105584], [ 1. , 0.13632803], [ 1. , 0.19237518], [ 1. , 0.2507207 ], [ 1. , 0.2548768 ], [ 1. , 0.28304642], [ 1. , 0.29937938], [ 1. , 0.3294042 ], [ 1. , 0.51909333], [ 1. , 0.559151 ], [ 1. , 0.59467036], [ 1. , 0.63452995], [ 1. , 0.6435871 ], [ 1. , 0.7075169 ], [ 1. , 0.7472348 ], [ 1. , 0.753683 ], [ 1. , 0.77188945], [ 1. , 0.77901787], [ 1. , 0.78336984], [ 1. , 0.82249224], [ 1. , 0.87238336], [ 1. , 0.8863593 ], [ 1. , 0.8916975 ], [ 1. , 0.8985204 ], [ 1. , 1.006009 ], [ 1. , 1.0749605 ], [ 1. , 1.1056927 ], [ 1. , 1.2062144 ], [ 1. , 1.2267364 ], [ 1. , 1.268053 ], [ 1. , 1.2966905 ], [ 1. , 1.3426594 ], [ 1. , 1.460442 ], [ 1. , 1.4679053 ], [ 1. , 1.5741758 ], [ 1. , 1.763243 ], [ 1. , 2.3950703 ]], dtype=float32) . XX[:,1] . matrix([[-2.2971632 ], [-2.1039104 ], [-2.0895088 ], [-1.9183004 ], [-1.8640488 ], [-1.8116142 ], [-1.7044138 ], [-1.699133 ], [-1.6495895 ], [-1.6286039 ], [-1.5477134 ], [-1.469909 ], [-1.4143386 ], [-1.3075817 ], [-1.2539034 ], [-1.2488844 ], [-1.1821247 ], [-1.1662971 ], [-1.1250314 ], [-0.93326014], [-0.88526654], [-0.8639698 ], [-0.8522789 ], [-0.82096314], [-0.7851367 ], [-0.7846103 ], [-0.775272 ], [-0.72431004], [-0.7026662 ], [-0.67990315], [-0.6649538 ], [-0.65587115], [-0.6549699 ], [-0.6170914 ], [-0.5964267 ], [-0.5796867 ], [-0.576962 ], [-0.573241 ], [-0.5656716 ], [-0.5440386 ], [-0.51049155], [-0.49526608], [-0.4791573 ], [-0.43899277], [-0.42762285], [-0.32772934], [-0.30849513], [-0.2955021 ], [-0.28497764], [-0.2776678 ], [-0.26418892], [-0.22294523], [-0.21685947], [-0.19773111], [-0.19453613], [-0.16434576], [-0.06597225], [-0.05200045], [-0.04561628], [-0.03639911], [ 0.00411945], [ 0.00889459], [ 0.0455331 ], [ 0.10105584], [ 0.13632803], [ 0.19237518], [ 0.2507207 ], [ 0.2548768 ], [ 0.28304642], [ 0.29937938], [ 0.3294042 ], [ 0.51909333], [ 0.559151 ], [ 0.59467036], [ 0.63452995], [ 0.6435871 ], [ 0.7075169 ], [ 0.7472348 ], [ 0.753683 ], [ 0.77188945], [ 0.77901787], [ 0.78336984], [ 0.82249224], [ 0.87238336], [ 0.8863593 ], [ 0.8916975 ], [ 0.8985204 ], [ 1.006009 ], [ 1.0749605 ], [ 1.1056927 ], [ 1.2062144 ], [ 1.2267364 ], [ 1.268053 ], [ 1.2966905 ], [ 1.3426594 ], [ 1.460442 ], [ 1.4679053 ], [ 1.5741758 ], [ 1.763243 ], [ 2.3950703 ]], dtype=float32) . 정상적을 잘 선택되었다. | . - 이제 XX에서 첫번째 row를 선택하고 싶다면? . XX[0,:] . matrix([[ 1. , -2.2971632]], dtype=float32) . - X에 관심을 가져보자. . - 첫번째 row를 뽑고싶다면? . X[0,:] . tensor([ 1.0000, -2.2972]) . - 두번째 col을 뽑고 싶다면? . X[:,1] # 왜 벡터형으로 나올까 . tensor([-2.2972, -2.1039, -2.0895, -1.9183, -1.8640, -1.8116, -1.7044, -1.6991, -1.6496, -1.6286, -1.5477, -1.4699, -1.4143, -1.3076, -1.2539, -1.2489, -1.1821, -1.1663, -1.1250, -0.9333, -0.8853, -0.8640, -0.8523, -0.8210, -0.7851, -0.7846, -0.7753, -0.7243, -0.7027, -0.6799, -0.6650, -0.6559, -0.6550, -0.6171, -0.5964, -0.5797, -0.5770, -0.5732, -0.5657, -0.5440, -0.5105, -0.4953, -0.4792, -0.4390, -0.4276, -0.3277, -0.3085, -0.2955, -0.2850, -0.2777, -0.2642, -0.2229, -0.2169, -0.1977, -0.1945, -0.1643, -0.0660, -0.0520, -0.0456, -0.0364, 0.0041, 0.0089, 0.0455, 0.1011, 0.1363, 0.1924, 0.2507, 0.2549, 0.2830, 0.2994, 0.3294, 0.5191, 0.5592, 0.5947, 0.6345, 0.6436, 0.7075, 0.7472, 0.7537, 0.7719, 0.7790, 0.7834, 0.8225, 0.8724, 0.8864, 0.8917, 0.8985, 1.0060, 1.0750, 1.1057, 1.2062, 1.2267, 1.2681, 1.2967, 1.3427, 1.4604, 1.4679, 1.5742, 1.7632, 2.3951]) . - shape 비교 . XX.shape,(XX[0,:]).shape,(XX[:,1]).shape . ((100, 2), (1, 2), (100, 1)) . X.shape,(X[0,:]).shape,(X[:,1]).shape . (torch.Size([100, 2]), torch.Size([2]), torch.Size([100])) . row-vec, col-vec의 구분없이 그냥 길이2인 벡터, 길이가 100인 벡터로 고려됨 | row-vec, col-vec의 구분을 하려면 2차원이 필요한데 1차원으로 축소가 되면서 생기는 현상 | 대부분의 경우 별로 문제가 되지 않음. | 수학적으로는 col-vec, row-vec를 엄밀하게 구분하는 것이 좋지만, 프로그래밍 효율을 생각하면 떄로는 구분이 모호한게 유리할 수도 있다. | .",
            "url": "https://seoyeonc.github.io/chch/2021/11/19/_bd_2%EC%A3%BC%EC%B0%A8_2.html",
            "relUrl": "/2021/11/19/_bd_2%EC%A3%BC%EC%B0%A8_2.html",
            "date": " • Nov 19, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "빅데이터 분석 (2주차) 9월9일",
            "content": "Path, &#51060;&#48120;&#51648; &#53356;&#47204;&#47553;&#44284; CNN&#47784;&#45944; . - (1/4) Path 설명 . - (2/4) 이미지 크롤링 . - (3/4) 모형학습 및 결과분석 . - (4/4) 테스트 . from fastai.data.all import * from fastai.vision.all import * . path=Path() # 현재 위치 저장 현재폴더=. 상위폴더=.. path . Path(&#39;.&#39;) . path.ls() . (#9) [Path(&#39;bd_1주차.ipynb&#39;),Path(&#39;601f57a1260000bd0c275eca.jpeg&#39;),Path(&#39;2021_09_07_(1주차)_9월7일.ipynb&#39;),Path(&#39;p1065602463397191_754_thum.jpg&#39;),Path(&#39;502104_3008_164.png&#39;),Path(&#39;2021_09_09_(2주차)_9월9일.ipynb&#39;),Path(&#39;.ipynb_checkpoints&#39;),Path(&#39;2021-09-27-(3주차)_9월27일(1).ipynb&#39;),Path(&#39;bd_2주차.ipynb&#39;)] . (path/&#39;폴더 이름 넣어~&#39;).ls() . path=Path() . (path/&#39;asdf&#39;).mkdir() . (path/&#39;asdf&#39;).ls() . (#0) [] . (path/&#39;asdf&#39;).mkdir() # 이미 있는 폴더면 오류 발생 . FileExistsError Traceback (most recent call last) &lt;ipython-input-19-96a686fc4db7&gt; in &lt;module&gt; -&gt; 1 (path/&#39;asdf&#39;).mkdir() # 이미 있는 폴더면 오류 발생 ~/anaconda3/envs/csy/lib/python3.8/pathlib.py in mkdir(self, mode, parents, exist_ok) 1286 self._raise_closed() 1287 try: -&gt; 1288 self._accessor.mkdir(self, mode) 1289 except FileNotFoundError: 1290 if not parents or self.parent == self: FileExistsError: [Errno 17] File exists: &#39;asdf&#39; . (path/&#39;asdf&#39;).mkdir(exist_ok=True) # 이미 존재하면 무시~ . (path/&#39;asdf&#39;).rmdir() # 생성한 폴더 삭제 . &#51060;&#48120;&#51648; &#53356;&#47204;&#47553; . - 이미지 크롤링 . 검색 2. 이미지 주소를 찾음 3. 해당 주소로 이동하여 저장하는 과정 반복 | | . - 다른방법: 덕덕고를 이용한 이미지 크롤링 . ref: https://github.com/fastai/fastbook/blob/master/utils.py | . def search_images_ddg(key,max_n=200): &quot;&quot;&quot;Search for &#39;key&#39; with DuckDuckGo and return a unique urls of &#39;max_n&#39; images (Adopted from https://github.com/deepanprabhu/duckduckgo-images-api) &quot;&quot;&quot; url = &#39;https://duckduckgo.com/&#39; params = {&#39;q&#39;:key} res = requests.post(url,data=params) searchObj = re.search(r&#39;vqd=([ d-]+) &amp;&#39;,res.text) if not searchObj: print(&#39;Token Parsing Failed !&#39;); return requestUrl = url + &#39;i.js&#39; headers = {&#39;User-Agent&#39;: &#39;Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:71.0) Gecko/20100101 Firefox/71.0&#39;} params = ((&#39;l&#39;,&#39;us-en&#39;),(&#39;o&#39;,&#39;json&#39;),(&#39;q&#39;,key),(&#39;vqd&#39;,searchObj.group(1)),(&#39;f&#39;,&#39;,,,&#39;),(&#39;p&#39;,&#39;1&#39;),(&#39;v7exp&#39;,&#39;a&#39;)) urls = [] while True: try: res = requests.get(requestUrl,headers=headers,params=params) data = json.loads(res.text) for obj in data[&#39;results&#39;]: urls.append(obj[&#39;image&#39;]) max_n = max_n - 1 if max_n &lt; 1: return L(set(urls)) # dedupe if &#39;next&#39; not in data: return L(set(urls)) requestUrl = url + data[&#39;next&#39;] except: pass . . search_images_ddg(검색어)를 이용하여 검색어에 해당하는 url 얻기m . search_images_ddg(&#39;Holybang&#39;,max_n=5) . (#5) [&#39;https://i.ytimg.com/vi/fcmDi1DCGDs/maxresdefault.jpg&#39;,&#39;http://one-we.cn/uploads/allimg/191218/1-19121Q35R5G9.jpg&#39;,&#39;https://i.ytimg.com/vi/SBWy4-ZU4qQ/maxresdefault.jpg&#39;,&#39;https://www.kpophighindia.com/wp-content/uploads/2021/07/crews-1.jpg&#39;,&#39;https://t1.daumcdn.net/cfile/tistory/993004335A12CB082C&#39;] . path=Path() . path.ls() . (#7) [Path(&#39;bd_1주차.ipynb&#39;),Path(&#39;2021_09_07_(1주차)_9월7일.ipynb&#39;),Path(&#39;bd_1st&#39;),Path(&#39;2021_09_09_(2주차)_9월9일.ipynb&#39;),Path(&#39;.ipynb_checkpoints&#39;),Path(&#39;2021-09-27-(3주차)_9월27일(1).ipynb&#39;),Path(&#39;bd_2주차.ipynb&#39;)] . download_images(path,urls=search_images_ddg(&#39;Holybang&#39;,max_n=5)) . 현재 working directory에 5개의 이미지가 저장된 모습! | . keywords=&#39;sunmi&#39;, &#39;Hyuna&#39; # 단어 한 개 쓰면 키워드로 입력되어서 알파벳 수대로 폴더 만들어짐.. path=Path(&#39;Singer&#39;) . if not path.exists(): # 현재폴더에 Singer 폴더가 있는지 체크 path.mkdir() # 현재폴더에 Singer 폴더가 만들어짐 for keyword in keywords: # keyword=&#39;sunmi&#39;, keyword=&#39;Hyuna&#39; 일때 아래내용을 반복 lastpath=path/keyword # ./Singer/sunmi or ./Singer/Hyuna lastpath.mkdir(exist_ok=True) # make ./Singer/sunmi or ./Singer/Hyuna urls=search_images_ddg(keyword) # &#39;sunmi&#39; 검색어로 url들의 리스트를 얻음 download_images(lastpath,urls=urls) # 그 url에 해당하는 이미지들을 ./Singer/sunmi or ./Singer/Hyuna 에 저장 . Cleaning Data . 탐색기로 파일들을 살펴보니 조금 이상한 확장자도 있음. . | 조금 이상해보이는 확장자도 열리기는 함. . | . PILImage.create(&#39;./singer/iu/00000015.jpg:large&#39;) . FileNotFoundError Traceback (most recent call last) &lt;ipython-input-44-2622c1a578e7&gt; in &lt;module&gt; -&gt; 1 PILImage.create(&#39;./singer/iu/00000015.jpg:large&#39;) ~/anaconda3/envs/csy/lib/python3.8/site-packages/fastai/vision/core.py in create(cls, fn, **kwargs) 108 if isinstance(fn,ndarray): return cls(Image.fromarray(fn)) 109 if isinstance(fn,bytes): fn = io.BytesIO(fn) --&gt; 110 return cls(load_image(fn, **merge(cls._open_args, kwargs))) 111 112 def show(self, ctx=None, **kwargs): ~/anaconda3/envs/csy/lib/python3.8/site-packages/fastai/vision/core.py in load_image(fn, mode) 83 def load_image(fn, mode=None): 84 &#34;Open and load a `PIL.Image` and convert to `mode`&#34; &gt; 85 im = Image.open(fn) 86 im.load() 87 im = im._new(im.im) ~/anaconda3/envs/csy/lib/python3.8/site-packages/PIL/Image.py in open(fp, mode, formats) 2973 2974 if filename: -&gt; 2975 fp = builtins.open(filename, &#34;rb&#34;) 2976 exclusive_fp = True 2977 FileNotFoundError: [Errno 2] No such file or directory: &#39;./singer/iu/00000015.jpg:large&#39; . verify_images(get_image_files(path)) . (#4) [Path(&#39;Singer/sunmi/00000065.jpg&#39;),Path(&#39;Singer/Hyuna/00000034.jpg&#39;),Path(&#39;Singer/Hyuna/00000039.jpg&#39;),Path(&#39;Singer/Hyuna/00000025.jpeg&#39;)] . 위에 해당하는 이미지를 수동으로 지워줌 | 나중에 지우는 함수 배움(조금 까다로움) | . - fastai 가 지원하는 함수로 분석하기 좋게 dls 만들기 . dls=ImageDataLoaders.from_folder( path, train=&#39;singer&#39;, valid_pct=0.2, item_tfms=Resize(224)) . ImageDataLoaders.from_folder(path, train=&#39;train&#39;, valid=&#39;valid&#39;, valid_pct=None, seed=None, vocab=None, item_tfms=None, batch_tfms=None, bs=64, val_bs=None, shuffle=True, device=None) . dls.show_batch(max_n=16) . learn=cnn_learner(dls,resnet34,metrics=error_rate) learn.fine_tune(7) . epoch train_loss valid_loss error_rate time . 0 | 1.169335 | 1.660869 | 0.470588 | 00:05 | . epoch train_loss valid_loss error_rate time . 0 | 0.718052 | 0.950780 | 0.397059 | 00:04 | . 1 | 0.634088 | 0.537583 | 0.205882 | 00:04 | . 2 | 0.490461 | 0.444096 | 0.205882 | 00:04 | . 3 | 0.389381 | 0.479742 | 0.161765 | 00:04 | . 4 | 0.317441 | 0.513656 | 0.176471 | 00:04 | . 5 | 0.269008 | 0.556920 | 0.191176 | 00:04 | . 6 | 0.234722 | 0.560562 | 0.205882 | 00:04 | . learn.show_results(max_n=16) . &#50724;&#45813;&#48516;&#49437; . interp=Interpretation.from_learner(learn) interp.plot_top_losses(16) . 수동으로 특정 observation에 대한 예측결과를 확인 | . dls.train_ds . (#275) [(PILImage mode=RGB size=1080x1080, TensorCategory(1)),(PILImage mode=RGB size=1038x1557, TensorCategory(1)),(PILImage mode=RGB size=642x858, TensorCategory(1)),(PILImage mode=RGB size=509x509, TensorCategory(0)),(PILImage mode=RGB size=960x1200, TensorCategory(1)),(PILImage mode=RGB size=800x1200, TensorCategory(0)),(PILImage mode=RGB size=3600x2025, TensorCategory(0)),(PILImage mode=RGB size=1100x1716, TensorCategory(1)),(PILImage mode=RGB size=1280x1920, TensorCategory(1)),(PILImage mode=RGB size=768x1024, TensorCategory(1))...] . training test | . dls.train_ds[0] # 첫 번째 observation, 즉, (x1,y1) . (PILImage mode=RGB size=1080x1080, TensorCategory(1)) . $x_1=$PILImage mode=RGB size=960x960 | $y_1=$TensorCategory(1) | . dls.train_ds[100][0] . $x_{100}$=위의 이미지 | . dls.train_ds[100][1] . TensorCategory(1) . $y_{100}=$TensorCategory(1) | . x100=dls.train_ds[100][0] . learn.predict(x100) . (&#39;sunmi&#39;, TensorBase(1), TensorBase([0.0015, 0.9985])) . Test . path=Path() . if not (path/&#39;test&#39;).exists(): (path/&#39;test&#39;).mkdir() . urls=search_images_ddg(&#39;sunmi 선미&#39;,max_n=20) download_images(path/&#39;test&#39;,urls=urls) testset=get_image_files(path/&#39;test&#39;) testset . (#20) [Path(&#39;test/00000010.jpg&#39;),Path(&#39;test/00000005.jpg&#39;),Path(&#39;test/00000013.jpg&#39;),Path(&#39;test/00000011.jpg&#39;),Path(&#39;test/00000003.jpg&#39;),Path(&#39;test/00000000.jpg&#39;),Path(&#39;test/00000004.jpg&#39;),Path(&#39;test/00000016.jpg&#39;),Path(&#39;test/00000012.jpg&#39;),Path(&#39;test/00000006.jpg&#39;)...] . for i in range(len(testset)): print(learn.predict(PILImage.create(testset[i]))) . (&#39;Hyuna&#39;, TensorBase(0), TensorBase([0.5452, 0.4548])) . (&#39;Hyuna&#39;, TensorBase(0), TensorBase([0.5311, 0.4689])) . (&#39;Hyuna&#39;, TensorBase(0), TensorBase([0.9941, 0.0059])) . (&#39;sunmi&#39;, TensorBase(1), TensorBase([0.0239, 0.9761])) . (&#39;sunmi&#39;, TensorBase(1), TensorBase([0.2874, 0.7126])) . (&#39;sunmi&#39;, TensorBase(1), TensorBase([0.2435, 0.7565])) . (&#39;sunmi&#39;, TensorBase(1), TensorBase([4.7129e-04, 9.9953e-01])) . (&#39;sunmi&#39;, TensorBase(1), TensorBase([0.0046, 0.9954])) . (&#39;sunmi&#39;, TensorBase(1), TensorBase([0.2166, 0.7834])) . (&#39;sunmi&#39;, TensorBase(1), TensorBase([0.0633, 0.9367])) . (&#39;Hyuna&#39;, TensorBase(0), TensorBase([0.9806, 0.0194])) . (&#39;Hyuna&#39;, TensorBase(0), TensorBase([9.9916e-01, 8.4005e-04])) . (&#39;Hyuna&#39;, TensorBase(0), TensorBase([0.9590, 0.0410])) . (&#39;sunmi&#39;, TensorBase(1), TensorBase([0.0581, 0.9419])) . (&#39;sunmi&#39;, TensorBase(1), TensorBase([5.8807e-04, 9.9941e-01])) . (&#39;sunmi&#39;, TensorBase(1), TensorBase([0.1369, 0.8631])) . (&#39;sunmi&#39;, TensorBase(1), TensorBase([0.1169, 0.8831])) . (&#39;sunmi&#39;, TensorBase(1), TensorBase([0.0784, 0.9216])) . (&#39;sunmi&#39;, TensorBase(1), TensorBase([7.0567e-07, 1.0000e+00])) . (&#39;Hyuna&#39;, TensorBase(0), TensorBase([0.7406, 0.2594])) . 결과를 보니까 sunmi이 많음 → 어느정도 맞추는것 같긴하다 | . PILImage.create(testset[1]) . 실제로 선미인데 현아로 예측한 사진 | . path=Path() . if not (path/&#39;test2&#39;).exists(): (path/&#39;test2&#39;).mkdir() . urls=search_images_ddg(&#39;hyuna 현아&#39;,max_n=20) download_images(path/&#39;test2&#39;,urls=urls) testset=get_image_files(path/&#39;test2&#39;) testset . (#19) [Path(&#39;test2/00000010.jpg&#39;),Path(&#39;test2/00000000.jpeg&#39;),Path(&#39;test2/00000005.jpg&#39;),Path(&#39;test2/00000013.jpg&#39;),Path(&#39;test2/00000011.jpg&#39;),Path(&#39;test2/00000003.jpg&#39;),Path(&#39;test2/00000018.jpeg&#39;),Path(&#39;test2/00000004.jpg&#39;),Path(&#39;test2/00000016.jpg&#39;),Path(&#39;test2/00000009.jpeg&#39;)...] . for i in range(len(testset)): print(learn.predict(PILImage.create(testset[i]))) . (&#39;Hyuna&#39;, TensorBase(0), TensorBase([1.0000e+00, 3.2445e-06])) . (&#39;sunmi&#39;, TensorBase(1), TensorBase([0.4499, 0.5501])) . (&#39;Hyuna&#39;, TensorBase(0), TensorBase([0.9945, 0.0055])) . (&#39;Hyuna&#39;, TensorBase(0), TensorBase([9.9906e-01, 9.4329e-04])) . (&#39;Hyuna&#39;, TensorBase(0), TensorBase([0.9759, 0.0241])) . (&#39;Hyuna&#39;, TensorBase(0), TensorBase([0.5947, 0.4053])) . (&#39;Hyuna&#39;, TensorBase(0), TensorBase([0.9765, 0.0235])) . (&#39;Hyuna&#39;, TensorBase(0), TensorBase([0.9819, 0.0181])) . (&#39;sunmi&#39;, TensorBase(1), TensorBase([0.3257, 0.6743])) . (&#39;Hyuna&#39;, TensorBase(0), TensorBase([0.9685, 0.0315])) . (&#39;Hyuna&#39;, TensorBase(0), TensorBase([9.9974e-01, 2.6368e-04])) . (&#39;Hyuna&#39;, TensorBase(0), TensorBase([0.9840, 0.0160])) . (&#39;Hyuna&#39;, TensorBase(0), TensorBase([9.9996e-01, 4.0536e-05])) . (&#39;sunmi&#39;, TensorBase(1), TensorBase([0.2522, 0.7478])) . (&#39;Hyuna&#39;, TensorBase(0), TensorBase([9.9949e-01, 5.0994e-04])) . (&#39;Hyuna&#39;, TensorBase(0), TensorBase([0.9084, 0.0916])) . (&#39;Hyuna&#39;, TensorBase(0), TensorBase([0.8650, 0.1350])) . (&#39;Hyuna&#39;, TensorBase(0), TensorBase([0.9987, 0.0013])) . (&#39;Hyuna&#39;, TensorBase(0), TensorBase([0.7162, 0.2838])) . 결과를 보니 Hyuna 역시 잘 맞추는 듯 보인다. | . - 정확률이 아쉽긴 하지만 어느정도 유의미한 결과를 얻었다. . PILImage.create(testset[1]) # 현아인데 선미로 예측한 사진 .",
            "url": "https://seoyeonc.github.io/chch/2021/11/19/_bd_2%EC%A3%BC%EC%B0%A8_1.html",
            "relUrl": "/2021/11/19/_bd_2%EC%A3%BC%EC%B0%A8_1.html",
            "date": " • Nov 19, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "빅데이터분석 (1주차) 21년9월7일",
            "content": "1&#51452;&#52264; 9&#50900; 7&#51068; . https://guebin.github.io/2021BDA/2021/09/07/(1%EC%A3%BC%EC%B0%A8)-9%EC%9B%947%EC%9D%BC.html . - (1/6): 아나콘다 가상환경 만들기, 파이토치 설치, 주피터랩 설치, conda install 과 pip install 의 차이 . - (2/6): 이미지 분석을 위한 데이터셋 준비 및 정리 . - (3/6): 학습 및 예측 . - (4/6): 코랩설명 + 깃허브/블로그 (뒷부분은 화면전환 오류로 설명이 부실함) . - (5/6): 코랩설명 + 깃허브/블로그 . - (6/6): 우리강아지 이미지를 활용한 예측 . from fastai.vision.all import * . fastai 깔기, error 뜬다면 런타임에서 GPU 변경 | !pip install --ungrade fastai | . path=untar_data(URLs.PETS)/&#39;images&#39; # To download model **pretrained** weights: . files=get_image_files(path) # 이미지파일들의 이름을 모두 복붙하여 리스트를 만든뒤에 files.txt로 저장하는 과정으로 비유할 수 있음 . files[2] # txt파일의 3번째 목록 . Path(&#39;/home/cgb4/.fastai/data/oxford-iiit-pet/images/leonberger_5.jpg&#39;) . def label_func(f): if f[0].isupper(): return &#39;cat&#39; else: return &#39;dog&#39; . 만일 f[0]파일 제목의 첫 글자가 대문자면 고양이, 소문자면 강아지로 반환 | 원래 있던 모델 | . label_func(&#39;asdf&#39;) # 소문자로 시작하니까 강아지로 리턴 . &#39;dog&#39; . dls=ImageDataLoaders.from_name_func(path,files,label_func,item_tfms=Resize(224)) . ImageDataLoaders.from_name_func(path, fnames, label_func, valid_pct=0.2, seed=None, item_tfms=None, batch_tfms=None, bs=64, val_bs=None, shuffle=True, device=None) . dls.show_batch(max_n=16) # 16개의 사진들을 보여줘라. . cnn_learner 사용 전 에러뜬다면 설치도 해주고~ . !conda install -c conda-forge jupyterlab_widgets -y . !conda install -c conda-forge ipywidgets -y . !conda install -c conda-forge nodejs -y . learn=cnn_learner(dls,resnet34,metrics=error_rate) . 모형이 만들어진 것. | Resnet34 is a 34 layer convolutional neural network(모형 이름) | metrics=error_rate 평가지표로 삼겠다 | cnn_learner(dls, arch, normalize=True, n_out=None, pretrained=True, config=None, loss_func=None, opt_func=Adam, lr=0.001, splitter=None, cbs=None, metrics=None, path=None, model_dir=&#39;models&#39;, wd=None, wd_bn_bias=False, train_bn=True, moms=(0.95, 0.85, 0.95), cut=None, n_in=3, init=kaimingnormal, custom_head=None, concat_pool=True, lin_ftrs=None, ps=0.5, first_bn=True, bn_final=False, lin_first=False, y_range=None) | . learn.fine_tune(1) . epoch train_loss valid_loss error_rate time . 0 | 0.154754 | 0.033434 | 0.006089 | 00:10 | . epoch train_loss valid_loss error_rate time . 0 | 0.061337 | 0.014634 | 0.004736 | 00:11 | . r과 달리 python은 object(learn) 만들어서 기능 세분화 후 분석 | 학습을 시키라는 뜻. | Learner.fine_tune(epochs, base_lr=0.002, freeze_epochs=1, lr_mult=100, pct_start=0.3, div=5.0, lr_max=None, div_final=100000.0, wd=None, moms=None, cbs=None, reset_opt=False) | . - 예측 . learn.predict(files[0]) # 파일중 첫 번째 사진 가져와라. . (&#39;dog&#39;, TensorBase(1), TensorBase([3.5456e-06, 1.0000e+00])) . output: (&#39;dog&#39;, tensor(1), tensor([6.1421e-07, 1.0000e+00])) | 이 파일은 개이며, tensor(1) 우리가 강아지는 1로 저장해놓놨음 tensor(확신 확률, loss확률) | Learner.predict(item, rm_type_tfms=None, with_input=False) | . learn.show_results() . - 오답분석 . interp = Interpretation.from_learner(learn) # Interpretation . interp.plot_top_losses(16) # 잘 틀리는 거 16개 뽑아서 보여주기 # 한 개 나온 결과는 이상한데..! . 1주차 4번째 . PILImage.create(&#39;502104_3008_164.png&#39;) # 귀여워.. . learn.predict(PILImage.create(&#39;502104_3008_164.png&#39;)) # 고양이 tensor=0 으로 잘 예측한 모습! . (&#39;cat&#39;, TensorBase(0), TensorBase([1.0000e+00, 1.4151e-11])) . PILImage.create(&#39;p1065602463397191_754_thum.jpg&#39;) # 너 누가 귀여우래.. . learn.predict(PILImage.create(&#39;p1065602463397191_754_thum.jpg&#39;)) # 잘 맞춘다! . (&#39;dog&#39;, TensorBase(1), TensorBase([0.0017, 0.9983])) . PILImage.create(&#39;601f57a1260000bd0c275eca.jpeg&#39;) # 귀여운 경태 . learn.predict(PILImage.create(&#39;601f57a1260000bd0c275eca.jpeg&#39;)) . (&#39;dog&#39;, TensorBase(1), TensorBase([2.4683e-04, 9.9975e-01])) .",
            "url": "https://seoyeonc.github.io/chch/2021/11/19/_bd_1%EC%A3%BC%EC%B0%A8.html",
            "relUrl": "/2021/11/19/_bd_1%EC%A3%BC%EC%B0%A8.html",
            "date": " • Nov 19, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "2021년 2학기 데이터시각화 특강 중간고사 풀이",
            "content": "1. &#45796;&#51020;&#51008; &#51060;&#48120;&#51648;&#50752; &#45824;&#51025;&#54616;&#45716; &#55176;&#49828;&#53664;&#44536;&#47016;&#51012; &#45208;&#53440;&#45240;&#44163;&#51060;&#45796;. &#51060;&#48120;&#51648;&#50752; &#55176;&#49828;&#53664;&#44536;&#47016;&#51012; &#50732;&#48148;&#47476;&#44172; &#51677;&#51648;&#50612;&#46972;. (5&#51216;) . 예시 a-c, b-d | . . Answer a-c, b-d | . 2. &#51452;&#50612;&#51652; &#51088;&#47308;&#47484; &#48148;&#53461;&#51004;&#47196; &#50696;&#49884;&#50752; &#44057;&#51008; &#49884;&#44033;&#54868;&#47484; &#44396;&#54788;&#54616;&#46972;. (5&#51216;) . 자료 . x=[1,2,3,4] y=[1,2,4,3] . 시각화예시 . . x=[1,2,3,4] y=[1,2,4,3] fig,((ax1,ax2),(ax3,ax4))=plt.subplots(2,2) ax1.plot(x,y,&#39;--bo&#39;) ax2.plot(x,y,&#39;or&#39;) ax3.plot(x,y,&#39;xk&#39;) ax4.plot(x,y,&#39;--m.&#39;) . [&lt;matplotlib.lines.Line2D at 0x7feeeb4c71c0&gt;] . 3. &#50500;&#47000;&#45716; &#50532;&#49828;&#53092;&#51032; &#54540;&#46991;&#51060;&#45796;. &#50739;&#44172; &#54644;&#49437;&#54620; &#49324;&#46988;&#51012; &#47784;&#46160; &#44256;&#47476;&#46972; (5&#51216;) . . (하니) 그림 (a)-(d)는 모두 양의 상관계수를 가진다. . (나애리) 그림 (b)는 산점도가 직선이 아니라 곡선의 모양을 띄고 있으므로 상관계수는 0이다. . (홍두깨) 그림 (c)에서 상단의 이상치를 제외하면 상관계수는 1이다. . (고은애) 그림 (d)의 우측 이상치의 값을 적절하게 바꾸면 (d)의 상관계수를 음수로 만드는 것이 가능하다. . (이창수) 그림 (c)역시 상단의 이상치 값을 적절하게 바꾸면 (c)의 상관계수를 음수로 만드는 것이 가능하다. . Anwer: 하니, 홍두꺠, 고은애, 이창수 | . 4. &#45796;&#51020;&#51008; &#50500;&#51060;&#49828;&#53356;&#47548; &#49548;&#48708;&#47049;&#44284; &#49548;&#50500;&#47560;&#48708;&#51032; &#44288;&#44228;&#47484; &#44536;&#47536; &#49328;&#51216;&#46020;&#51060;&#45796;. &#51060;&#46412; &#49353;&#44628;&#51008; &#50728;&#46020;&#44032; &#48708;&#49847;&#54620; &#44288;&#52769;&#52824;&#47196; &#44536;&#47353;&#54609;&#46104;&#50632;&#45796;. &#50739;&#51008; &#54644;&#49437;&#51012; &#47784;&#46160; &#44264;&#46972;&#46972;. (10&#51216;) . . (하니) 아이스크림과 소아마비는 양의 상관관계에 있다. . (나애리) 상관계수의 값이 1에 가까울수록 아이스크림과 소아마비의 인과성이 명확하다고 볼 수 있다. . (홍두깨) 비슷한 온도를 가진 관측치에서는 아이스크림과 소아마비의 상관계수가 0에 가깝다. . (고은애) 온도를 통제하였을 경우 아이스크림과 소아마비의 상관계수가 0이므로 둘 사이의 인과성이 있다고 보긴 어렵다. (단, 온도를 통제하였을 경우에는 아이스크림은 랜덤으로 먹었다고 가정한다.) . Answer: 하니, 홍두깨, 고은애 | . 5. FIFA22 (100&#51216;) . 아래의 코드를 활용하여 FIFA22의 자료를 불러온뒤 물음에 답하라. . df=pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/2021DV/master/_notebooks/2021-10-25-FIFA22_official_data.csv&#39;) . import pandas as pd df=pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/2021DV/master/_notebooks/2021-10-25-FIFA22_official_data.csv&#39;) . (a) Loaned From,Marking &#50676;&#51012; &#49440;&#53469;&#54616;&#45716; &#53076;&#46300;&#47484; &#51089;&#49457;&#54616;&#44256; &#44050;&#51012; &#54869;&#51064;&#54616;&#46972;. . df.loc[:,[&#39;Loaned From&#39;,&#39;Marking&#39;]] . Loaned From Marking . 0 NaN | NaN | . 1 NaN | NaN | . 2 NaN | NaN | . 3 NaN | NaN | . 4 NaN | NaN | . ... ... | ... | . 16705 NaN | 5.0 | . 16706 NaN | NaN | . 16707 NaN | NaN | . 16708 NaN | NaN | . 16709 NaN | 15.0 | . 16710 rows × 2 columns . (b) &#44592;&#51316;&#51032; &#45936;&#51060;&#53552;&#54532;&#47112;&#51076;&#50640;&#49436; Loaned From, Marking&#50676;&#51012; &#51228;&#50808;&#54616;&#45716; &#53076;&#46300;&#47484; &#51089;&#49457;&#54616;&#46972;. . 내 Answer | . df.drop([&#39;Loaned From&#39;,&#39;Marking&#39;],axis=1) . ID Name Age Photo Nationality Flag Overall Potential Club Club Logo ... SlidingTackle GKDiving GKHandling GKKicking GKPositioning GKReflexes Best Position Best Overall Rating Release Clause DefensiveAwareness . 0 212198 | Bruno Fernandes | 26 | https://cdn.sofifa.com/players/212/198/22_60.png | Portugal | https://cdn.sofifa.com/flags/pt.png | 88 | 89 | Manchester United | https://cdn.sofifa.com/teams/11/30.png | ... | 65.0 | 12.0 | 14.0 | 15.0 | 8.0 | 14.0 | CAM | 88.0 | €206.9M | 72.0 | . 1 209658 | L. Goretzka | 26 | https://cdn.sofifa.com/players/209/658/22_60.png | Germany | https://cdn.sofifa.com/flags/de.png | 87 | 88 | FC Bayern München | https://cdn.sofifa.com/teams/21/30.png | ... | 77.0 | 13.0 | 8.0 | 15.0 | 11.0 | 9.0 | CM | 87.0 | €160.4M | 74.0 | . 2 176580 | L. Suárez | 34 | https://cdn.sofifa.com/players/176/580/22_60.png | Uruguay | https://cdn.sofifa.com/flags/uy.png | 88 | 88 | Atlético de Madrid | https://cdn.sofifa.com/teams/240/30.png | ... | 38.0 | 27.0 | 25.0 | 31.0 | 33.0 | 37.0 | ST | 88.0 | €91.2M | 42.0 | . 3 192985 | K. De Bruyne | 30 | https://cdn.sofifa.com/players/192/985/22_60.png | Belgium | https://cdn.sofifa.com/flags/be.png | 91 | 91 | Manchester City | https://cdn.sofifa.com/teams/10/30.png | ... | 53.0 | 15.0 | 13.0 | 5.0 | 10.0 | 13.0 | CM | 91.0 | €232.2M | 68.0 | . 4 224334 | M. Acuña | 29 | https://cdn.sofifa.com/players/224/334/22_60.png | Argentina | https://cdn.sofifa.com/flags/ar.png | 84 | 84 | Sevilla FC | https://cdn.sofifa.com/teams/481/30.png | ... | 82.0 | 8.0 | 14.0 | 13.0 | 13.0 | 14.0 | LB | 84.0 | €77.7M | 80.0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 16705 240558 | 18 L. Clayton | 17 | https://cdn.sofifa.com/players/240/558/18_60.png | England | https://cdn.sofifa.com/flags/gb-eng.png | 53 | 70 | Cheltenham Town | https://cdn.sofifa.com/teams/1936/30.png | ... | 12.0 | 55.0 | 54.0 | 52.0 | 50.0 | 59.0 | GK | 52.0 | €238K | NaN | . 16706 262846 | �. Dobre | 20 | https://cdn.sofifa.com/players/262/846/22_60.png | Romania | https://cdn.sofifa.com/flags/ro.png | 53 | 63 | FC Academica Clinceni | https://cdn.sofifa.com/teams/113391/30.png | ... | 12.0 | 57.0 | 52.0 | 53.0 | 48.0 | 58.0 | GK | 53.0 | €279K | 5.0 | . 16707 241317 | 21 Xue Qinghao | 19 | https://cdn.sofifa.com/players/241/317/21_60.png | China PR | https://cdn.sofifa.com/flags/cn.png | 47 | 60 | Shanghai Shenhua FC | https://cdn.sofifa.com/teams/110955/30.png | ... | 9.0 | 49.0 | 48.0 | 45.0 | 38.0 | 52.0 | GK | 47.0 | €223K | 21.0 | . 16708 259646 | A. Shaikh | 18 | https://cdn.sofifa.com/players/259/646/22_60.png | India | https://cdn.sofifa.com/flags/in.png | 47 | 67 | ATK Mohun Bagan FC | https://cdn.sofifa.com/teams/113146/30.png | ... | 13.0 | 49.0 | 41.0 | 39.0 | 45.0 | 49.0 | GK | 47.0 | €259K | 7.0 | . 16709 178453 | 07 A. Censori | 17 | https://cdn.sofifa.com/players/178/453/07_60.png | Italy | https://cdn.sofifa.com/flags/it.png | 28 | 38 | Arezzo | https://cdn.sofifa.com/teams/110907/30.png | ... | NaN | 7.0 | 1.0 | 36.0 | 6.0 | 9.0 | ST | 36.0 | NaN | NaN | . 16710 rows × 63 columns . 교수님 Answer | . df.iloc[:,map(lambda x: &#39;Loaned From&#39; != x and &#39;Marking&#39; != x ,df.columns )] . ID Name Age Photo Nationality Flag Overall Potential Club Club Logo ... SlidingTackle GKDiving GKHandling GKKicking GKPositioning GKReflexes Best Position Best Overall Rating Release Clause DefensiveAwareness . 0 212198 | Bruno Fernandes | 26 | https://cdn.sofifa.com/players/212/198/22_60.png | Portugal | https://cdn.sofifa.com/flags/pt.png | 88 | 89 | Manchester United | https://cdn.sofifa.com/teams/11/30.png | ... | 65.0 | 12.0 | 14.0 | 15.0 | 8.0 | 14.0 | CAM | 88.0 | €206.9M | 72.0 | . 1 209658 | L. Goretzka | 26 | https://cdn.sofifa.com/players/209/658/22_60.png | Germany | https://cdn.sofifa.com/flags/de.png | 87 | 88 | FC Bayern München | https://cdn.sofifa.com/teams/21/30.png | ... | 77.0 | 13.0 | 8.0 | 15.0 | 11.0 | 9.0 | CM | 87.0 | €160.4M | 74.0 | . 2 176580 | L. Suárez | 34 | https://cdn.sofifa.com/players/176/580/22_60.png | Uruguay | https://cdn.sofifa.com/flags/uy.png | 88 | 88 | Atlético de Madrid | https://cdn.sofifa.com/teams/240/30.png | ... | 38.0 | 27.0 | 25.0 | 31.0 | 33.0 | 37.0 | ST | 88.0 | €91.2M | 42.0 | . 3 192985 | K. De Bruyne | 30 | https://cdn.sofifa.com/players/192/985/22_60.png | Belgium | https://cdn.sofifa.com/flags/be.png | 91 | 91 | Manchester City | https://cdn.sofifa.com/teams/10/30.png | ... | 53.0 | 15.0 | 13.0 | 5.0 | 10.0 | 13.0 | CM | 91.0 | €232.2M | 68.0 | . 4 224334 | M. Acuña | 29 | https://cdn.sofifa.com/players/224/334/22_60.png | Argentina | https://cdn.sofifa.com/flags/ar.png | 84 | 84 | Sevilla FC | https://cdn.sofifa.com/teams/481/30.png | ... | 82.0 | 8.0 | 14.0 | 13.0 | 13.0 | 14.0 | LB | 84.0 | €77.7M | 80.0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 16705 240558 | 18 L. Clayton | 17 | https://cdn.sofifa.com/players/240/558/18_60.png | England | https://cdn.sofifa.com/flags/gb-eng.png | 53 | 70 | Cheltenham Town | https://cdn.sofifa.com/teams/1936/30.png | ... | 12.0 | 55.0 | 54.0 | 52.0 | 50.0 | 59.0 | GK | 52.0 | €238K | NaN | . 16706 262846 | �. Dobre | 20 | https://cdn.sofifa.com/players/262/846/22_60.png | Romania | https://cdn.sofifa.com/flags/ro.png | 53 | 63 | FC Academica Clinceni | https://cdn.sofifa.com/teams/113391/30.png | ... | 12.0 | 57.0 | 52.0 | 53.0 | 48.0 | 58.0 | GK | 53.0 | €279K | 5.0 | . 16707 241317 | 21 Xue Qinghao | 19 | https://cdn.sofifa.com/players/241/317/21_60.png | China PR | https://cdn.sofifa.com/flags/cn.png | 47 | 60 | Shanghai Shenhua FC | https://cdn.sofifa.com/teams/110955/30.png | ... | 9.0 | 49.0 | 48.0 | 45.0 | 38.0 | 52.0 | GK | 47.0 | €223K | 21.0 | . 16708 259646 | A. Shaikh | 18 | https://cdn.sofifa.com/players/259/646/22_60.png | India | https://cdn.sofifa.com/flags/in.png | 47 | 67 | ATK Mohun Bagan FC | https://cdn.sofifa.com/teams/113146/30.png | ... | 13.0 | 49.0 | 41.0 | 39.0 | 45.0 | 49.0 | GK | 47.0 | €259K | 7.0 | . 16709 178453 | 07 A. Censori | 17 | https://cdn.sofifa.com/players/178/453/07_60.png | Italy | https://cdn.sofifa.com/flags/it.png | 28 | 38 | Arezzo | https://cdn.sofifa.com/teams/110907/30.png | ... | NaN | 7.0 | 1.0 | 36.0 | 6.0 | 9.0 | ST | 36.0 | NaN | NaN | . 16710 rows × 63 columns . (c) (b)&#51032; &#44208;&#44284;&#50640; .dropna()&#47484; &#49324;&#50857;&#54616;&#50668; &#44208;&#52769;&#52824;&#47484; &#51228;&#44144;&#54616;&#45716; &#53076;&#46300;&#47484; &#51089;&#49457;&#54616;&#46972;. &#47751;&#44060;&#51032; &#44208;&#52769;&#52824;&#44032; &#51228;&#44144;&#46104;&#50632;&#45716;&#44032;? . 내 Answer | . len(df.drop([&#39;Loaned From&#39;,&#39;Marking&#39;],axis=1))-len(df.drop([&#39;Loaned From&#39;,&#39;Marking&#39;],axis=1).dropna()) . 2312 . 교수님 Answer | . df.iloc[:,map(lambda x: &#39;Loaned From&#39; != x and &#39;Marking&#39; != x ,df.columns )].dropna() . ID Name Age Photo Nationality Flag Overall Potential Club Club Logo ... SlidingTackle GKDiving GKHandling GKKicking GKPositioning GKReflexes Best Position Best Overall Rating Release Clause DefensiveAwareness . 0 212198 | Bruno Fernandes | 26 | https://cdn.sofifa.com/players/212/198/22_60.png | Portugal | https://cdn.sofifa.com/flags/pt.png | 88 | 89 | Manchester United | https://cdn.sofifa.com/teams/11/30.png | ... | 65.0 | 12.0 | 14.0 | 15.0 | 8.0 | 14.0 | CAM | 88.0 | €206.9M | 72.0 | . 1 209658 | L. Goretzka | 26 | https://cdn.sofifa.com/players/209/658/22_60.png | Germany | https://cdn.sofifa.com/flags/de.png | 87 | 88 | FC Bayern München | https://cdn.sofifa.com/teams/21/30.png | ... | 77.0 | 13.0 | 8.0 | 15.0 | 11.0 | 9.0 | CM | 87.0 | €160.4M | 74.0 | . 2 176580 | L. Suárez | 34 | https://cdn.sofifa.com/players/176/580/22_60.png | Uruguay | https://cdn.sofifa.com/flags/uy.png | 88 | 88 | Atlético de Madrid | https://cdn.sofifa.com/teams/240/30.png | ... | 38.0 | 27.0 | 25.0 | 31.0 | 33.0 | 37.0 | ST | 88.0 | €91.2M | 42.0 | . 3 192985 | K. De Bruyne | 30 | https://cdn.sofifa.com/players/192/985/22_60.png | Belgium | https://cdn.sofifa.com/flags/be.png | 91 | 91 | Manchester City | https://cdn.sofifa.com/teams/10/30.png | ... | 53.0 | 15.0 | 13.0 | 5.0 | 10.0 | 13.0 | CM | 91.0 | €232.2M | 68.0 | . 4 224334 | M. Acuña | 29 | https://cdn.sofifa.com/players/224/334/22_60.png | Argentina | https://cdn.sofifa.com/flags/ar.png | 84 | 84 | Sevilla FC | https://cdn.sofifa.com/teams/481/30.png | ... | 82.0 | 8.0 | 14.0 | 13.0 | 13.0 | 14.0 | LB | 84.0 | €77.7M | 80.0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 16703 259718 | F. Gebhardt | 19 | https://cdn.sofifa.com/players/259/718/22_60.png | Germany | https://cdn.sofifa.com/flags/de.png | 52 | 66 | FC Basel 1893 | https://cdn.sofifa.com/teams/896/30.png | ... | 10.0 | 53.0 | 45.0 | 47.0 | 52.0 | 57.0 | GK | 52.0 | €361K | 6.0 | . 16704 251433 | B. Voll | 20 | https://cdn.sofifa.com/players/251/433/22_60.png | Germany | https://cdn.sofifa.com/flags/de.png | 58 | 69 | F.C. Hansa Rostock | https://cdn.sofifa.com/teams/27/30.png | ... | 10.0 | 59.0 | 60.0 | 56.0 | 55.0 | 61.0 | GK | 58.0 | €656K | 5.0 | . 16706 262846 | �. Dobre | 20 | https://cdn.sofifa.com/players/262/846/22_60.png | Romania | https://cdn.sofifa.com/flags/ro.png | 53 | 63 | FC Academica Clinceni | https://cdn.sofifa.com/teams/113391/30.png | ... | 12.0 | 57.0 | 52.0 | 53.0 | 48.0 | 58.0 | GK | 53.0 | €279K | 5.0 | . 16707 241317 | 21 Xue Qinghao | 19 | https://cdn.sofifa.com/players/241/317/21_60.png | China PR | https://cdn.sofifa.com/flags/cn.png | 47 | 60 | Shanghai Shenhua FC | https://cdn.sofifa.com/teams/110955/30.png | ... | 9.0 | 49.0 | 48.0 | 45.0 | 38.0 | 52.0 | GK | 47.0 | €223K | 21.0 | . 16708 259646 | A. Shaikh | 18 | https://cdn.sofifa.com/players/259/646/22_60.png | India | https://cdn.sofifa.com/flags/in.png | 47 | 67 | ATK Mohun Bagan FC | https://cdn.sofifa.com/teams/113146/30.png | ... | 13.0 | 49.0 | 41.0 | 39.0 | 45.0 | 49.0 | GK | 47.0 | €259K | 7.0 | . 14398 rows × 63 columns . print(str(16710-14398),&#39;개가 제거되었다.&#39;) . 2312 개가 제거되었다. . (d) (c)&#51032; &#44208;&#44284;&#50640; &#50500;&#47000;&#51032; &#53076;&#46300;&#47484; &#54876;&#50857;&#54616;&#50668; Wage&#51032; &#44050;&#51012; &#51201;&#51208;&#54616;&#44172; &#48320;&#54872;&#54616;&#46972;. . ### 코드1 def convert_currency(value): floatvalue = 0.0 strvalue=&quot;&quot; if &quot;M&quot; in value: strvalue=value.replace(&quot;M&quot;,&quot;&quot;).replace(&quot;€&quot;,&quot;&quot;) floatvalue=float(float(strvalue)*1000000) elif &quot;K&quot; in value: strvalue=value.replace(&quot;K&quot;,&quot;&quot;).replace(&quot;€&quot;,&quot;&quot;) floatvalue=float(float(strvalue)*1000) else: floatvalue=value.replace(&quot;€&quot;,&quot;&quot;) return floatvalue . 코드출처: https://www.kaggle.com/talhademirezen/cost-effective-youth-players-fifa22 | . 교수님 Answer | . def convert_currency(value): floatvalue = 0.0 strvalue=&quot;&quot; if &quot;M&quot; in value: strvalue=value.replace(&quot;M&quot;,&quot;&quot;).replace(&quot;€&quot;,&quot;&quot;) floatvalue=float(float(strvalue)*1000000) elif &quot;K&quot; in value: strvalue=value.replace(&quot;K&quot;,&quot;&quot;).replace(&quot;€&quot;,&quot;&quot;) floatvalue=float(float(strvalue)*1000) else: floatvalue=value.replace(&quot;€&quot;,&quot;&quot;) return floatvalue . df=df.iloc[:,map(lambda x: &#39;Loaned From&#39; != x and &#39;Marking&#39; != x ,df.columns )].dropna() df[&#39;Wage&#39;]=list(map(convert_currency,df.Wage)) . (e) &#50500;&#47000;&#51032; &#49464;&#48512;&#49324;&#54637;&#50640; &#47582;&#52656;&#49436; Best Position&#50640; &#46384;&#47480; &#49884;&#51109;&#44032;&#52824;(Value)&#51032; &#54217;&#44512;&#51012; barplot&#51012; &#51060;&#50857;&#54616;&#50668; &#49884;&#44033;&#54868; &#54616;&#46972;. . x축을 Best Position으로 하고 y축은 Value의 평균으로 할 것 | Value가 가장 높은 3개의 포지션을 다른색으로 하이라이팅 할 것 | . 시각화예시 . 교수님 Answer | . df[&#39;Value&#39;]=list(map(convert_currency,df.Value)) . import numpy as np . _df=df.groupby(&#39;Best Position&#39;).agg({&#39;Value&#39;:np.mean}) .rename(columns={&#39;Value&#39;:&#39;mean(Value)&#39;}) .sort_values(&#39;mean(Value)&#39;,ascending=False) .reset_index() _df[&#39;Highlight&#39;]=_df[&#39;mean(Value)&#39;]&gt;=_df[&#39;mean(Value)&#39;][2] _df . Best Position mean(Value) Highlight . 0 CF | 9.122222e+06 | True | . 1 LW | 6.443137e+06 | True | . 2 CM | 5.630414e+06 | True | . 3 CAM | 4.356162e+06 | False | . 4 RW | 3.977832e+06 | False | . 5 CDM | 3.539740e+06 | False | . 6 LWB | 3.451340e+06 | False | . 7 LM | 3.439977e+06 | False | . 8 ST | 3.295080e+06 | False | . 9 RB | 3.203283e+06 | False | . 10 LB | 3.051887e+06 | False | . 11 CB | 3.038834e+06 | False | . 12 RWB | 3.023522e+06 | False | . 13 GK | 2.703686e+06 | False | . 14 RM | 2.550153e+06 | False | . from plotnine import * . ggplot(_df)+geom_bar(aes(x=&#39;Best Position&#39;,y=&#39;mean(Value)&#39;,fill=&#39;Highlight&#39;),stat=&#39;identity&#39;) . &lt;ggplot: (8791507800552)&gt; . 내 Answer | . df3=df.groupby(by=&#39;Best Position&#39;).agg({&#39;Value&#39;:np.mean}).rename(columns={&#39;Value&#39;:&#39;mean(Value)&#39;}).reset_index() def f(x): if x==&#39;CF&#39;:y=&#39;True&#39; elif x==&#39;CM&#39;:y=&#39;True&#39; elif x==&#39;LW&#39;:y=&#39;True&#39; else: y=&#39;False&#39; return y df3[&#39;Bp&#39;]=df3[&#39;Best Position&#39;] df3[&#39;Hightlight&#39;]=list(map(f,df3.Bp)) ggplot(df3)+geom_bar(aes(x=&#39;Best Position&#39;,y=&#39;mean(Value)&#39;,color=&#39;Hightlight&#39;,fill=&#39;Hightlight&#39;),stat=&#39;identity&#39;) . &lt;ggplot: (8791507709085)&gt; . (f) &#50500;&#47000;&#51032; &#49464;&#48512;&#49324;&#54637;&#50640; &#47582;&#52628;&#50612; (Dribbling,SlidingTackle)&#51032; &#49328;&#51216;&#46020;&#47484; &#44536;&#47140;&#46972;. . 세부사항 . (i) Best Position의 값을 바탕으로 면분할을 하라. . (ii) Age를 색으로 표현하라. . (iii) 산점도의 투명도는 alpha=0.5로 size=0.5로 설정할 것. . ggplot(df) +geom_point(aes(x=&#39;Dribbling&#39;,y=&#39;SlidingTackle&#39;,color=&#39;Age&#39;),alpha=0.5,size=0.5) +facet_wrap(&#39;Best Position&#39;) . &lt;ggplot: (8777787744886)&gt; . (g) (f)&#51032; &#44536;&#47548;&#51012; &#50732;&#48148;&#47476;&#44172; &#54644;&#49437;&#54620; &#49324;&#46988;&#51008;? . (하니) 포지션 GK에 있는 선수는 Dribbling, SlidingTackle 값이 다른포지션대비 상대적으로 낮다. . (나애리) 모든 포지션에서 Dribbling, SlidingTackle은 서로 독립이라 볼 수 있다. . (홍두깨) 포지션 CAM은 나이와 Dribbling 사이에 양의 상관관계에 있다. . (고은애) 포지션 CB은 나이와 Dribbling 사이에 상관계수가 거의 0이다. . Answer: 하니, 홍두깨, 고은애 | . (h) Best Position&#51060; &quot;CAM&quot; &#54841;&#51008; &quot;CB&quot;&#51064; &#54540;&#47112;&#51060;&#50612;&#47564; &#44264;&#46972;&#49436; (Dribbling,SlidingTackle)&#51032; &#49328;&#51216;&#46020;&#47484; &#44536;&#47140;&#46972;. . 세부사항 . x축: Dribbling, y축: SlidingTackle 로 설정 | Value에 따라 점의 크기를 다르게 설정 | 나이에 따라 색깔을 다르게 설정 | . 시각화예시 . 교수님 Answer | . ggplot(df.loc[(df[&#39;Best Position&#39;]==&#39;CAM&#39;) |(df[&#39;Best Position&#39;]==&#39;CB&#39;)]) +geom_point(aes(x=&#39;Dribbling&#39;,y=&#39;SlidingTackle&#39;,color=&#39;Age&#39;,size=&#39;Value&#39;),alpha=0.5) +facet_wrap(&#39;Best Position&#39;) . &lt;ggplot: (8777787037434)&gt; . 내 Answer | . a=df.groupby(by=&#39;Best Position&#39;).get_group(&#39;CAM&#39;) b=df.groupby(by=&#39;Best Position&#39;).get_group(&#39;CB&#39;) c=pd.concat([a,b]) ggplot(c)+geom_point(aes(x=&#39;Dribbling&#39;,y=&#39;SlidingTackle&#39;,color=&#39;Age&#39;,size=&#39;Value&#39;),alpha=0.3)+facet_wrap(&#39;Best Position&#39;) . &lt;ggplot: (8791508078189)&gt; . (i) &#44536;&#47548; (h)&#47484; &#50732;&#48148;&#47476;&#44172; &#54644;&#49437;&#54620;&#44163;&#51012; &#47784;&#46160; &#44256;&#47476;&#46972;. . (하니) AGE와 Value는 양의 상관관계에 있다. . (나애리) 따라서 축구선수는 AGE가 증가함 따라 Value가 올라가는 것을 알 수 있다. 즉 AGE와 Value사이에는 인과성이 있다. . (홍두깨) 포지션 CAM은 Dribbiling 능력과 Value가 양의 상관관계에 있어보인다. . (고은애) 반면에 포지션 CB는 Dribbling 능력보다는 SlidingTackle이 Value와 양의 상관관계에 있다고 볼 수 있다. . Answer: 하니, 홍두깨, 고은애 | . 6. &#54616;&#45768;&#51032; &#49328;&#52293;&#44221;&#47196; (40&#51216;) . 공원에서 뛰는것을 좋아하는 강아지 하니가 있다. 아래는 강아지 하니가 주인과 함께 공원을 산책한 경로이다. 산책코스는 아래와 같이 집에서 공원으로 가는 A코스와 공원에서 집으로 오는 B코스로 나누어진다. . - A코스: 집 $ to$ 카페 $ to$ 초등학교 정문 $ to$ 공원 . - B코스: 공원 $ to$ 초등학교 후문 $ to$ 동물병원 $ to$ 집 . 각 위치의 좌표는 아래와 같다. . 집: (0,0) | 카페: (1,2) | 초등학교 정문: (4,3) | 공원: (5,5) | 초등학교 후문: (4.1,3) | 동물병원: (1,0.5) | . 집에서 출발시에 하니의 체력은 100이며, 각 중간지점에서 하니의 체력은 이동거리에 비례하여 감소한다고 하자. 예를들어 A코스-카페에서 하니의 체력은 아래와 같이 계산할 수 있다. . $100- sqrt{1^2+2^2}$ | . 또한 하니는 공원정문에서 달리기를 시작하였고 이후에 60의 체력을 소진한뒤 공원후문에 도착하였다고 하자. (즉 공원정문에서하니의 체력이 $x$ 라면 공원후문에서 하니의 체력은 $x-60$ 이다.) . 하니의 이동경로에 따른 체력의 변화를 시각화 하라. . (풀이) . 내 Answer | . x=[0,1,4,5,5,4.1,1,0] y=[0,2,3,5,5,3,0.5,0] . def inc(x,y): return x**2+y**2 . def f(x,y): if x==&#39;B&#39;: y=y-70 elif x==&#39;A&#39;: y=y return y . g=np.sqrt(np.array(list(map(inc,x,y)))) g1=100-np.array(g.cumsum()) course=[&#39;A&#39;]*4+[&#39;B&#39;]*4 . df1=pd.DataFrame({&#39;x&#39;:x,&#39;y&#39;:y,&#39;g1&#39;:g1,&#39;course&#39;:course}) df1 . x y g1 course . 0 0.0 | 0.0 | 100.000000 | A | . 1 1.0 | 2.0 | 97.763932 | A | . 2 4.0 | 3.0 | 92.763932 | A | . 3 5.0 | 5.0 | 85.692864 | A | . 4 5.0 | 5.0 | 78.621796 | B | . 5 4.1 | 3.0 | 73.541442 | B | . 6 1.0 | 0.5 | 72.423408 | B | . 7 0.0 | 0.0 | 72.423408 | B | . def f(x,y): if x==&#39;B&#39;: y=y-70+50**0.5 elif x==&#39;A&#39;: y=y return y . df1[&#39;stamina&#39;]=list(map(f,df1.course,df1.g1)) df1 . x y g1 course stamina . 0 0.0 | 0.0 | 100.000000 | A | 100.000000 | . 1 1.0 | 2.0 | 97.763932 | A | 97.763932 | . 2 4.0 | 3.0 | 92.763932 | A | 92.763932 | . 3 5.0 | 5.0 | 85.692864 | A | 85.692864 | . 4 5.0 | 5.0 | 78.621796 | B | 15.692864 | . 5 4.1 | 3.0 | 73.541442 | B | 10.612510 | . 6 1.0 | 0.5 | 72.423408 | B | 9.494476 | . 7 0.0 | 0.0 | 72.423408 | B | 9.494476 | . ggplot(df1)+geom_line(aes(x=&#39;x&#39;,y=&#39;y&#39;,size=&#39;stamina&#39;,color=&#39;course&#39;))+geom_point(aes(x=&#39;x&#39;,y=&#39;y&#39;)) . &lt;ggplot: (8791507421365)&gt; . 교수님 Answer | . x=[0, 1, 4, 5, 5, 4.1, 1, 0] y=[0, 2, 3, 5, 5, 3, 0.5, 0] course=[&#39;A&#39;]*4 + [&#39;B&#39;]*4 _delta=[np.sqrt((x[i]-x[i-1])**2+(y[i]-y[i-1])**2)for i in range(len(x))] stamina = np.array([100,100,100,100, 40, 40, 40, 40]) - [sum(_delta[:(i+1)]) for i in range(8)] . ggplot(pd.DataFrame({&#39;x&#39;:x, &#39;y&#39;:y, &#39;course&#39;:course, &#39;stamina&#39;:stamina}))+ geom_point(aes(x=&#39;x&#39;,y=&#39;y&#39;))+ geom_line(aes(x=&#39;x&#39;,y=&#39;y&#39;,size=&#39;stamina&#39;,color=&#39;course&#39;)) . &lt;ggplot: (8777787037395)&gt; . 7. &#48712;&#52856;&#50640; &#51201;&#51208;&#54620; &#44050;&#51012; &#52292;&#50892; &#49900;&#49832;&#51032; &#50669;&#49444;&#51012; &#49444;&#47749;&#54616;&#45716; &#50696;&#51228;&#47484; &#50756;&#49457;&#54616;&#44256; &#49884;&#44033;&#54868; &#54616;&#46972;. (30&#51216;) . 다음은 농구선수 A,B의 시즌별 자유투 성공률이다. . 시즌1 시즌2 . A선수 | 7/10 | 999999/1000000 | . B선수 | 8/10 | 4/4 | . 표안의 값은 성공횟수/총자유투시도 | . ?에 적절한 값을 채워 시즌 1,2 모두 B선수의 자유투 성공률이 높지만 시즌1-2를 전체 합치면 A선수의 자유투 성공률이 더 높도록 하라. (즉 ?에 적절한 값을 채워 심슨의 역설을 설명하기 위한 자료를 구성하라.) . 만들어진 자료를 바탕으로 심슨의 역설을 시각화하라. (즉 시즌 1,2의 자유투 성공률과 전체 자유투 성공률을 barplot으로 시각화하라) . ref: https://books.google.co.kr/books?id=qy4iEAAAQBAJ&amp;pg=PT87&amp;lpg=PT87&amp;dq=%EC%95%84%EC%9D%B4%EC%8A%A4%ED%81%AC%EB%A6%BC%EC%9D%84+%EB%A7%8E%EC%9D%B4+%EB%A8%B9%EC%9C%BC%EB%A9%B4+%EA%B1%B8%EB%A6%AC%EB%8A%94+%EB%B3%91+%EC%86%8C%EC%95%84%EB%A7%88%EB%B9%84&amp;source=bl&amp;ots=V9B7ZG6oR-&amp;sig=ACfU3U0UMd4ehuRXYxI69TT6lIlU-r91bA&amp;hl=en&amp;sa=X&amp;ved=2ahUKEwj13JSV19LzAhVEGaYKHdgfDgcQ6AF6BAgCEAM#v=onepage&amp;q=%EC%95%84%EC%9D%B4%EC%8A%A4%ED%81%AC%EB%A6%BC%EC%9D%84%20%EB%A7%8E%EC%9D%B4%20%EB%A8%B9%EC%9C%BC%EB%A9%B4%20%EA%B1%B8%EB%A6%AC%EB%8A%94%20%EB%B3%91%20%EC%86%8C%EC%95%84%EB%A7%88%EB%B9%84&amp;f=false | . 내 Answer | . season=([&#39;season1&#39;]*2+[&#39;season2&#39;]*2+[&#39;season1&#39;]*2+[&#39;season2&#39;]*2) player=[&#39;A&#39;]*4+[&#39;B&#39;]*4 STATE=[&#39;WIN&#39;,&#39;LOSE&#39;]*4 COUNT=[7,3,999999,1,8,2,4,0] df=pd.DataFrame({&#39;season&#39;:season,&#39;STATE&#39;:STATE,&#39;player&#39;:player,&#39;COUNT&#39;:COUNT}) df . season STATE player COUNT . 0 season1 | WIN | A | 7 | . 1 season1 | LOSE | A | 3 | . 2 season2 | WIN | A | 999999 | . 3 season2 | LOSE | A | 1 | . 4 season1 | WIN | B | 8 | . 5 season1 | LOSE | B | 2 | . 6 season2 | WIN | B | 4 | . 7 season2 | LOSE | B | 0 | . _df1=df.groupby(by=[&#39;player&#39;,&#39;STATE&#39;]).agg({&#39;COUNT&#39;:np.sum}).reset_index() _df2=df.groupby(by=&#39;player&#39;).agg({&#39;COUNT&#39;:np.sum}).reset_index().rename(columns={&#39;COUNT&#39;:&#39;SUM&#39;}) td=pd.merge(_df1,_df2) td[&#39;PROP&#39;]=td.COUNT/td.SUM ggplot(td.query(&#39;STATE==&quot;WIN&quot;&#39;))+geom_bar(aes(x=&#39;player&#39;,y=&#39;PROP&#39;,fill=&#39;player&#39;),stat=&#39;identity&#39;) . &lt;ggplot: (8791507122740)&gt; . td=df.groupby([&#39;season&#39;,&#39;player&#39;]).agg({&#39;COUNT&#39;:sum}).reset_index().rename(columns={&#39;COUNT&#39;:&#39;SUM&#39;}).merge(df) td[&#39;PROP&#39;]=td.COUNT/td.SUM ggplot(td.query(&#39;STATE==&quot;WIN&quot;&#39;))+geom_bar(aes(x=&#39;player&#39;,y=&#39;PROP&#39;,fill=&#39;player&#39;),stat=&#39;identity&#39;)+facet_wrap(&#39;season&#39;) . &lt;ggplot: (8791507113397)&gt; .",
            "url": "https://seoyeonc.github.io/chch/2021/11/07/midsol.html",
            "relUrl": "/2021/11/07/midsol.html",
            "date": " • Nov 7, 2021"
        }
        
    
  
    
        ,"post5": {
            "title": "데이터시각화 특강 (6주차) 10월18일",
            "content": "&#54644;&#46308;&#47532;&#50948;&#52980; &#44536;&#47000;&#54532;&#47112;&#51060;&#50612; . import . import pandas as pd from plotnine import * . data . - ref: https://r4ds.had.co.nz/index.html . rpy2 . import rpy2 . %load_ext rpy2.ipython . %%R ### 여기는 R처럼 쓸 수 있다. a&lt;-c(1,2,3) a+1 . [1] 2 3 4 . a . NameError Traceback (most recent call last) /tmp/ipykernel_2170811/2167009006.py in &lt;module&gt; -&gt; 1 a NameError: name &#39;a&#39; is not defined . %%R library(tidyverse) mpg . R[write to console]: ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ── R[write to console]: ✔ ggplot2 3.3.5 ✔ purrr 0.3.4 ✔ tibble 3.1.3 ✔ dplyr 1.0.7 ✔ tidyr 1.1.3 ✔ stringr 1.4.0 ✔ readr 1.4.0 ✔ forcats 0.5.1 R[write to console]: ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── ✖ dplyr::filter() masks stats::filter() ✖ dplyr::lag() masks stats::lag() . # A tibble: 234 × 11 manufacturer model displ year cyl trans drv cty hwy fl class &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; 1 audi a4 1.8 1999 4 auto… f 18 29 p comp… 2 audi a4 1.8 1999 4 manu… f 21 29 p comp… 3 audi a4 2 2008 4 manu… f 20 31 p comp… 4 audi a4 2 2008 4 auto… f 21 30 p comp… 5 audi a4 2.8 1999 6 auto… f 16 26 p comp… 6 audi a4 2.8 1999 6 manu… f 18 26 p comp… 7 audi a4 3.1 2008 6 auto… f 18 27 p comp… 8 audi a4 quattro 1.8 1999 4 manu… 4 18 26 p comp… 9 audi a4 quattro 1.8 1999 4 auto… 4 16 25 p comp… 10 audi a4 quattro 2 2008 4 manu… 4 20 28 p comp… # … with 224 more rows . mpg . NameError Traceback (most recent call last) /tmp/ipykernel_2170811/602803287.py in &lt;module&gt; -&gt; 1 mpg NameError: name &#39;mpg&#39; is not defined . %R -o mpg # R에 있던 자료가 파이썬으로 넘어옴 . mpg . manufacturer model displ year cyl trans drv cty hwy fl class . 1 audi | a4 | 1.8 | 1999 | 4 | auto(l5) | f | 18 | 29 | p | compact | . 2 audi | a4 | 1.8 | 1999 | 4 | manual(m5) | f | 21 | 29 | p | compact | . 3 audi | a4 | 2.0 | 2008 | 4 | manual(m6) | f | 20 | 31 | p | compact | . 4 audi | a4 | 2.0 | 2008 | 4 | auto(av) | f | 21 | 30 | p | compact | . 5 audi | a4 | 2.8 | 1999 | 6 | auto(l5) | f | 16 | 26 | p | compact | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 230 volkswagen | passat | 2.0 | 2008 | 4 | auto(s6) | f | 19 | 28 | p | midsize | . 231 volkswagen | passat | 2.0 | 2008 | 4 | manual(m6) | f | 21 | 29 | p | midsize | . 232 volkswagen | passat | 2.8 | 1999 | 6 | auto(l5) | f | 16 | 26 | p | midsize | . 233 volkswagen | passat | 2.8 | 1999 | 6 | manual(m5) | f | 18 | 26 | p | midsize | . 234 volkswagen | passat | 3.6 | 2008 | 6 | auto(s6) | f | 17 | 26 | p | midsize | . 234 rows × 11 columns . &#51200;&#51109;&#46108; &#54028;&#51068;&#51012; &#53685;&#54616;&#50668; &#45936;&#51060;&#53552;&#47484; &#54869;&#48372; . mpg.to_csv(&quot;mpg.csv&quot;) . pd.read_csv(&quot;mpg.csv&quot;) # mpg = pd.read_csv(&quot;mpg.csv&quot;) . Unnamed: 0 manufacturer model displ year cyl trans drv cty hwy fl class . 0 1 | audi | a4 | 1.8 | 1999 | 4 | auto(l5) | f | 18 | 29 | p | compact | . 1 2 | audi | a4 | 1.8 | 1999 | 4 | manual(m5) | f | 21 | 29 | p | compact | . 2 3 | audi | a4 | 2.0 | 2008 | 4 | manual(m6) | f | 20 | 31 | p | compact | . 3 4 | audi | a4 | 2.0 | 2008 | 4 | auto(av) | f | 21 | 30 | p | compact | . 4 5 | audi | a4 | 2.8 | 1999 | 6 | auto(l5) | f | 16 | 26 | p | compact | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 229 230 | volkswagen | passat | 2.0 | 2008 | 4 | auto(s6) | f | 19 | 28 | p | midsize | . 230 231 | volkswagen | passat | 2.0 | 2008 | 4 | manual(m6) | f | 21 | 29 | p | midsize | . 231 232 | volkswagen | passat | 2.8 | 1999 | 6 | auto(l5) | f | 16 | 26 | p | midsize | . 232 233 | volkswagen | passat | 2.8 | 1999 | 6 | manual(m5) | f | 18 | 26 | p | midsize | . 233 234 | volkswagen | passat | 3.6 | 2008 | 6 | auto(s6) | f | 17 | 26 | p | midsize | . 234 rows × 12 columns . - 무언가 잘못되었다? . - 다시 저장하자. . mpg.to_csv(&quot;mpg.csv&quot;,index=False) . pd.read_csv(&quot;mpg.csv&quot;) # mpg=pd.read_csv(&quot;mpg.csv&quot;) . manufacturer model displ year cyl trans drv cty hwy fl class . 0 audi | a4 | 1.8 | 1999 | 4 | auto(l5) | f | 18 | 29 | p | compact | . 1 audi | a4 | 1.8 | 1999 | 4 | manual(m5) | f | 21 | 29 | p | compact | . 2 audi | a4 | 2.0 | 2008 | 4 | manual(m6) | f | 20 | 31 | p | compact | . 3 audi | a4 | 2.0 | 2008 | 4 | auto(av) | f | 21 | 30 | p | compact | . 4 audi | a4 | 2.8 | 1999 | 6 | auto(l5) | f | 16 | 26 | p | compact | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 229 volkswagen | passat | 2.0 | 2008 | 4 | auto(s6) | f | 19 | 28 | p | midsize | . 230 volkswagen | passat | 2.0 | 2008 | 4 | manual(m6) | f | 21 | 29 | p | midsize | . 231 volkswagen | passat | 2.8 | 1999 | 6 | auto(l5) | f | 16 | 26 | p | midsize | . 232 volkswagen | passat | 2.8 | 1999 | 6 | manual(m5) | f | 18 | 26 | p | midsize | . 233 volkswagen | passat | 3.6 | 2008 | 6 | auto(s6) | f | 17 | 26 | p | midsize | . 234 rows × 11 columns . 제대로 불러졌음 | . github&#46321;&#50640; &#44277;&#44060;&#46108; csv&#47484; &#51069;&#50612;&#50724;&#44592; . pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/2021DV/master/_notebooks/mpg.csv&#39;) # mpg=pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/2021DV/master/_notebooks/mpg.csv&#39;) . manufacturer model displ year cyl trans drv cty hwy fl class . 0 audi | a4 | 1.8 | 1999 | 4 | auto(l5) | f | 18 | 29 | p | compact | . 1 audi | a4 | 1.8 | 1999 | 4 | manual(m5) | f | 21 | 29 | p | compact | . 2 audi | a4 | 2.0 | 2008 | 4 | manual(m6) | f | 20 | 31 | p | compact | . 3 audi | a4 | 2.0 | 2008 | 4 | auto(av) | f | 21 | 30 | p | compact | . 4 audi | a4 | 2.8 | 1999 | 6 | auto(l5) | f | 16 | 26 | p | compact | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 229 volkswagen | passat | 2.0 | 2008 | 4 | auto(s6) | f | 19 | 28 | p | midsize | . 230 volkswagen | passat | 2.0 | 2008 | 4 | manual(m6) | f | 21 | 29 | p | midsize | . 231 volkswagen | passat | 2.8 | 1999 | 6 | auto(l5) | f | 16 | 26 | p | midsize | . 232 volkswagen | passat | 2.8 | 1999 | 6 | manual(m5) | f | 18 | 26 | p | midsize | . 233 volkswagen | passat | 3.6 | 2008 | 6 | auto(s6) | f | 17 | 26 | p | midsize | . 234 rows × 11 columns . - 깃허브 저장소에 아예 데이터만 따로 모아서 관리하는 것도 좋은 방법입니다. . - Visual Studio Code깔면 바로 쥬피터 코드 볼 수 있음 . data &#49444;&#47749; . - displ: 자동차의 엔진크기 . - hwy: 연료의 효율, 동일한 연료로 얼마나 멀리 가느냐? . - 자세한 설명은 R에서 ?mpg로 알아볼것 . &#44592;&#48376;&#49328;&#51216;&#46020; (2&#52264;&#50896;) . ggplot(data = mpg) + geom_point(mapping = aes(x = &quot;displ&quot;, y = &quot;hwy&quot;)) ## plotnine . &lt;ggplot: (8773810655413)&gt; . 산점도: 엔진크기와 연료효율은 반비례. (엔진이 큰 차일수록 연비가 좋지 않다) | . - ggplot2를 이용한 산점도 . %%R -w 800 ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy)) ## 진짜 ggplot에서 그릴때에는 변수이름에 &quot;&quot; 를 제거함 . - 객체지향적인 느낌으로 산점도 그리기 . step1: 도화지를 준비한다 . fig=ggplot(data=mpg) fig . &lt;ggplot: (8773810615616)&gt; . step2: 변수와 에스테틱사이의 맵핑을 설정한다. . a1=aes(x=&#39;displ&#39;,y=&#39;hwy&#39;) a1 . {&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;} . step3: 점들의 집합을 만든다. 즉 포인트지옴을 만든다. . point1=geom_point(mapping=a1) . geom_point(): 점들을 그려! 어떻게? | a1에서 설정된 표를 보고 | . step4: 도화지와 지옴을 합친다. . fig+point1 . &lt;ggplot: (8773810011612)&gt; . - 빠르게 그리기: mapping = 와 data=는 생략가능함 . ggplot(mpg) + geom_point(aes(x = &quot;displ&quot;, y = &quot;hwy&quot;)) ## plotnine . &lt;ggplot: (8773809969372)&gt; . &#49328;&#51216;&#46020;&#51025;&#50857; (3&#52264;&#50896;) . - 데이터를 다시관찰 . mpg.head() . manufacturer model displ year cyl trans drv cty hwy fl class . 0 audi | a4 | 1.8 | 1999 | 4 | auto(l5) | f | 18 | 29 | p | compact | . 1 audi | a4 | 1.8 | 1999 | 4 | manual(m5) | f | 21 | 29 | p | compact | . 2 audi | a4 | 2.0 | 2008 | 4 | manual(m6) | f | 20 | 31 | p | compact | . 3 audi | a4 | 2.0 | 2008 | 4 | auto(av) | f | 21 | 30 | p | compact | . 4 audi | a4 | 2.8 | 1999 | 6 | auto(l5) | f | 16 | 26 | p | compact | . - class도 함께 plot에 표시하면 데이터를 탐색할때 좀 더 좋을것 같다. . &#49328;&#51216;&#46020; + &#51216;&#53356;&#44592;&#48320;&#44221; . ggplot(data=mpg)+ geom_point(mapping=aes(x=&#39;displ&#39;,y=&#39;hwy&#39;,size= &#39;class&#39;)) . /home/cgb4/anaconda3/envs/csy/lib/python3.8/site-packages/plotnine/scales/scale_size.py:48: PlotnineWarning: Using size for a discrete variable is not advised. . &lt;ggplot: (8773809915974)&gt; . &#49328;&#51216;&#46020; + &#53804;&#47749;&#46020;&#48320;&#44221; . ggplot(data=mpg)+ geom_point(mapping=aes(x=&#39;displ&#39;,y=&#39;hwy&#39;,alpha= &#39;class&#39;)) . /home/cgb4/anaconda3/envs/csy/lib/python3.8/site-packages/plotnine/scales/scale_alpha.py:68: PlotnineWarning: Using alpha for a discrete variable is not advised. . &lt;ggplot: (8773810049663)&gt; . ggplot(data=mpg)+ geom_point(mapping=aes(x=&#39;displ&#39;,y=&#39;hwy&#39;,size= &#39;class&#39;,alpha=&#39;class&#39;)) . /home/cgb4/anaconda3/envs/csy/lib/python3.8/site-packages/plotnine/scales/scale_size.py:48: PlotnineWarning: Using size for a discrete variable is not advised. /home/cgb4/anaconda3/envs/csy/lib/python3.8/site-packages/plotnine/scales/scale_alpha.py:68: PlotnineWarning: Using alpha for a discrete variable is not advised. . &lt;ggplot: (8773809838635)&gt; . &#49328;&#51216;&#46020; + &#54805;&#53468; . ggplot(data=mpg)+ geom_point(mapping=aes(x=&#39;displ&#39;,y=&#39;hwy&#39;,shape=&#39;class&#39;)) . &lt;ggplot: (8773809789236)&gt; . &#49328;&#51216;&#46020; + &#49353;&#44628; . ggplot(data=mpg)+ geom_point(mapping=aes(x=&#39;displ&#39;,y=&#39;hwy&#39;,color=&#39;class&#39;)) . &lt;ggplot: (8773809784652)&gt; . - 객체지향적으로? . a2=aes(x=&#39;displ&#39;,y=&#39;hwy&#39;,color=&#39;class&#39;) . a1,a2 . ({&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;}, {&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;, &#39;color&#39;: &#39;class&#39;}) . point2=geom_point(a2) . fig+point2 . &lt;ggplot: (8773809974459)&gt; . &#51648;&#50740;&#51012; &#45908; &#52628;&#44032; (&#51201;&#54633;&#49440;) . fig+point1 . &lt;ggplot: (8773803889451)&gt; . sline1=geom_smooth(a1) . fig+point1+sline1 . /home/cgb4/anaconda3/envs/csy/lib/python3.8/site-packages/plotnine/stats/smoothers.py:310: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings. . &lt;ggplot: (8773803889445)&gt; . fig+point2+sline1 . /home/cgb4/anaconda3/envs/csy/lib/python3.8/site-packages/plotnine/stats/smoothers.py:310: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings. . &lt;ggplot: (8773803810157)&gt; . - 명령어로 한번에 그리기 . ggplot(data=mpg)+geom_point(mapping=aes(x=&#39;displ&#39;,y=&#39;hwy&#39;,color=&#39;class&#39;))+geom_smooth(mapping=aes(x=&#39;displ&#39;,y=&#39;hwy&#39;)) . /home/cgb4/anaconda3/envs/csy/lib/python3.8/site-packages/plotnine/stats/smoothers.py:310: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings. . &lt;ggplot: (8773803755331)&gt; . - 공통적인 맵핑규칙은 ggplot()쪽으로 빼기도 한다. (figure를 선언하는 곳에서 공통으로 선언함) . ggplot(data=mpg,mapping=aes(x=&#39;displ&#39;,y=&#39;hwy&#39;))+geom_point(mapping=aes(color=&#39;class&#39;))+geom_smooth() . /home/cgb4/anaconda3/envs/csy/lib/python3.8/site-packages/plotnine/stats/smoothers.py:310: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings. . &lt;ggplot: (8773803734658)&gt; . - R에서는 confidence interval도 geom_smooth()를 이용하여 확인할 수 있다. . %%R -w 800 ggplot(data=mpg,mapping=aes(x=displ,y=hwy))+geom_point(mapping=aes(color=class))+geom_smooth() . R[write to console]: `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; . &#49328;&#51216;&#46020;&#51025;&#50857;2 (4&#52264;&#50896;) . - 데이터를 살펴보자. . mpg.head() . manufacturer model displ year cyl trans drv cty hwy fl class . 0 audi | a4 | 1.8 | 1999 | 4 | auto(l5) | f | 18 | 29 | p | compact | . 1 audi | a4 | 1.8 | 1999 | 4 | manual(m5) | f | 21 | 29 | p | compact | . 2 audi | a4 | 2.0 | 2008 | 4 | manual(m6) | f | 20 | 31 | p | compact | . 3 audi | a4 | 2.0 | 2008 | 4 | auto(av) | f | 21 | 30 | p | compact | . 4 audi | a4 | 2.8 | 1999 | 6 | auto(l5) | f | 16 | 26 | p | compact | . - drv (전륜, 후륜, 4륜 구동)에 따라서 데이터를 시각화 하고 싶다. . ggplot(data=mpg,mapping=aes(x=&#39;displ&#39;,y=&#39;hwy&#39;))+geom_point(mapping=aes(size=&#39;class&#39;,color=&#39;drv&#39;),alpha=0.2) . /home/cgb4/anaconda3/envs/csy/lib/python3.8/site-packages/plotnine/scales/scale_size.py:48: PlotnineWarning: Using size for a discrete variable is not advised. . &lt;ggplot: (8773803683777)&gt; . 모든 $x$에 대하여 붉은색 점들이 대부분 초록선과 보라색 점들에 비하여 아래쪽에 위치하여 있음 $ to$ 4륜구동방식이 연비가 좋지 않음 | . - 객체지향적 . a1,a2 . ({&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;}, {&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;, &#39;color&#39;: &#39;class&#39;}) . a3=a2.copy() # 다른 주소 -&gt; 메모리를 더 많이 써서 약간 비효율적.. . id(a1),id(a2),id(a3) # 주소를 알려주는 코드 . (140380960625184, 140380956739040, 140380861881376) . a1,a2,a3 . ({&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;}, {&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;, &#39;color&#39;: &#39;class&#39;}, {&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;, &#39;color&#39;: &#39;class&#39;}) . a3[&#39;color&#39;]=&#39;drv&#39; a3[&#39;size&#39;]=&#39;class&#39; . a1,a2,a3 # 물론 원래 하던대로 # a3=aes(x=&#39;displ&#39;,y=&#39;hwy&#39;,color=&#39;drv&#39;,size=&#39;class&#39;) 가능~ . ({&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;}, {&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;, &#39;color&#39;: &#39;class&#39;}, {&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;, &#39;color&#39;: &#39;drv&#39;, &#39;size&#39;: &#39;class&#39;}) . 아래와 같이 선언해도 괜찮음 a3=aes(x=&#39;displ&#39;,y=&#39;hwy&#39;,color=&#39;drv&#39;,size=&#39;class&#39;) . | . point3=geom_point(a3) . fig+point3 . /home/cgb4/anaconda3/envs/csy/lib/python3.8/site-packages/plotnine/scales/scale_size.py:48: PlotnineWarning: Using size for a discrete variable is not advised. . &lt;ggplot: (8773803649958)&gt; . 앗 투명도 조절 | . point3=geom_point(a3,alpha=0.2) fig+point3 . /home/cgb4/anaconda3/envs/csy/lib/python3.8/site-packages/plotnine/scales/scale_size.py:48: PlotnineWarning: Using size for a discrete variable is not advised. . &lt;ggplot: (8773803810488)&gt; . - 여기에 선을 추가하여 보자. . fig+point3+sline1 . /home/cgb4/anaconda3/envs/csy/lib/python3.8/site-packages/plotnine/scales/scale_size.py:48: PlotnineWarning: Using size for a discrete variable is not advised. /home/cgb4/anaconda3/envs/csy/lib/python3.8/site-packages/plotnine/stats/smoothers.py:310: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings. . &lt;ggplot: (8773803890258)&gt; . - 각 그룹별로 선을 따로 그릴수도 있을까? . a1,a2,a3 . ({&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;}, {&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;, &#39;color&#39;: &#39;class&#39;}, {&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;, &#39;color&#39;: &#39;drv&#39;, &#39;size&#39;: &#39;class&#39;}) . a4=a2.copy() . a4[&#39;color&#39;]=&#39;drv&#39; . sline2=geom_smooth(a4) . fig+sline2+point3 . /home/cgb4/anaconda3/envs/csy/lib/python3.8/site-packages/plotnine/scales/scale_size.py:48: PlotnineWarning: Using size for a discrete variable is not advised. /home/cgb4/anaconda3/envs/csy/lib/python3.8/site-packages/plotnine/stats/smoothers.py:310: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings. . &lt;ggplot: (8773810065351)&gt; . - 선의 색깔을 동일하게 하고 선의 타입을 변경하여 그룹을 표시할수도 있지 않을까? . a1,a2,a3,a4 . ({&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;}, {&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;, &#39;color&#39;: &#39;class&#39;}, {&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;, &#39;color&#39;: &#39;drv&#39;, &#39;size&#39;: &#39;class&#39;}, {&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;, &#39;color&#39;: &#39;drv&#39;}) . a5=a1.copy() . a5[&#39;linetype&#39;]=&#39;drv&#39; . a5 . {&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;, &#39;linetype&#39;: &#39;drv&#39;} . sline3=geom_smooth(a5,size=0.5,color=&#39;gray&#39;) . fig+point3+sline3 . /home/cgb4/anaconda3/envs/csy/lib/python3.8/site-packages/plotnine/scales/scale_size.py:48: PlotnineWarning: Using size for a discrete variable is not advised. /home/cgb4/anaconda3/envs/csy/lib/python3.8/site-packages/plotnine/stats/smoothers.py:310: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings. . &lt;ggplot: (8773803600309)&gt; . fig+point3+sline3+sline1 . /home/cgb4/anaconda3/envs/csy/lib/python3.8/site-packages/plotnine/scales/scale_size.py:48: PlotnineWarning: Using size for a discrete variable is not advised. /home/cgb4/anaconda3/envs/csy/lib/python3.8/site-packages/plotnine/stats/smoothers.py:310: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings. . &lt;ggplot: (8773803477757)&gt; . - 그래도 색깔로 구분하는것이 나은것 같다. . sline2=geom_smooth(a4,size=0.5,linetype=&#39;dashed&#39;) fig+point3+sline2+sline1 . /home/cgb4/anaconda3/envs/csy/lib/python3.8/site-packages/plotnine/scales/scale_size.py:48: PlotnineWarning: Using size for a discrete variable is not advised. /home/cgb4/anaconda3/envs/csy/lib/python3.8/site-packages/plotnine/stats/smoothers.py:310: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings. . &lt;ggplot: (8773803412989)&gt; . - 고차원의 변수를 표현할 수 있는 무기는 다양하다. . 산점도(포인트지옴): 점의크기, 점의형태, 점의색깔, 점의투명도 | 라인플랏(스무스지옴, 라인지옴): 선의형태, 선의색깔, 선의굵기 | . &#44208;&#47200; . - 잘 훈련한다면 여러가지 형태의 고차원 그래프를 우리도 그릴 수 있다. (마치 미나드처럼) . - 해들리위컴은 이러한 방법을 체계적으로 정리했다고 보여진다. . - 해들리위컴: 그래프는 데이터 + 지옴 + 맵핑(변수와 에스테틱간의 맵핑) + 스탯(통계) + 포지션 + 축 + 패싯그리드 7개의 조합으로 그릴수 있다. . &#54032;&#45796;&#49828;&#50640;&#49436; column&#51012; &#49440;&#53469;&#54616;&#45716; &#48169;&#48277; . import . &#50696;&#51228;1 . import numpy as np . dic={&#39;X1&#39;:np.random.normal(0,1,5), &#39;X2&#39;:np.random.normal(0,1,5), &#39;X3&#39;:np.random.normal(0,1,5)} df=pd.DataFrame(dic) df . X1 X2 X3 . 0 -0.841873 | 0.593642 | 0.508719 | . 1 1.055403 | 0.100994 | 0.152208 | . 2 0.195445 | 1.494363 | 1.329374 | . 3 -0.204469 | 1.308790 | -0.773303 | . 4 -0.207039 | 0.908317 | -1.973013 | . - 방법1 . df.X1 . 0 -0.841873 1 1.055403 2 0.195445 3 -0.204469 4 -0.207039 Name: X1, dtype: float64 . - 방법2 . df[&#39;X1&#39;] # 딕셔너리인것처럼 봄 pandas series 리턴 . 0 -0.841873 1 1.055403 2 0.195445 3 -0.204469 4 -0.207039 Name: X1, dtype: float64 . - 방법3 . df[[&#39;X1&#39;]] # dataframe 리턴 . X1 . 0 -0.841873 | . 1 1.055403 | . 2 0.195445 | . 3 -0.204469 | . 4 -0.207039 | . df[&#39;X1&#39;]는 series를 리턴하고 df[[&#39;X1&#39;]]는 dataframe을 리턴한다. | . - 방법4 . df.loc[:,&#39;X1&#39;] # pandas series return . 0 -0.841873 1 1.055403 2 0.195445 3 -0.204469 4 -0.207039 Name: X1, dtype: float64 . - 방법5 . df.loc[:,[&#39;X1&#39;]] # dataframe return . X1 . 0 -0.841873 | . 1 1.055403 | . 2 0.195445 | . 3 -0.204469 | . 4 -0.207039 | . df.loc[:,&#39;X1&#39;]는 series를 리턴하고 df.loc[:,[&#39;X1&#39;]]는 dataframe을 리턴한다. | . - 방법6 . df.loc[:,[True,False,False]] . X1 . 0 -0.841873 | . 1 1.055403 | . 2 0.195445 | . 3 -0.204469 | . 4 -0.207039 | . 불인덱싱가능(=Boolean indexing) | . 컴퓨터 과학에서 불리언(boolean) 자료형은 논리 자료형이라고도 하며, 참과 거짓을 나타내는 데 쓰인다 | . - 방법7 . df.iloc[:,0] # iloc 인테거 로케이션 integer location . 0 -0.841873 1 1.055403 2 0.195445 3 -0.204469 4 -0.207039 Name: X1, dtype: float64 . - 방법8 . df.iloc[:,[0]] # 여기서 0이 첫 번째! . X1 . 0 -0.841873 | . 1 1.055403 | . 2 0.195445 | . 3 -0.204469 | . 4 -0.207039 | . - 방법9 . df.iloc[:,[True,False,False]] . X1 . 0 -0.841873 | . 1 1.055403 | . 2 0.195445 | . 3 -0.204469 | . 4 -0.207039 | . &#52280;&#44256;&#49324;&#54637;: &#50676;&#51060;&#47492;&#51060; interger&#51068; &#44221;&#50864; . import numpy as np . _df = pd.DataFrame(np.array([[1,2,3],[3,4,5],[5,6,7]])) _df . 0 1 2 . 0 1 | 2 | 3 | . 1 3 | 4 | 5 | . 2 5 | 6 | 7 | . - 아래가 모두 가능하다. . _df[0] . 0 1 1 3 2 5 Name: 0, dtype: int64 . _df[[0]] . 0 . 0 1 | . 1 3 | . 2 5 | . _df.loc[:,0] . 0 1 1 3 2 5 Name: 0, dtype: int64 . _df.loc[:,[0]] . 0 . 0 1 | . 1 3 | . 2 5 | . _df.iloc[:,0] . 0 1 1 3 2 5 Name: 0, dtype: int64 . data . _df.iloc[:,[0]] . 0 . 0 1 | . 1 3 | . 2 5 | . &#48169;&#48277;1~9&#51032; &#50836;&#50557; (&#51228; &#49373;&#44033;) . - df.X1로 열을 선택하는게 간단하고 편리함. . 단점1: 변수이름을 알고 있어야 한다는 단점이 있음. | 단점2: 변수이름에 .이 있거나 변수이름에서 공백이 있을경우 사용할 수 없음 | . - 언급한 단점의 예시 . dic={&#39;X.1&#39;:np.random.normal(0,1,5), &#39;X.2&#39;:np.random.normal(0,1,5), &#39;X.3&#39;:np.random.normal(0,1,5)} _df=pd.DataFrame(dic) _df . X.1 X.2 X.3 . 0 -0.096366 | 2.058774 | 1.238681 | . 1 0.483778 | 0.251183 | -1.631879 | . 2 -1.342857 | -0.418954 | -0.451790 | . 3 -0.013712 | -1.544823 | -0.804091 | . 4 0.454819 | -2.895464 | -0.098231 | . _df[&#39;X.1&#39;] . 0 -0.096366 1 0.483778 2 -1.342857 3 -0.013712 4 0.454819 Name: X.1, dtype: float64 . df=pd.read_csv(&#39;https://raw.githubusercontent.com/PacktPublishing/Pandas-Cookbook/master/data/movie.csv&#39;) . _df.X.1 . File &#34;&lt;ipython-input-79-e6f439cfc6a9&gt;&#34;, line 1 _df.X.1 ^ SyntaxError: invalid syntax . &#50696;&#51228;2: &#50668;&#47084;&#44060;&#51032; &#50676;&#51012; &#49440;&#53469; . - 데이터 . dic={&#39;X1&#39;:np.random.normal(0,1,5), &#39;X2&#39;:np.random.normal(0,1,5), &#39;X3&#39;:np.random.normal(0,1,5), &#39;X4&#39;:np.random.normal(0,1,5)} df=pd.DataFrame(dic) df . X1 X2 X3 X4 . 0 -1.011589 | 0.227927 | 0.182539 | 1.034401 | . 1 -1.561713 | -2.049213 | 0.581165 | 0.177517 | . 2 0.827120 | 0.202107 | -0.080779 | -0.429167 | . 3 -0.873938 | -0.164898 | -0.115116 | -0.022730 | . 4 1.398402 | -0.550470 | -0.568468 | -0.845263 | . - 목표: 1,2,3열을 선택 . - 방법1 . df[[&#39;X1&#39;,&#39;X2&#39;,&#39;X3&#39;]] . X1 X2 X3 . 0 -1.011589 | 0.227927 | 0.182539 | . 1 -1.561713 | -2.049213 | 0.581165 | . 2 0.827120 | 0.202107 | -0.080779 | . 3 -0.873938 | -0.164898 | -0.115116 | . 4 1.398402 | -0.550470 | -0.568468 | . - 방법2 . df.loc[:,[&#39;X1&#39;,&#39;X2&#39;,&#39;X3&#39;]] . X1 X2 X3 . 0 -1.011589 | 0.227927 | 0.182539 | . 1 -1.561713 | -2.049213 | 0.581165 | . 2 0.827120 | 0.202107 | -0.080779 | . 3 -0.873938 | -0.164898 | -0.115116 | . 4 1.398402 | -0.550470 | -0.568468 | . - 방법3 . df.loc[:,&#39;X1&#39;:&#39;X3&#39;] . X1 X2 X3 . 0 -1.011589 | 0.227927 | 0.182539 | . 1 -1.561713 | -2.049213 | 0.581165 | . 2 0.827120 | 0.202107 | -0.080779 | . 3 -0.873938 | -0.164898 | -0.115116 | . 4 1.398402 | -0.550470 | -0.568468 | . - 방법4 . df.loc[:,[True,True,True,False]] . X1 X2 X3 . 0 -1.011589 | 0.227927 | 0.182539 | . 1 -1.561713 | -2.049213 | 0.581165 | . 2 0.827120 | 0.202107 | -0.080779 | . 3 -0.873938 | -0.164898 | -0.115116 | . 4 1.398402 | -0.550470 | -0.568468 | . - 방법5 . df.iloc[:,[0,1,2]] . X1 X2 X3 . 0 -1.011589 | 0.227927 | 0.182539 | . 1 -1.561713 | -2.049213 | 0.581165 | . 2 0.827120 | 0.202107 | -0.080779 | . 3 -0.873938 | -0.164898 | -0.115116 | . 4 1.398402 | -0.550470 | -0.568468 | . - 방법6 . df.iloc[:,:3] . X1 X2 X3 . 0 -1.011589 | 0.227927 | 0.182539 | . 1 -1.561713 | -2.049213 | 0.581165 | . 2 0.827120 | 0.202107 | -0.080779 | . 3 -0.873938 | -0.164898 | -0.115116 | . 4 1.398402 | -0.550470 | -0.568468 | . df.iloc[:,0:3] . X1 X2 X3 . 0 -1.011589 | 0.227927 | 0.182539 | . 1 -1.561713 | -2.049213 | 0.581165 | . 2 0.827120 | 0.202107 | -0.080779 | . 3 -0.873938 | -0.164898 | -0.115116 | . 4 1.398402 | -0.550470 | -0.568468 | . df.iloc[:,range(3)] . X1 X2 X3 . 0 -1.011589 | 0.227927 | 0.182539 | . 1 -1.561713 | -2.049213 | 0.581165 | . 2 0.827120 | 0.202107 | -0.080779 | . 3 -0.873938 | -0.164898 | -0.115116 | . 4 1.398402 | -0.550470 | -0.568468 | . - 방법7 . df.iloc[:,[True,True,True,False]] . X1 X2 X3 . 0 -1.011589 | 0.227927 | 0.182539 | . 1 -1.561713 | -2.049213 | 0.581165 | . 2 0.827120 | 0.202107 | -0.080779 | . 3 -0.873938 | -0.164898 | -0.115116 | . 4 1.398402 | -0.550470 | -0.568468 | . (주의) loc에서의 슬라이싱은 마지막변수를 포함하지만 iloc에서는 포함하지 않음 . - 아래를 비교하라. . df.iloc[:,0:3] ## 0,1,2,3중 3은 포함되지 않는다. # iloc에서 3은 X4임 . X1 X2 X3 . 0 -1.011589 | 0.227927 | 0.182539 | . 1 -1.561713 | -2.049213 | 0.581165 | . 2 0.827120 | 0.202107 | -0.080779 | . 3 -0.873938 | -0.164898 | -0.115116 | . 4 1.398402 | -0.550470 | -0.568468 | . df.loc[:,&#39;X1&#39;:&#39;X3&#39;] ## &#39;X3&#39;도 포함된다. . X1 X2 X3 . 0 -1.011589 | 0.227927 | 0.182539 | . 1 -1.561713 | -2.049213 | 0.581165 | . 2 0.827120 | 0.202107 | -0.080779 | . 3 -0.873938 | -0.164898 | -0.115116 | . 4 1.398402 | -0.550470 | -0.568468 | . - 그래서 column의 이름이 integer일 경우는 종종 매우 헷갈리는 일이 일어남 . _df = pd.DataFrame(np.array([[1,2,3,4],[3,4,5,6],[5,6,7,8]])) _df . 0 1 2 3 . 0 1 | 2 | 3 | 4 | . 1 3 | 4 | 5 | 6 | . 2 5 | 6 | 7 | 8 | . _df.loc[:,0:2] . 0 1 2 . 0 1 | 2 | 3 | . 1 3 | 4 | 5 | . 2 5 | 6 | 7 | . _df.iloc[:,0:2] . 0 1 . 0 1 | 2 | . 1 3 | 4 | . 2 5 | 6 | . . Note: 사실 이것은 일부러 헷갈리게 예제를 구성한 것이다. 실제로는 헷갈리는 상황이 그렇게 자주 발생하지 않는다. 왜냐하면 보통 위와 같은 형태의 자료는 ndarray로 처리하고 colname이 있는 경우만 데이터프레임으로 처리하기 때문. . &#50696;&#51228;3: movie data - &#53945;&#51221;&#51312;&#44148;&#50640; &#47582;&#45716; &#50676;&#51012; &#49440;&#53469; . df=pd.read_csv(&#39;https://raw.githubusercontent.com/PacktPublishing/Pandas-Cookbook/master/data/movie.csv&#39;) df . color director_name num_critic_for_reviews duration director_facebook_likes actor_3_facebook_likes actor_2_name actor_1_facebook_likes gross genres ... num_user_for_reviews language country content_rating budget title_year actor_2_facebook_likes imdb_score aspect_ratio movie_facebook_likes . 0 Color | James Cameron | 723.0 | 178.0 | 0.0 | 855.0 | Joel David Moore | 1000.0 | 760505847.0 | Action|Adventure|Fantasy|Sci-Fi | ... | 3054.0 | English | USA | PG-13 | 237000000.0 | 2009.0 | 936.0 | 7.9 | 1.78 | 33000 | . 1 Color | Gore Verbinski | 302.0 | 169.0 | 563.0 | 1000.0 | Orlando Bloom | 40000.0 | 309404152.0 | Action|Adventure|Fantasy | ... | 1238.0 | English | USA | PG-13 | 300000000.0 | 2007.0 | 5000.0 | 7.1 | 2.35 | 0 | . 2 Color | Sam Mendes | 602.0 | 148.0 | 0.0 | 161.0 | Rory Kinnear | 11000.0 | 200074175.0 | Action|Adventure|Thriller | ... | 994.0 | English | UK | PG-13 | 245000000.0 | 2015.0 | 393.0 | 6.8 | 2.35 | 85000 | . 3 Color | Christopher Nolan | 813.0 | 164.0 | 22000.0 | 23000.0 | Christian Bale | 27000.0 | 448130642.0 | Action|Thriller | ... | 2701.0 | English | USA | PG-13 | 250000000.0 | 2012.0 | 23000.0 | 8.5 | 2.35 | 164000 | . 4 NaN | Doug Walker | NaN | NaN | 131.0 | NaN | Rob Walker | 131.0 | NaN | Documentary | ... | NaN | NaN | NaN | NaN | NaN | NaN | 12.0 | 7.1 | NaN | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 4911 Color | Scott Smith | 1.0 | 87.0 | 2.0 | 318.0 | Daphne Zuniga | 637.0 | NaN | Comedy|Drama | ... | 6.0 | English | Canada | NaN | NaN | 2013.0 | 470.0 | 7.7 | NaN | 84 | . 4912 Color | NaN | 43.0 | 43.0 | NaN | 319.0 | Valorie Curry | 841.0 | NaN | Crime|Drama|Mystery|Thriller | ... | 359.0 | English | USA | TV-14 | NaN | NaN | 593.0 | 7.5 | 16.00 | 32000 | . 4913 Color | Benjamin Roberds | 13.0 | 76.0 | 0.0 | 0.0 | Maxwell Moody | 0.0 | NaN | Drama|Horror|Thriller | ... | 3.0 | English | USA | NaN | 1400.0 | 2013.0 | 0.0 | 6.3 | NaN | 16 | . 4914 Color | Daniel Hsia | 14.0 | 100.0 | 0.0 | 489.0 | Daniel Henney | 946.0 | 10443.0 | Comedy|Drama|Romance | ... | 9.0 | English | USA | PG-13 | NaN | 2012.0 | 719.0 | 6.3 | 2.35 | 660 | . 4915 Color | Jon Gunn | 43.0 | 90.0 | 16.0 | 16.0 | Brian Herzlinger | 86.0 | 85222.0 | Documentary | ... | 84.0 | English | USA | PG | 1100.0 | 2004.0 | 23.0 | 6.6 | 1.85 | 456 | . 4916 rows × 28 columns . - 열의 이름을 출력하여 보자. . df.columns . Index([&#39;color&#39;, &#39;director_name&#39;, &#39;num_critic_for_reviews&#39;, &#39;duration&#39;, &#39;director_facebook_likes&#39;, &#39;actor_3_facebook_likes&#39;, &#39;actor_2_name&#39;, &#39;actor_1_facebook_likes&#39;, &#39;gross&#39;, &#39;genres&#39;, &#39;actor_1_name&#39;, &#39;movie_title&#39;, &#39;num_voted_users&#39;, &#39;cast_total_facebook_likes&#39;, &#39;actor_3_name&#39;, &#39;facenumber_in_poster&#39;, &#39;plot_keywords&#39;, &#39;movie_imdb_link&#39;, &#39;num_user_for_reviews&#39;, &#39;language&#39;, &#39;country&#39;, &#39;content_rating&#39;, &#39;budget&#39;, &#39;title_year&#39;, &#39;actor_2_facebook_likes&#39;, &#39;imdb_score&#39;, &#39;aspect_ratio&#39;, &#39;movie_facebook_likes&#39;], dtype=&#39;object&#39;) . - color ~ num_voted_user 를 뽑고 + aspect_ratio 도 추가적으로 뽑고싶다. . df.loc[:,[&#39;color&#39;:&#39;num_voted_users&#39;,&#39;aspect_ratio&#39;]] # 이름에 : 적용하면 error . File &#34;&lt;ipython-input-100-bd22dfdd8311&gt;&#34;, line 1 df.loc[:,[&#39;color&#39;:&#39;num_voted_users&#39;,&#39;aspect_ratio&#39;]] # 이름에 : 적용하면 error ^ SyntaxError: invalid syntax . - (팁) 복잡한 조건은 iloc으로 쓰는게 편할때가 있다. $ to$ 그런데 df.columns 변수들이 몇번인지 알아보기 힘듬 $ to$ 아래와 같이 하면 열의 이름을 인덱스와 함께 출력할 수 있음 . pd.Series(df.columns) . 0 color 1 director_name 2 num_critic_for_reviews 3 duration 4 director_facebook_likes 5 actor_3_facebook_likes 6 actor_2_name 7 actor_1_facebook_likes 8 gross 9 genres 10 actor_1_name 11 movie_title 12 num_voted_users 13 cast_total_facebook_likes 14 actor_3_name 15 facenumber_in_poster 16 plot_keywords 17 movie_imdb_link 18 num_user_for_reviews 19 language 20 country 21 content_rating 22 budget 23 title_year 24 actor_2_facebook_likes 25 imdb_score 26 aspect_ratio 27 movie_facebook_likes dtype: object . list(range(13))+[26] . [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 26] . df.iloc[:,list(range(13))+[26]] . color director_name num_critic_for_reviews duration director_facebook_likes actor_3_facebook_likes actor_2_name actor_1_facebook_likes gross genres actor_1_name movie_title num_voted_users aspect_ratio . 0 Color | James Cameron | 723.0 | 178.0 | 0.0 | 855.0 | Joel David Moore | 1000.0 | 760505847.0 | Action|Adventure|Fantasy|Sci-Fi | CCH Pounder | Avatar | 886204 | 1.78 | . 1 Color | Gore Verbinski | 302.0 | 169.0 | 563.0 | 1000.0 | Orlando Bloom | 40000.0 | 309404152.0 | Action|Adventure|Fantasy | Johnny Depp | Pirates of the Caribbean: At World&#39;s End | 471220 | 2.35 | . 2 Color | Sam Mendes | 602.0 | 148.0 | 0.0 | 161.0 | Rory Kinnear | 11000.0 | 200074175.0 | Action|Adventure|Thriller | Christoph Waltz | Spectre | 275868 | 2.35 | . 3 Color | Christopher Nolan | 813.0 | 164.0 | 22000.0 | 23000.0 | Christian Bale | 27000.0 | 448130642.0 | Action|Thriller | Tom Hardy | The Dark Knight Rises | 1144337 | 2.35 | . 4 NaN | Doug Walker | NaN | NaN | 131.0 | NaN | Rob Walker | 131.0 | NaN | Documentary | Doug Walker | Star Wars: Episode VII - The Force Awakens | 8 | NaN | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 4911 Color | Scott Smith | 1.0 | 87.0 | 2.0 | 318.0 | Daphne Zuniga | 637.0 | NaN | Comedy|Drama | Eric Mabius | Signed Sealed Delivered | 629 | NaN | . 4912 Color | NaN | 43.0 | 43.0 | NaN | 319.0 | Valorie Curry | 841.0 | NaN | Crime|Drama|Mystery|Thriller | Natalie Zea | The Following | 73839 | 16.00 | . 4913 Color | Benjamin Roberds | 13.0 | 76.0 | 0.0 | 0.0 | Maxwell Moody | 0.0 | NaN | Drama|Horror|Thriller | Eva Boehnke | A Plague So Pleasant | 38 | NaN | . 4914 Color | Daniel Hsia | 14.0 | 100.0 | 0.0 | 489.0 | Daniel Henney | 946.0 | 10443.0 | Comedy|Drama|Romance | Alan Ruck | Shanghai Calling | 1255 | 2.35 | . 4915 Color | Jon Gunn | 43.0 | 90.0 | 16.0 | 16.0 | Brian Herzlinger | 86.0 | 85222.0 | Documentary | John August | My Date with Drew | 4285 | 1.85 | . 4916 rows × 14 columns . - 다시열의 이름들을 확인 . df.columns . Index([&#39;color&#39;, &#39;director_name&#39;, &#39;num_critic_for_reviews&#39;, &#39;duration&#39;, &#39;director_facebook_likes&#39;, &#39;actor_3_facebook_likes&#39;, &#39;actor_2_name&#39;, &#39;actor_1_facebook_likes&#39;, &#39;gross&#39;, &#39;genres&#39;, &#39;actor_1_name&#39;, &#39;movie_title&#39;, &#39;num_voted_users&#39;, &#39;cast_total_facebook_likes&#39;, &#39;actor_3_name&#39;, &#39;facenumber_in_poster&#39;, &#39;plot_keywords&#39;, &#39;movie_imdb_link&#39;, &#39;num_user_for_reviews&#39;, &#39;language&#39;, &#39;country&#39;, &#39;content_rating&#39;, &#39;budget&#39;, &#39;title_year&#39;, &#39;actor_2_facebook_likes&#39;, &#39;imdb_score&#39;, &#39;aspect_ratio&#39;, &#39;movie_facebook_likes&#39;], dtype=&#39;object&#39;) . actor&#46972;&#45716; &#45800;&#50612;&#44032; &#54252;&#54632;&#46108; &#48320;&#49688;&#46308;&#47564; &#48977;&#44256;&#49910;&#45796;. . - 방법1 . df.iloc[:,list(map(lambda x : &#39;actor&#39; in x, df.columns) )] . actor_3_facebook_likes actor_2_name actor_1_facebook_likes actor_1_name actor_3_name actor_2_facebook_likes . 0 855.0 | Joel David Moore | 1000.0 | CCH Pounder | Wes Studi | 936.0 | . 1 1000.0 | Orlando Bloom | 40000.0 | Johnny Depp | Jack Davenport | 5000.0 | . 2 161.0 | Rory Kinnear | 11000.0 | Christoph Waltz | Stephanie Sigman | 393.0 | . 3 23000.0 | Christian Bale | 27000.0 | Tom Hardy | Joseph Gordon-Levitt | 23000.0 | . 4 NaN | Rob Walker | 131.0 | Doug Walker | NaN | 12.0 | . ... ... | ... | ... | ... | ... | ... | . 4911 318.0 | Daphne Zuniga | 637.0 | Eric Mabius | Crystal Lowe | 470.0 | . 4912 319.0 | Valorie Curry | 841.0 | Natalie Zea | Sam Underwood | 593.0 | . 4913 0.0 | Maxwell Moody | 0.0 | Eva Boehnke | David Chandler | 0.0 | . 4914 489.0 | Daniel Henney | 946.0 | Alan Ruck | Eliza Coupe | 719.0 | . 4915 16.0 | Brian Herzlinger | 86.0 | John August | Jon Gunn | 23.0 | . 4916 rows × 6 columns . df.iloc[:,list(map(lambda x : &#39;actor&#39; not in x, df.columns) )] # actor 제외하는 열만 뽑는 방법 . color director_name num_critic_for_reviews duration director_facebook_likes gross genres movie_title num_voted_users cast_total_facebook_likes ... movie_imdb_link num_user_for_reviews language country content_rating budget title_year imdb_score aspect_ratio movie_facebook_likes . 0 Color | James Cameron | 723.0 | 178.0 | 0.0 | 760505847.0 | Action|Adventure|Fantasy|Sci-Fi | Avatar | 886204 | 4834 | ... | http://www.imdb.com/title/tt0499549/?ref_=fn_t... | 3054.0 | English | USA | PG-13 | 237000000.0 | 2009.0 | 7.9 | 1.78 | 33000 | . 1 Color | Gore Verbinski | 302.0 | 169.0 | 563.0 | 309404152.0 | Action|Adventure|Fantasy | Pirates of the Caribbean: At World&#39;s End | 471220 | 48350 | ... | http://www.imdb.com/title/tt0449088/?ref_=fn_t... | 1238.0 | English | USA | PG-13 | 300000000.0 | 2007.0 | 7.1 | 2.35 | 0 | . 2 Color | Sam Mendes | 602.0 | 148.0 | 0.0 | 200074175.0 | Action|Adventure|Thriller | Spectre | 275868 | 11700 | ... | http://www.imdb.com/title/tt2379713/?ref_=fn_t... | 994.0 | English | UK | PG-13 | 245000000.0 | 2015.0 | 6.8 | 2.35 | 85000 | . 3 Color | Christopher Nolan | 813.0 | 164.0 | 22000.0 | 448130642.0 | Action|Thriller | The Dark Knight Rises | 1144337 | 106759 | ... | http://www.imdb.com/title/tt1345836/?ref_=fn_t... | 2701.0 | English | USA | PG-13 | 250000000.0 | 2012.0 | 8.5 | 2.35 | 164000 | . 4 NaN | Doug Walker | NaN | NaN | 131.0 | NaN | Documentary | Star Wars: Episode VII - The Force Awakens | 8 | 143 | ... | http://www.imdb.com/title/tt5289954/?ref_=fn_t... | NaN | NaN | NaN | NaN | NaN | NaN | 7.1 | NaN | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 4911 Color | Scott Smith | 1.0 | 87.0 | 2.0 | NaN | Comedy|Drama | Signed Sealed Delivered | 629 | 2283 | ... | http://www.imdb.com/title/tt3000844/?ref_=fn_t... | 6.0 | English | Canada | NaN | NaN | 2013.0 | 7.7 | NaN | 84 | . 4912 Color | NaN | 43.0 | 43.0 | NaN | NaN | Crime|Drama|Mystery|Thriller | The Following | 73839 | 1753 | ... | http://www.imdb.com/title/tt2071645/?ref_=fn_t... | 359.0 | English | USA | TV-14 | NaN | NaN | 7.5 | 16.00 | 32000 | . 4913 Color | Benjamin Roberds | 13.0 | 76.0 | 0.0 | NaN | Drama|Horror|Thriller | A Plague So Pleasant | 38 | 0 | ... | http://www.imdb.com/title/tt2107644/?ref_=fn_t... | 3.0 | English | USA | NaN | 1400.0 | 2013.0 | 6.3 | NaN | 16 | . 4914 Color | Daniel Hsia | 14.0 | 100.0 | 0.0 | 10443.0 | Comedy|Drama|Romance | Shanghai Calling | 1255 | 2386 | ... | http://www.imdb.com/title/tt2070597/?ref_=fn_t... | 9.0 | English | USA | PG-13 | NaN | 2012.0 | 6.3 | 2.35 | 660 | . 4915 Color | Jon Gunn | 43.0 | 90.0 | 16.0 | 85222.0 | Documentary | My Date with Drew | 4285 | 163 | ... | http://www.imdb.com/title/tt0378407/?ref_=fn_t... | 84.0 | English | USA | PG | 1100.0 | 2004.0 | 6.6 | 1.85 | 456 | . 4916 rows × 22 columns . - 방법2 . df.loc[:,list(map(lambda x : &#39;actor&#39; in x, df.columns) )] . actor_3_facebook_likes actor_2_name actor_1_facebook_likes actor_1_name actor_3_name actor_2_facebook_likes . 0 855.0 | Joel David Moore | 1000.0 | CCH Pounder | Wes Studi | 936.0 | . 1 1000.0 | Orlando Bloom | 40000.0 | Johnny Depp | Jack Davenport | 5000.0 | . 2 161.0 | Rory Kinnear | 11000.0 | Christoph Waltz | Stephanie Sigman | 393.0 | . 3 23000.0 | Christian Bale | 27000.0 | Tom Hardy | Joseph Gordon-Levitt | 23000.0 | . 4 NaN | Rob Walker | 131.0 | Doug Walker | NaN | 12.0 | . ... ... | ... | ... | ... | ... | ... | . 4911 318.0 | Daphne Zuniga | 637.0 | Eric Mabius | Crystal Lowe | 470.0 | . 4912 319.0 | Valorie Curry | 841.0 | Natalie Zea | Sam Underwood | 593.0 | . 4913 0.0 | Maxwell Moody | 0.0 | Eva Boehnke | David Chandler | 0.0 | . 4914 489.0 | Daniel Henney | 946.0 | Alan Ruck | Eliza Coupe | 719.0 | . 4915 16.0 | Brian Herzlinger | 86.0 | John August | Jon Gunn | 23.0 | . 4916 rows × 6 columns . - 방법3 . df.iloc[:,map(lambda x : &#39;actor&#39; in x, df.columns)] . actor_3_facebook_likes actor_2_name actor_1_facebook_likes actor_1_name actor_3_name actor_2_facebook_likes . 0 855.0 | Joel David Moore | 1000.0 | CCH Pounder | Wes Studi | 936.0 | . 1 1000.0 | Orlando Bloom | 40000.0 | Johnny Depp | Jack Davenport | 5000.0 | . 2 161.0 | Rory Kinnear | 11000.0 | Christoph Waltz | Stephanie Sigman | 393.0 | . 3 23000.0 | Christian Bale | 27000.0 | Tom Hardy | Joseph Gordon-Levitt | 23000.0 | . 4 NaN | Rob Walker | 131.0 | Doug Walker | NaN | 12.0 | . ... ... | ... | ... | ... | ... | ... | . 4911 318.0 | Daphne Zuniga | 637.0 | Eric Mabius | Crystal Lowe | 470.0 | . 4912 319.0 | Valorie Curry | 841.0 | Natalie Zea | Sam Underwood | 593.0 | . 4913 0.0 | Maxwell Moody | 0.0 | Eva Boehnke | David Chandler | 0.0 | . 4914 489.0 | Daniel Henney | 946.0 | Alan Ruck | Eliza Coupe | 719.0 | . 4915 16.0 | Brian Herzlinger | 86.0 | John August | Jon Gunn | 23.0 | . 4916 rows × 6 columns . - 방법4 . df.loc[:,map(lambda x : &#39;actor&#39; in x, df.columns)] . actor_3_facebook_likes actor_2_name actor_1_facebook_likes actor_1_name actor_3_name actor_2_facebook_likes . 0 855.0 | Joel David Moore | 1000.0 | CCH Pounder | Wes Studi | 936.0 | . 1 1000.0 | Orlando Bloom | 40000.0 | Johnny Depp | Jack Davenport | 5000.0 | . 2 161.0 | Rory Kinnear | 11000.0 | Christoph Waltz | Stephanie Sigman | 393.0 | . 3 23000.0 | Christian Bale | 27000.0 | Tom Hardy | Joseph Gordon-Levitt | 23000.0 | . 4 NaN | Rob Walker | 131.0 | Doug Walker | NaN | 12.0 | . ... ... | ... | ... | ... | ... | ... | . 4911 318.0 | Daphne Zuniga | 637.0 | Eric Mabius | Crystal Lowe | 470.0 | . 4912 319.0 | Valorie Curry | 841.0 | Natalie Zea | Sam Underwood | 593.0 | . 4913 0.0 | Maxwell Moody | 0.0 | Eva Boehnke | David Chandler | 0.0 | . 4914 489.0 | Daniel Henney | 946.0 | Alan Ruck | Eliza Coupe | 719.0 | . 4915 16.0 | Brian Herzlinger | 86.0 | John August | Jon Gunn | 23.0 | . 4916 rows × 6 columns . - 방법5 . df.loc[:,filter(lambda x : &#39;actor&#39; in x, df.columns)] . actor_3_facebook_likes actor_2_name actor_1_facebook_likes actor_1_name actor_3_name actor_2_facebook_likes . 0 855.0 | Joel David Moore | 1000.0 | CCH Pounder | Wes Studi | 936.0 | . 1 1000.0 | Orlando Bloom | 40000.0 | Johnny Depp | Jack Davenport | 5000.0 | . 2 161.0 | Rory Kinnear | 11000.0 | Christoph Waltz | Stephanie Sigman | 393.0 | . 3 23000.0 | Christian Bale | 27000.0 | Tom Hardy | Joseph Gordon-Levitt | 23000.0 | . 4 NaN | Rob Walker | 131.0 | Doug Walker | NaN | 12.0 | . ... ... | ... | ... | ... | ... | ... | . 4911 318.0 | Daphne Zuniga | 637.0 | Eric Mabius | Crystal Lowe | 470.0 | . 4912 319.0 | Valorie Curry | 841.0 | Natalie Zea | Sam Underwood | 593.0 | . 4913 0.0 | Maxwell Moody | 0.0 | Eva Boehnke | David Chandler | 0.0 | . 4914 489.0 | Daniel Henney | 946.0 | Alan Ruck | Eliza Coupe | 719.0 | . 4915 16.0 | Brian Herzlinger | 86.0 | John August | Jon Gunn | 23.0 | . 4916 rows × 6 columns . &#48320;&#49688;&#51060;&#47492;&#51060; s&#47196; &#45149;&#45208;&#45716; &#48320;&#49688;&#46308;&#47564; &#48977;&#44256;&#49910;&#45796;. . df.iloc[:,map(lambda x: &#39;s&#39; == x[-1],df.columns )] . num_critic_for_reviews director_facebook_likes actor_3_facebook_likes actor_1_facebook_likes gross genres num_voted_users cast_total_facebook_likes plot_keywords num_user_for_reviews actor_2_facebook_likes movie_facebook_likes . 0 723.0 | 0.0 | 855.0 | 1000.0 | 760505847.0 | Action|Adventure|Fantasy|Sci-Fi | 886204 | 4834 | avatar|future|marine|native|paraplegic | 3054.0 | 936.0 | 33000 | . 1 302.0 | 563.0 | 1000.0 | 40000.0 | 309404152.0 | Action|Adventure|Fantasy | 471220 | 48350 | goddess|marriage ceremony|marriage proposal|pi... | 1238.0 | 5000.0 | 0 | . 2 602.0 | 0.0 | 161.0 | 11000.0 | 200074175.0 | Action|Adventure|Thriller | 275868 | 11700 | bomb|espionage|sequel|spy|terrorist | 994.0 | 393.0 | 85000 | . 3 813.0 | 22000.0 | 23000.0 | 27000.0 | 448130642.0 | Action|Thriller | 1144337 | 106759 | deception|imprisonment|lawlessness|police offi... | 2701.0 | 23000.0 | 164000 | . 4 NaN | 131.0 | NaN | 131.0 | NaN | Documentary | 8 | 143 | NaN | NaN | 12.0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 4911 1.0 | 2.0 | 318.0 | 637.0 | NaN | Comedy|Drama | 629 | 2283 | fraud|postal worker|prison|theft|trial | 6.0 | 470.0 | 84 | . 4912 43.0 | NaN | 319.0 | 841.0 | NaN | Crime|Drama|Mystery|Thriller | 73839 | 1753 | cult|fbi|hideout|prison escape|serial killer | 359.0 | 593.0 | 32000 | . 4913 13.0 | 0.0 | 0.0 | 0.0 | NaN | Drama|Horror|Thriller | 38 | 0 | NaN | 3.0 | 0.0 | 16 | . 4914 14.0 | 0.0 | 489.0 | 946.0 | 10443.0 | Comedy|Drama|Romance | 1255 | 2386 | NaN | 9.0 | 719.0 | 660 | . 4915 43.0 | 16.0 | 16.0 | 86.0 | 85222.0 | Documentary | 4285 | 163 | actress name in title|crush|date|four word tit... | 84.0 | 23.0 | 456 | . 4916 rows × 12 columns . df.iloc[:,map(lambda x: &#39;s&#39; != x[-1],df.columns )] # s로 끝나지 않는 변수들만 뽑기 . color director_name duration actor_2_name actor_1_name movie_title actor_3_name facenumber_in_poster movie_imdb_link language country content_rating budget title_year imdb_score aspect_ratio . 0 Color | James Cameron | 178.0 | Joel David Moore | CCH Pounder | Avatar | Wes Studi | 0.0 | http://www.imdb.com/title/tt0499549/?ref_=fn_t... | English | USA | PG-13 | 237000000.0 | 2009.0 | 7.9 | 1.78 | . 1 Color | Gore Verbinski | 169.0 | Orlando Bloom | Johnny Depp | Pirates of the Caribbean: At World&#39;s End | Jack Davenport | 0.0 | http://www.imdb.com/title/tt0449088/?ref_=fn_t... | English | USA | PG-13 | 300000000.0 | 2007.0 | 7.1 | 2.35 | . 2 Color | Sam Mendes | 148.0 | Rory Kinnear | Christoph Waltz | Spectre | Stephanie Sigman | 1.0 | http://www.imdb.com/title/tt2379713/?ref_=fn_t... | English | UK | PG-13 | 245000000.0 | 2015.0 | 6.8 | 2.35 | . 3 Color | Christopher Nolan | 164.0 | Christian Bale | Tom Hardy | The Dark Knight Rises | Joseph Gordon-Levitt | 0.0 | http://www.imdb.com/title/tt1345836/?ref_=fn_t... | English | USA | PG-13 | 250000000.0 | 2012.0 | 8.5 | 2.35 | . 4 NaN | Doug Walker | NaN | Rob Walker | Doug Walker | Star Wars: Episode VII - The Force Awakens | NaN | 0.0 | http://www.imdb.com/title/tt5289954/?ref_=fn_t... | NaN | NaN | NaN | NaN | NaN | 7.1 | NaN | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 4911 Color | Scott Smith | 87.0 | Daphne Zuniga | Eric Mabius | Signed Sealed Delivered | Crystal Lowe | 2.0 | http://www.imdb.com/title/tt3000844/?ref_=fn_t... | English | Canada | NaN | NaN | 2013.0 | 7.7 | NaN | . 4912 Color | NaN | 43.0 | Valorie Curry | Natalie Zea | The Following | Sam Underwood | 1.0 | http://www.imdb.com/title/tt2071645/?ref_=fn_t... | English | USA | TV-14 | NaN | NaN | 7.5 | 16.00 | . 4913 Color | Benjamin Roberds | 76.0 | Maxwell Moody | Eva Boehnke | A Plague So Pleasant | David Chandler | 0.0 | http://www.imdb.com/title/tt2107644/?ref_=fn_t... | English | USA | NaN | 1400.0 | 2013.0 | 6.3 | NaN | . 4914 Color | Daniel Hsia | 100.0 | Daniel Henney | Alan Ruck | Shanghai Calling | Eliza Coupe | 5.0 | http://www.imdb.com/title/tt2070597/?ref_=fn_t... | English | USA | PG-13 | NaN | 2012.0 | 6.3 | 2.35 | . 4915 Color | Jon Gunn | 90.0 | Brian Herzlinger | John August | My Date with Drew | Jon Gunn | 0.0 | http://www.imdb.com/title/tt0378407/?ref_=fn_t... | English | USA | PG | 1100.0 | 2004.0 | 6.6 | 1.85 | . 4916 rows × 16 columns . df.loc[:,map(lambda x: &#39;s&#39; == x[-1],df.columns )] . num_critic_for_reviews director_facebook_likes actor_3_facebook_likes actor_1_facebook_likes gross genres num_voted_users cast_total_facebook_likes plot_keywords num_user_for_reviews actor_2_facebook_likes movie_facebook_likes . 0 723.0 | 0.0 | 855.0 | 1000.0 | 760505847.0 | Action|Adventure|Fantasy|Sci-Fi | 886204 | 4834 | avatar|future|marine|native|paraplegic | 3054.0 | 936.0 | 33000 | . 1 302.0 | 563.0 | 1000.0 | 40000.0 | 309404152.0 | Action|Adventure|Fantasy | 471220 | 48350 | goddess|marriage ceremony|marriage proposal|pi... | 1238.0 | 5000.0 | 0 | . 2 602.0 | 0.0 | 161.0 | 11000.0 | 200074175.0 | Action|Adventure|Thriller | 275868 | 11700 | bomb|espionage|sequel|spy|terrorist | 994.0 | 393.0 | 85000 | . 3 813.0 | 22000.0 | 23000.0 | 27000.0 | 448130642.0 | Action|Thriller | 1144337 | 106759 | deception|imprisonment|lawlessness|police offi... | 2701.0 | 23000.0 | 164000 | . 4 NaN | 131.0 | NaN | 131.0 | NaN | Documentary | 8 | 143 | NaN | NaN | 12.0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 4911 1.0 | 2.0 | 318.0 | 637.0 | NaN | Comedy|Drama | 629 | 2283 | fraud|postal worker|prison|theft|trial | 6.0 | 470.0 | 84 | . 4912 43.0 | NaN | 319.0 | 841.0 | NaN | Crime|Drama|Mystery|Thriller | 73839 | 1753 | cult|fbi|hideout|prison escape|serial killer | 359.0 | 593.0 | 32000 | . 4913 13.0 | 0.0 | 0.0 | 0.0 | NaN | Drama|Horror|Thriller | 38 | 0 | NaN | 3.0 | 0.0 | 16 | . 4914 14.0 | 0.0 | 489.0 | 946.0 | 10443.0 | Comedy|Drama|Romance | 1255 | 2386 | NaN | 9.0 | 719.0 | 660 | . 4915 43.0 | 16.0 | 16.0 | 86.0 | 85222.0 | Documentary | 4285 | 163 | actress name in title|crush|date|four word tit... | 84.0 | 23.0 | 456 | . 4916 rows × 12 columns . &#48320;&#49688;&#51060;&#47492;&#51060; c &#54841;&#51008; d&#47196; &#49884;&#51089;&#54616;&#45716; &#48320;&#49688;&#46308;&#47564; &#48977;&#44256;&#49910;&#45796;. . df.iloc[:,map(lambda x: &#39;c&#39; == x[0] or &#39;d&#39; == x[0] ,df.columns )] . color director_name duration director_facebook_likes cast_total_facebook_likes country content_rating . 0 Color | James Cameron | 178.0 | 0.0 | 4834 | USA | PG-13 | . 1 Color | Gore Verbinski | 169.0 | 563.0 | 48350 | USA | PG-13 | . 2 Color | Sam Mendes | 148.0 | 0.0 | 11700 | UK | PG-13 | . 3 Color | Christopher Nolan | 164.0 | 22000.0 | 106759 | USA | PG-13 | . 4 NaN | Doug Walker | NaN | 131.0 | 143 | NaN | NaN | . ... ... | ... | ... | ... | ... | ... | ... | . 4911 Color | Scott Smith | 87.0 | 2.0 | 2283 | Canada | NaN | . 4912 Color | NaN | 43.0 | NaN | 1753 | USA | TV-14 | . 4913 Color | Benjamin Roberds | 76.0 | 0.0 | 0 | USA | NaN | . 4914 Color | Daniel Hsia | 100.0 | 0.0 | 2386 | USA | PG-13 | . 4915 Color | Jon Gunn | 90.0 | 16.0 | 163 | USA | PG | . 4916 rows × 7 columns . &#49689;&#51228; . movie data frame에서 &#39;face&#39;라는 단어가 포함된 변수열을 선택하라. . df.loc[:,map(lambda x: &#39;face&#39; in x, df.columns)] . director_facebook_likes actor_3_facebook_likes actor_1_facebook_likes cast_total_facebook_likes facenumber_in_poster actor_2_facebook_likes movie_facebook_likes . 0 0.0 | 855.0 | 1000.0 | 4834 | 0.0 | 936.0 | 33000 | . 1 563.0 | 1000.0 | 40000.0 | 48350 | 0.0 | 5000.0 | 0 | . 2 0.0 | 161.0 | 11000.0 | 11700 | 1.0 | 393.0 | 85000 | . 3 22000.0 | 23000.0 | 27000.0 | 106759 | 0.0 | 23000.0 | 164000 | . 4 131.0 | NaN | 131.0 | 143 | 0.0 | 12.0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | . 4911 2.0 | 318.0 | 637.0 | 2283 | 2.0 | 470.0 | 84 | . 4912 NaN | 319.0 | 841.0 | 1753 | 1.0 | 593.0 | 32000 | . 4913 0.0 | 0.0 | 0.0 | 0 | 0.0 | 0.0 | 16 | . 4914 0.0 | 489.0 | 946.0 | 2386 | 5.0 | 719.0 | 660 | . 4915 16.0 | 16.0 | 86.0 | 163 | 0.0 | 23.0 | 456 | . 4916 rows × 7 columns . df.loc[:,map(lambda x: &#39;face&#39; not in x, df.columns)] # face가 들어가지 않는 변수 열 . color director_name num_critic_for_reviews duration actor_2_name gross genres actor_1_name movie_title num_voted_users ... plot_keywords movie_imdb_link num_user_for_reviews language country content_rating budget title_year imdb_score aspect_ratio . 0 Color | James Cameron | 723.0 | 178.0 | Joel David Moore | 760505847.0 | Action|Adventure|Fantasy|Sci-Fi | CCH Pounder | Avatar | 886204 | ... | avatar|future|marine|native|paraplegic | http://www.imdb.com/title/tt0499549/?ref_=fn_t... | 3054.0 | English | USA | PG-13 | 237000000.0 | 2009.0 | 7.9 | 1.78 | . 1 Color | Gore Verbinski | 302.0 | 169.0 | Orlando Bloom | 309404152.0 | Action|Adventure|Fantasy | Johnny Depp | Pirates of the Caribbean: At World&#39;s End | 471220 | ... | goddess|marriage ceremony|marriage proposal|pi... | http://www.imdb.com/title/tt0449088/?ref_=fn_t... | 1238.0 | English | USA | PG-13 | 300000000.0 | 2007.0 | 7.1 | 2.35 | . 2 Color | Sam Mendes | 602.0 | 148.0 | Rory Kinnear | 200074175.0 | Action|Adventure|Thriller | Christoph Waltz | Spectre | 275868 | ... | bomb|espionage|sequel|spy|terrorist | http://www.imdb.com/title/tt2379713/?ref_=fn_t... | 994.0 | English | UK | PG-13 | 245000000.0 | 2015.0 | 6.8 | 2.35 | . 3 Color | Christopher Nolan | 813.0 | 164.0 | Christian Bale | 448130642.0 | Action|Thriller | Tom Hardy | The Dark Knight Rises | 1144337 | ... | deception|imprisonment|lawlessness|police offi... | http://www.imdb.com/title/tt1345836/?ref_=fn_t... | 2701.0 | English | USA | PG-13 | 250000000.0 | 2012.0 | 8.5 | 2.35 | . 4 NaN | Doug Walker | NaN | NaN | Rob Walker | NaN | Documentary | Doug Walker | Star Wars: Episode VII - The Force Awakens | 8 | ... | NaN | http://www.imdb.com/title/tt5289954/?ref_=fn_t... | NaN | NaN | NaN | NaN | NaN | NaN | 7.1 | NaN | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 4911 Color | Scott Smith | 1.0 | 87.0 | Daphne Zuniga | NaN | Comedy|Drama | Eric Mabius | Signed Sealed Delivered | 629 | ... | fraud|postal worker|prison|theft|trial | http://www.imdb.com/title/tt3000844/?ref_=fn_t... | 6.0 | English | Canada | NaN | NaN | 2013.0 | 7.7 | NaN | . 4912 Color | NaN | 43.0 | 43.0 | Valorie Curry | NaN | Crime|Drama|Mystery|Thriller | Natalie Zea | The Following | 73839 | ... | cult|fbi|hideout|prison escape|serial killer | http://www.imdb.com/title/tt2071645/?ref_=fn_t... | 359.0 | English | USA | TV-14 | NaN | NaN | 7.5 | 16.00 | . 4913 Color | Benjamin Roberds | 13.0 | 76.0 | Maxwell Moody | NaN | Drama|Horror|Thriller | Eva Boehnke | A Plague So Pleasant | 38 | ... | NaN | http://www.imdb.com/title/tt2107644/?ref_=fn_t... | 3.0 | English | USA | NaN | 1400.0 | 2013.0 | 6.3 | NaN | . 4914 Color | Daniel Hsia | 14.0 | 100.0 | Daniel Henney | 10443.0 | Comedy|Drama|Romance | Alan Ruck | Shanghai Calling | 1255 | ... | NaN | http://www.imdb.com/title/tt2070597/?ref_=fn_t... | 9.0 | English | USA | PG-13 | NaN | 2012.0 | 6.3 | 2.35 | . 4915 Color | Jon Gunn | 43.0 | 90.0 | Brian Herzlinger | 85222.0 | Documentary | John August | My Date with Drew | 4285 | ... | actress name in title|crush|date|four word tit... | http://www.imdb.com/title/tt0378407/?ref_=fn_t... | 84.0 | English | USA | PG | 1100.0 | 2004.0 | 6.6 | 1.85 | . 4916 rows × 21 columns .",
            "url": "https://seoyeonc.github.io/chch/2021/10/18/%EB%8D%B0%EC%8B%9C_6%EC%A3%BC%EC%B0%A8.html",
            "relUrl": "/2021/10/18/%EB%8D%B0%EC%8B%9C_6%EC%A3%BC%EC%B0%A8.html",
            "date": " • Oct 18, 2021"
        }
        
    
  
    
        ,"post6": {
            "title": "데이터시각화 특강 (5주차) 10월12일",
            "content": "- (1/8) qqplot . - (2/8) 정규분포, t분포 qqplot 비교 . - (3/8) 분위수를 구하는 다양한 방법 . - (4/8) lambda . - (5/8) map (1) . - (6/8) map (2) . - (7/8) 에드워드 터프티, 찰스미나드의 도표. . &#50696;&#51228; (qqplot): . - 히스토그램이나 박스플랏보다 분포를 특정하기에 좋은 시각화는 없을까? . import numpy as np import matplotlib.pyplot as plt import pandas as pd import seaborn as sns from scipy import stats . np.random.seed(202150754) x=np.random.normal(size=1000,loc=2,scale=1.5) y=stats.t.rvs(df=10,size=1000)/np.sqrt(10/8)*1.5 + 2 . - 우리가 관측한 $x_1, dots,x_{1000}$이 $N(2,1.5^2)$에서 나온 샘플인지 궁금하다. . - 아이디어 . (1) 관측한 값을 순서대로 나열하여 $x_{(1)},x_{(2)}, dots, x_{(1000)}$을 만든다. . x[:2] . array([1.69112919, 2.6509918 ]) . $x_1=2.57513073, quad x_2=3.62626175$ | . x.sort() # 정렬하고 싶을 때 . x[:2] #전이랑 바뀐 순서 볼 수 있다. . array([-3.68558942, -2.10072397]) . $x_{(1)}= -2.44398446, quad x_{(2)}=-2.14071467$ | . (2) 파이썬이나 R로 $N(2,1.5^2)$에서 1000개의 정규분포를 생성. 그리고 순서대로 나열하여 $ tilde{x}_{(1)}, tilde{x}_{(2)}, dots, tilde{x}_{(1000)}$를 만든다. . (3) $x_{(1)} approx tilde{x}_{(1)}, dots , x_{(1000)} approx tilde{x}_{(1000)}$ 이면 x는 정규분포일것 . - 그런데 $ tilde{x}_{(1)}, tilde{x}_{(2)}, dots, tilde{x}_{(1000)}$은 시뮬레이션을 할때마다 다른값이 나올테니까 불안정한 느낌이 든다. $ to$ 이론적인 값을 계산하자. . xx = (x-np.mean(x)) / np.std(x,ddof=1) xx[:2] . array([-4.00826428, -2.9063461 ]) . 실제우리가 관측한값 | . print(stats.norm.ppf(0.001)) print(stats.norm.ppf(0.002)) . -3.090232306167813 -2.878161739095483 . - stats.norm.ppf(0.001) 확률 0.001에 해당하는 정규분포 상에서의 값 . 이론적인 값 | . - 분위수 . m=[i/1000 for i in np.arange(1000)+1] . q=[] for i in range(len(m)): q=q+[stats.norm.ppf(m[i])] . q[:2] . [-3.090232306167813, -2.878161739095483] . - $xx approx q$ 을 확인하기 위해서 $(q,q)$그래프와 $(q,xx)$의 그래프를 그려서 겹쳐보자. . plt.plot(q,xx,&#39;o&#39;) plt.plot(q,q,&#39;-&#39;) # xx가 q와 비슷한지 확인하기 위해서 그래프 겹쳐서 그려보기 . [&lt;matplotlib.lines.Line2D at 0x7fe41f282100&gt;] . 해석: 점들이 주황색선 근처에 모여있을수록 정규분포에 가깝다. | . - 아래와 같이 쉽게 그릴수도 있다. (우리가 그린그림과 조금 다르게 보인다) . _ = stats.probplot(x,plot=plt) . 자세히보면 조금 다르게 그려지긴 하는데 이는 $m=( frac{1}{1000}, dots, frac{999}{1000}, frac{1000}{1000})$와 같이 계산하지 않고 약간 보정한값을 계산하기 때문임 | stats.probplot? 을 통하여 확인한 결과 아래와 같은 코드로 구현됨### 보정하는방법1 n=len(xx) m=[((i+1)-0.3175)/(n+0.365) for i in range(n)] m[-n]=0.5**(1/n) m[0]=1-m[-n] . | 프로그램에 따라서 아래와 같이 보정하는 경우도 있음### 보정하는방법2 m=[(i-3/8)/(n+1/4) for i in np.arange(1000)+1] . | 또 자세히보면 stats.probplot은 y축에 표준화전의 x값이 있음을 알 수 있음. | . - 정규분포와 t분포의 qqplot을 그려서 비교해보자. . _ = stats.probplot(x,plot=plt) # 정규분포 . 정규분포 | . _ = stats.probplot(y,plot=plt) # t분포 . t분포: 푸른점들이 대체로 붉은선위에 놓여있는듯 하지만 양끝단에서는 그렇지 않다. (중앙부근은 정규분포와 비슷하지만, 꼬리부분은 정규분포와 확실히 다르다) | 왼쪽꼬리: 이론적으로 나와야 할 값보다 더 작은값이 실제로 관측됨 | 오른쪽꼬리: 이론적으로 나와야 할 값보다 더 큰값이 실제로 관측됨 | 해석: 이 분포는 정규분포보다 두꺼운 꼬리를 가진다. | . - 서브플랏팅: 두 분포를 양옆에 나란히 비교하고 싶음 . fig , (ax1,ax2) = plt.subplots(1,2) . _ = stats.probplot(x,plot=ax1) _ = stats.probplot(y,plot=ax2) . fig # 이것은 메트플랏라이브러리 기반이라 같이 그릴 수 있음 . fig.set_figwidth(8) . fig . ax1.set_title(&#39;normal dist&#39;) ax2.set_title(&#39;t dist&#39;) . Text(0.5, 1.0, &#39;t dist&#39;) . fig . &#50696;&#51228;4 (boxplot, histrogram, qqplot) . - 박스플랏, 히스토그램, qqplot을 그려보자. . fig, ax =plt.subplots(2,3) . (ax1,ax2,ax3), (ax4,ax5,ax6) = ax . sns.boxplot(x,ax=ax1) sns.histplot(x,kde=True,ax=ax2) _ = stats.probplot(x,plot=ax3) sns.boxplot(y,ax=ax4) sns.histplot(y,kde=True,ax=ax5) _ = stats.probplot(y,plot=ax6) . /home/cgb4/anaconda3/envs/csy/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation. warnings.warn( /home/cgb4/anaconda3/envs/csy/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation. warnings.warn( . fig . fig.set_figwidth(10) fig.set_figheight(8) fig.tight_layout() . fig . Appendix: &#48516;&#50948;&#49688;&#47484; &#44396;&#54616;&#45716; &#45796;&#50577;&#54620;&#48169;&#48277; . m=[i/1000 for i in np.arange(1000)+1] . $m= big { frac{i}{1000}: i in {1,2,3, dots,1000 } big }= big { frac{1}{1000}, frac{2}{1000}, dots, frac{1000}{1000} big }$ | . - 방법1 . q=[] for i in range(len(m)): q=q+[stats.norm.ppf(m[i])] q[:5] . [-3.090232306167813, -2.878161739095483, -2.7477813854449926, -2.6520698079021954, -2.575829303548901] . - 방법2 . q=[stats.norm.ppf(m[i]) for i in range(len(m))] . q[:5] # 두 번째 방법 stats.norm.ppf는 여기서 m(i)에 대응하는 정규분포의 값 . [-3.090232306167813, -2.878161739095483, -2.7477813854449926, -2.6520698079021954, -2.575829303548901] . - 방법3 . q=list(map(stats.norm.ppf, m)) q[:5] # 세 번째 방법 list 꼭 해줘야 값들이 나타남 . [-3.090232306167813, -2.878161739095483, -2.7477813854449926, -2.6520698079021954, -2.575829303548901] . - 방법4 . stats.norm.ppf(m)[:5] . array([-3.09023231, -2.87816174, -2.74778139, -2.65206981, -2.5758293 ]) . Appendix: lambda, map . lambda . - 예제1: 사용방법 . f = lambda x,y,z : x+y+z ## lambda 입력:출력 . f(2,3,4) . 9 . - 예제2: 디폴트입력값 . x= (lambda a=&#39;fee&#39;,b=&#39;fie&#39;,c=&#39;foe&#39;: a+b+c) . x(&#39;wee&#39;) # x가 object화 된다. . &#39;weefiefoe&#39; . - 예제3: 람다들의 리스트가능 . l=[lambda x: x**2, lambda x: x**3, lambda x: x**4] . for f in l: print(f(2)) . 4 8 16 . - 예제4: 람다들의 딕셔너리 가능 . dct={&#39;f1&#39;: (lambda x: x+1), &#39;f2&#39;: (lambda x: x+22), &#39;f3&#39;: (lambda x: x+333)} . dct[&#39;f1&#39;](1), dct[&#39;f2&#39;](1), dct[&#39;f3&#39;](1) . (2, 23, 334) . - 예제5: 조건부 출력 . (예비학습) 문자열의 대소비교 . &#39;a&#39; &lt; &#39;b&#39; . True . &#39;c&#39; &lt; &#39;b&#39; . False . (예제시작) . lower = lambda x,y : x if x&lt;y else y . lower(&#39;a&#39;,&#39;b&#39;) . &#39;a&#39; . lower(&#39;c&#39;,&#39;b&#39;) . &#39;b&#39; . - 예제6 : lambda expression 을 return력가능 . def action(x): return (lambda y : x+y) # 예제 6 lambda expression을 return 출력 가능 # lambda y:x+y 자체가 오브젝트라 가능 # lambda 괄호 생략해도 가능! 여기서는 단순히 구분하기 위함 . act = action(99) ## act는 99+y를 수행하는 함수 act2 = action(98) ## act2는 99+y를 수행하는 함수 . action은 마치 함수를 만드는 함수같다.. | . print(act(2)) print(act2(2)) . 101 100 . - 예제7: 예제6의 발전 . action = lambda x: (lambda y: x+y) . act= action(99) act2=action(98) . print(act(2)) print(act2(2)) . 101 100 . 괄호를 생략하여 선언하면 . action = lambda x: lambda y: x+y act= action(99) act2=action(98) print(act(2)) print(act2(2)) # 괄호 생략해도 값은 같은 모습을 볼 수 있다. . 101 100 . map . - 예제1: 사용방법 . def inc(x): return x+1 . list(map(inc,[1,2,3,4])) . [2, 3, 4, 5] . - 예제1의 변형(람다사용) . list(map(lambda x: x+1,[1,2,3,4])) . [2, 3, 4, 5] . list(map(def inc(x): return x+1,[1,2,3,4])) # 이 코드는 오류뜨는 코드 . File &#34;&lt;ipython-input-67-e9cc33ee66ab&gt;&#34;, line 1 list(map(def inc(x): return x+1,[1,2,3,4])) # 이 코드는 오류뜨는 코드 ^ SyntaxError: invalid syntax . 함수명을 쓰는 자리에 lambda로 표현한 오브젝트 자체를 전달할 수 있다. $ to$ 코드가 간단하다. | . - 예제2: map과 리스트컴프리헨션 비교 . (함수선언) . f = lambda x: &#39;X&#39; in x . f(&#39;X1&#39;),f(&#39;X2&#39;),f(&#39;Y1&#39;),f(&#39;Y2&#39;) . (True, True, False, False) . (map) . list(map(f,[&#39;X1&#39;,&#39;X2&#39;,&#39;Y3&#39;,&#39;Y4&#39;])) . [True, True, False, False] . (리스트컴프리헨션과 비교) . [f(x) for x in [&#39;X1&#39;,&#39;X2&#39;,&#39;Y3&#39;,&#39;Y4&#39;]] . [True, True, False, False] . - 예제3: 두개의 입력을 받는 함수(pow) map, 리스트컴프리헨션 비교 . (함수소개) . pow(2,3) # 2의 3제곱 해주는 함수 . 8 . (map) . list(map(pow,[2,2,2,3,3,3],[0,1,2,0,1,2])) . [1, 2, 4, 1, 3, 9] . (리스트컴프리헨션과 비교) . [pow(x,y) for x,y in zip([2,2,2,3,3,3],[0,1,2,0,1,2])] . [1, 2, 4, 1, 3, 9] . - 예제4: map은 (하나의 함수,다양한 입력)인 경우 사용가능 . l=[lambda x: x+1, lambda x: x+2, lambda x: x+3 ] . list(map(l,[100,200,300]))# 오류 뜨는 코드 # l 함수 자체에 매핑해주면 오류가.. . TypeError Traceback (most recent call last) &lt;ipython-input-76-1316ab488d60&gt; in &lt;module&gt; -&gt; 1 list(map(l,[100,200,300]))# 오류 뜨는 코드 2 # l 함수 자체에 매핑해주면 오류가.. TypeError: &#39;list&#39; object is not callable . 리스트컴프리헨션은 (다양한함수,다양한입력)이 가능함 . [l[i](x) for i,x in zip([0,1,2],[100,200,300])] . [101, 202, 303] . - 종합: 리스트컴프리헨션과 비교하면 (1) 반복인덱스를 쓰지 않는 장점이 있는 반면 (2) 좀 더 제약적으로 사용할 수밖에 없다는 단점이 있음 . &#50528;&#46300;&#50892;&#46300; &#53552;&#54532;&#54000; . - 시각화계의 거장 . - 터프티의 이론중 백미: 엄격한 미니멀리즘 . 최소한의 잉크로 많은 정보를 전달할 수 있다면 그것이 바로 좋은 그래프이다. | 작은 지면 내에서 잉크를 최대한 적게 써서 짧은 시간 안에 많은 영감을 주어야 한다. | . - 데이터-잉크비: 데이터를 표현하는데 들아가는 잉크의 양 / 그래픽을 인쇄하는데 들어가는 잉크의 총량 . - 차트정크 (나이젤홈즈의 그래프) . . “Lurking behind chartjunk is contempt both for information and for the audience. Chartjunk promoters imagine that numbers and details are boring, dull, and tedious, requiring ornament to enliven. Cosmetic decoration, which frequently distorts the data, will never salvage an underlying lack of content. If the numbers are boring, then you’ve got the wrong numbers (...) Worse is contempt for our audience, designing as if readers were obtuse and uncaring. In fact, consumers of graphics are often more intelligent about the information at hand than those who fabricate the data decoration (...) The operating moral premise of information design should be that our readers are alert and caring; they may be busy, eager to get on with it, but they are not stupid.” . 차트정크 = 대중을 멸시 + 데이터에 대한 모독 | 차트정크 옹호가는 숫자와 데이터가 지루하여 활기가 필요하다고 생각하는 모양이다.. | . - 별로인 그래프 (왼쪽) / 우수한 그래프 오른쪽 . . - 별로인 그래프 (왼쪽) / 우수한 그래프 오른쪽 . . - 별로인 그래프 (왼쪽) / 우수한 그래프 오른쪽 . . - 글쎼... . &#52272;&#49828;&#48120;&#45208;&#46300;&#51032; &#46020;&#54364; (&#51064;&#47448;&#50669;&#49324;&#49345; &#44032;&#51109; &#54988;&#47469;&#54620; &#49884;&#44033;&#54868;) . . - 터프티의 평 . 지금까지 그려진 최고의 통계 그래픽일지도 모른다. | 여기에서는 군대의 크기, 2차원 평면상의 위치, 군대의 이동방향, 모스코바에서 퇴각하는 동안의 여러날짜, 온도 $ to$ 6차원의 변수 | 백만번에 한번 이런 그림을 그릴수는 있겠지만 이러한 멋진 그래픽을 만드는 방법에 대한 원칙은 없다. $ to$ 미니멀리즘.. | . - 왜 우수한 그래프일까? . 자료를 파악하는 기법은 최근까지도 산점도, 막대그래프, 라인플랏에 의존 | 이러한 플랏의 단점은 고차원의 자료를 분석하기 어렵다는 것임 | 미나드는 여러그램을 그리는 방법 대신에 한 그림에서 패널을 늘리는 방법을 선택함. | . &#50696;&#51228; . x=[44,48,49,58,62,68,69,70,76,79] ## 몸무게 y=[159,160,162,165,167,162,165,175,165,172] ## 키 g= &#39;f&#39;,&#39;f&#39;,&#39;f&#39;,&#39;f&#39;,&#39;m&#39;,&#39;f&#39;,&#39;m&#39;,&#39;m&#39;,&#39;m&#39;,&#39;m&#39; df=pd.DataFrame({&#39;w&#39;:x,&#39;h&#39;:y,&#39;g&#39;:g}) . df . w h g . 0 44 | 159 | f | . 1 48 | 160 | f | . 2 49 | 162 | f | . 3 58 | 165 | f | . 4 62 | 167 | m | . 5 68 | 162 | f | . 6 69 | 165 | m | . 7 70 | 175 | m | . 8 76 | 165 | m | . 9 79 | 172 | m | . - 미나드의 접근방법 . sns.scatterplot(data=df,x=&#39;w&#39;,y=&#39;h&#39;,hue=&#39;g&#39;) . &lt;AxesSubplot:xlabel=&#39;w&#39;, ylabel=&#39;h&#39;&gt; . - 일반적인 사람들 (보통 색깔을 사용할 생각을 못한다.) . figs = sns.FacetGrid(df,col=&#39;g&#39;) # 다중 그래프 그릴때 많이 사용됨 figs.map (sns.scatterplot,&#39;w&#39;,&#39;h&#39;) . &lt;seaborn.axisgrid.FacetGrid at 0x7fe41e51d460&gt; . - 생각보다 데이터가 정리된 형태에 따라서 시각화에 대한 사고방식이 달라진다. 아래와 같은 자료를 받았다고 하자. . df1=df.query(&quot;g ==&#39;f&#39;&quot;)[[&#39;w&#39;,&#39;h&#39;]] ## 여성.csv df2=df.query(&quot;g ==&#39;m&#39;&quot;)[[&#39;w&#39;,&#39;h&#39;]] ## 남성.csv #query 함수의 비교 연산자 사용한 경우 . query 함수의 6가지 기능 . 비교 연산자( ==, &gt;, &gt;=, &lt;, &lt;=, != ) | in 연산자( in, ==, not in, != ) | 논리 연산자(and, or, not) | 외부 변수(또는 함수) 참조 연산 | 인덱스 검색 | 문자열 부분검색( str.contains, str.startswith, str.endswith ) | df1 . w h . 0 44 | 159 | . 1 48 | 160 | . 2 49 | 162 | . 3 58 | 165 | . 5 68 | 162 | . df2 . w h . 4 62 | 167 | . 6 69 | 165 | . 7 70 | 175 | . 8 76 | 165 | . 9 79 | 172 | . - 데이터프레임을 바꿀 생각을 하는게 쉽지 않다. . (방법1) . df1[&#39;g&#39;]= &#39;f&#39; # 성별이 여성인 경우만 가져왔기에 성별에 f 표시 . df1 . w h g . 0 44 | 159 | f | . 1 48 | 160 | f | . 2 49 | 162 | f | . 3 58 | 165 | f | . 5 68 | 162 | f | . df2[&#39;g&#39;]= &#39;m&#39; # 성별이 남성인 경우만 가져왔기에 성별에 m 표시 . df2 . w h g . 4 62 | 167 | m | . 6 69 | 165 | m | . 7 70 | 175 | m | . 8 76 | 165 | m | . 9 79 | 172 | m | . pd.concat([df1,df2]) # concat 은 데이터프레임 이어붙여주는 함수 . w h g . 0 44 | 159 | f | . 1 48 | 160 | f | . 2 49 | 162 | f | . 3 58 | 165 | f | . 5 68 | 162 | f | . 4 62 | 167 | m | . 6 69 | 165 | m | . 7 70 | 175 | m | . 8 76 | 165 | m | . 9 79 | 172 | m | . (방법2) . df1=df.query(&quot;g ==&#39;f&#39;&quot;)[[&#39;w&#39;,&#39;h&#39;]] ## 여성.csv df2=df.query(&quot;g ==&#39;m&#39;&quot;)[[&#39;w&#39;,&#39;h&#39;]] ## 남성.csv . pd.concat([df1,df2],keys=[&#39;f&#39;,&#39;m&#39;]).reset_index().iloc[:,[0,2,3]].rename(columns={&#39;level_0&#39;:&#39;g&#39;}) . g w h . 0 f | 44 | 159 | . 1 f | 48 | 160 | . 2 f | 49 | 162 | . 3 f | 58 | 165 | . 4 f | 68 | 162 | . 5 m | 62 | 167 | . 6 m | 69 | 165 | . 7 m | 70 | 175 | . 8 m | 76 | 165 | . 9 m | 79 | 172 | . - 어려운점: (1) 센스가 없어서 색깔을 넣어서 그룹을 구분할 생각을 못함 (2) 변형해야할 데이터를 생각못함 (3) 데이터를 변형할 생각을 한다고 해도 변형하는 실제적인 코드를 구현할 수 없음 (그래서 엑셀을 킨다..) . (1) 기획력부족 -&gt; 훌륭한 시각화를 많이 볼것 | (2) 데이터프레임에 대한 이해도가 부족 -&gt; tidydata에 대한 개념 | (3) 프로그래밍 능력 부족 -&gt; 코딩공부열심히.. | . - 목표: (2) 어떠한 데이터 형태로 변형해야하는가? (3) 그러한 데이터 형태로 바꾸기 위한 pandas 숙련도 . &#49689;&#51228; . - 자유도가5인 카이제곱분포에서 100개의 랜덤변수를 만들고, boxplot / histogram / qqplot . x=np.random.chisquare(df=5, size=100) . fig,(ax1,ax2,ax3)=plt.subplots(1,3) sns.boxplot(x,ax=ax1) sns.histplot(x, kde=True,ax=ax2) _ = stats.probplot(x,plot=ax3) fig.set_figwidth(10) . /home/cgb4/anaconda3/envs/csy/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation. warnings.warn( .",
            "url": "https://seoyeonc.github.io/chch/2021/10/12/%EB%8D%B0%EC%8B%9C_5%EC%A3%BC%EC%B0%A8.html",
            "relUrl": "/2021/10/12/%EB%8D%B0%EC%8B%9C_5%EC%A3%BC%EC%B0%A8.html",
            "date": " • Oct 12, 2021"
        }
        
    
  
    
        ,"post7": {
            "title": "데이터시각화 특강 (4주차) 10월5일",
            "content": "- (1/11): 액시즈를 이용한 플랏 (1) . - (2/11): 액시즈를 이용한 플랏 (2) . - (3/11): 액시즈를 이용한 플랏 (3) . - (4/11): 액시즈를 이용한 플랏 (4) . - (5/11): 액시즈를 이용한 플랏 (5) . - (6/11): title 설정 . - (7/11): 축의 범위를 설정, 독립과 상관계수 (1) . - (8/11): 독립과 상관계수 (2) . - (9/11): matplotlib + seaborn (1) . - (10/11): matplotlib + seaborn (2), qqplot motivation (1) . - (11/11): qqplot motivation (2) . matplotlib&#47196; (&#51652;&#51676; &#50612;&#47157;&#44172;) &#44536;&#47548;&#51012; &#44536;&#47532;&#45716; &#48169;&#48277; . &#50640;&#51228;1: &#50529;&#49884;&#51592;&#47484; &#51060;&#50857;&#54620; &#54540;&#46991; . - 목표: plt.plot() 을 사용하지 않고 아래 그림을 그려보자. . import matplotlib.pyplot as plt plt.plot([1,2,3],&#39;or&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f80e0730f70&gt;] . - 구조: axis $ subset$ axes $ subset$ figure . https://matplotlib.org/stable/gallery/showcase/anatomy.html#sphx-glr-gallery-showcase-anatomy-py | . - 전략: 그림을 만들고 (도화지를 준비) $ to$ 액시즈를 만들고 (네모틀을 만든다) $ to$ 액시즈에 그림을 그린다. (.plot()을 이용) . - 우선 그림객체를 생성한다. . fig = plt.figure() # 도화지를 준비한다. . &lt;Figure size 432x288 with 0 Axes&gt; . fig # 현재 도화지상태를 체크 . &lt;Figure size 432x288 with 0 Axes&gt; . 그림객체를 출력해봐야 아무것도 나오지 않는다. (아무것도 없으니까..) | . fig.add_axes() ## 액시즈를 fig에 추가하라. fig.axes ## 현재 fig에 있는 액시즈 정보 . fig.axes # 현재 네모틀 상태를 체크 . [] . fig.add_axes([0,0,1,1]) # 도화지안에 (0,0) 위치에 길이가 (1,1) 인 네모틀을 만든다. . &lt;Axes:&gt; . fig.axes # 현재 네모틀 상태를 체크 --&gt; 네모틀이 하나 있음. . [&lt;Axes:&gt;] . fig # 현재도화지 상태 체크 --&gt; 도화지에 (하나의) 네모틀이 잘 들어가 있음 . axs1=fig.axes[0] ## 첫번째 액시즈 . axs1.plot([1,2,3],&#39;ob&#39;) # 첫번쨰 액시즈에 접근하여 그림을 그림 . [&lt;matplotlib.lines.Line2D at 0x7f80dfe94340&gt;] . fig #현재 도화지 상태 체크 --&gt; 그림이 잘 그려짐 . &#50696;&#51228;2: &#50529;&#49884;&#51592;&#47484; &#51060;&#50857;&#54620; &#49436;&#48652;&#54540;&#46991; (&#48169;&#48277;1) . - 목표: subplot . fig # 현재 도화지 출력 . - 액시즈추가 . fig.add_axes([1,0,1,1]) . &lt;Axes:&gt; . fig.axes . [&lt;Axes:&gt;, &lt;Axes:&gt;] . fig . axs2=fig.axes[1] ## 두번째 액시즈 . - 두번째 액시즈에 그림그림 . axs2.plot([1,2,3],&#39;ok&#39;) ## 두번째 액시즈에 그림그림 . [&lt;matplotlib.lines.Line2D at 0x7f80dfe0cf40&gt;] . fig ## 현재 도화지 체크 . - 첫번째 액시즈에 그림추가 . axs1.plot([1,2,3],&#39;--b&#39;) ### 액시즈1에 점선추가 . [&lt;matplotlib.lines.Line2D at 0x7f80dfdc7af0&gt;] . fig ## 현재 도화지 체크 . &#50696;&#51228;3: &#50529;&#49884;&#51592;&#47484; &#51060;&#50857;&#54616;&#50668; &#49436;&#48652;&#54540;&#46991; (&#48169;&#48277;2) . - 예제2의 레이아웃이 좀 아쉽다. . - 다시 그려보자. . fig = plt.figure() . &lt;Figure size 432x288 with 0 Axes&gt; . fig.axes . [] . fig.subplots(1,2) . array([&lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;], dtype=object) . fig.axes . [&lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;] . ax1,ax2 = fig.axes . ax1.plot([1,2,3],&#39;or&#39;) ax2.plot([1,2,3],&#39;ob&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f80dfd4a7f0&gt;] . fig . 그림이 좀 좁은것 같다. (도화지를 늘려보자) | . fig.set_figwidth(10) . fig . ax1.plot([1,2,3],&#39;--b&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f80dfd0da60&gt;] . fig . &#50696;&#51228;4: &#50529;&#49884;&#51592;&#47484; &#51060;&#50857;&#54616;&#50668; 2$ times$2 &#49436;&#48652;&#54540;&#46991; &#44536;&#47532;&#44592; . fig = plt.figure() fig.axes . [] . &lt;Figure size 432x288 with 0 Axes&gt; . fig.subplots(2,2) fig.axes . [&lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;] . ax1,ax2,ax3,ax4=fig.axes . ax1.plot([1,2,3],&#39;ob&#39;) ax2.plot([1,2,3],&#39;or&#39;) ax3.plot([1,2,3],&#39;ok&#39;) ax4.plot([1,2,3],&#39;oy&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f80dfc1eac0&gt;] . fig . &#50696;&#51228;5: plt.subplots()&#47484; &#51060;&#50857;&#54616;&#50668; 2$ times$2 &#49436;&#48652;&#54540;&#46991; (&#48373;&#49845;) . x=[1,2,3,4] y=[1,2,4,3] _, axs = plt.subplots(2,2) axs[0,0].plot(x,y,&#39;o:r&#39;) axs[0,1].plot(x,y,&#39;Xb&#39;) axs[1,0].plot(x,y,&#39;xm&#39;) axs[1,1].plot(x,y,&#39;.--k&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f80dfae33d0&gt;] . - 단계적으로 코드를 실행하고 싶을때 . x=[1,2,3,4] y=[1,2,4,3] . _, axs = plt.subplots(2,2) . axs[0,0].plot(x,y,&#39;o:r&#39;) axs[0,1].plot(x,y,&#39;Xb&#39;) axs[1,0].plot(x,y,&#39;xm&#39;) axs[1,1].plot(x,y,&#39;.--k&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f80df90c490&gt;] . 어? 그림을 볼려면 어떻게 하지? | . _ . 이렇게 하면된다. | . - 단계적으로 그림을 그릴경우에는 도화지객체를 fig라는 변수로 명시하여 받는것이 가독성이 좋다. . x=[1,2,3,4] y=[1,2,4,3] . fig, axs = plt.subplots(2,2) . axs[0,0].plot(x,y,&#39;o:r&#39;) axs[0,1].plot(x,y,&#39;Xb&#39;) axs[1,0].plot(x,y,&#39;xm&#39;) axs[1,1].plot(x,y,&#39;.--k&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f80df7ef730&gt;] . fig # 현재 도화지 확인 . &#50696;&#51228;6: plt.subplots()&#47484; 2$ times$2 subplot &#44536;&#47532;&#44592; -- &#50529;&#49884;&#51592;&#47484; &#44033;&#44033; &#48320;&#49688;&#47749;&#51004;&#47196; &#51200;&#51109; . x=[1,2,3,4] y=[1,2,4,3] fig, axs = plt.subplots(2,2) . ax1,ax2,ax3,ax4 =axs . ValueError Traceback (most recent call last) &lt;ipython-input-50-3b8534556de7&gt; in &lt;module&gt; -&gt; 1 ax1,ax2,ax3,ax4 =axs ValueError: not enough values to unpack (expected 4, got 2) . 2x2로 만들어줬으니까 행,열 개수 별로 묶어주기 | . (ax1,ax2), (ax3,ax4) = axs . ax1.plot(x,y,&#39;o:r&#39;) ax2.plot(x,y,&#39;Xb&#39;) ax3.plot(x,y,&#39;xm&#39;) ax4.plot(x,y,&#39;.--k&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f80df5c3160&gt;] . fig . &#50696;&#51228;7: plt.subplots()&#47484; &#51060;&#50857;&#54616;&#50668; 2$ times$2 &#49436;&#48652;&#54540;&#46991; &#44536;&#47532;&#44592; -- fig.axes&#50640;&#49436; &#51217;&#44540;! . fig, _ = plt.subplots(2,2) . fig.axes . [&lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;] . _를 그대로 받지 않고, fig옵션에서 axes를 받아온 거라 안 묶어줘도 된다. | . ax1, ax2, ax3, ax4= fig.axes . ax1.plot(x,y,&#39;o:r&#39;) ax2.plot(x,y,&#39;Xb&#39;) ax3.plot(x,y,&#39;xm&#39;) ax4.plot(x,y,&#39;.--k&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f80df5c7280&gt;] . fig . - 예제7, 예제4와 비교해볼것: 거의 비슷함 . - matplotlib은 그래프를 쉽게 그릴수도 있지만 어렵게 그릴수도 있다. . - 오브젝트를 컨트르로 하기 어려우므로 여러가지 축약버전이 존재함. . 사실 그래서 서브플랏을 그리는 방법 1,2,3... 와 같은 식으로 정리하여 암기하기에는 무리가 있다. | . - 원리를 깨우치면 다양한 방법을 자유자재로 쓸 수 있음. (자유도가 높음) . &#51228;&#47785;&#49444;&#51221; . &#50696;&#51228;1: plt.plot() . x=[1,2,3] y=[1,2,2] . plt.plot(x,y) plt.title(&#39;title&#39;) . Text(0.5, 1.0, &#39;title&#39;) . &#50696;&#51228;2: &#50529;&#49884;&#51592;&#47484; &#51060;&#50857; . fig = plt.figure() fig.subplots() . &lt;AxesSubplot:&gt; . ax1=fig.axes[0] . ax1.set_title(&#39;title&#39;) . Text(0.5, 1.0, &#39;title&#39;) . fig . - 문법을 잘 이해했으면 각 서브플랏의 제목을 설정하는 방법도 쉽게 알 수 있다. . &#50696;&#51228;3: subplot&#50640;&#49436; &#44033;&#44033;&#51032; &#51228;&#47785;&#49444;&#51221; . fig, ax = plt.subplots(2,2) . (ax1,ax2),(ax3,ax4) =ax . ax1.set_title(&#39;title1&#39;) ax2.set_title(&#39;title2&#39;) ax3.set_title(&#39;title3&#39;) ax4.set_title(&#39;title4&#39;) . Text(0.5, 1.0, &#39;title4&#39;) . fig . - 보기싫음 $ to$ 서브플랏의 레이아웃 재정렬 . fig.tight_layout() # 외우세요.. . 서브플랏의 레이아웃 재정렬 옵션 | . &#50696;&#51228;4: &#50529;&#49884;&#51592;&#51032; &#51228;&#47785; + Figure&#51228;&#47785; . fig.suptitle(&#39;sup title&#39;) . Text(0.5, 0.98, &#39;sup title&#39;) . fig . fig.tight_layout() . fig . &#52629;&#48276;&#50948;&#49444;&#51221; . &#50696;&#51228;1 . x=[1,2,3] y=[4,5,6] . plt.plot(x,y,&#39;o&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f80df1f6940&gt;] . plt.plot(x,y,&#39;o&#39;) plt.xlim(-1,5) plt.ylim(3,7) . (3.0, 7.0) . &#50696;&#51228;2 . fig = plt.figure() fig.subplots() . &lt;AxesSubplot:&gt; . ax1=fig.axes[0] . import numpy as np . ax1.plot(np.random.normal(size=100),&#39;o&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f80df15bd00&gt;] . fig . ax1.set_xlim(-10,110) ax1.set_ylim(-5,5) . (-5.0, 5.0) . fig . &#53685;&#44228;&#50696;&#51228; . - 여러가지 경우의 산점도와 표본상관계수 . &#50696;&#51228;1 . np.random.seed(202150754) x1=np.linspace(-1,1,100,endpoint=True) y1=x1**2+np.random.normal(scale=0.1,size=100) . plt.plot(x1,y1,&#39;o&#39;) plt.title(&#39;y=x**2&#39;) . Text(0.5, 1.0, &#39;y=x**2&#39;) . np.corrcoef(x1,y1) . array([[ 1. , -0.01756063], [-0.01756063, 1. ]]) . - (표본)상관계수의 값이 0에 가까운 것은 두 변수의 직선관계가 약한것을 의미한 것이지 두 변수 사이에 아무런 함수관계가 없다는 것을 의미하는 것은 아니다. . &#50696;&#51228;2 . - 아래와 같은 자료를 고려하자. . np.random.seed(202150754) x2=np.random.uniform(low=-1,high=1,size=100000) y2=np.random.uniform(low=-1,high=1,size=100000) . plt.plot(x2,y2,&#39;.&#39;) plt.title(&#39;rect&#39;) . Text(0.5, 1.0, &#39;rect&#39;) . np.corrcoef(x2,y2) . array([[ 1. , -0.00332475], [-0.00332475, 1. ]]) . &#50696;&#51228;3 . np.random.seed(202150754) _x3=np.random.uniform(low=-1,high=1,size=100000) _y3=np.random.uniform(low=-1,high=1,size=100000) . plt.plot(_x3,_y3,&#39;.&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f80dec03fd0&gt;] . radius = _x3**2+_y3**2 . x3=_x3[radius&lt;1] y3=_y3[radius&lt;1] plt.plot(_x3,_y3,&#39;.&#39;) plt.plot(x3,y3,&#39;.&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f80deb78f10&gt;] . plt.plot(x3,y3,&#39;.&#39;) plt.title(&#39;circ&#39;) . Text(0.5, 1.0, &#39;circ&#39;) . np.corrcoef(x3,y3) . array([[1. , 0.00194254], [0.00194254, 1. ]]) . &#49689;&#51228; 1 . - 예제1,2,3 을 하나의 figure안에 subplot 으로 그려보기 (1$ times$3 행렬처럼 그릴것) . fig,(ax1,ax2,ax3)=plt.subplots(1,3) ax1.plot(x1,y1,&#39;o&#39;) ax2.plot(x2,y2,&#39;o&#39;) ax3.plot(x3,y3,&#39;o&#39;) fig.set_figwidth(10) . &#50696;&#51228;2~3&#51004;&#47196; &#50508;&#50500;&#48372;&#45716; &#46160; &#48320;&#49688;&#51032; &#46021;&#47549;&#49457; . - 예제2,3에 대하여 아래와 같은 절차를 고려하여 보자. . (1) $X in [-h,h]$일 경우 $Y$의 분포를 생각해보자. 그리고 히스토그램을 그려보자. . (2) $X in [0.9-h,0.9+h]$일 경우 $Y$의 분포를 생각해보자. 그리고 히스토그램을 그려보자. . (3) (1)-(2)를 비교해보자. . - 그림으로 살펴보자. . h=0.05 plt.hist(y2[(x2&gt; -h )*(x2&lt; h )]) . (array([528., 552., 514., 505., 480., 454., 517., 525., 532., 443.]), array([-9.99496915e-01, -7.99599650e-01, -5.99702385e-01, -3.99805120e-01, -1.99907855e-01, -1.05899721e-05, 1.99886675e-01, 3.99783940e-01, 5.99681205e-01, 7.99578470e-01, 9.99475735e-01]), &lt;BarContainer object of 10 artists&gt;) . h=0.05 _,axs= plt.subplots(2,2) axs[0,0].hist(y2[(x2&gt; -h )*(x2&lt; h )]) axs[0,1].hist(y2[(x2&gt; 0.9-h )*(x2&lt; 0.9+h )]) axs[1,0].hist(y3[(x3&gt; -h )*(x3&lt; h )]) axs[1,1].hist(y3[(x3&gt; 0.9-h )*(x3&lt; 0.9+h )]) . (array([ 87., 207., 234., 236., 277., 282., 286., 261., 230., 81.]), array([-0.51033572, -0.40740268, -0.30446965, -0.20153661, -0.09860358, 0.00432945, 0.10726249, 0.21019552, 0.31312855, 0.41606159, 0.51899462]), &lt;BarContainer object of 10 artists&gt;) . - 축의범위를 조절하여보자. . h=0.05 _,axs= plt.subplots(2,2) axs[0,0].hist(y2[(x2&gt; -h )*(x2&lt; h )]) axs[0,0].set_xlim(-1.1,1.1) axs[0,1].hist(y2[(x2&gt; 0.9-h )*(x2&lt; 0.9+h )]) axs[0,1].set_xlim(-1.1,1.1) axs[1,0].hist(y3[(x3&gt; -h )*(x3&lt; h )]) axs[1,0].set_xlim(-1.1,1.1) axs[1,1].hist(y3[(x3&gt; 0.9-h )*(x3&lt; 0.9+h )]) axs[1,1].set_xlim(-1.1,1.1) . (-1.1, 1.1) . &#50696;&#51228;4 . np.random.seed(202150754) x4=np.random.normal(size=10000) y4=np.random.normal(size=10000) . plt.plot(x4,y4,&#39;o&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f80d4566190&gt;] . plt.plot(x4,y4,&#39;.&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f80d40932b0&gt;] . - 디자인적인 측면에서 보면 올바른 시각화라 볼 수 없다. (이 그림이 밀도를 왜곡시킨다) . - 아래와 같은 그림이 더 우수하다. (밀도를 표현하기 위해 투명도라는 개념을 도입) . plt.scatter(x4,y4,alpha=0.01) . &lt;matplotlib.collections.PathCollection at 0x7f80d47b3250&gt; . np.corrcoef(x4,y4) . array([[1. , 0.01337901], [0.01337901, 1. ]]) . h=0.05 fig, _ = plt.subplots(3,3) . fig.tight_layout() . fig . fig.set_figwidth(10) fig.set_figheight(10) fig . fig.axes . [&lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;] . k=np.linspace(-2,2,9) k . array([-2. , -1.5, -1. , -0.5, 0. , 0.5, 1. , 1.5, 2. ]) . h . 0.05 . h=0.2 for i in range(9): fig.axes[i].hist(y4[(x4&gt;k[i]-h) * (x4&lt;k[i]+h)]) . fig . &#49689;&#51228; 2 . plt.scatter(x4,y4,alpha=0.01) . &lt;matplotlib.collections.PathCollection at 0x7f80a9d271f0&gt; . - 이 그림의 색깔을 붉은색으로 바꿔서 그려보자. (주의: 수업시간에 알려주지 않은 방법임) . plt.scatter(x4,y4,alpha=0.01,color=&#39;red&#39;) . &lt;matplotlib.collections.PathCollection at 0x7f80a9c7ffa0&gt; . maplotlib + seaborn . import matplotlib.pyplot as plt import numpy as np import seaborn as sns . x=[44,48,49,58,62,68,69,70,76,79] # 몸무게 y=[159,160,162,165,167,162,165,175,165,172] #키 g=&#39;F&#39;,&#39;F&#39;,&#39;F&#39;,&#39;F&#39;,&#39;F&#39;,&#39;M&#39;,&#39;M&#39;,&#39;M&#39;,&#39;M&#39;,&#39;M&#39; . plt.plot(x,y,&#39;o&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f80537913d0&gt;] . sns.scatterplot(x=x,y=y,hue=g) . &lt;AxesSubplot:&gt; . - 두 그림을 나란히 겹쳐 그릴수 있을까? . fig, (ax1,ax2) = plt.subplots(1,2) ax1.plot(x,y,&#39;o&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f8053663c10&gt;] . sns.scatterplot(x=x,y=y,hue=g,ax=ax2) . &lt;AxesSubplot:&gt; . fig . fig.set_figwidth(8) . fig . ax1.set_title(&#39;matplotlib&#39;) ax2.set_title(&#39;seaborn&#39;) . Text(0.5, 1.0, &#39;seaborn&#39;) . fig . - 마치 matplotlib에 seaborn을 plugin하듯이 사용할 수 있다. . matplotlib vs seaborn . - 디자인이 예쁜 패키지를 선택하여 하나만 공부하는 것은 그렇게 좋은 전략이 아니다. . sns.set_theme() . plt.plot([1,2,3],[3,4,5],&#39;or&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f80535a25e0&gt;] . &#50696;&#51228; . - 아래와 같은 자료가 있다고 하자. . np.random.seed(202150754) x=np.random.normal(size=1000,loc=2,scale=1.5) . - 이 자료가 정규분포를 따르는지 어떻게 체크할 수 있을까? . plt.hist(x) . (array([ 1., 4., 18., 113., 216., 294., 196., 121., 31., 6.]), array([-3.68558942, -2.64396364, -1.60233786, -0.56071208, 0.48091371, 1.52253949, 2.56416527, 3.60579105, 4.64741684, 5.68904262, 6.7306684 ]), &lt;BarContainer object of 10 artists&gt;) . - 종모양이므로 정규분포인듯 하다. . - 밀도추정곡선이 있었으면 좋겠다. (KDE로 추정) $ to$ seaborn을 활용하여 그려보자. . sns.histplot(x,kde=True) . &lt;AxesSubplot:ylabel=&#39;Count&#39;&gt; . - 종모양인것 같다. . - 그렇다면 아래는 어떤가? . np.random.seed(202150754) from scipy import stats . y=stats.t.rvs(10,size=1000) . sns.histplot(y,kde=True) . &lt;AxesSubplot:ylabel=&#39;Count&#39;&gt; . - 종모양이다..? . - 비교 . fig, (ax1,ax2) = plt.subplots(1,2) sns.histplot(x,kde=True,ax=ax1) sns.histplot(y,kde=True,ax=ax2) . &lt;AxesSubplot:ylabel=&#39;Count&#39;&gt; . xx= (x-np.mean(x)) / np.std(x,ddof=1) # ddof=1의 의미는 x-1해줘라~ yy= (y-np.mean(y)) / np.std(y,ddof=1) fig, (ax1,ax2) = plt.subplots(1,2) sns.histplot(xx,kde=True,ax=ax1) sns.histplot(yy,kde=True,ax=ax2) . &lt;AxesSubplot:ylabel=&#39;Count&#39;&gt; . xx= (x-np.mean(x)) / np.std(x,ddof=1) yy= (y-np.mean(y)) / np.std(y,ddof=1) fig, ((ax1,ax2),(ax3,ax4)) = plt.subplots(2,2) ax1.boxplot(xx) sns.histplot(xx,kde=True,ax=ax2) ax3.boxplot(yy) sns.histplot(yy,kde=True,ax=ax4) . &lt;AxesSubplot:ylabel=&#39;Count&#39;&gt; . fig.tight_layout() . fig . - 주의: 아래와 같이 해석하면 잘못된 해석이다. . $y$ 히스토그램을 그려보니 모양이 종모양이다. $ to$ $y$는 정규분포이다 | . - 관찰: boxplot을 그려보니 $y$의 꼬리가 정규분포보다 두꺼워 보인다. . 히스토그램이 종모양이라는 이유로 무조건 정규분포라 가정하지 말자 | . &#49689;&#51228;3 . sns.set_theme(style=&quot;whitegrid&quot;, palette=&quot;pastel&quot;) plt.plot([1,2,3]) . [&lt;matplotlib.lines.Line2D at 0x7f8052df48b0&gt;] . 와 같이 테마를 바꿔서 그림을 그려보고 스샷제출 . sns.set_style(&quot;darkgrid&quot;) sns.set_context(&quot;poster&quot;) plt.plot([1,2,3]) sns.despine(left=True, bottom=True) .",
            "url": "https://seoyeonc.github.io/chch/2021/10/05/%EB%8D%B0%EC%8B%9C_4%EC%A3%BC%EC%B0%A8.html",
            "relUrl": "/2021/10/05/%EB%8D%B0%EC%8B%9C_4%EC%A3%BC%EC%B0%A8.html",
            "date": " • Oct 5, 2021"
        }
        
    
  
    
        ,"post8": {
            "title": "데이터시각화 특강 (3주차) 9월27일",
            "content": "&#44053;&#51032;&#50689;&#49345; . - (2/8) 이미지 자료에 대한 이해 . - (3/8) 산점도와 상관계수1 . - (4/8) 산점도와 상관계수2 . - (5/8) 여러그림 그리기 . - (6/8) 앤스콤의 플랏 . - (7/8) 앤스콤의 플랏 . (&#51648;&#45212;&#44053;&#51032;&#45432;&#53944; &#48372;&#52649;) &#51060;&#48120;&#51648; &#51088;&#47308;&#50640; &#45824;&#54620; &#51060;&#54644; . - 흑백이미지 . 차원: 세로픽셀수 $ times$ 가로픽셀수 | 값: 0~255 (값이 클수록 흰색) | . - 칼라이미지 . 차원: 세로픽셀수 $ times$ 가로픽셀수 $ times$ 3 | 값: 0~255 (값이 클수록 진한빨강, 진한파랑, 진한녹색) | . import cv2 as cv . hani=cv.imread(&#39;hw_img.png&#39;) . import matplotlib.pyplot as plt plt.imshow(hani) . &lt;matplotlib.image.AxesImage at 0x7fd10d619940&gt; . hani.shape . (531, 468, 3) . import numpy as np hani_red=np.zeros_like(hani) hani_green=np.zeros_like(hani) hani_blue=np.zeros_like(hani) hani_red[:,:,0]=hani[:,:,0] hani_green[:,:,1]=hani[:,:,1] hani_blue[:,:,2]=hani[:,:,2] . plt.imshow(hani_red) . &lt;matplotlib.image.AxesImage at 0x7fd10d5856d0&gt; . plt.imshow(hani_green) . &lt;matplotlib.image.AxesImage at 0x7fd10d56f2b0&gt; . plt.imshow(hani_blue) . &lt;matplotlib.image.AxesImage at 0x7fd10d6ccd60&gt; . plt.imshow(hani_blue+hani_red) . &lt;matplotlib.image.AxesImage at 0x7fd10d7e2190&gt; . plt.imshow(hani_blue+hani_green) . &lt;matplotlib.image.AxesImage at 0x7fd10d6c5550&gt; . plt.imshow(hani_red+hani_green) . &lt;matplotlib.image.AxesImage at 0x7fd10d4d8ee0&gt; . plt.imshow(hani_red+hani_green+hani_blue) . &lt;matplotlib.image.AxesImage at 0x7fd10d4b9bb0&gt; . &#49328;&#51216;&#46020; (scatter plot) . import matplotlib.pyplot as plt . - 산점도: 산점도는 직교 좌표계(도표)를 이용해 좌표상의 점들을 표시함으로써 두 개 변수 간의 관계를 나타내는 그래프 방법 . ref: https://ko.wikipedia.org/wiki/%EC%82%B0%EC%A0%90%EB%8F%84 | . x=[1,2,3,4] y=[2,3,5,5] plt.plot(x,y,&#39;o&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fd10d42a070&gt;] . - 산점도는 보통 $X$와 $Y$의 관계를 알고 싶을 경우 그린다. . &#50696;&#51228;: &#47800;&#47924;&#44172;&#50752; &#53412; . - 아래와 같은 자료를 수집하였다고 하자. . 몸무게=[44,48,49,58,62,68,69,70,76,79] | 키=[159,160,162,165,167,162,165,175,165,172] | . x=[44,48,49,58,62,68,69,70,76,79] y=[159,160,162,165,167,162,165,175,165,172] . plt.plot(x,y,&#39;o&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fd10d38db80&gt;] . 키가 큰 사람일수록 몸무게도 많이 나간다. (반대도 성립) | 키와 몸무게는 관계가 있어보인다. (정비례관계) | . - 얼만큼 정비례 인지? . 이 질문에 대답하기 위해서는 상관계수의 개념을 알아야 한다. | 상관계수에 대한 개념은 산점도를 이해함에 있어서 핵심개념이다. | . &#49345;&#44288;&#44228;&#49688; (&#44036;&#45800;&#54620; &#47532;&#48624;) . - (표본)상관계수 . $$r= frac{ sum_{i=1}^{n}(x_i- bar{x})(y_i- bar{y})}{ sqrt{ sum_{i=1}^{n}(x_i- bar{x})^2 sum_{i=1}^{n}(y_i- bar{y})^2}}$$ . - 복잡해보이지만 아무튼 (1) 분자를 계산하고 (2) 분모를 계산하고 (3) 분자를 분모로 나누면 된다. . - 분모를 계산했다고 치자. 계산한 값을 상수 $c$라고 생각하자. 이 값을 분자의 sum안에 넣으면... . $$r= sum_{i=1}^{n} frac{1}{c}(x_i- bar{x})(y_i- bar{y})$$ . - 이 식을 정리하면 . $$r= sum_{i=1}^{n} Bigg( frac{(x_i- bar{x})}{ sqrt{ sum_{i=1}^{n}(x_i- bar{x})^2}} frac{(y_i- bar{y})}{ sqrt{ sum_{i=1}^{n}(y_i- bar{y})^2}} Bigg)$$ . - 편의상 다음과 같이 정의하자. $ tilde{x}_i = frac{(x_i- bar{x})}{ sqrt{ sum_{i=1}^{n}(x_i- bar{x})^2}}$, $ tilde{y}_i = frac{(y_i- bar{y})}{ sqrt{ sum_{i=1}^{n}(y_i- bar{y})^2}}$ . - 결국 $r$은 아래와 같은 모양이다. . $$r= sum_{i=1}^{n} tilde{x}_i tilde{y}_i$$ . - 의미? . import numpy as np x=np.array(x) y=np.array(y) . plt.plot(x,y,&#39;o&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fd10d3057f0&gt;] . plt.plot(x-np.mean(x), y-np.mean(y),&#39;o&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fd10d2f7670&gt;] . - $a= sqrt{ sum_{i=1}^{n}(x_i- bar{x})^2}, b= sqrt{ sum_{i=1}^{n}(y_i- bar{y})^2}$ . a=np.sqrt(np.sum((x-np.mean(x))**2)) b=np.sqrt(np.sum((y-np.mean(y))**2)) a,b . (36.58004920718396, 15.218409903797438) . $a&gt;b$ 이므로 $ {x_i }$들이 $ {y_i }$들 보다 좀 더 퍼져있다. (=평균근처에 몰려있지 않다) | . - 사실 $a,b$는 아래와 같이 계산할 수 있다. . $a= sqrt{n} times{ tt np.std(x)}$ . $b= sqrt{n} times{ tt np.std(y)}$ . n=len(x) np.sqrt(n)*np.std(x), np.sqrt(n)*np.std(y) . (36.58004920718397, 15.21840990379744) . ${ tt np.std(x)}= sqrt{ frac{1}{n} sum_{i=1}^{n}(x_i- bar{x})^2}$ | ${ tt np.std(y)}= sqrt{ frac{1}{n} sum_{i=1}^{n}(y_i- bar{y})^2}$ | . . Note: ${ tt np.std(x,ddof=1)}= sqrt{ frac{1}{n-1} sum_{i=1}^{n}(x_i- bar{x})^2}$ . - 이제 $( tilde{x}_i, tilde{y}_i)$를 그려보자. . xx= (x-np.mean(x))/a yy= (y-np.mean(y))/b plt.plot(xx,yy,&#39;o&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fd10d267970&gt;] . 평균도 비슷하고 퍼진정도도 비슷하다. | . - 질문1: $r$의 값이 양수인가? 음수인가? . plotly 사용하여 그려보자. . import plotly.express as px from IPython.display import HTML fig=px.scatter(x=xx, y=yy) HTML(fig.to_html(include_plotlyjs=&#39;cdn&#39;,include_mathjax=False)) . . . $ tilde{x}_i$, $ tilde{y}_i$ 를 곱한값이 양수인것과 음수인것을 체크해보자. | 양수인쪽이 많은지 음수인쪽이 많은지 생각해보자. | $r= sum_{i=1}^{n} tilde{x}_i tilde{y}_i$ 의 부호는? | . - 질문2: 아래와 같은 두개의 데이터set이 있다고 하자. . x1=np.arange(0,10,0.1) y1=x1+np.random.normal(loc=0,scale=1.0,size=len(x1)) . plt.plot(x1,y1,&#39;o&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fd10a8fee20&gt;] . x2=np.arange(0,10,0.1) y2=x2+np.random.normal(loc=0,scale=7.0,size=len(x2)) plt.plot(x2,y2,&#39;x&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fd10a8e8760&gt;] . plt.plot(x1,y1,&#39;o&#39;) plt.plot(x2,y2,&#39;x&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fd10a853b20&gt;] . 각 데이터셋의 표준상관계수를 각각 $r_1$(파란색), $r_2$(주황색)라고 하자. . (1) $r_1$, $r_2$의 부호는 양수인가? 음수인가? . 양수이다 | . (2) $r_1,r_2$의 값중 어떠한 값이 더 절대값이 큰가? . $r_1$이 더 커보인다. 분산이 작아보임 | . n=len(x1) xx1= (x1-np.mean(x1)) / (np.std(x1) * np.sqrt(n)) yy1= (y1-np.mean(y1)) / (np.std(y1) * np.sqrt(n)) xx2= (x2-np.mean(x2)) / (np.std(x2) * np.sqrt(n)) yy2= (y2-np.mean(y2)) / (np.std(y2) * np.sqrt(n)) . plt.plot(xx1,yy1,&#39;o&#39;) ## 파란색 plt.plot(xx2,yy2,&#39;x&#39;) ## 주황색 . [&lt;matplotlib.lines.Line2D at 0x7fd10a7c9400&gt;] . sum(xx1*yy1), sum(xx2*yy2) . (0.947517466375085, 0.37004797528671085) . &#49689;&#51228;1 . - 임의의 이미지를 cv.imread() 로 불러온뒤에 아래와 같이 blue+green의 조합으로 이미지를 변경해볼것 . plt.imshow(hani_blue+hani_green) . &lt;matplotlib.image.AxesImage at 0x7fd10a7ae520&gt; . &#46972;&#51064;&#54540;&#46991;&#51012; &#44536;&#47532;&#45716; &#48169;&#48277; . import matplotlib.pyplot as plt x=[1,2,3,4] y=[1,2,4,3] plt.plot(x,y) . [&lt;matplotlib.lines.Line2D at 0x7fd10a710970&gt;] . matplotlib&#50640;&#49436; &#49328;&#51216;&#46020;&#50752; &#46972;&#51064;&#54540;&#46991; &#44536;&#47532;&#44592; (&#51333;&#54633;) . - plt.plot()를 사용하면 산점도와 라인플랏을 다양한 조합으로 쉽고 편리하게 그릴수 있음 . x=[1,2,3,4] y=[1,2,4,3] plt.plot(x,y,&#39;o:r&#39;) # 20정도의 점의 모양, 4개의 선의모양, 8개의 색깔 . [&lt;matplotlib.lines.Line2D at 0x7fd10a678790&gt;] . &#50668;&#47084;&#44536;&#47548;&#51012; &#44536;&#47532;&#44592; . (1) &#44217;&#52432;&#44536;&#47532;&#44592; . import numpy as np x=np.arange(-5,5,0.1) y=2*x+np.random.normal(loc=0,scale=1,size=100) plt.plot(x,y,&#39;.b&#39;) plt.plot(x,2*x,&#39;--r&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fd10a6711f0&gt;] . (2) &#46384;&#47196;&#44536;&#47532;&#44592; - subplots . x=[1,2,3,4] y=[1,2,4,3] _, axs = plt.subplots(2,2) axs[0,0].plot(x,y,&#39;o:r&#39;) axs[0,1].plot(x,y,&#39;Xb&#39;) axs[1,0].plot(x,y,&#39;xm&#39;) axs[1,1].plot(x,y,&#39;.--k&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fd10a4fbdc0&gt;] . plt.subplots?? . Signature: plt.subplots( nrows=1, ncols=1, *, sharex=False, sharey=False, squeeze=True, subplot_kw=None, gridspec_kw=None, **fig_kw, ) Source: @_api.make_keyword_only(&#34;3.3&#34;, &#34;sharex&#34;) def subplots(nrows=1, ncols=1, sharex=False, sharey=False, squeeze=True, subplot_kw=None, gridspec_kw=None, **fig_kw): &#34;&#34;&#34; Create a figure and a set of subplots. This utility wrapper makes it convenient to create common layouts of subplots, including the enclosing figure object, in a single call. Parameters - nrows, ncols : int, default: 1 Number of rows/columns of the subplot grid. sharex, sharey : bool or {&#39;none&#39;, &#39;all&#39;, &#39;row&#39;, &#39;col&#39;}, default: False Controls sharing of properties among x (*sharex*) or y (*sharey*) axes: - True or &#39;all&#39;: x- or y-axis will be shared among all subplots. - False or &#39;none&#39;: each subplot x- or y-axis will be independent. - &#39;row&#39;: each subplot row will share an x- or y-axis. - &#39;col&#39;: each subplot column will share an x- or y-axis. When subplots have a shared x-axis along a column, only the x tick labels of the bottom subplot are created. Similarly, when subplots have a shared y-axis along a row, only the y tick labels of the first column subplot are created. To later turn other subplots&#39; ticklabels on, use `~matplotlib.axes.Axes.tick_params`. When subplots have a shared axis that has units, calling `~matplotlib.axis.Axis.set_units` will update each axis with the new units. squeeze : bool, default: True - If True, extra dimensions are squeezed out from the returned array of `~matplotlib.axes.Axes`: - if only one subplot is constructed (nrows=ncols=1), the resulting single Axes object is returned as a scalar. - for Nx1 or 1xM subplots, the returned object is a 1D numpy object array of Axes objects. - for NxM, subplots with N&gt;1 and M&gt;1 are returned as a 2D array. - If False, no squeezing at all is done: the returned Axes object is always a 2D array containing Axes instances, even if it ends up being 1x1. subplot_kw : dict, optional Dict with keywords passed to the `~matplotlib.figure.Figure.add_subplot` call used to create each subplot. gridspec_kw : dict, optional Dict with keywords passed to the `~matplotlib.gridspec.GridSpec` constructor used to create the grid the subplots are placed on. **fig_kw All additional keyword arguments are passed to the `.pyplot.figure` call. Returns - fig : `~.figure.Figure` ax : `.axes.Axes` or array of Axes *ax* can be either a single `~matplotlib.axes.Axes` object or an array of Axes objects if more than one subplot was created. The dimensions of the resulting array can be controlled with the squeeze keyword, see above. Typical idioms for handling the return value are:: # using the variable ax for single a Axes fig, ax = plt.subplots() # using the variable axs for multiple Axes fig, axs = plt.subplots(2, 2) # using tuple unpacking for multiple Axes fig, (ax1, ax2) = plt.subplots(1, 2) fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2) The names ``ax`` and pluralized ``axs`` are preferred over ``axes`` because for the latter it&#39;s not clear if it refers to a single `~.axes.Axes` instance or a collection of these. See Also -- .pyplot.figure .pyplot.subplot .pyplot.axes .Figure.subplots .Figure.add_subplot Examples -- :: # First create some toy data: x = np.linspace(0, 2*np.pi, 400) y = np.sin(x**2) # Create just a figure and only one subplot fig, ax = plt.subplots() ax.plot(x, y) ax.set_title(&#39;Simple plot&#39;) # Create two subplots and unpack the output array immediately f, (ax1, ax2) = plt.subplots(1, 2, sharey=True) ax1.plot(x, y) ax1.set_title(&#39;Sharing Y axis&#39;) ax2.scatter(x, y) # Create four polar axes and access them through the returned array fig, axs = plt.subplots(2, 2, subplot_kw=dict(projection=&#34;polar&#34;)) axs[0, 0].plot(x, y) axs[1, 1].scatter(x, y) # Share a X axis with each column of subplots plt.subplots(2, 2, sharex=&#39;col&#39;) # Share a Y axis with each row of subplots plt.subplots(2, 2, sharey=&#39;row&#39;) # Share both X and Y axes with all subplots plt.subplots(2, 2, sharex=&#39;all&#39;, sharey=&#39;all&#39;) # Note that this is the same as plt.subplots(2, 2, sharex=True, sharey=True) # Create figure number 10 with a single subplot # and clears it if it already exists. fig, ax = plt.subplots(num=10, clear=True) &#34;&#34;&#34; fig = figure(**fig_kw) axs = fig.subplots(nrows=nrows, ncols=ncols, sharex=sharex, sharey=sharey, squeeze=squeeze, subplot_kw=subplot_kw, gridspec_kw=gridspec_kw) return fig, axs File: ~/anaconda3/envs/csy/lib/python3.8/site-packages/matplotlib/pyplot.py Type: function . subplots의 리턴값이 (fig,axs) 이 나오게된다. 우리는 뒤의 axs만 관심이 있으므로 앞의 fig는 _로 처리한다. | . Anscombe&#39;s quartet . - 교과서에 나오는 그림임. . - 교훈: 데이터를 분석하기 전에 항상 시각화를 하라. . x = [10, 8, 13, 9, 11, 14, 6, 4, 12, 7, 5] y1 = [8.04, 6.95, 7.58, 8.81, 8.33, 9.96, 7.24, 4.26, 10.84, 4.82, 5.68] y2 = [9.14, 8.14, 8.74, 8.77, 9.26, 8.10, 6.13, 3.10, 9.13, 7.26, 4.74] y3 = [7.46, 6.77, 12.74, 7.11, 7.81, 8.84, 6.08, 5.39, 8.15, 6.42, 5.73] x4 = [8, 8, 8, 8, 8, 8, 8, 19, 8, 8, 8] y4 = [6.58, 5.76, 7.71, 8.84, 8.47, 7.04, 5.25, 12.50, 5.56, 7.91, 6.89] . _, axs = plt.subplots(2,2) axs[0,0].plot(x,y1,&#39;o&#39;) axs[0,1].plot(x,y2,&#39;o&#39;) axs[1,0].plot(x,y3,&#39;o&#39;) axs[1,1].plot(x4,y4,&#39;o&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fd10a392880&gt;] . - 상관계수를 잠깐 복습해보자. . 상관계수는 -1 ~ 1 사이의 값을 가진다. (코쉬슈바르츠 부등식을 사용하여 증명가능) | 완전한 직선이라면 상관계수가 1 또는 -1이다. | 상관계수가 1에 가까우면 양의 상관관계에 있다고 말하고 -1에 가까우면 음의 상관관계에 있다고 말한다. | . - 의문: 자료의 모양이 직선모양에 가까우면 상관계수가 큰것이 맞나? . $x,y$ 값이 모두 큰 하나의 관측치가 상관계수값을 키울 수 있지 않나? | . - 상관계수가 좋은것은 맞나? (=상관계수는 두 변수의 관계를 설명하기에 충분히 적절한 통계량인가?) . n=len(x) # xtilde = (x-np.mean(x)) / (np.std(x)*np.sqrt(n)) y1tilde = (y1-np.mean(y1)) / (np.std(y1)*np.sqrt(n)) . sum(xtilde*y1tilde) . 0.81642051634484 . np.corrcoef(x,y1) . array([[1. , 0.81642052], [0.81642052, 1. ]]) . np.corrcoef([x,y1,y2,y3]) . array([[1. , 0.81642052, 0.81623651, 0.81628674], [0.81642052, 1. , 0.7500054 , 0.46871668], [0.81623651, 0.7500054 , 1. , 0.58791933], [0.81628674, 0.46871668, 0.58791933, 1. ]]) . np.corrcoef([x4,y4]) . array([[1. , 0.81652144], [0.81652144, 1. ]]) . - 위의 4개의 그림에 대한 상관계수는 모두 같다. (0.81652) . - 상관계수는 두 변수의 관계를 설명하기에 부적절하다. . 상관계수는 1번그림과 같이 두 변수가 선형관계에 있을때 그 정도를 나타내는 통계량일뿐이다. | 선형관계가 아닌것처럼 보이는 자료에서는 상관계수를 계산할수는 있겠으나 의미가 없다. | . - 교훈2: 기본적인 통계량들은 실제자료를 분석하기에 부적절할수 있다. (=통계량은 적절한 가정이 동반되어야 의미가 있다) . . Note: 통계학자는 (1) 적절한 가정을 수학적인 언어로 정의하고 (2) 그 가정하에서 통계량이 의미있다는 것을 증명해야 한다. (3) 그리고 그 결과를 시각화하여 설득한다. . &#49689;&#51228;2 . - 앤스콤의 플랏을 붉은색을 사용하여 그려보기! . _, axs = plt.subplots(2,2) axs[0,0].plot(x,y1,&#39;or&#39;) axs[0,1].plot(x,y2,&#39;or&#39;) axs[1,0].plot(x,y3,&#39;or&#39;) axs[1,1].plot(x4,y4,&#39;or&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fd109e50850&gt;] .",
            "url": "https://seoyeonc.github.io/chch/2021/09/27/%EB%8D%B0%EC%8B%9C_3%EC%A3%BC%EC%B0%A8.html",
            "relUrl": "/2021/09/27/%EB%8D%B0%EC%8B%9C_3%EC%A3%BC%EC%B0%A8.html",
            "date": " • Sep 27, 2021"
        }
        
    
  
    
        ,"post9": {
            "title": "데이터 시각화 특강 (2주차) 9월13일",
            "content": "- (1/8): 박스플랏: 전북고예제 (평균은 좋은 측정값인가?) (숫자 무시~~) . - (2/8): 박스플랏 기본개념 . - (3/8): plotly . - (4/8): 히스토그램 . - (5/8): 히스토그램 2개 겹쳐서 비교하기 . - (7/8): 히스토그램 평활화 . - (8/8): 히스토그램 평활화 . import . import matplotlib.pyplot as plt import numpy as np . boxplot . &#51204;&#48513;&#44256;&#50696;&#51228;: &#54217;&#44512;&#51008; &#44316;&#52270;&#51008; &#52769;&#51221;&#44050;&#51064;&#44032;? . - 전북고등학교에서 통계학을 수업하는 두 선생님이 있다. 편의상 A선생님과 B선생님이라고 하자. A선생님이 강의한 반의 통계학 점수는 79.1점이고, B선생님이 강의한 반의 통계학 점수는 78.3점 이라고 하자. . - 의사결정: A선생님에게 배운 학생들의 실력이 평균적으로 좋을 것이다. . y1=[75,75,76,76,77,77,79,79,79,98] # A선생님에게 통계학을 배운 학생의 점수들 y2=[76,76,77,77,78,78,80,80,80,81] # B선생님에게 통계학을 배운 학생의 점수들 . np.mean(y1),np.mean(y2) . (79.1, 78.3) . - 평균은 A반(=A선생님에게 통계학을 배운 반)이 더 높다. 그런데 98점을 받은 학생때문에 전체평균이 올라간 것이고, 나머지 학생들은 전체적으로 B반 학생들이 점수가 더 높다고 해석할 수 있다. . - 단순한 평균비교보다 분포를 비교해보는 것이 중요하다. 분포를 살펴보는 방법 중 유용한 방법이 박스플랏이다. . plt.boxplot(y1) . {&#39;whiskers&#39;: [&lt;matplotlib.lines.Line2D at 0x7f6a8ef5e430&gt;, &lt;matplotlib.lines.Line2D at 0x7f6a8ef5e7c0&gt;], &#39;caps&#39;: [&lt;matplotlib.lines.Line2D at 0x7f6a8ef5eb50&gt;, &lt;matplotlib.lines.Line2D at 0x7f6a8ef5eee0&gt;], &#39;boxes&#39;: [&lt;matplotlib.lines.Line2D at 0x7f6a8ef5e0a0&gt;], &#39;medians&#39;: [&lt;matplotlib.lines.Line2D at 0x7f6a8ef672b0&gt;], &#39;fliers&#39;: [&lt;matplotlib.lines.Line2D at 0x7f6a8ef67640&gt;], &#39;means&#39;: []} . A반의 boxplot | 뚝 떨어진 하나의 점은 98점 | 붉은 선은 중앙값 (평균이 아니라 중앙값) | 나머지 점들은 7~80점에 분포되어있다. | . plt.boxplot(y2) . {&#39;whiskers&#39;: [&lt;matplotlib.lines.Line2D at 0x7f6a8eec0ac0&gt;, &lt;matplotlib.lines.Line2D at 0x7f6a8eec0e50&gt;], &#39;caps&#39;: [&lt;matplotlib.lines.Line2D at 0x7f6a8eecc220&gt;, &lt;matplotlib.lines.Line2D at 0x7f6a8eecc5b0&gt;], &#39;boxes&#39;: [&lt;matplotlib.lines.Line2D at 0x7f6a8eec0700&gt;], &#39;medians&#39;: [&lt;matplotlib.lines.Line2D at 0x7f6a8eecc940&gt;], &#39;fliers&#39;: [&lt;matplotlib.lines.Line2D at 0x7f6a8eecccd0&gt;], &#39;means&#39;: []} . B반의 boxplot | . - 아래와 같이 하면 박스플랏을 나란히 그릴 수 있다. . plt.boxplot([y1,y2]) # 묶어주는 것 잊지 말기.. . {&#39;whiskers&#39;: [&lt;matplotlib.lines.Line2D at 0x7f6a8eeb07c0&gt;, &lt;matplotlib.lines.Line2D at 0x7f6a8eeb0b50&gt;, &lt;matplotlib.lines.Line2D at 0x7f6a8ee47130&gt;, &lt;matplotlib.lines.Line2D at 0x7f6a8ee474c0&gt;], &#39;caps&#39;: [&lt;matplotlib.lines.Line2D at 0x7f6a8eeb0ee0&gt;, &lt;matplotlib.lines.Line2D at 0x7f6a8ee3c2b0&gt;, &lt;matplotlib.lines.Line2D at 0x7f6a8ee47850&gt;, &lt;matplotlib.lines.Line2D at 0x7f6a8ee47be0&gt;], &#39;boxes&#39;: [&lt;matplotlib.lines.Line2D at 0x7f6a8eeb0430&gt;, &lt;matplotlib.lines.Line2D at 0x7f6a8ee3cd60&gt;], &#39;medians&#39;: [&lt;matplotlib.lines.Line2D at 0x7f6a8ee3c640&gt;, &lt;matplotlib.lines.Line2D at 0x7f6a8ee47f70&gt;], &#39;fliers&#39;: [&lt;matplotlib.lines.Line2D at 0x7f6a8ee3c9d0&gt;, &lt;matplotlib.lines.Line2D at 0x7f6a8ee55340&gt;], &#39;means&#39;: []} . - 미적인 그래프는 아니지만 이정도는 괜찮은것 같다. . boxplot&#51060;&#46976;? . - ref: https://github.com/mGalarnyk/Python_Tutorials/blob/master/Statistics/boxplot/box_plot.ipynb . np.random.seed(916170) # connection path is here: https://stackoverflow.com/questions/6146290/plotting-a-line-over-several-graphs mu, sigma = 0, 1 # mean and standard deviation s = np.random.normal(mu, sigma, 1000) fig, axes = plt.subplots(nrows = 1, ncols = 1, figsize=(10, 5)) # rectangular box plot bplot = axes.boxplot(s, vert=False, patch_artist=True, showfliers=True, # This would show outliers (the remaining .7% of the data) positions = [0], boxprops = dict(linestyle=&#39;--&#39;, linewidth=2, color=&#39;Black&#39;, facecolor = &#39;red&#39;, alpha = .4), medianprops = dict(linestyle=&#39;-&#39;, linewidth=2, color=&#39;Yellow&#39;), whiskerprops = dict(linestyle=&#39;-&#39;, linewidth=2, color=&#39;Blue&#39;, alpha = .4), capprops = dict(linestyle=&#39;-&#39;, linewidth=2, color=&#39;Black&#39;), flierprops = dict(marker=&#39;o&#39;, markerfacecolor=&#39;green&#39;, markersize=10, linestyle=&#39;none&#39;, alpha = .4), widths = .3, zorder = 1) axes.set_xlim(-4, 4) plt.xticks(fontsize = 14) axes.set_yticks([]) axes.annotate(r&#39;&#39;, xy=(-.73, .205), xycoords=&#39;data&#39;, xytext=(.66, .205), textcoords=&#39;data&#39;, arrowprops=dict(arrowstyle=&quot;|-|&quot;, connectionstyle=&quot;arc3&quot;) ); axes.text(0, .25, &quot;Interquartile Range n(IQR)&quot;, horizontalalignment=&#39;center&#39;, fontsize=18) axes.text(0, -.21, r&quot;Median&quot;, horizontalalignment=&#39;center&#39;, fontsize=16); axes.text(2.65, -.15, &quot; &quot;Maximum &quot;&quot;, horizontalalignment=&#39;center&#39;, fontsize=18); axes.text(-2.65, -.15, &quot; &quot;Minimum &quot;&quot;, horizontalalignment=&#39;center&#39;, fontsize=18); axes.text(-.68, -.24, r&quot;Q1&quot;, horizontalalignment=&#39;center&#39;, fontsize=18); axes.text(-2.65, -.21, r&quot;(Q1 - 1.5*IQR)&quot;, horizontalalignment=&#39;center&#39;, fontsize=16); axes.text(.6745, -.24, r&quot;Q3&quot;, horizontalalignment=&#39;center&#39;, fontsize=18); axes.text(.6745, -.30, r&quot;(75th Percentile)&quot;, horizontalalignment=&#39;center&#39;, fontsize=12); axes.text(-.68, -.30, r&quot;(25th Percentile)&quot;, horizontalalignment=&#39;center&#39;, fontsize=12); axes.text(2.65, -.21, r&quot;(Q3 + 1.5*IQR)&quot;, horizontalalignment=&#39;center&#39;, fontsize=16); axes.annotate(&#39;Outliers&#39;, xy=(2.93,0.015), xytext=(2.52,0.20), fontsize = 18, arrowprops={&#39;arrowstyle&#39;: &#39;-&gt;&#39;, &#39;color&#39;: &#39;black&#39;, &#39;lw&#39;: 2}, va=&#39;center&#39;); axes.annotate(&#39;Outliers&#39;, xy=(-3.01,0.015), xytext=(-3.41,0.20), fontsize = 18, arrowprops={&#39;arrowstyle&#39;: &#39;-&gt;&#39;, &#39;color&#39;: &#39;black&#39;, &#39;lw&#39;: 2}, va=&#39;center&#39;); fig.tight_layout() . . 이상점은 동 떨어진 점들 | 1사분위부터 3사분위까지 박스로 나타냄! | 1사분위수 - 1.5IQR부터 3사분위수 + 1.5IQR까지 선으로 나타냄 | . plotly . !pip install plotly !pip install ipywidgets !pip install jupyter-dash !pip install dash !pip install pandas . import plotly.express as px import pandas as pd from IPython.display import HTML . A=pd.DataFrame({&#39;score&#39;:y1,&#39;class&#39;:[&#39;A&#39;]*len(y1)}) # score열에는 y1을 입력, class 열에는 A를 y1의 길이만큼 반복 B=pd.DataFrame({&#39;score&#39;:y2,&#39;class&#39;:[&#39;B&#39;]*len(y2)}) # score열에는 y2를 입력, class 열에는 B를 y2의 길이만큼 반복 . df=pd.concat([A,B],ignore_index=True) # ignore_index는 순서를 이어주는, 즉 각 데이터 셋의 순서 무시하기 df . score class . 0 75 | A | . 1 75 | A | . 2 76 | A | . 3 76 | A | . 4 77 | A | . 5 77 | A | . 6 79 | A | . 7 79 | A | . 8 79 | A | . 9 98 | A | . 10 76 | B | . 11 76 | B | . 12 77 | B | . 13 77 | B | . 14 78 | B | . 15 78 | B | . 16 80 | B | . 17 80 | B | . 18 80 | B | . 19 81 | B | . fig=px.box(data_frame=df, x=&#39;class&#39;,y=&#39;score&#39;) HTML(fig.to_html(include_plotlyjs=&#39;cdn&#39;,include_mathjax=False)) # 이거 해줘야 블로그 같은 곳에 나타남/ . . . histogram . &#55176;&#49828;&#53664;&#44536;&#47016;&#51060;&#46976;? . - X축이 변수의 구간, Y축은 그 구간에 포함된 빈도를 의미하는 그림 . - 예를들면 아래와 같음 . plt.hist(np.random.normal(loc=0, scale=1, size=1000000)) # 평균은 0이고 표준편차는 1인 1000000 사이즈의 랜덤 정규분포 . (array([2.40000e+01, 1.21000e+03, 2.13380e+04, 1.39948e+05, 3.51614e+05, 3.39662e+05, 1.27147e+05, 1.80510e+04, 9.87000e+02, 1.90000e+01]), array([-5.05590169, -4.03792348, -3.01994528, -2.00196708, -0.98398887, 0.03398933, 1.05196753, 2.06994573, 3.08792394, 4.10590214, 5.12388034]), &lt;BarContainer object of 10 artists&gt;) . &#51204;&#48513;&#44256;&#50696;&#51228; . - 중심경향값, 집중경향치 (Measure of central tendency): 분포의 중심성을 나타내기 위한 값, 예시로는 평균, 중앙값. . https://en.wikipedia.org/wiki/Central_tendency | . - &#39;평균이 항상 좋은 중심경향값은 아니다.&#39;라는 사실은 이해했음. . - 하지만 특수한 상황을 가정하면 평균이 좋은 중심경향값임 . np.random.seed(43052) y1=np.random.normal(loc=0,scale=1,size=10000) #전북고 A반의 통계학 성적이라 생각하자. y2=np.random.normal(loc=0.5,scale=1,size=10000) #전북고 B반의 통계학 성적이라 생각하자. . np.mean(y1), np.mean(y2) . (-0.011790879905079434, 0.4979147460611458) . (np.mean(y2)-np.mean(y1)).round(3) . 0.51 . plt.boxplot([y1,y2]) . {&#39;whiskers&#39;: [&lt;matplotlib.lines.Line2D at 0x7f6a86a419d0&gt;, &lt;matplotlib.lines.Line2D at 0x7f6a86a41d60&gt;, &lt;matplotlib.lines.Line2D at 0x7f6a86a59370&gt;, &lt;matplotlib.lines.Line2D at 0x7f6a86a59700&gt;], &#39;caps&#39;: [&lt;matplotlib.lines.Line2D at 0x7f6a86a4f130&gt;, &lt;matplotlib.lines.Line2D at 0x7f6a86a4f4c0&gt;, &lt;matplotlib.lines.Line2D at 0x7f6a86a59a90&gt;, &lt;matplotlib.lines.Line2D at 0x7f6a86a59e20&gt;], &#39;boxes&#39;: [&lt;matplotlib.lines.Line2D at 0x7f6a86a41640&gt;, &lt;matplotlib.lines.Line2D at 0x7f6a86a4ffa0&gt;], &#39;medians&#39;: [&lt;matplotlib.lines.Line2D at 0x7f6a86a4f880&gt;, &lt;matplotlib.lines.Line2D at 0x7f6a86a651f0&gt;], &#39;fliers&#39;: [&lt;matplotlib.lines.Line2D at 0x7f6a86a4fc10&gt;, &lt;matplotlib.lines.Line2D at 0x7f6a86a65580&gt;], &#39;means&#39;: []} . 분포의 모양이 거의 비슷하고, 왼쪽그림을 거의 컨트롤+C,V 오른쪽에 붙인다음 위치조정을 한 느낌 | 이런상황에서는 $B반의 성적 approx A반의 성적 + 0.51$ 라고 주장해도 큰 무리가 없음. | . - 정규분포인것은 어떻게 아는가? $ to$ 히스토그램을 그려보아서 종 모양이 나오는지 살펴보자. . plt.hist(y1,bins=50) # 50개의 구간으로 나누어서 히스토그램을 그릴것 . (array([ 1., 1., 3., 0., 1., 4., 5., 12., 14., 26., 32., 52., 67., 89., 144., 171., 238., 282., 325., 378., 489., 492., 561., 635., 652., 636., 626., 606., 573., 539., 475., 444., 350., 250., 232., 172., 137., 80., 58., 47., 30., 23., 17., 12., 9., 4., 4., 0., 1., 1.]), array([-4.12186916, -3.96068404, -3.79949892, -3.6383138 , -3.47712868, -3.31594356, -3.15475844, -2.99357332, -2.8323882 , -2.67120308, -2.51001796, -2.34883284, -2.18764772, -2.0264626 , -1.86527748, -1.70409236, -1.54290724, -1.38172212, -1.220537 , -1.05935188, -0.89816676, -0.73698164, -0.57579652, -0.4146114 , -0.25342628, -0.09224116, 0.06894396, 0.23012908, 0.3913142 , 0.55249932, 0.71368444, 0.87486956, 1.03605468, 1.1972398 , 1.35842492, 1.51961004, 1.68079516, 1.84198028, 2.0031654 , 2.16435052, 2.32553564, 2.48672076, 2.64790588, 2.809091 , 2.97027612, 3.13146124, 3.29264636, 3.45383148, 3.6150166 , 3.77620172, 3.93738684]), &lt;BarContainer object of 50 artists&gt;) . plt.hist(y2,bins=50) . (array([ 1., 0., 3., 2., 4., 5., 5., 10., 16., 25., 33., 56., 74., 116., 119., 152., 244., 272., 351., 362., 438., 509., 531., 621., 624., 690., 636., 571., 564., 514., 462., 402., 356., 297., 233., 184., 144., 113., 80., 55., 38., 34., 21., 18., 4., 3., 2., 4., 1., 1.]), array([-3.5752867 , -3.4164866 , -3.2576865 , -3.0988864 , -2.9400863 , -2.7812862 , -2.6224861 , -2.463686 , -2.3048859 , -2.1460858 , -1.9872857 , -1.8284856 , -1.6696855 , -1.5108854 , -1.3520853 , -1.1932852 , -1.0344851 , -0.875685 , -0.7168849 , -0.5580848 , -0.3992847 , -0.2404846 , -0.0816845 , 0.0771156 , 0.2359157 , 0.3947158 , 0.5535159 , 0.712316 , 0.87111611, 1.02991621, 1.18871631, 1.34751641, 1.50631651, 1.66511661, 1.82391671, 1.98271681, 2.14151691, 2.30031701, 2.45911711, 2.61791721, 2.77671731, 2.93551741, 3.09431751, 3.25311761, 3.41191771, 3.57071781, 3.72951791, 3.88831801, 4.04711811, 4.20591821, 4.36471831]), &lt;BarContainer object of 50 artists&gt;) . plt.hist([y1,y2],bins=200) # 히스토그램 겹쳐 그리기 . (array([[ 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 2., 1., 0., 1., 1., 3., 4., 4., 2., 2., 6., 4., 1., 4., 7., 8., 9., 11., 5., 9., 9., 14., 12., 16., 11., 9., 18., 25., 30., 22., 18., 28., 29., 39., 40., 41., 37., 42., 48., 56., 58., 49., 80., 62., 62., 91., 78., 75., 82., 89., 81., 106., 85., 89., 126., 125., 106., 142., 141., 121., 121., 135., 154., 166., 146., 125., 169., 160., 170., 172., 162., 161., 161., 193., 146., 186., 170., 166., 197., 152., 149., 167., 173., 158., 155., 156., 153., 152., 137., 151., 147., 126., 141., 125., 139., 117., 116., 135., 118., 93., 115., 99., 78., 91., 77., 63., 81., 52., 83., 53., 61., 49., 46., 46., 47., 45., 26., 48., 31., 27., 27., 20., 17., 22., 15., 15., 14., 14., 15., 10., 8., 13., 7., 5., 8., 6., 6., 6., 2., 4., 9., 3., 3., 6., 2., 1., 4., 2., 2., 2., 2., 0., 1., 1., 2., 2., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [ 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 3., 1., 2., 1., 1., 1., 2., 1., 2., 2., 1., 6., 1., 6., 3., 7., 7., 5., 6., 10., 5., 7., 16., 9., 11., 13., 28., 21., 16., 20., 27., 25., 32., 33., 28., 31., 31., 39., 42., 34., 43., 44., 64., 56., 80., 64., 74., 77., 69., 82., 92., 101., 99., 81., 90., 115., 110., 106., 108., 127., 127., 138., 145., 138., 121., 159., 135., 145., 156., 186., 158., 164., 172., 182., 147., 194., 178., 176., 195., 162., 182., 164., 164., 163., 145., 150., 143., 155., 144., 142., 161., 141., 146., 129., 115., 132., 120., 118., 128., 103., 88., 111., 104., 97., 82., 77., 83., 83., 80., 77., 67., 58., 48., 47., 54., 50., 43., 36., 43., 33., 33., 42., 29., 24., 28., 19., 22., 16., 18., 14., 14., 11., 10., 9., 7., 12., 10., 8., 8., 9., 4., 7., 4., 6., 3., 8., 1., 1., 1., 0., 1., 0., 2., 1., 0., 2., 0., 0., 2., 2., 0., 0., 0., 0., 1., 0., 0., 0., 1.]]), array([-4.12186916, -4.07943623, -4.03700329, -3.99457035, -3.95213741, -3.90970448, -3.86727154, -3.8248386 , -3.78240567, -3.73997273, -3.69753979, -3.65510685, -3.61267392, -3.57024098, -3.52780804, -3.4853751 , -3.44294217, -3.40050923, -3.35807629, -3.31564335, -3.27321042, -3.23077748, -3.18834454, -3.1459116 , -3.10347867, -3.06104573, -3.01861279, -2.97617986, -2.93374692, -2.89131398, -2.84888104, -2.80644811, -2.76401517, -2.72158223, -2.67914929, -2.63671636, -2.59428342, -2.55185048, -2.50941754, -2.46698461, -2.42455167, -2.38211873, -2.33968579, -2.29725286, -2.25481992, -2.21238698, -2.16995405, -2.12752111, -2.08508817, -2.04265523, -2.0002223 , -1.95778936, -1.91535642, -1.87292348, -1.83049055, -1.78805761, -1.74562467, -1.70319173, -1.6607588 , -1.61832586, -1.57589292, -1.53345998, -1.49102705, -1.44859411, -1.40616117, -1.36372824, -1.3212953 , -1.27886236, -1.23642942, -1.19399649, -1.15156355, -1.10913061, -1.06669767, -1.02426474, -0.9818318 , -0.93939886, -0.89696592, -0.85453299, -0.81210005, -0.76966711, -0.72723417, -0.68480124, -0.6423683 , -0.59993536, -0.55750243, -0.51506949, -0.47263655, -0.43020361, -0.38777068, -0.34533774, -0.3029048 , -0.26047186, -0.21803893, -0.17560599, -0.13317305, -0.09074011, -0.04830718, -0.00587424, 0.0365587 , 0.07899164, 0.12142457, 0.16385751, 0.20629045, 0.24872338, 0.29115632, 0.33358926, 0.3760222 , 0.41845513, 0.46088807, 0.50332101, 0.54575395, 0.58818688, 0.63061982, 0.67305276, 0.7154857 , 0.75791863, 0.80035157, 0.84278451, 0.88521744, 0.92765038, 0.97008332, 1.01251626, 1.05494919, 1.09738213, 1.13981507, 1.18224801, 1.22468094, 1.26711388, 1.30954682, 1.35197976, 1.39441269, 1.43684563, 1.47927857, 1.52171151, 1.56414444, 1.60657738, 1.64901032, 1.69144325, 1.73387619, 1.77630913, 1.81874207, 1.861175 , 1.90360794, 1.94604088, 1.98847382, 2.03090675, 2.07333969, 2.11577263, 2.15820557, 2.2006385 , 2.24307144, 2.28550438, 2.32793732, 2.37037025, 2.41280319, 2.45523613, 2.49766906, 2.540102 , 2.58253494, 2.62496788, 2.66740081, 2.70983375, 2.75226669, 2.79469963, 2.83713256, 2.8795655 , 2.92199844, 2.96443138, 3.00686431, 3.04929725, 3.09173019, 3.13416313, 3.17659606, 3.219029 , 3.26146194, 3.30389487, 3.34632781, 3.38876075, 3.43119369, 3.47362662, 3.51605956, 3.5584925 , 3.60092544, 3.64335837, 3.68579131, 3.72822425, 3.77065719, 3.81309012, 3.85552306, 3.897956 , 3.94038894, 3.98282187, 4.02525481, 4.06768775, 4.11012068, 4.15255362, 4.19498656, 4.2374195 , 4.27985243, 4.32228537, 4.36471831]), &lt;a list of 2 BarContainer objects&gt;) . seaborn . import seaborn as sns . A=pd.DataFrame({&#39;score&#39;:y1,&#39;class&#39;:[&#39;A&#39;]*len(y1)}) B=pd.DataFrame({&#39;score&#39;:y2,&#39;class&#39;:[&#39;B&#39;]*len(y2)}) df=pd.concat([A,B],ignore_index=True) . sns.histplot(df,x=&#39;score&#39;,hue=&#39;class&#39;) . &lt;AxesSubplot:xlabel=&#39;score&#39;, ylabel=&#39;Count&#39;&gt; . plotnine . from plotnine import * . ggplot(df)+geom_histogram(aes(x=&#39;score&#39;,fill=&#39;class&#39;),position=&#39;identity&#39;,alpha=0.5) . /home/cgb4/anaconda3/envs/csy/lib/python3.8/site-packages/plotnine/stats/stat_bin.py:95: PlotnineWarning: &#39;stat_bin()&#39; using &#39;bins = 84&#39;. Pick better value with &#39;binwidth&#39;. . &lt;ggplot: (8755886288517)&gt; . plotly . - 인터랙티브 그래프를 위해서 plotly 홈페이지를 방문하여 적당한 코드를 가져온다. . import plotly.figure_factory as ff import numpy as np . hist_data=[y1,y2] group_labels=[&#39;A&#39;,&#39;B&#39;] fig = ff.create_distplot(hist_data, group_labels,bin_size=.2, show_rug=False) HTML(fig.to_html(include_plotlyjs=&#39;cdn&#39;,include_mathjax=False)) . . . [&#49689;&#51228;1] . (1) 자기학번으로 np.random.seed(202043052)를 만들고 . (2) y1, y2 // 10만개의 정규분포를 생성해서 저장 . y1: 평균 0, 표준편차=1 | y2: 평균 1, 표준편차=1 | . (3) plotly 를 활용하여 히스토그램을 겹쳐서 그려보는것. . np.random.seed(202150754) y1=np.random.normal(loc=0,scale=1,size=100000) y2=np.random.normal(loc=1,scale=1,size=100000) plt.hist([y1,y2],bins=200) . (array([[1.000e+00, 0.000e+00, 2.000e+00, 1.000e+00, 0.000e+00, 4.000e+00, 0.000e+00, 1.000e+00, 2.000e+00, 4.000e+00, 2.000e+00, 1.000e+00, 7.000e+00, 1.000e+00, 7.000e+00, 6.000e+00, 7.000e+00, 9.000e+00, 1.200e+01, 4.000e+00, 1.100e+01, 1.500e+01, 1.800e+01, 1.900e+01, 2.900e+01, 3.500e+01, 3.300e+01, 3.700e+01, 5.100e+01, 5.100e+01, 6.800e+01, 6.900e+01, 8.300e+01, 8.400e+01, 8.700e+01, 9.400e+01, 1.140e+02, 1.360e+02, 1.450e+02, 1.580e+02, 1.840e+02, 1.850e+02, 2.180e+02, 2.580e+02, 2.700e+02, 2.850e+02, 2.990e+02, 3.320e+02, 3.800e+02, 4.060e+02, 4.270e+02, 5.110e+02, 4.850e+02, 5.380e+02, 6.160e+02, 6.140e+02, 6.540e+02, 7.110e+02, 8.180e+02, 8.170e+02, 8.610e+02, 9.200e+02, 8.990e+02, 9.870e+02, 1.033e+03, 1.116e+03, 1.152e+03, 1.177e+03, 1.252e+03, 1.302e+03, 1.382e+03, 1.430e+03, 1.494e+03, 1.466e+03, 1.572e+03, 1.596e+03, 1.597e+03, 1.632e+03, 1.671e+03, 1.699e+03, 1.755e+03, 1.820e+03, 1.760e+03, 1.796e+03, 1.834e+03, 1.800e+03, 1.936e+03, 1.901e+03, 1.821e+03, 1.899e+03, 1.803e+03, 1.722e+03, 1.673e+03, 1.756e+03, 1.743e+03, 1.728e+03, 1.697e+03, 1.693e+03, 1.594e+03, 1.506e+03, 1.486e+03, 1.529e+03, 1.438e+03, 1.392e+03, 1.394e+03, 1.304e+03, 1.286e+03, 1.232e+03, 1.129e+03, 1.138e+03, 1.029e+03, 1.005e+03, 9.240e+02, 8.700e+02, 8.540e+02, 8.140e+02, 7.090e+02, 7.270e+02, 6.440e+02, 5.890e+02, 5.790e+02, 5.650e+02, 4.890e+02, 4.300e+02, 4.550e+02, 4.110e+02, 3.190e+02, 3.450e+02, 2.970e+02, 2.880e+02, 2.530e+02, 2.410e+02, 2.000e+02, 1.730e+02, 1.620e+02, 1.540e+02, 1.570e+02, 1.320e+02, 1.120e+02, 9.500e+01, 8.100e+01, 8.600e+01, 8.200e+01, 7.200e+01, 6.700e+01, 4.400e+01, 4.500e+01, 4.500e+01, 2.800e+01, 2.000e+01, 2.400e+01, 2.800e+01, 2.000e+01, 2.500e+01, 8.000e+00, 1.500e+01, 1.000e+01, 7.000e+00, 1.000e+01, 7.000e+00, 3.000e+00, 9.000e+00, 4.000e+00, 3.000e+00, 3.000e+00, 1.000e+00, 4.000e+00, 1.000e+00, 0.000e+00, 1.000e+00, 1.000e+00, 0.000e+00, 1.000e+00, 1.000e+00, 0.000e+00, 2.000e+00, 0.000e+00, 1.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00], [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 1.000e+00, 1.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 1.000e+00, 1.000e+00, 0.000e+00, 2.000e+00, 1.000e+00, 1.000e+00, 2.000e+00, 1.000e+00, 1.000e+00, 3.000e+00, 3.000e+00, 2.000e+00, 3.000e+00, 6.000e+00, 3.000e+00, 9.000e+00, 1.000e+01, 1.100e+01, 6.000e+00, 9.000e+00, 1.300e+01, 1.800e+01, 1.500e+01, 1.600e+01, 3.600e+01, 2.300e+01, 2.800e+01, 3.300e+01, 4.300e+01, 6.500e+01, 6.000e+01, 7.000e+01, 7.600e+01, 7.000e+01, 6.600e+01, 9.400e+01, 1.060e+02, 1.300e+02, 1.440e+02, 1.430e+02, 1.630e+02, 1.900e+02, 1.890e+02, 2.410e+02, 2.540e+02, 2.720e+02, 2.990e+02, 3.860e+02, 3.220e+02, 3.970e+02, 4.100e+02, 4.230e+02, 4.590e+02, 5.070e+02, 5.340e+02, 6.230e+02, 6.520e+02, 7.010e+02, 6.890e+02, 7.730e+02, 7.950e+02, 8.880e+02, 9.260e+02, 9.080e+02, 1.016e+03, 1.065e+03, 1.098e+03, 1.203e+03, 1.194e+03, 1.307e+03, 1.287e+03, 1.367e+03, 1.408e+03, 1.528e+03, 1.516e+03, 1.550e+03, 1.615e+03, 1.593e+03, 1.610e+03, 1.730e+03, 1.784e+03, 1.786e+03, 1.804e+03, 1.800e+03, 1.802e+03, 1.748e+03, 1.817e+03, 1.796e+03, 1.862e+03, 1.837e+03, 1.776e+03, 1.794e+03, 1.798e+03, 1.770e+03, 1.723e+03, 1.779e+03, 1.712e+03, 1.688e+03, 1.694e+03, 1.524e+03, 1.563e+03, 1.566e+03, 1.514e+03, 1.405e+03, 1.329e+03, 1.360e+03, 1.286e+03, 1.271e+03, 1.131e+03, 1.146e+03, 1.054e+03, 1.044e+03, 9.620e+02, 9.050e+02, 9.360e+02, 8.110e+02, 8.290e+02, 7.080e+02, 7.530e+02, 6.310e+02, 6.010e+02, 5.700e+02, 5.130e+02, 5.080e+02, 4.610e+02, 4.150e+02, 3.810e+02, 3.520e+02, 3.380e+02, 3.040e+02, 2.550e+02, 2.550e+02, 2.160e+02, 2.090e+02, 1.810e+02, 1.650e+02, 1.430e+02, 1.410e+02, 1.200e+02, 1.080e+02, 8.400e+01, 9.200e+01, 7.800e+01, 7.500e+01, 7.500e+01, 5.500e+01, 4.300e+01, 4.700e+01, 4.200e+01, 4.300e+01, 3.700e+01, 1.900e+01, 3.000e+01, 2.100e+01, 1.800e+01, 1.400e+01, 8.000e+00, 1.400e+01, 1.100e+01, 7.000e+00, 5.000e+00, 7.000e+00, 4.000e+00, 5.000e+00, 2.000e+00, 2.000e+00, 4.000e+00, 3.000e+00, 1.000e+00, 0.000e+00, 0.000e+00, 1.000e+00, 2.000e+00, 1.000e+00, 0.000e+00, 1.000e+00, 0.000e+00, 0.000e+00, 1.000e+00]]), array([-4.03250572, -3.98635668, -3.94020763, -3.89405858, -3.84790954, -3.80176049, -3.75561144, -3.7094624 , -3.66331335, -3.6171643 , -3.57101526, -3.52486621, -3.47871716, -3.43256812, -3.38641907, -3.34027002, -3.29412098, -3.24797193, -3.20182288, -3.15567384, -3.10952479, -3.06337574, -3.0172267 , -2.97107765, -2.92492861, -2.87877956, -2.83263051, -2.78648147, -2.74033242, -2.69418337, -2.64803433, -2.60188528, -2.55573623, -2.50958719, -2.46343814, -2.41728909, -2.37114005, -2.324991 , -2.27884195, -2.23269291, -2.18654386, -2.14039481, -2.09424577, -2.04809672, -2.00194767, -1.95579863, -1.90964958, -1.86350053, -1.81735149, -1.77120244, -1.7250534 , -1.67890435, -1.6327553 , -1.58660626, -1.54045721, -1.49430816, -1.44815912, -1.40201007, -1.35586102, -1.30971198, -1.26356293, -1.21741388, -1.17126484, -1.12511579, -1.07896674, -1.0328177 , -0.98666865, -0.9405196 , -0.89437056, -0.84822151, -0.80207246, -0.75592342, -0.70977437, -0.66362533, -0.61747628, -0.57132723, -0.52517819, -0.47902914, -0.43288009, -0.38673105, -0.340582 , -0.29443295, -0.24828391, -0.20213486, -0.15598581, -0.10983677, -0.06368772, -0.01753867, 0.02861037, 0.07475942, 0.12090847, 0.16705751, 0.21320656, 0.25935561, 0.30550465, 0.3516537 , 0.39780274, 0.44395179, 0.49010084, 0.53624988, 0.58239893, 0.62854798, 0.67469702, 0.72084607, 0.76699512, 0.81314416, 0.85929321, 0.90544226, 0.9515913 , 0.99774035, 1.0438894 , 1.09003844, 1.13618749, 1.18233654, 1.22848558, 1.27463463, 1.32078368, 1.36693272, 1.41308177, 1.45923081, 1.50537986, 1.55152891, 1.59767795, 1.643827 , 1.68997605, 1.73612509, 1.78227414, 1.82842319, 1.87457223, 1.92072128, 1.96687033, 2.01301937, 2.05916842, 2.10531747, 2.15146651, 2.19761556, 2.24376461, 2.28991365, 2.3360627 , 2.38221175, 2.42836079, 2.47450984, 2.52065889, 2.56680793, 2.61295698, 2.65910602, 2.70525507, 2.75140412, 2.79755316, 2.84370221, 2.88985126, 2.9360003 , 2.98214935, 3.0282984 , 3.07444744, 3.12059649, 3.16674554, 3.21289458, 3.25904363, 3.30519268, 3.35134172, 3.39749077, 3.44363982, 3.48978886, 3.53593791, 3.58208696, 3.628236 , 3.67438505, 3.72053409, 3.76668314, 3.81283219, 3.85898123, 3.90513028, 3.95127933, 3.99742837, 4.04357742, 4.08972647, 4.13587551, 4.18202456, 4.22817361, 4.27432265, 4.3204717 , 4.36662075, 4.41276979, 4.45891884, 4.50506789, 4.55121693, 4.59736598, 4.64351503, 4.68966407, 4.73581312, 4.78196216, 4.82811121, 4.87426026, 4.9204093 , 4.96655835, 5.0127074 , 5.05885644, 5.10500549, 5.15115454, 5.19730358]), &lt;a list of 2 BarContainer objects&gt;) . Histogram Equalization, HE . - ref: https://en.wikipedia.org/wiki/Histogram_equalization . - 히스토그램 평활화: 이미지의 명암대비 개선 . !pip install opencv-python . import cv2 as cv import matplotlib.pyplot as plt import pandas as pd . img = cv.imread(&#39;Unequalized_Hawkes_Bay_NZ.jpg&#39;,0) . plt.imshow(img,cmap=&#39;gray&#39;,vmin=0,vmax=255) plt.colorbar() . &lt;matplotlib.colorbar.Colorbar at 0x7f6a713a2280&gt; . - 이미지자료는 사실 0~255 사이의 어떠한 숫자들이 포함된 매트릭스일 뿐이다. . img . array([[127, 145, 149, ..., 168, 167, 166], [165, 152, 143, ..., 168, 169, 168], [171, 145, 140, ..., 156, 154, 151], ..., [147, 132, 134, ..., 146, 145, 144], [146, 130, 132, ..., 146, 145, 144], [145, 128, 129, ..., 146, 145, 144]], dtype=uint8) . 확인: 이미지가 있다고 믿었던 img는 그냥 넘파이 매트릭스 | 위의 매트릭스에 있는 숫자들을 색깔로 표현하여 값이 클수록 하얗게, 값이 작을수록 검게 그린다. 극단적으로 0은 검은색, 255는 흰색이다. | . - 이미지가 넘파이 매트릭스일 뿐이라는 것을 판다스를 활용하면 더 잘 시각화하여 이해할 수 있다. . plt.imshow(img[200:300,400:500],cmap=&#39;gray&#39;,vmin=0,vmax=255) . &lt;matplotlib.image.AxesImage at 0x7fb294190bb0&gt; . df=pd.DataFrame(img) df.iloc[200:300,400:500].style.set_properties(**{&#39;font-size&#39;:&#39;10pt&#39;}).background_gradient(&#39;gray&#39;,vmin=0,vmax=255) . &nbsp; 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 . 200 155 | 155 | 151 | 149 | 152 | 152 | 151 | 152 | 152 | 152 | 152 | 153 | 154 | 155 | 157 | 158 | 164 | 157 | 150 | 148 | 146 | 143 | 139 | 138 | 138 | 140 | 142 | 140 | 138 | 137 | 137 | 137 | 131 | 142 | 147 | 143 | 143 | 150 | 153 | 151 | 149 | 148 | 146 | 143 | 141 | 141 | 142 | 143 | 143 | 143 | 140 | 138 | 137 | 138 | 136 | 133 | 133 | 134 | 133 | 131 | 128 | 127 | 129 | 131 | 128 | 129 | 132 | 129 | 130 | 129 | 125 | 131 | 128 | 128 | 128 | 130 | 132 | 133 | 132 | 131 | 137 | 136 | 135 | 138 | 140 | 133 | 127 | 129 | 132 | 130 | 130 | 132 | 135 | 135 | 134 | 134 | 137 | 138 | 137 | 134 | . 201 139 | 148 | 152 | 149 | 145 | 142 | 147 | 156 | 150 | 152 | 154 | 154 | 153 | 153 | 155 | 157 | 158 | 159 | 155 | 149 | 144 | 142 | 139 | 136 | 138 | 139 | 140 | 139 | 137 | 136 | 136 | 137 | 141 | 140 | 139 | 141 | 147 | 152 | 152 | 150 | 151 | 150 | 149 | 147 | 145 | 143 | 143 | 143 | 141 | 142 | 142 | 141 | 141 | 141 | 138 | 134 | 133 | 132 | 132 | 131 | 130 | 131 | 133 | 135 | 128 | 128 | 132 | 130 | 132 | 131 | 126 | 132 | 129 | 129 | 128 | 129 | 130 | 132 | 132 | 133 | 137 | 135 | 132 | 133 | 134 | 129 | 126 | 130 | 129 | 129 | 131 | 133 | 134 | 133 | 134 | 136 | 136 | 137 | 137 | 135 | . 202 138 | 145 | 149 | 149 | 149 | 144 | 138 | 139 | 144 | 148 | 153 | 155 | 153 | 152 | 153 | 155 | 153 | 158 | 157 | 147 | 140 | 140 | 139 | 136 | 137 | 135 | 135 | 137 | 137 | 135 | 134 | 136 | 142 | 138 | 139 | 145 | 147 | 144 | 145 | 151 | 150 | 150 | 151 | 150 | 149 | 147 | 145 | 143 | 140 | 140 | 140 | 140 | 140 | 141 | 139 | 135 | 133 | 131 | 129 | 128 | 129 | 130 | 132 | 133 | 128 | 128 | 131 | 131 | 134 | 133 | 128 | 133 | 132 | 132 | 131 | 130 | 129 | 131 | 133 | 135 | 133 | 132 | 129 | 129 | 132 | 131 | 133 | 140 | 135 | 136 | 137 | 137 | 134 | 131 | 131 | 134 | 135 | 136 | 136 | 136 | . 203 152 | 151 | 148 | 150 | 156 | 152 | 141 | 134 | 137 | 141 | 147 | 151 | 152 | 152 | 153 | 154 | 152 | 155 | 153 | 144 | 137 | 138 | 139 | 139 | 134 | 130 | 130 | 134 | 135 | 133 | 133 | 136 | 133 | 132 | 137 | 146 | 147 | 141 | 141 | 147 | 146 | 147 | 148 | 149 | 150 | 149 | 147 | 145 | 143 | 142 | 140 | 137 | 137 | 139 | 139 | 137 | 136 | 133 | 129 | 127 | 127 | 128 | 128 | 128 | 129 | 127 | 130 | 129 | 133 | 134 | 130 | 136 | 136 | 136 | 134 | 132 | 130 | 131 | 133 | 135 | 132 | 133 | 132 | 133 | 137 | 137 | 140 | 147 | 144 | 143 | 142 | 140 | 137 | 133 | 134 | 136 | 136 | 136 | 135 | 135 | . 204 155 | 156 | 153 | 151 | 153 | 153 | 152 | 155 | 141 | 141 | 142 | 144 | 147 | 149 | 151 | 151 | 153 | 152 | 149 | 145 | 140 | 137 | 138 | 140 | 133 | 130 | 129 | 131 | 132 | 131 | 132 | 134 | 130 | 127 | 130 | 139 | 147 | 147 | 144 | 141 | 144 | 144 | 144 | 146 | 147 | 147 | 147 | 146 | 147 | 146 | 143 | 140 | 139 | 140 | 139 | 137 | 138 | 134 | 130 | 127 | 128 | 129 | 129 | 128 | 129 | 127 | 129 | 127 | 131 | 134 | 131 | 139 | 139 | 138 | 136 | 133 | 131 | 130 | 132 | 134 | 137 | 140 | 141 | 141 | 143 | 140 | 139 | 143 | 145 | 141 | 138 | 139 | 140 | 141 | 142 | 144 | 138 | 136 | 134 | 133 | . 205 145 | 151 | 152 | 153 | 154 | 152 | 152 | 156 | 151 | 147 | 141 | 139 | 141 | 144 | 147 | 148 | 151 | 149 | 149 | 148 | 145 | 138 | 135 | 136 | 134 | 133 | 131 | 130 | 130 | 130 | 131 | 132 | 134 | 133 | 134 | 136 | 139 | 142 | 143 | 143 | 145 | 144 | 142 | 143 | 144 | 145 | 144 | 144 | 146 | 146 | 145 | 143 | 141 | 140 | 137 | 133 | 134 | 131 | 127 | 126 | 128 | 129 | 130 | 129 | 129 | 128 | 130 | 127 | 130 | 133 | 132 | 141 | 140 | 138 | 136 | 133 | 130 | 130 | 132 | 133 | 139 | 143 | 143 | 143 | 145 | 141 | 137 | 139 | 144 | 138 | 134 | 136 | 141 | 144 | 145 | 145 | 141 | 137 | 134 | 134 | . 206 143 | 147 | 149 | 151 | 155 | 152 | 146 | 145 | 154 | 151 | 146 | 143 | 142 | 143 | 144 | 145 | 144 | 146 | 147 | 146 | 142 | 138 | 136 | 134 | 133 | 135 | 134 | 130 | 129 | 132 | 134 | 134 | 135 | 136 | 137 | 136 | 133 | 135 | 142 | 150 | 147 | 145 | 143 | 143 | 144 | 145 | 144 | 143 | 145 | 145 | 144 | 142 | 141 | 140 | 136 | 132 | 130 | 128 | 126 | 126 | 127 | 128 | 129 | 129 | 129 | 129 | 131 | 129 | 130 | 133 | 133 | 143 | 143 | 139 | 135 | 132 | 131 | 132 | 134 | 136 | 138 | 141 | 140 | 139 | 142 | 141 | 139 | 140 | 143 | 137 | 133 | 136 | 141 | 143 | 143 | 142 | 143 | 139 | 136 | 136 | . 207 148 | 151 | 150 | 149 | 151 | 150 | 149 | 151 | 150 | 150 | 151 | 150 | 148 | 145 | 144 | 144 | 137 | 144 | 145 | 139 | 135 | 137 | 138 | 135 | 131 | 136 | 136 | 130 | 129 | 135 | 138 | 137 | 134 | 129 | 128 | 132 | 137 | 140 | 146 | 153 | 147 | 145 | 144 | 144 | 145 | 146 | 145 | 143 | 147 | 147 | 144 | 142 | 141 | 141 | 139 | 136 | 132 | 131 | 129 | 128 | 128 | 128 | 128 | 129 | 128 | 130 | 133 | 131 | 131 | 133 | 133 | 144 | 145 | 141 | 135 | 132 | 132 | 135 | 138 | 140 | 141 | 141 | 137 | 135 | 139 | 140 | 139 | 140 | 139 | 135 | 133 | 136 | 141 | 143 | 143 | 143 | 144 | 140 | 137 | 138 | . 208 150 | 148 | 151 | 145 | 143 | 147 | 148 | 153 | 158 | 153 | 150 | 152 | 149 | 143 | 141 | 144 | 145 | 145 | 144 | 142 | 140 | 137 | 133 | 131 | 130 | 133 | 131 | 130 | 137 | 143 | 140 | 135 | 141 | 139 | 130 | 134 | 147 | 142 | 135 | 144 | 147 | 143 | 146 | 148 | 144 | 146 | 149 | 144 | 148 | 144 | 140 | 141 | 143 | 144 | 141 | 137 | 132 | 128 | 126 | 127 | 128 | 127 | 125 | 125 | 128 | 127 | 129 | 135 | 138 | 138 | 138 | 139 | 138 | 133 | 129 | 130 | 133 | 135 | 138 | 140 | 140 | 136 | 135 | 137 | 138 | 136 | 136 | 139 | 139 | 137 | 137 | 138 | 139 | 140 | 141 | 143 | 141 | 144 | 143 | 143 | . 209 153 | 147 | 147 | 143 | 144 | 147 | 144 | 146 | 150 | 149 | 150 | 152 | 153 | 151 | 146 | 143 | 142 | 142 | 141 | 139 | 137 | 135 | 134 | 134 | 133 | 131 | 130 | 129 | 130 | 132 | 134 | 133 | 136 | 139 | 137 | 130 | 132 | 146 | 151 | 142 | 145 | 146 | 153 | 156 | 154 | 156 | 156 | 149 | 145 | 148 | 149 | 148 | 143 | 140 | 139 | 140 | 143 | 137 | 130 | 125 | 122 | 122 | 126 | 129 | 128 | 128 | 129 | 132 | 137 | 139 | 139 | 137 | 133 | 130 | 129 | 133 | 138 | 139 | 137 | 135 | 140 | 136 | 134 | 136 | 136 | 133 | 132 | 135 | 137 | 136 | 136 | 137 | 136 | 136 | 137 | 140 | 137 | 140 | 139 | 139 | . 210 154 | 147 | 147 | 145 | 145 | 145 | 141 | 145 | 143 | 145 | 147 | 149 | 153 | 155 | 151 | 144 | 144 | 143 | 141 | 139 | 137 | 136 | 137 | 137 | 136 | 130 | 132 | 135 | 129 | 129 | 133 | 133 | 137 | 128 | 138 | 144 | 135 | 141 | 149 | 139 | 141 | 142 | 146 | 146 | 145 | 152 | 155 | 150 | 145 | 145 | 144 | 144 | 144 | 143 | 141 | 140 | 142 | 139 | 135 | 132 | 127 | 124 | 125 | 127 | 126 | 126 | 127 | 128 | 133 | 137 | 136 | 133 | 132 | 130 | 131 | 137 | 143 | 142 | 138 | 134 | 138 | 135 | 134 | 136 | 136 | 134 | 134 | 135 | 135 | 135 | 136 | 137 | 135 | 134 | 136 | 140 | 137 | 140 | 139 | 138 | . 211 153 | 149 | 152 | 151 | 148 | 146 | 143 | 150 | 143 | 143 | 143 | 145 | 148 | 150 | 150 | 148 | 149 | 146 | 142 | 140 | 139 | 139 | 138 | 137 | 137 | 131 | 137 | 143 | 137 | 139 | 141 | 134 | 145 | 129 | 145 | 167 | 157 | 144 | 144 | 140 | 139 | 142 | 143 | 140 | 141 | 149 | 153 | 151 | 148 | 145 | 141 | 141 | 142 | 143 | 142 | 141 | 139 | 138 | 139 | 139 | 135 | 129 | 124 | 122 | 125 | 124 | 124 | 127 | 130 | 132 | 133 | 134 | 133 | 131 | 132 | 137 | 140 | 140 | 137 | 135 | 138 | 135 | 133 | 134 | 134 | 133 | 134 | 135 | 133 | 134 | 136 | 136 | 135 | 134 | 136 | 140 | 139 | 141 | 139 | 139 | . 212 156 | 151 | 153 | 151 | 150 | 149 | 145 | 149 | 147 | 144 | 144 | 146 | 146 | 143 | 144 | 149 | 149 | 144 | 139 | 138 | 139 | 139 | 136 | 132 | 136 | 132 | 138 | 142 | 141 | 147 | 147 | 132 | 137 | 136 | 145 | 155 | 154 | 147 | 141 | 135 | 133 | 140 | 142 | 141 | 144 | 148 | 148 | 147 | 149 | 151 | 152 | 149 | 143 | 140 | 141 | 144 | 146 | 142 | 140 | 139 | 137 | 133 | 129 | 127 | 127 | 123 | 124 | 128 | 130 | 127 | 130 | 135 | 130 | 131 | 133 | 136 | 136 | 134 | 134 | 134 | 138 | 135 | 132 | 131 | 131 | 131 | 131 | 133 | 131 | 132 | 134 | 135 | 133 | 131 | 134 | 137 | 135 | 139 | 137 | 136 | . 213 160 | 152 | 151 | 149 | 151 | 153 | 145 | 142 | 148 | 145 | 146 | 150 | 148 | 141 | 141 | 147 | 146 | 142 | 137 | 137 | 139 | 139 | 135 | 131 | 134 | 132 | 134 | 134 | 136 | 144 | 143 | 131 | 128 | 132 | 130 | 129 | 134 | 138 | 137 | 137 | 132 | 138 | 138 | 137 | 141 | 143 | 144 | 147 | 148 | 150 | 151 | 152 | 150 | 148 | 145 | 144 | 145 | 142 | 140 | 142 | 143 | 141 | 139 | 137 | 129 | 125 | 123 | 126 | 127 | 125 | 127 | 131 | 129 | 131 | 135 | 138 | 137 | 134 | 133 | 134 | 135 | 133 | 132 | 132 | 133 | 135 | 136 | 138 | 135 | 135 | 136 | 136 | 134 | 132 | 132 | 135 | 133 | 137 | 136 | 134 | . 214 160 | 157 | 157 | 150 | 150 | 153 | 146 | 143 | 146 | 146 | 147 | 149 | 147 | 144 | 143 | 144 | 144 | 142 | 138 | 137 | 138 | 137 | 136 | 134 | 132 | 133 | 133 | 132 | 132 | 135 | 136 | 133 | 131 | 130 | 129 | 131 | 133 | 135 | 139 | 146 | 140 | 142 | 138 | 137 | 141 | 141 | 142 | 152 | 147 | 144 | 143 | 147 | 153 | 155 | 151 | 147 | 142 | 142 | 143 | 146 | 148 | 146 | 143 | 142 | 134 | 132 | 127 | 124 | 126 | 129 | 128 | 124 | 130 | 131 | 134 | 137 | 137 | 134 | 133 | 134 | 135 | 134 | 134 | 135 | 137 | 140 | 141 | 142 | 138 | 137 | 138 | 138 | 136 | 134 | 133 | 135 | 134 | 140 | 139 | 135 | . 215 157 | 162 | 167 | 156 | 148 | 151 | 149 | 151 | 145 | 145 | 145 | 143 | 144 | 146 | 146 | 143 | 143 | 142 | 139 | 137 | 135 | 134 | 134 | 135 | 130 | 134 | 136 | 136 | 134 | 130 | 131 | 138 | 128 | 130 | 138 | 141 | 136 | 138 | 143 | 140 | 137 | 140 | 138 | 140 | 143 | 137 | 134 | 143 | 147 | 147 | 146 | 147 | 148 | 150 | 153 | 155 | 149 | 147 | 146 | 146 | 143 | 141 | 141 | 143 | 141 | 141 | 133 | 124 | 128 | 137 | 134 | 122 | 129 | 128 | 129 | 131 | 132 | 132 | 132 | 133 | 138 | 138 | 138 | 138 | 138 | 139 | 138 | 137 | 137 | 136 | 136 | 137 | 136 | 134 | 133 | 134 | 136 | 142 | 141 | 136 | . 216 156 | 146 | 149 | 163 | 166 | 153 | 146 | 152 | 145 | 144 | 143 | 144 | 145 | 145 | 143 | 141 | 139 | 141 | 136 | 133 | 138 | 136 | 130 | 131 | 131 | 132 | 136 | 137 | 134 | 130 | 130 | 132 | 132 | 135 | 126 | 136 | 141 | 137 | 146 | 141 | 135 | 137 | 138 | 141 | 143 | 138 | 137 | 143 | 146 | 146 | 146 | 148 | 149 | 145 | 143 | 148 | 147 | 147 | 146 | 144 | 142 | 141 | 140 | 140 | 142 | 143 | 143 | 144 | 144 | 143 | 140 | 138 | 123 | 126 | 137 | 137 | 141 | 131 | 133 | 132 | 138 | 141 | 137 | 135 | 138 | 135 | 132 | 137 | 137 | 135 | 135 | 137 | 136 | 132 | 131 | 134 | 134 | 137 | 139 | 137 | . 217 155 | 156 | 158 | 158 | 159 | 158 | 154 | 148 | 150 | 146 | 142 | 143 | 145 | 145 | 142 | 138 | 136 | 135 | 131 | 132 | 137 | 138 | 135 | 133 | 136 | 131 | 129 | 130 | 132 | 131 | 128 | 127 | 143 | 144 | 130 | 132 | 134 | 132 | 144 | 141 | 134 | 138 | 138 | 136 | 137 | 136 | 135 | 138 | 132 | 144 | 151 | 146 | 144 | 150 | 152 | 147 | 142 | 143 | 143 | 143 | 143 | 142 | 142 | 142 | 144 | 144 | 144 | 145 | 146 | 146 | 146 | 145 | 136 | 133 | 132 | 135 | 136 | 136 | 133 | 133 | 133 | 134 | 133 | 135 | 139 | 138 | 135 | 135 | 134 | 133 | 134 | 136 | 134 | 129 | 129 | 132 | 133 | 134 | 135 | 135 | . 218 153 | 161 | 162 | 156 | 157 | 164 | 164 | 156 | 152 | 150 | 148 | 145 | 142 | 141 | 141 | 141 | 141 | 135 | 132 | 133 | 135 | 136 | 135 | 130 | 135 | 130 | 127 | 128 | 130 | 129 | 127 | 124 | 139 | 145 | 136 | 135 | 134 | 132 | 139 | 132 | 132 | 139 | 137 | 132 | 134 | 136 | 137 | 137 | 135 | 141 | 154 | 158 | 153 | 152 | 151 | 144 | 142 | 142 | 143 | 142 | 142 | 140 | 139 | 138 | 144 | 143 | 142 | 142 | 142 | 143 | 144 | 145 | 144 | 138 | 127 | 134 | 132 | 138 | 129 | 127 | 131 | 127 | 129 | 135 | 138 | 137 | 135 | 130 | 130 | 131 | 132 | 134 | 131 | 127 | 127 | 131 | 134 | 134 | 134 | 135 | . 219 153 | 155 | 157 | 158 | 159 | 161 | 164 | 165 | 157 | 155 | 151 | 147 | 144 | 142 | 142 | 142 | 148 | 139 | 137 | 136 | 132 | 131 | 132 | 126 | 129 | 130 | 131 | 131 | 130 | 128 | 126 | 126 | 127 | 137 | 136 | 136 | 135 | 134 | 136 | 127 | 131 | 136 | 136 | 134 | 137 | 139 | 138 | 140 | 133 | 133 | 146 | 155 | 150 | 150 | 152 | 145 | 143 | 142 | 141 | 140 | 139 | 138 | 136 | 135 | 142 | 141 | 140 | 138 | 137 | 137 | 137 | 138 | 152 | 147 | 139 | 143 | 142 | 144 | 135 | 130 | 131 | 125 | 128 | 135 | 134 | 134 | 134 | 129 | 131 | 132 | 134 | 134 | 131 | 128 | 130 | 135 | 133 | 133 | 134 | 136 | . 220 151 | 151 | 153 | 157 | 157 | 156 | 158 | 162 | 164 | 159 | 153 | 150 | 150 | 148 | 144 | 140 | 145 | 137 | 137 | 137 | 130 | 129 | 131 | 129 | 127 | 129 | 131 | 131 | 130 | 129 | 128 | 128 | 125 | 134 | 133 | 130 | 129 | 132 | 136 | 130 | 130 | 133 | 134 | 137 | 140 | 136 | 134 | 137 | 137 | 146 | 156 | 151 | 140 | 147 | 154 | 144 | 141 | 139 | 138 | 137 | 137 | 137 | 137 | 136 | 138 | 138 | 139 | 138 | 137 | 136 | 136 | 137 | 147 | 146 | 149 | 145 | 148 | 142 | 141 | 136 | 136 | 130 | 133 | 138 | 133 | 131 | 134 | 133 | 133 | 135 | 136 | 136 | 133 | 132 | 135 | 140 | 131 | 132 | 133 | 134 | . 221 147 | 151 | 154 | 154 | 155 | 158 | 160 | 159 | 161 | 164 | 164 | 160 | 152 | 146 | 144 | 145 | 142 | 137 | 137 | 136 | 130 | 127 | 129 | 131 | 131 | 129 | 127 | 126 | 128 | 130 | 130 | 127 | 126 | 132 | 133 | 129 | 128 | 132 | 134 | 130 | 131 | 131 | 131 | 135 | 137 | 131 | 127 | 131 | 136 | 148 | 162 | 161 | 146 | 141 | 144 | 142 | 142 | 140 | 136 | 135 | 135 | 135 | 134 | 134 | 131 | 134 | 137 | 138 | 138 | 138 | 139 | 139 | 139 | 140 | 147 | 140 | 143 | 137 | 142 | 141 | 147 | 143 | 144 | 144 | 136 | 129 | 128 | 131 | 131 | 133 | 135 | 135 | 134 | 134 | 137 | 140 | 134 | 134 | 134 | 132 | . 222 146 | 151 | 153 | 152 | 154 | 159 | 160 | 158 | 156 | 162 | 168 | 166 | 157 | 150 | 148 | 150 | 145 | 142 | 138 | 136 | 133 | 127 | 125 | 129 | 131 | 131 | 129 | 126 | 126 | 128 | 128 | 127 | 125 | 129 | 134 | 132 | 132 | 134 | 130 | 127 | 130 | 132 | 131 | 131 | 133 | 132 | 129 | 131 | 130 | 133 | 144 | 155 | 152 | 140 | 138 | 145 | 143 | 140 | 137 | 135 | 134 | 134 | 132 | 130 | 129 | 132 | 137 | 139 | 139 | 140 | 140 | 141 | 141 | 144 | 147 | 143 | 142 | 142 | 145 | 147 | 149 | 149 | 149 | 148 | 142 | 130 | 124 | 129 | 129 | 132 | 135 | 137 | 138 | 138 | 139 | 140 | 138 | 136 | 133 | 131 | . 223 151 | 149 | 149 | 151 | 152 | 151 | 152 | 153 | 159 | 157 | 157 | 162 | 167 | 165 | 155 | 145 | 147 | 146 | 139 | 136 | 137 | 130 | 124 | 130 | 128 | 134 | 136 | 132 | 126 | 124 | 126 | 127 | 125 | 126 | 131 | 129 | 131 | 134 | 131 | 130 | 129 | 133 | 131 | 128 | 132 | 136 | 136 | 136 | 154 | 150 | 143 | 141 | 145 | 146 | 142 | 140 | 138 | 136 | 135 | 134 | 135 | 136 | 134 | 133 | 133 | 136 | 140 | 142 | 141 | 141 | 142 | 142 | 141 | 146 | 143 | 145 | 138 | 144 | 141 | 143 | 140 | 144 | 145 | 148 | 147 | 135 | 127 | 133 | 131 | 134 | 139 | 142 | 144 | 145 | 144 | 142 | 139 | 135 | 130 | 129 | . 224 152 | 151 | 150 | 150 | 150 | 151 | 152 | 152 | 151 | 155 | 160 | 161 | 161 | 161 | 164 | 167 | 146 | 149 | 145 | 136 | 131 | 132 | 131 | 126 | 128 | 126 | 126 | 128 | 130 | 130 | 127 | 124 | 125 | 126 | 127 | 128 | 130 | 133 | 133 | 131 | 128 | 129 | 130 | 133 | 135 | 132 | 131 | 137 | 144 | 143 | 151 | 151 | 146 | 139 | 133 | 137 | 137 | 135 | 136 | 136 | 132 | 131 | 134 | 133 | 133 | 138 | 140 | 139 | 138 | 134 | 133 | 139 | 141 | 142 | 143 | 144 | 142 | 140 | 139 | 141 | 139 | 146 | 146 | 140 | 139 | 138 | 132 | 127 | 129 | 137 | 145 | 145 | 144 | 145 | 147 | 149 | 141 | 127 | 124 | 130 | . 225 151 | 149 | 147 | 146 | 146 | 147 | 149 | 149 | 151 | 153 | 155 | 156 | 157 | 159 | 161 | 164 | 162 | 151 | 144 | 143 | 140 | 132 | 128 | 129 | 132 | 129 | 127 | 127 | 128 | 129 | 128 | 127 | 126 | 128 | 129 | 130 | 131 | 132 | 130 | 127 | 131 | 131 | 130 | 132 | 134 | 130 | 129 | 134 | 130 | 134 | 146 | 147 | 143 | 138 | 132 | 136 | 133 | 132 | 134 | 135 | 130 | 130 | 132 | 130 | 133 | 136 | 136 | 136 | 138 | 136 | 136 | 142 | 144 | 143 | 143 | 143 | 141 | 139 | 138 | 139 | 142 | 143 | 141 | 141 | 142 | 136 | 128 | 127 | 137 | 145 | 148 | 143 | 141 | 143 | 144 | 140 | 141 | 132 | 128 | 128 | . 226 148 | 147 | 146 | 146 | 148 | 150 | 151 | 151 | 152 | 151 | 150 | 151 | 153 | 156 | 159 | 160 | 164 | 162 | 155 | 147 | 142 | 140 | 135 | 130 | 125 | 125 | 126 | 127 | 129 | 129 | 128 | 127 | 131 | 132 | 131 | 131 | 132 | 132 | 130 | 127 | 132 | 132 | 129 | 129 | 131 | 128 | 127 | 132 | 131 | 138 | 149 | 146 | 140 | 137 | 132 | 133 | 131 | 131 | 134 | 135 | 131 | 131 | 132 | 130 | 131 | 134 | 133 | 133 | 135 | 135 | 139 | 147 | 147 | 144 | 142 | 142 | 141 | 138 | 137 | 138 | 144 | 141 | 138 | 140 | 139 | 130 | 127 | 135 | 139 | 146 | 146 | 139 | 138 | 144 | 143 | 136 | 141 | 137 | 132 | 126 | . 227 148 | 149 | 149 | 150 | 151 | 151 | 150 | 149 | 150 | 150 | 150 | 151 | 153 | 155 | 156 | 157 | 157 | 165 | 166 | 156 | 148 | 146 | 143 | 137 | 126 | 126 | 126 | 126 | 126 | 126 | 127 | 128 | 133 | 133 | 131 | 129 | 130 | 131 | 131 | 129 | 129 | 130 | 128 | 127 | 128 | 126 | 128 | 134 | 144 | 148 | 153 | 145 | 139 | 140 | 136 | 135 | 133 | 132 | 135 | 136 | 132 | 132 | 134 | 132 | 129 | 132 | 133 | 132 | 133 | 133 | 137 | 147 | 147 | 144 | 140 | 140 | 139 | 138 | 136 | 136 | 143 | 141 | 139 | 137 | 132 | 125 | 131 | 147 | 142 | 144 | 142 | 138 | 140 | 145 | 145 | 140 | 141 | 139 | 135 | 130 | . 228 153 | 152 | 150 | 149 | 148 | 146 | 145 | 143 | 147 | 149 | 151 | 153 | 153 | 153 | 154 | 155 | 154 | 157 | 163 | 166 | 160 | 150 | 146 | 148 | 140 | 136 | 130 | 125 | 122 | 124 | 127 | 130 | 130 | 130 | 129 | 129 | 130 | 131 | 130 | 128 | 126 | 129 | 129 | 127 | 127 | 127 | 132 | 140 | 146 | 147 | 150 | 143 | 142 | 147 | 142 | 139 | 134 | 133 | 135 | 135 | 131 | 131 | 133 | 132 | 131 | 131 | 130 | 131 | 136 | 136 | 135 | 138 | 143 | 139 | 137 | 137 | 137 | 136 | 135 | 135 | 140 | 141 | 138 | 134 | 132 | 131 | 138 | 150 | 148 | 144 | 141 | 142 | 144 | 143 | 142 | 142 | 143 | 140 | 141 | 141 | . 229 155 | 152 | 149 | 147 | 146 | 146 | 147 | 147 | 144 | 146 | 149 | 151 | 150 | 150 | 151 | 153 | 153 | 155 | 158 | 162 | 163 | 161 | 154 | 149 | 141 | 138 | 134 | 131 | 129 | 128 | 127 | 127 | 127 | 129 | 131 | 133 | 134 | 135 | 132 | 128 | 127 | 131 | 130 | 128 | 128 | 130 | 134 | 143 | 142 | 144 | 148 | 146 | 148 | 151 | 143 | 137 | 132 | 131 | 132 | 132 | 128 | 128 | 131 | 130 | 135 | 132 | 128 | 132 | 142 | 142 | 134 | 130 | 137 | 135 | 135 | 136 | 136 | 135 | 134 | 135 | 137 | 138 | 134 | 132 | 136 | 140 | 140 | 143 | 145 | 140 | 139 | 143 | 143 | 138 | 137 | 140 | 143 | 141 | 144 | 148 | . 230 154 | 153 | 151 | 149 | 149 | 149 | 149 | 149 | 145 | 145 | 145 | 145 | 147 | 149 | 151 | 152 | 151 | 157 | 157 | 153 | 157 | 166 | 163 | 154 | 141 | 139 | 137 | 136 | 136 | 134 | 131 | 128 | 129 | 131 | 132 | 133 | 134 | 135 | 133 | 129 | 131 | 132 | 129 | 126 | 128 | 130 | 132 | 137 | 139 | 140 | 147 | 147 | 148 | 148 | 138 | 133 | 131 | 130 | 132 | 132 | 128 | 129 | 131 | 129 | 134 | 134 | 134 | 139 | 145 | 142 | 134 | 132 | 135 | 135 | 137 | 139 | 139 | 137 | 137 | 138 | 134 | 136 | 134 | 133 | 137 | 138 | 138 | 140 | 138 | 137 | 139 | 141 | 140 | 136 | 134 | 136 | 138 | 138 | 142 | 144 | . 231 156 | 155 | 155 | 154 | 152 | 148 | 145 | 142 | 148 | 144 | 141 | 141 | 145 | 149 | 152 | 153 | 155 | 153 | 152 | 154 | 156 | 158 | 163 | 168 | 154 | 147 | 139 | 135 | 134 | 136 | 136 | 136 | 130 | 130 | 128 | 127 | 129 | 131 | 131 | 129 | 134 | 133 | 127 | 123 | 127 | 128 | 128 | 130 | 135 | 135 | 143 | 143 | 143 | 142 | 133 | 130 | 131 | 130 | 134 | 135 | 131 | 131 | 133 | 131 | 129 | 137 | 144 | 146 | 144 | 138 | 135 | 140 | 136 | 137 | 141 | 143 | 143 | 140 | 140 | 141 | 131 | 136 | 136 | 135 | 132 | 130 | 133 | 143 | 139 | 143 | 145 | 143 | 139 | 135 | 133 | 131 | 131 | 134 | 138 | 137 | . 232 156 | 156 | 155 | 153 | 153 | 152 | 150 | 146 | 147 | 146 | 146 | 147 | 147 | 147 | 146 | 145 | 150 | 152 | 153 | 153 | 154 | 156 | 159 | 161 | 170 | 158 | 142 | 133 | 134 | 137 | 136 | 132 | 132 | 134 | 135 | 132 | 129 | 127 | 129 | 131 | 136 | 135 | 134 | 132 | 132 | 133 | 134 | 135 | 135 | 135 | 136 | 139 | 141 | 139 | 136 | 135 | 134 | 131 | 129 | 134 | 140 | 136 | 130 | 132 | 132 | 135 | 142 | 144 | 141 | 143 | 146 | 143 | 147 | 138 | 138 | 142 | 140 | 136 | 135 | 135 | 132 | 129 | 129 | 131 | 131 | 130 | 134 | 140 | 143 | 139 | 136 | 137 | 137 | 135 | 132 | 132 | 133 | 134 | 134 | 133 | . 233 153 | 157 | 160 | 158 | 153 | 151 | 150 | 149 | 146 | 148 | 149 | 149 | 147 | 145 | 143 | 142 | 144 | 146 | 148 | 150 | 151 | 154 | 156 | 158 | 163 | 165 | 161 | 150 | 139 | 134 | 136 | 139 | 137 | 136 | 135 | 136 | 135 | 133 | 129 | 126 | 129 | 132 | 135 | 139 | 142 | 143 | 144 | 143 | 144 | 141 | 139 | 137 | 134 | 131 | 131 | 133 | 130 | 137 | 140 | 138 | 132 | 126 | 130 | 142 | 131 | 130 | 134 | 139 | 137 | 137 | 140 | 141 | 140 | 134 | 136 | 141 | 140 | 139 | 138 | 137 | 133 | 130 | 129 | 130 | 129 | 127 | 130 | 135 | 141 | 140 | 141 | 142 | 140 | 136 | 134 | 134 | 129 | 130 | 132 | 133 | . 234 157 | 155 | 154 | 153 | 155 | 156 | 152 | 147 | 144 | 147 | 149 | 148 | 145 | 144 | 144 | 145 | 144 | 145 | 146 | 149 | 152 | 154 | 155 | 155 | 156 | 161 | 166 | 163 | 156 | 148 | 141 | 136 | 137 | 135 | 135 | 136 | 138 | 137 | 134 | 131 | 128 | 128 | 129 | 130 | 133 | 135 | 138 | 140 | 146 | 146 | 148 | 148 | 145 | 141 | 140 | 141 | 131 | 137 | 139 | 137 | 134 | 130 | 130 | 136 | 137 | 131 | 134 | 140 | 139 | 136 | 140 | 144 | 143 | 139 | 139 | 138 | 135 | 135 | 134 | 130 | 132 | 130 | 129 | 131 | 130 | 129 | 131 | 135 | 135 | 138 | 141 | 142 | 138 | 133 | 132 | 134 | 132 | 133 | 133 | 133 | . 235 159 | 156 | 151 | 151 | 155 | 158 | 155 | 150 | 148 | 149 | 148 | 146 | 144 | 144 | 145 | 147 | 147 | 147 | 146 | 148 | 151 | 153 | 153 | 153 | 154 | 155 | 157 | 161 | 165 | 163 | 153 | 143 | 140 | 139 | 137 | 136 | 135 | 136 | 138 | 139 | 137 | 135 | 132 | 130 | 130 | 131 | 133 | 135 | 135 | 136 | 139 | 142 | 143 | 141 | 141 | 142 | 137 | 136 | 131 | 129 | 135 | 136 | 132 | 129 | 134 | 129 | 130 | 135 | 133 | 132 | 135 | 137 | 140 | 138 | 138 | 135 | 133 | 138 | 141 | 137 | 131 | 129 | 129 | 130 | 130 | 129 | 130 | 132 | 132 | 135 | 138 | 137 | 133 | 130 | 131 | 133 | 137 | 137 | 135 | 134 | . 236 155 | 159 | 161 | 159 | 155 | 156 | 158 | 160 | 156 | 155 | 153 | 150 | 148 | 147 | 145 | 144 | 144 | 143 | 142 | 143 | 145 | 148 | 150 | 150 | 155 | 156 | 156 | 155 | 157 | 160 | 163 | 164 | 154 | 149 | 143 | 139 | 139 | 140 | 141 | 141 | 138 | 139 | 139 | 139 | 137 | 135 | 133 | 132 | 134 | 129 | 125 | 126 | 128 | 130 | 132 | 134 | 137 | 137 | 131 | 126 | 128 | 131 | 133 | 136 | 130 | 129 | 132 | 132 | 129 | 130 | 132 | 129 | 139 | 139 | 139 | 137 | 135 | 140 | 142 | 137 | 131 | 129 | 128 | 128 | 127 | 125 | 125 | 125 | 136 | 137 | 135 | 133 | 131 | 131 | 132 | 133 | 133 | 134 | 135 | 136 | . 237 154 | 158 | 162 | 161 | 160 | 159 | 158 | 157 | 157 | 157 | 156 | 156 | 156 | 154 | 150 | 147 | 141 | 140 | 139 | 140 | 143 | 146 | 149 | 150 | 151 | 154 | 155 | 153 | 153 | 156 | 160 | 162 | 162 | 154 | 147 | 146 | 149 | 151 | 148 | 143 | 140 | 140 | 139 | 138 | 136 | 134 | 132 | 131 | 137 | 131 | 126 | 127 | 129 | 130 | 130 | 130 | 133 | 135 | 132 | 131 | 133 | 133 | 131 | 134 | 131 | 134 | 138 | 137 | 133 | 134 | 135 | 131 | 137 | 137 | 139 | 138 | 134 | 135 | 134 | 128 | 131 | 129 | 128 | 128 | 128 | 129 | 129 | 129 | 139 | 138 | 135 | 131 | 130 | 132 | 133 | 132 | 128 | 132 | 135 | 138 | . 238 160 | 158 | 157 | 157 | 161 | 162 | 158 | 153 | 154 | 155 | 156 | 157 | 157 | 157 | 156 | 156 | 146 | 146 | 145 | 144 | 144 | 146 | 148 | 149 | 148 | 150 | 152 | 153 | 155 | 156 | 154 | 151 | 159 | 156 | 152 | 151 | 151 | 152 | 151 | 150 | 150 | 148 | 145 | 142 | 140 | 138 | 138 | 138 | 132 | 130 | 130 | 132 | 134 | 133 | 131 | 130 | 132 | 130 | 129 | 134 | 139 | 135 | 129 | 128 | 128 | 130 | 136 | 137 | 132 | 129 | 131 | 130 | 130 | 130 | 134 | 136 | 135 | 136 | 137 | 134 | 130 | 130 | 129 | 130 | 133 | 135 | 136 | 136 | 139 | 139 | 136 | 132 | 131 | 131 | 131 | 130 | 129 | 132 | 135 | 136 | . 239 163 | 163 | 161 | 158 | 157 | 158 | 159 | 159 | 155 | 156 | 156 | 154 | 153 | 154 | 157 | 161 | 153 | 153 | 152 | 149 | 146 | 144 | 144 | 145 | 149 | 152 | 153 | 151 | 150 | 152 | 155 | 157 | 156 | 159 | 159 | 152 | 145 | 142 | 147 | 153 | 147 | 148 | 150 | 150 | 149 | 146 | 142 | 140 | 137 | 135 | 133 | 134 | 135 | 135 | 136 | 138 | 135 | 131 | 127 | 129 | 132 | 128 | 128 | 134 | 128 | 127 | 134 | 139 | 133 | 126 | 129 | 133 | 140 | 137 | 138 | 138 | 135 | 135 | 137 | 137 | 132 | 131 | 130 | 131 | 133 | 136 | 137 | 137 | 139 | 140 | 139 | 135 | 133 | 132 | 131 | 129 | 129 | 130 | 131 | 132 | . 240 158 | 159 | 162 | 165 | 165 | 163 | 158 | 155 | 166 | 156 | 150 | 153 | 155 | 153 | 153 | 157 | 156 | 153 | 150 | 149 | 150 | 150 | 148 | 146 | 144 | 148 | 151 | 151 | 150 | 150 | 153 | 157 | 162 | 154 | 153 | 158 | 156 | 146 | 141 | 143 | 148 | 147 | 148 | 150 | 150 | 147 | 145 | 146 | 140 | 134 | 131 | 133 | 136 | 136 | 135 | 135 | 141 | 133 | 128 | 129 | 130 | 129 | 128 | 129 | 124 | 132 | 136 | 140 | 132 | 123 | 132 | 140 | 142 | 135 | 140 | 142 | 145 | 131 | 134 | 139 | 133 | 132 | 130 | 129 | 130 | 132 | 133 | 133 | 141 | 140 | 139 | 137 | 135 | 133 | 131 | 130 | 126 | 130 | 131 | 129 | . 241 156 | 157 | 159 | 161 | 163 | 163 | 161 | 160 | 158 | 162 | 161 | 154 | 151 | 155 | 157 | 156 | 152 | 155 | 157 | 154 | 149 | 147 | 148 | 150 | 147 | 146 | 146 | 148 | 152 | 155 | 156 | 156 | 152 | 160 | 162 | 157 | 157 | 159 | 152 | 141 | 135 | 143 | 146 | 142 | 144 | 149 | 146 | 136 | 140 | 134 | 130 | 130 | 131 | 131 | 132 | 133 | 136 | 130 | 127 | 130 | 133 | 131 | 130 | 130 | 130 | 129 | 126 | 133 | 135 | 132 | 137 | 139 | 127 | 135 | 142 | 137 | 135 | 132 | 134 | 132 | 130 | 130 | 129 | 130 | 132 | 133 | 132 | 132 | 136 | 135 | 134 | 133 | 131 | 130 | 129 | 128 | 131 | 131 | 129 | 128 | . 242 155 | 155 | 155 | 157 | 160 | 162 | 164 | 164 | 160 | 160 | 161 | 161 | 157 | 152 | 154 | 158 | 155 | 155 | 154 | 154 | 154 | 152 | 150 | 148 | 148 | 146 | 145 | 147 | 151 | 155 | 155 | 153 | 155 | 156 | 156 | 155 | 156 | 157 | 155 | 151 | 135 | 133 | 131 | 131 | 133 | 137 | 140 | 141 | 145 | 140 | 135 | 132 | 131 | 131 | 133 | 135 | 135 | 131 | 130 | 133 | 135 | 132 | 128 | 127 | 130 | 130 | 127 | 130 | 130 | 128 | 137 | 140 | 137 | 135 | 133 | 137 | 135 | 134 | 129 | 127 | 131 | 130 | 129 | 129 | 130 | 130 | 130 | 130 | 135 | 135 | 133 | 132 | 130 | 130 | 129 | 129 | 128 | 129 | 128 | 127 | . 243 155 | 154 | 153 | 154 | 157 | 160 | 162 | 164 | 164 | 157 | 157 | 162 | 162 | 155 | 153 | 156 | 156 | 153 | 152 | 153 | 156 | 156 | 153 | 150 | 149 | 149 | 149 | 148 | 147 | 147 | 149 | 151 | 157 | 153 | 151 | 154 | 156 | 155 | 157 | 161 | 161 | 152 | 143 | 138 | 134 | 131 | 135 | 142 | 145 | 143 | 140 | 136 | 134 | 132 | 133 | 134 | 134 | 132 | 131 | 134 | 135 | 132 | 128 | 127 | 130 | 133 | 130 | 129 | 126 | 123 | 132 | 135 | 147 | 139 | 130 | 136 | 133 | 135 | 127 | 128 | 131 | 129 | 127 | 126 | 127 | 128 | 130 | 131 | 135 | 135 | 134 | 133 | 132 | 131 | 130 | 130 | 125 | 130 | 131 | 129 | . 244 155 | 154 | 153 | 154 | 155 | 157 | 159 | 159 | 159 | 163 | 162 | 158 | 158 | 163 | 160 | 153 | 151 | 153 | 155 | 154 | 152 | 151 | 155 | 158 | 153 | 152 | 151 | 149 | 147 | 146 | 147 | 148 | 148 | 152 | 153 | 153 | 156 | 161 | 161 | 159 | 159 | 164 | 161 | 149 | 142 | 143 | 142 | 136 | 140 | 141 | 140 | 138 | 135 | 132 | 131 | 131 | 130 | 128 | 128 | 130 | 132 | 131 | 130 | 129 | 132 | 133 | 128 | 128 | 129 | 128 | 132 | 128 | 134 | 143 | 139 | 133 | 123 | 132 | 132 | 131 | 129 | 128 | 128 | 127 | 127 | 128 | 130 | 131 | 130 | 130 | 130 | 130 | 130 | 129 | 128 | 128 | 129 | 133 | 134 | 130 | . 245 154 | 153 | 153 | 153 | 154 | 155 | 155 | 155 | 158 | 162 | 164 | 162 | 160 | 161 | 161 | 160 | 154 | 154 | 153 | 152 | 152 | 153 | 155 | 157 | 157 | 154 | 150 | 150 | 151 | 152 | 150 | 148 | 146 | 143 | 143 | 146 | 149 | 150 | 154 | 159 | 152 | 157 | 160 | 157 | 152 | 149 | 146 | 142 | 141 | 143 | 144 | 143 | 141 | 139 | 136 | 134 | 133 | 130 | 128 | 127 | 127 | 127 | 127 | 126 | 126 | 132 | 131 | 131 | 131 | 131 | 137 | 136 | 135 | 139 | 137 | 136 | 130 | 130 | 130 | 131 | 133 | 133 | 133 | 131 | 129 | 127 | 126 | 125 | 127 | 128 | 128 | 128 | 128 | 128 | 128 | 128 | 131 | 131 | 130 | 130 | . 246 152 | 152 | 152 | 153 | 154 | 154 | 154 | 154 | 159 | 156 | 158 | 164 | 165 | 160 | 159 | 162 | 161 | 156 | 151 | 151 | 154 | 156 | 155 | 152 | 156 | 154 | 152 | 152 | 153 | 154 | 152 | 151 | 152 | 143 | 138 | 141 | 142 | 140 | 146 | 157 | 163 | 159 | 159 | 163 | 160 | 152 | 147 | 149 | 148 | 149 | 149 | 147 | 146 | 145 | 143 | 141 | 140 | 137 | 132 | 128 | 126 | 126 | 125 | 124 | 121 | 132 | 133 | 132 | 129 | 131 | 142 | 144 | 143 | 132 | 131 | 136 | 139 | 129 | 129 | 134 | 138 | 137 | 136 | 133 | 129 | 128 | 127 | 128 | 134 | 133 | 131 | 129 | 128 | 128 | 128 | 128 | 128 | 128 | 129 | 132 | . 247 150 | 150 | 150 | 152 | 153 | 155 | 155 | 155 | 154 | 156 | 156 | 156 | 162 | 168 | 163 | 152 | 159 | 159 | 158 | 155 | 151 | 150 | 152 | 154 | 152 | 155 | 157 | 155 | 151 | 149 | 152 | 155 | 152 | 156 | 153 | 144 | 142 | 149 | 151 | 147 | 145 | 151 | 154 | 156 | 160 | 164 | 159 | 150 | 149 | 149 | 147 | 145 | 144 | 145 | 144 | 142 | 142 | 139 | 135 | 131 | 129 | 129 | 128 | 128 | 127 | 131 | 127 | 127 | 131 | 137 | 145 | 141 | 133 | 131 | 135 | 129 | 133 | 128 | 136 | 139 | 136 | 135 | 132 | 130 | 129 | 131 | 136 | 140 | 141 | 138 | 134 | 131 | 128 | 127 | 127 | 128 | 127 | 130 | 134 | 135 | . 248 150 | 151 | 150 | 149 | 150 | 152 | 154 | 153 | 154 | 152 | 152 | 154 | 157 | 160 | 164 | 168 | 159 | 159 | 163 | 164 | 157 | 148 | 147 | 151 | 152 | 154 | 155 | 157 | 157 | 156 | 154 | 153 | 155 | 153 | 153 | 155 | 154 | 149 | 146 | 144 | 147 | 154 | 156 | 154 | 155 | 162 | 166 | 165 | 158 | 152 | 147 | 147 | 149 | 148 | 146 | 145 | 146 | 145 | 141 | 136 | 135 | 135 | 132 | 128 | 130 | 128 | 126 | 126 | 129 | 132 | 132 | 129 | 132 | 133 | 132 | 134 | 136 | 133 | 134 | 140 | 138 | 130 | 128 | 137 | 144 | 142 | 137 | 136 | 133 | 131 | 130 | 129 | 128 | 126 | 127 | 129 | 129 | 130 | 130 | 129 | . 249 149 | 150 | 150 | 149 | 149 | 151 | 153 | 152 | 154 | 152 | 152 | 153 | 154 | 155 | 158 | 161 | 162 | 161 | 162 | 164 | 166 | 164 | 157 | 150 | 153 | 153 | 153 | 153 | 153 | 153 | 153 | 152 | 155 | 154 | 154 | 154 | 152 | 149 | 151 | 154 | 152 | 144 | 142 | 148 | 151 | 151 | 157 | 165 | 165 | 161 | 157 | 153 | 151 | 150 | 147 | 145 | 146 | 145 | 143 | 141 | 140 | 139 | 136 | 131 | 133 | 132 | 129 | 127 | 129 | 132 | 133 | 132 | 134 | 133 | 131 | 131 | 132 | 130 | 130 | 137 | 138 | 134 | 131 | 133 | 137 | 141 | 144 | 146 | 146 | 137 | 131 | 133 | 135 | 132 | 129 | 129 | 129 | 128 | 128 | 128 | . 250 147 | 148 | 149 | 148 | 148 | 151 | 151 | 151 | 155 | 154 | 153 | 155 | 155 | 154 | 155 | 156 | 156 | 160 | 160 | 157 | 159 | 164 | 166 | 163 | 155 | 155 | 153 | 152 | 151 | 151 | 151 | 151 | 147 | 152 | 158 | 160 | 157 | 154 | 154 | 156 | 146 | 137 | 135 | 140 | 139 | 135 | 143 | 158 | 161 | 163 | 163 | 159 | 157 | 156 | 154 | 151 | 149 | 150 | 149 | 148 | 147 | 144 | 139 | 135 | 137 | 136 | 134 | 130 | 130 | 132 | 133 | 133 | 133 | 132 | 128 | 128 | 129 | 127 | 128 | 135 | 135 | 135 | 132 | 126 | 126 | 135 | 145 | 150 | 143 | 135 | 129 | 131 | 134 | 131 | 129 | 129 | 129 | 127 | 125 | 126 | . 251 144 | 146 | 147 | 146 | 148 | 150 | 150 | 150 | 153 | 152 | 153 | 155 | 155 | 154 | 154 | 156 | 153 | 157 | 157 | 153 | 152 | 158 | 164 | 166 | 157 | 158 | 158 | 156 | 152 | 150 | 151 | 152 | 151 | 152 | 153 | 154 | 154 | 155 | 158 | 161 | 154 | 149 | 143 | 141 | 146 | 151 | 150 | 145 | 150 | 158 | 162 | 160 | 159 | 160 | 159 | 155 | 153 | 153 | 154 | 154 | 153 | 150 | 146 | 142 | 139 | 140 | 139 | 136 | 133 | 133 | 133 | 133 | 131 | 130 | 126 | 127 | 129 | 127 | 128 | 135 | 133 | 134 | 132 | 126 | 125 | 131 | 140 | 146 | 138 | 138 | 135 | 133 | 130 | 129 | 129 | 129 | 130 | 128 | 126 | 125 | . 252 143 | 145 | 145 | 145 | 146 | 149 | 149 | 149 | 149 | 148 | 150 | 152 | 154 | 153 | 153 | 154 | 157 | 156 | 156 | 157 | 159 | 159 | 157 | 156 | 155 | 159 | 162 | 160 | 156 | 153 | 153 | 154 | 149 | 149 | 151 | 154 | 158 | 159 | 156 | 152 | 148 | 158 | 162 | 156 | 152 | 155 | 153 | 148 | 147 | 154 | 157 | 154 | 153 | 156 | 157 | 155 | 153 | 154 | 155 | 157 | 157 | 155 | 153 | 152 | 140 | 143 | 144 | 142 | 138 | 136 | 134 | 132 | 131 | 130 | 127 | 128 | 131 | 129 | 129 | 134 | 133 | 132 | 133 | 135 | 136 | 137 | 141 | 145 | 144 | 148 | 145 | 137 | 133 | 135 | 133 | 128 | 128 | 129 | 129 | 128 | . 253 143 | 145 | 145 | 144 | 145 | 147 | 148 | 147 | 149 | 148 | 149 | 151 | 152 | 152 | 152 | 154 | 155 | 155 | 156 | 157 | 157 | 155 | 157 | 160 | 153 | 156 | 160 | 160 | 159 | 157 | 156 | 157 | 150 | 150 | 150 | 153 | 156 | 157 | 153 | 147 | 142 | 152 | 161 | 160 | 153 | 148 | 149 | 151 | 148 | 150 | 150 | 147 | 148 | 153 | 156 | 156 | 157 | 156 | 156 | 157 | 156 | 154 | 153 | 153 | 143 | 146 | 148 | 146 | 143 | 140 | 136 | 133 | 133 | 132 | 129 | 131 | 133 | 130 | 127 | 132 | 130 | 128 | 131 | 139 | 145 | 145 | 143 | 143 | 140 | 141 | 137 | 131 | 133 | 139 | 134 | 125 | 126 | 129 | 132 | 132 | . 254 145 | 146 | 145 | 144 | 144 | 145 | 146 | 146 | 150 | 148 | 148 | 150 | 151 | 151 | 152 | 154 | 150 | 155 | 156 | 152 | 149 | 153 | 160 | 165 | 156 | 155 | 155 | 157 | 160 | 160 | 159 | 157 | 159 | 156 | 150 | 143 | 142 | 148 | 154 | 158 | 160 | 152 | 148 | 153 | 160 | 161 | 156 | 150 | 151 | 149 | 147 | 148 | 151 | 154 | 156 | 156 | 157 | 156 | 156 | 156 | 154 | 151 | 150 | 151 | 148 | 150 | 150 | 148 | 145 | 143 | 140 | 138 | 135 | 133 | 130 | 131 | 133 | 129 | 126 | 130 | 128 | 127 | 129 | 135 | 143 | 146 | 142 | 136 | 132 | 129 | 125 | 125 | 130 | 134 | 133 | 129 | 130 | 131 | 131 | 131 | . 255 147 | 147 | 146 | 143 | 143 | 144 | 145 | 144 | 147 | 146 | 145 | 147 | 148 | 148 | 150 | 153 | 153 | 156 | 154 | 150 | 153 | 161 | 159 | 151 | 162 | 157 | 153 | 154 | 160 | 163 | 160 | 156 | 147 | 154 | 159 | 156 | 150 | 148 | 148 | 149 | 158 | 160 | 159 | 153 | 150 | 154 | 160 | 163 | 155 | 151 | 150 | 154 | 157 | 155 | 152 | 150 | 151 | 151 | 152 | 154 | 154 | 152 | 151 | 153 | 152 | 152 | 151 | 148 | 146 | 145 | 144 | 142 | 135 | 133 | 129 | 130 | 132 | 129 | 126 | 130 | 129 | 131 | 130 | 130 | 137 | 143 | 139 | 129 | 133 | 129 | 127 | 131 | 131 | 130 | 133 | 140 | 137 | 133 | 128 | 126 | . 256 146 | 147 | 148 | 147 | 146 | 146 | 148 | 151 | 143 | 146 | 147 | 147 | 147 | 148 | 149 | 148 | 149 | 151 | 149 | 146 | 146 | 149 | 151 | 149 | 157 | 157 | 158 | 156 | 149 | 145 | 156 | 171 | 161 | 151 | 150 | 157 | 161 | 160 | 155 | 148 | 154 | 150 | 151 | 154 | 153 | 150 | 155 | 163 | 163 | 158 | 156 | 159 | 158 | 153 | 150 | 151 | 151 | 152 | 151 | 150 | 152 | 156 | 156 | 154 | 152 | 152 | 152 | 151 | 150 | 148 | 147 | 146 | 138 | 139 | 137 | 132 | 128 | 127 | 127 | 126 | 130 | 130 | 132 | 136 | 138 | 138 | 141 | 144 | 142 | 138 | 133 | 130 | 129 | 129 | 129 | 129 | 140 | 127 | 127 | 128 | . 257 144 | 145 | 146 | 146 | 145 | 145 | 146 | 148 | 149 | 148 | 146 | 142 | 141 | 143 | 146 | 146 | 146 | 147 | 146 | 145 | 146 | 148 | 150 | 150 | 148 | 153 | 157 | 156 | 151 | 150 | 153 | 156 | 166 | 163 | 159 | 150 | 145 | 152 | 159 | 159 | 143 | 142 | 145 | 152 | 158 | 159 | 154 | 150 | 157 | 161 | 163 | 160 | 160 | 163 | 162 | 158 | 150 | 152 | 153 | 152 | 153 | 153 | 151 | 147 | 154 | 153 | 152 | 150 | 149 | 148 | 148 | 148 | 145 | 143 | 138 | 133 | 130 | 130 | 129 | 128 | 131 | 129 | 129 | 131 | 134 | 136 | 141 | 146 | 144 | 141 | 137 | 133 | 131 | 130 | 129 | 128 | 131 | 124 | 129 | 131 | . 258 143 | 144 | 146 | 146 | 145 | 145 | 146 | 147 | 149 | 148 | 144 | 139 | 138 | 140 | 142 | 143 | 146 | 144 | 144 | 146 | 147 | 147 | 149 | 151 | 146 | 154 | 157 | 153 | 153 | 158 | 156 | 150 | 158 | 160 | 162 | 158 | 150 | 151 | 155 | 156 | 169 | 157 | 142 | 135 | 143 | 155 | 159 | 156 | 156 | 161 | 162 | 158 | 157 | 160 | 162 | 161 | 162 | 160 | 155 | 149 | 146 | 148 | 151 | 152 | 153 | 153 | 152 | 152 | 151 | 151 | 150 | 150 | 147 | 144 | 138 | 132 | 131 | 132 | 131 | 129 | 130 | 128 | 128 | 129 | 131 | 133 | 138 | 142 | 139 | 137 | 134 | 132 | 130 | 128 | 126 | 124 | 128 | 123 | 132 | 136 | . 259 143 | 145 | 146 | 146 | 145 | 145 | 145 | 144 | 145 | 146 | 145 | 143 | 142 | 143 | 144 | 143 | 147 | 145 | 145 | 148 | 149 | 147 | 149 | 152 | 151 | 155 | 153 | 148 | 151 | 159 | 161 | 156 | 151 | 146 | 153 | 166 | 165 | 156 | 150 | 149 | 149 | 161 | 170 | 165 | 154 | 148 | 148 | 151 | 154 | 153 | 155 | 160 | 159 | 154 | 153 | 156 | 157 | 159 | 161 | 160 | 158 | 155 | 154 | 153 | 150 | 151 | 153 | 154 | 154 | 153 | 151 | 150 | 144 | 143 | 139 | 135 | 133 | 133 | 132 | 130 | 128 | 128 | 129 | 130 | 130 | 130 | 131 | 133 | 130 | 129 | 128 | 127 | 126 | 125 | 124 | 123 | 128 | 124 | 131 | 139 | . 260 143 | 146 | 146 | 145 | 144 | 145 | 144 | 142 | 145 | 147 | 149 | 148 | 147 | 148 | 148 | 147 | 149 | 146 | 147 | 149 | 150 | 147 | 147 | 150 | 153 | 153 | 150 | 147 | 149 | 154 | 158 | 158 | 156 | 145 | 145 | 155 | 158 | 157 | 157 | 157 | 159 | 153 | 149 | 155 | 163 | 163 | 157 | 151 | 149 | 148 | 152 | 160 | 162 | 158 | 154 | 154 | 153 | 155 | 159 | 161 | 161 | 160 | 160 | 161 | 152 | 153 | 153 | 154 | 153 | 153 | 152 | 151 | 145 | 147 | 146 | 142 | 138 | 135 | 133 | 131 | 128 | 129 | 130 | 130 | 129 | 128 | 128 | 127 | 127 | 127 | 126 | 125 | 125 | 125 | 126 | 126 | 127 | 123 | 128 | 134 | . 261 147 | 149 | 148 | 145 | 145 | 147 | 147 | 145 | 146 | 148 | 148 | 146 | 146 | 147 | 148 | 148 | 147 | 147 | 147 | 148 | 148 | 147 | 147 | 147 | 149 | 150 | 152 | 153 | 153 | 152 | 153 | 155 | 159 | 155 | 150 | 144 | 144 | 155 | 163 | 162 | 155 | 154 | 156 | 158 | 156 | 153 | 156 | 161 | 154 | 156 | 153 | 150 | 152 | 158 | 160 | 156 | 161 | 158 | 154 | 153 | 153 | 155 | 160 | 164 | 158 | 157 | 155 | 153 | 151 | 151 | 152 | 153 | 151 | 154 | 155 | 151 | 145 | 141 | 137 | 134 | 134 | 134 | 133 | 130 | 128 | 129 | 130 | 130 | 128 | 128 | 127 | 125 | 124 | 124 | 126 | 127 | 127 | 128 | 129 | 127 | . 262 147 | 149 | 148 | 144 | 144 | 148 | 149 | 147 | 145 | 146 | 146 | 145 | 144 | 145 | 146 | 145 | 144 | 146 | 147 | 147 | 147 | 148 | 148 | 147 | 146 | 149 | 152 | 155 | 155 | 153 | 153 | 154 | 154 | 159 | 160 | 153 | 148 | 154 | 158 | 152 | 162 | 162 | 159 | 155 | 154 | 155 | 157 | 158 | 161 | 161 | 156 | 148 | 148 | 154 | 157 | 156 | 156 | 155 | 156 | 159 | 159 | 156 | 154 | 154 | 160 | 159 | 157 | 155 | 154 | 153 | 153 | 153 | 153 | 155 | 155 | 152 | 149 | 147 | 144 | 142 | 141 | 141 | 138 | 133 | 130 | 131 | 132 | 132 | 130 | 130 | 129 | 127 | 125 | 124 | 125 | 126 | 128 | 131 | 130 | 124 | . 263 144 | 145 | 143 | 140 | 141 | 146 | 147 | 145 | 143 | 146 | 148 | 148 | 147 | 147 | 147 | 145 | 142 | 146 | 147 | 146 | 147 | 150 | 150 | 147 | 144 | 148 | 150 | 150 | 151 | 154 | 156 | 156 | 150 | 154 | 162 | 165 | 160 | 154 | 149 | 141 | 148 | 160 | 166 | 162 | 157 | 158 | 159 | 156 | 155 | 155 | 158 | 163 | 160 | 153 | 151 | 153 | 156 | 154 | 153 | 156 | 159 | 159 | 160 | 161 | 157 | 158 | 159 | 159 | 159 | 157 | 154 | 152 | 150 | 150 | 149 | 149 | 150 | 152 | 151 | 149 | 147 | 147 | 144 | 138 | 134 | 134 | 133 | 132 | 132 | 133 | 132 | 131 | 128 | 127 | 127 | 127 | 125 | 128 | 128 | 125 | . 264 149 | 142 | 139 | 143 | 147 | 147 | 146 | 146 | 146 | 147 | 147 | 146 | 145 | 145 | 147 | 148 | 148 | 146 | 146 | 146 | 146 | 146 | 148 | 151 | 149 | 148 | 148 | 149 | 149 | 149 | 151 | 155 | 155 | 155 | 156 | 159 | 163 | 161 | 152 | 142 | 149 | 150 | 159 | 167 | 163 | 156 | 156 | 158 | 157 | 160 | 159 | 156 | 158 | 162 | 160 | 153 | 155 | 155 | 156 | 156 | 156 | 156 | 156 | 155 | 162 | 160 | 158 | 157 | 158 | 159 | 159 | 158 | 152 | 151 | 151 | 152 | 153 | 154 | 153 | 152 | 150 | 150 | 148 | 144 | 140 | 138 | 137 | 138 | 135 | 135 | 135 | 134 | 131 | 129 | 127 | 127 | 128 | 129 | 130 | 131 | . 265 145 | 145 | 146 | 146 | 144 | 142 | 144 | 146 | 143 | 144 | 146 | 147 | 146 | 145 | 145 | 145 | 149 | 147 | 146 | 146 | 145 | 144 | 145 | 148 | 148 | 148 | 149 | 151 | 151 | 150 | 151 | 154 | 153 | 153 | 155 | 158 | 163 | 165 | 161 | 155 | 152 | 143 | 144 | 154 | 163 | 165 | 162 | 156 | 156 | 157 | 158 | 158 | 158 | 159 | 159 | 158 | 155 | 155 | 154 | 154 | 154 | 155 | 155 | 155 | 158 | 158 | 158 | 157 | 157 | 157 | 158 | 158 | 162 | 160 | 157 | 154 | 152 | 153 | 155 | 157 | 151 | 152 | 152 | 150 | 146 | 143 | 141 | 141 | 138 | 137 | 137 | 137 | 137 | 134 | 130 | 127 | 129 | 132 | 133 | 131 | . 266 141 | 144 | 144 | 140 | 137 | 137 | 140 | 142 | 144 | 145 | 146 | 147 | 146 | 146 | 146 | 147 | 148 | 146 | 146 | 145 | 144 | 143 | 144 | 146 | 147 | 147 | 149 | 152 | 152 | 150 | 150 | 152 | 150 | 151 | 151 | 153 | 158 | 163 | 164 | 162 | 160 | 152 | 147 | 146 | 150 | 158 | 165 | 165 | 160 | 157 | 155 | 157 | 158 | 157 | 158 | 162 | 158 | 157 | 156 | 155 | 155 | 154 | 154 | 154 | 156 | 157 | 159 | 158 | 157 | 156 | 157 | 159 | 159 | 157 | 154 | 150 | 146 | 146 | 149 | 152 | 151 | 153 | 154 | 153 | 151 | 148 | 146 | 145 | 145 | 142 | 139 | 139 | 141 | 140 | 135 | 131 | 131 | 130 | 133 | 142 | . 267 151 | 151 | 147 | 142 | 142 | 146 | 147 | 145 | 146 | 146 | 144 | 143 | 144 | 145 | 147 | 149 | 145 | 144 | 144 | 145 | 145 | 144 | 145 | 148 | 146 | 147 | 149 | 150 | 151 | 150 | 150 | 150 | 150 | 151 | 150 | 149 | 152 | 156 | 159 | 160 | 166 | 166 | 163 | 153 | 144 | 148 | 159 | 163 | 166 | 160 | 155 | 155 | 157 | 158 | 159 | 160 | 161 | 160 | 159 | 158 | 156 | 154 | 152 | 151 | 154 | 156 | 157 | 158 | 158 | 157 | 158 | 159 | 155 | 156 | 156 | 154 | 152 | 150 | 150 | 150 | 150 | 151 | 152 | 152 | 152 | 150 | 149 | 149 | 151 | 147 | 142 | 140 | 141 | 141 | 139 | 137 | 131 | 132 | 132 | 134 | . 268 146 | 147 | 144 | 139 | 139 | 142 | 141 | 138 | 144 | 143 | 142 | 141 | 142 | 143 | 145 | 145 | 144 | 143 | 143 | 145 | 145 | 145 | 146 | 148 | 146 | 147 | 147 | 147 | 148 | 149 | 149 | 148 | 151 | 152 | 151 | 150 | 150 | 154 | 157 | 158 | 163 | 165 | 168 | 164 | 157 | 155 | 153 | 147 | 161 | 162 | 161 | 157 | 156 | 157 | 158 | 158 | 160 | 160 | 160 | 159 | 157 | 155 | 152 | 150 | 152 | 152 | 153 | 155 | 158 | 159 | 159 | 159 | 155 | 155 | 157 | 158 | 159 | 157 | 154 | 151 | 151 | 150 | 149 | 149 | 150 | 151 | 152 | 152 | 152 | 150 | 146 | 144 | 142 | 142 | 141 | 141 | 140 | 137 | 133 | 128 | . 269 145 | 149 | 152 | 150 | 146 | 143 | 142 | 141 | 141 | 142 | 143 | 145 | 146 | 145 | 143 | 141 | 144 | 143 | 143 | 145 | 145 | 144 | 145 | 147 | 146 | 147 | 146 | 145 | 146 | 148 | 148 | 147 | 147 | 149 | 149 | 149 | 150 | 153 | 156 | 156 | 156 | 159 | 166 | 168 | 165 | 164 | 160 | 152 | 151 | 160 | 165 | 162 | 157 | 156 | 156 | 157 | 159 | 160 | 161 | 161 | 161 | 159 | 157 | 156 | 151 | 150 | 150 | 152 | 156 | 158 | 159 | 158 | 155 | 155 | 154 | 156 | 157 | 157 | 154 | 152 | 154 | 152 | 150 | 149 | 150 | 152 | 153 | 154 | 149 | 150 | 151 | 150 | 147 | 144 | 143 | 142 | 146 | 143 | 140 | 139 | . 270 140 | 143 | 146 | 148 | 146 | 141 | 139 | 139 | 143 | 144 | 146 | 148 | 149 | 147 | 143 | 140 | 143 | 142 | 143 | 144 | 144 | 143 | 144 | 146 | 146 | 147 | 146 | 145 | 146 | 148 | 148 | 146 | 145 | 146 | 147 | 147 | 148 | 152 | 154 | 154 | 154 | 156 | 162 | 165 | 162 | 164 | 167 | 166 | 154 | 155 | 157 | 159 | 160 | 157 | 155 | 154 | 159 | 159 | 160 | 160 | 161 | 161 | 161 | 161 | 156 | 155 | 153 | 153 | 153 | 155 | 156 | 157 | 159 | 158 | 158 | 157 | 158 | 158 | 157 | 157 | 157 | 155 | 153 | 152 | 153 | 153 | 153 | 152 | 149 | 151 | 153 | 153 | 151 | 148 | 147 | 146 | 145 | 148 | 149 | 143 | . 271 147 | 142 | 141 | 146 | 150 | 149 | 145 | 144 | 144 | 144 | 145 | 146 | 147 | 146 | 143 | 140 | 141 | 141 | 142 | 143 | 143 | 143 | 143 | 145 | 146 | 147 | 146 | 145 | 146 | 149 | 148 | 145 | 146 | 147 | 147 | 147 | 148 | 151 | 152 | 151 | 154 | 151 | 155 | 161 | 162 | 164 | 165 | 162 | 166 | 152 | 144 | 152 | 162 | 161 | 155 | 151 | 157 | 157 | 156 | 156 | 156 | 157 | 158 | 159 | 162 | 161 | 159 | 155 | 152 | 151 | 153 | 155 | 154 | 156 | 157 | 156 | 155 | 155 | 156 | 157 | 158 | 157 | 156 | 155 | 155 | 153 | 151 | 149 | 151 | 152 | 152 | 153 | 152 | 151 | 151 | 151 | 151 | 149 | 148 | 148 | . 272 148 | 147 | 145 | 144 | 145 | 146 | 148 | 149 | 146 | 144 | 142 | 142 | 143 | 145 | 146 | 146 | 143 | 144 | 145 | 145 | 148 | 149 | 147 | 143 | 146 | 145 | 146 | 146 | 143 | 141 | 143 | 147 | 148 | 147 | 147 | 148 | 149 | 150 | 150 | 150 | 152 | 152 | 154 | 158 | 160 | 160 | 161 | 162 | 168 | 167 | 157 | 150 | 155 | 157 | 155 | 158 | 150 | 154 | 157 | 157 | 157 | 157 | 157 | 155 | 159 | 159 | 161 | 162 | 161 | 158 | 155 | 152 | 153 | 154 | 155 | 155 | 154 | 154 | 155 | 155 | 154 | 155 | 155 | 154 | 153 | 153 | 155 | 156 | 153 | 152 | 151 | 151 | 151 | 151 | 151 | 151 | 151 | 150 | 148 | 147 | . 273 147 | 147 | 146 | 145 | 145 | 146 | 147 | 148 | 144 | 143 | 143 | 144 | 145 | 146 | 145 | 145 | 143 | 144 | 144 | 144 | 145 | 146 | 144 | 141 | 144 | 142 | 141 | 142 | 142 | 141 | 141 | 143 | 144 | 144 | 145 | 147 | 149 | 151 | 152 | 152 | 152 | 151 | 152 | 156 | 159 | 159 | 159 | 159 | 157 | 166 | 170 | 164 | 157 | 152 | 153 | 158 | 151 | 153 | 155 | 156 | 156 | 155 | 156 | 157 | 156 | 156 | 157 | 158 | 159 | 158 | 157 | 156 | 156 | 156 | 156 | 155 | 154 | 154 | 156 | 157 | 155 | 155 | 156 | 156 | 155 | 154 | 155 | 156 | 154 | 153 | 151 | 150 | 149 | 148 | 147 | 145 | 151 | 150 | 149 | 149 | . 274 145 | 146 | 146 | 146 | 146 | 145 | 145 | 145 | 146 | 145 | 144 | 144 | 143 | 142 | 141 | 140 | 143 | 144 | 143 | 142 | 143 | 144 | 143 | 140 | 146 | 143 | 141 | 143 | 145 | 145 | 144 | 143 | 144 | 144 | 145 | 147 | 147 | 148 | 148 | 148 | 151 | 150 | 151 | 155 | 157 | 158 | 157 | 158 | 160 | 164 | 169 | 169 | 164 | 160 | 157 | 152 | 153 | 151 | 152 | 154 | 155 | 153 | 155 | 158 | 155 | 155 | 154 | 155 | 157 | 158 | 159 | 160 | 157 | 157 | 157 | 156 | 155 | 155 | 155 | 156 | 154 | 154 | 155 | 155 | 154 | 154 | 154 | 154 | 154 | 152 | 151 | 151 | 153 | 153 | 151 | 150 | 150 | 150 | 149 | 149 | . 275 143 | 144 | 145 | 145 | 145 | 144 | 143 | 143 | 148 | 147 | 145 | 143 | 142 | 142 | 142 | 142 | 143 | 144 | 143 | 142 | 142 | 144 | 143 | 141 | 147 | 145 | 144 | 146 | 148 | 148 | 147 | 146 | 145 | 146 | 147 | 148 | 147 | 147 | 146 | 146 | 150 | 150 | 151 | 154 | 156 | 156 | 157 | 159 | 164 | 157 | 159 | 163 | 166 | 171 | 168 | 157 | 160 | 153 | 150 | 154 | 155 | 153 | 154 | 157 | 157 | 156 | 155 | 156 | 157 | 159 | 160 | 160 | 156 | 158 | 159 | 159 | 158 | 156 | 154 | 154 | 154 | 154 | 154 | 154 | 154 | 154 | 155 | 155 | 152 | 151 | 150 | 152 | 155 | 156 | 154 | 152 | 151 | 151 | 151 | 150 | . 276 143 | 144 | 145 | 146 | 146 | 145 | 144 | 143 | 145 | 145 | 146 | 146 | 145 | 145 | 145 | 146 | 143 | 144 | 144 | 142 | 143 | 145 | 145 | 144 | 143 | 144 | 144 | 144 | 144 | 144 | 145 | 145 | 142 | 144 | 146 | 148 | 149 | 149 | 150 | 151 | 147 | 148 | 151 | 153 | 153 | 153 | 155 | 159 | 157 | 154 | 158 | 160 | 159 | 166 | 174 | 172 | 167 | 159 | 153 | 156 | 159 | 156 | 155 | 157 | 158 | 157 | 156 | 157 | 158 | 158 | 159 | 159 | 159 | 159 | 160 | 160 | 159 | 157 | 157 | 156 | 157 | 156 | 155 | 155 | 155 | 156 | 157 | 157 | 154 | 152 | 151 | 152 | 153 | 152 | 150 | 148 | 151 | 151 | 152 | 153 | . 277 144 | 145 | 146 | 147 | 147 | 146 | 146 | 145 | 143 | 145 | 147 | 148 | 146 | 144 | 141 | 140 | 142 | 144 | 144 | 143 | 144 | 146 | 147 | 146 | 140 | 143 | 144 | 143 | 140 | 141 | 142 | 144 | 140 | 142 | 144 | 146 | 146 | 146 | 147 | 149 | 145 | 146 | 149 | 151 | 150 | 150 | 152 | 156 | 156 | 158 | 160 | 159 | 156 | 159 | 166 | 168 | 170 | 164 | 160 | 161 | 162 | 160 | 158 | 158 | 157 | 156 | 156 | 157 | 158 | 158 | 158 | 157 | 162 | 162 | 161 | 159 | 159 | 159 | 160 | 162 | 158 | 156 | 155 | 155 | 155 | 155 | 155 | 155 | 157 | 156 | 155 | 155 | 155 | 154 | 153 | 152 | 153 | 152 | 151 | 151 | . 278 144 | 145 | 145 | 145 | 146 | 146 | 146 | 146 | 146 | 147 | 148 | 147 | 144 | 141 | 139 | 138 | 141 | 143 | 144 | 143 | 143 | 145 | 146 | 145 | 141 | 145 | 146 | 143 | 140 | 141 | 143 | 144 | 143 | 144 | 145 | 144 | 141 | 140 | 141 | 142 | 147 | 146 | 146 | 149 | 150 | 150 | 150 | 152 | 157 | 159 | 157 | 155 | 157 | 158 | 158 | 158 | 165 | 165 | 164 | 163 | 161 | 159 | 159 | 160 | 158 | 158 | 158 | 158 | 158 | 158 | 157 | 156 | 160 | 160 | 160 | 160 | 160 | 160 | 161 | 162 | 159 | 158 | 157 | 157 | 157 | 156 | 153 | 152 | 155 | 156 | 157 | 157 | 156 | 157 | 158 | 159 | 156 | 154 | 152 | 151 | . 279 143 | 143 | 143 | 143 | 144 | 145 | 146 | 146 | 149 | 149 | 148 | 146 | 144 | 144 | 146 | 148 | 140 | 142 | 143 | 143 | 143 | 144 | 145 | 144 | 143 | 146 | 146 | 143 | 141 | 143 | 144 | 144 | 146 | 146 | 147 | 145 | 142 | 140 | 141 | 142 | 151 | 147 | 145 | 148 | 151 | 151 | 150 | 149 | 148 | 155 | 154 | 152 | 157 | 158 | 157 | 163 | 158 | 163 | 166 | 163 | 159 | 157 | 159 | 160 | 162 | 161 | 160 | 159 | 159 | 158 | 157 | 156 | 154 | 157 | 160 | 162 | 162 | 160 | 159 | 158 | 164 | 163 | 163 | 162 | 162 | 159 | 155 | 152 | 152 | 153 | 154 | 153 | 151 | 151 | 153 | 155 | 159 | 158 | 157 | 156 | . 280 148 | 145 | 140 | 138 | 140 | 143 | 143 | 141 | 142 | 143 | 144 | 146 | 147 | 147 | 147 | 146 | 143 | 141 | 142 | 145 | 146 | 145 | 146 | 147 | 143 | 145 | 146 | 145 | 145 | 146 | 144 | 142 | 140 | 142 | 145 | 146 | 146 | 146 | 146 | 146 | 146 | 147 | 148 | 148 | 147 | 148 | 150 | 152 | 152 | 150 | 152 | 156 | 156 | 154 | 155 | 158 | 162 | 158 | 162 | 166 | 164 | 165 | 160 | 146 | 152 | 159 | 162 | 159 | 160 | 164 | 161 | 153 | 151 | 157 | 159 | 159 | 160 | 157 | 155 | 157 | 161 | 159 | 157 | 158 | 160 | 161 | 160 | 159 | 156 | 154 | 152 | 152 | 153 | 155 | 154 | 152 | 154 | 154 | 153 | 154 | . 281 144 | 144 | 142 | 139 | 138 | 141 | 143 | 144 | 141 | 143 | 144 | 145 | 146 | 146 | 147 | 148 | 147 | 145 | 145 | 146 | 147 | 145 | 146 | 147 | 143 | 144 | 145 | 144 | 144 | 146 | 145 | 144 | 140 | 141 | 142 | 142 | 144 | 145 | 147 | 148 | 144 | 146 | 149 | 149 | 148 | 147 | 147 | 148 | 145 | 146 | 148 | 150 | 152 | 152 | 154 | 156 | 159 | 158 | 162 | 163 | 160 | 165 | 171 | 168 | 145 | 147 | 151 | 155 | 158 | 158 | 158 | 158 | 160 | 158 | 153 | 152 | 158 | 161 | 161 | 162 | 158 | 158 | 158 | 159 | 161 | 161 | 161 | 161 | 161 | 159 | 156 | 154 | 153 | 153 | 154 | 154 | 155 | 153 | 152 | 152 | . 282 143 | 146 | 146 | 142 | 138 | 139 | 143 | 145 | 143 | 144 | 145 | 146 | 145 | 146 | 147 | 148 | 148 | 147 | 146 | 146 | 145 | 144 | 143 | 144 | 143 | 144 | 144 | 143 | 143 | 145 | 147 | 146 | 146 | 145 | 143 | 143 | 143 | 143 | 143 | 143 | 142 | 144 | 147 | 149 | 148 | 147 | 146 | 146 | 144 | 146 | 148 | 148 | 150 | 153 | 155 | 155 | 153 | 155 | 161 | 163 | 160 | 163 | 167 | 166 | 175 | 158 | 148 | 152 | 154 | 150 | 152 | 160 | 162 | 164 | 161 | 158 | 157 | 156 | 157 | 162 | 159 | 160 | 160 | 160 | 159 | 158 | 158 | 158 | 162 | 162 | 161 | 157 | 153 | 151 | 150 | 150 | 155 | 153 | 152 | 152 | . 283 148 | 150 | 150 | 146 | 142 | 141 | 142 | 142 | 143 | 145 | 147 | 147 | 145 | 145 | 145 | 147 | 146 | 146 | 147 | 146 | 145 | 144 | 143 | 143 | 144 | 144 | 143 | 142 | 142 | 145 | 147 | 147 | 149 | 148 | 147 | 147 | 146 | 144 | 141 | 139 | 141 | 143 | 145 | 147 | 147 | 147 | 147 | 148 | 147 | 151 | 151 | 149 | 149 | 153 | 154 | 153 | 151 | 153 | 157 | 161 | 162 | 161 | 158 | 154 | 167 | 171 | 159 | 137 | 132 | 147 | 154 | 148 | 154 | 159 | 162 | 163 | 162 | 158 | 156 | 160 | 159 | 160 | 161 | 159 | 157 | 156 | 156 | 157 | 158 | 159 | 160 | 160 | 158 | 155 | 152 | 151 | 152 | 152 | 153 | 153 | . 284 149 | 149 | 148 | 146 | 147 | 147 | 143 | 139 | 141 | 143 | 145 | 145 | 145 | 144 | 144 | 144 | 144 | 146 | 148 | 149 | 148 | 147 | 146 | 145 | 145 | 146 | 144 | 142 | 142 | 145 | 146 | 147 | 146 | 147 | 147 | 148 | 149 | 148 | 147 | 146 | 144 | 144 | 144 | 144 | 145 | 146 | 148 | 149 | 148 | 151 | 151 | 148 | 147 | 150 | 151 | 150 | 154 | 154 | 154 | 155 | 159 | 160 | 160 | 161 | 155 | 162 | 165 | 155 | 142 | 138 | 143 | 149 | 150 | 148 | 145 | 152 | 163 | 166 | 163 | 164 | 159 | 160 | 161 | 160 | 158 | 157 | 159 | 162 | 156 | 156 | 157 | 159 | 162 | 162 | 161 | 159 | 153 | 154 | 154 | 154 | . 285 147 | 146 | 144 | 145 | 148 | 149 | 146 | 141 | 139 | 139 | 141 | 142 | 143 | 144 | 143 | 143 | 140 | 144 | 147 | 148 | 147 | 147 | 146 | 145 | 146 | 147 | 145 | 143 | 143 | 145 | 146 | 146 | 146 | 147 | 146 | 146 | 146 | 148 | 150 | 152 | 148 | 146 | 145 | 143 | 143 | 145 | 147 | 148 | 147 | 148 | 149 | 148 | 148 | 149 | 150 | 150 | 150 | 155 | 156 | 156 | 157 | 156 | 158 | 166 | 164 | 156 | 161 | 173 | 168 | 151 | 148 | 161 | 159 | 152 | 144 | 143 | 151 | 155 | 159 | 166 | 163 | 164 | 164 | 163 | 160 | 159 | 160 | 161 | 163 | 160 | 157 | 157 | 159 | 160 | 160 | 158 | 158 | 159 | 158 | 156 | . 286 147 | 147 | 146 | 145 | 145 | 147 | 146 | 144 | 142 | 141 | 140 | 141 | 143 | 144 | 144 | 143 | 140 | 143 | 146 | 145 | 144 | 145 | 146 | 145 | 146 | 147 | 146 | 144 | 144 | 146 | 146 | 145 | 145 | 146 | 147 | 145 | 143 | 144 | 147 | 150 | 147 | 146 | 145 | 144 | 144 | 145 | 145 | 145 | 145 | 146 | 147 | 149 | 149 | 149 | 150 | 152 | 147 | 154 | 155 | 157 | 160 | 155 | 153 | 159 | 150 | 156 | 158 | 155 | 161 | 171 | 170 | 160 | 165 | 163 | 157 | 152 | 148 | 144 | 148 | 159 | 164 | 165 | 166 | 165 | 163 | 161 | 160 | 160 | 166 | 163 | 160 | 158 | 157 | 156 | 154 | 153 | 160 | 159 | 158 | 158 | . 287 150 | 152 | 152 | 147 | 142 | 142 | 144 | 146 | 149 | 145 | 142 | 141 | 143 | 145 | 145 | 143 | 142 | 146 | 147 | 145 | 144 | 145 | 147 | 147 | 146 | 147 | 147 | 145 | 145 | 147 | 147 | 145 | 140 | 143 | 146 | 146 | 143 | 143 | 145 | 148 | 144 | 144 | 145 | 145 | 146 | 145 | 144 | 144 | 144 | 142 | 144 | 148 | 149 | 147 | 147 | 151 | 150 | 152 | 149 | 152 | 160 | 158 | 153 | 157 | 152 | 153 | 159 | 162 | 158 | 152 | 155 | 163 | 161 | 162 | 161 | 162 | 161 | 152 | 147 | 150 | 157 | 159 | 162 | 164 | 165 | 164 | 163 | 163 | 161 | 162 | 164 | 163 | 161 | 158 | 156 | 155 | 156 | 154 | 154 | 157 | . 288 144 | 147 | 151 | 151 | 147 | 143 | 145 | 150 | 144 | 148 | 148 | 144 | 142 | 144 | 144 | 142 | 144 | 144 | 144 | 143 | 143 | 145 | 145 | 144 | 146 | 148 | 147 | 144 | 143 | 147 | 148 | 147 | 144 | 147 | 147 | 145 | 146 | 148 | 147 | 144 | 145 | 144 | 143 | 140 | 137 | 140 | 144 | 141 | 142 | 144 | 146 | 146 | 146 | 146 | 147 | 149 | 148 | 149 | 149 | 149 | 150 | 154 | 156 | 156 | 158 | 152 | 148 | 151 | 155 | 156 | 155 | 155 | 163 | 159 | 155 | 157 | 163 | 165 | 159 | 151 | 149 | 158 | 161 | 161 | 164 | 165 | 164 | 164 | 161 | 164 | 162 | 158 | 159 | 164 | 165 | 161 | 159 | 157 | 156 | 157 | . 289 148 | 141 | 136 | 140 | 147 | 150 | 148 | 146 | 146 | 150 | 151 | 145 | 140 | 141 | 144 | 144 | 143 | 145 | 144 | 142 | 141 | 143 | 144 | 143 | 141 | 143 | 145 | 144 | 144 | 145 | 145 | 144 | 146 | 146 | 144 | 142 | 143 | 145 | 146 | 145 | 144 | 144 | 146 | 145 | 141 | 142 | 143 | 140 | 143 | 144 | 145 | 145 | 145 | 146 | 148 | 150 | 148 | 149 | 148 | 147 | 148 | 151 | 152 | 152 | 155 | 160 | 156 | 143 | 138 | 147 | 156 | 156 | 154 | 157 | 159 | 158 | 157 | 160 | 163 | 165 | 169 | 159 | 149 | 153 | 162 | 162 | 160 | 163 | 165 | 163 | 165 | 169 | 166 | 158 | 159 | 166 | 165 | 162 | 159 | 158 | . 290 173 | 165 | 155 | 148 | 145 | 145 | 146 | 148 | 140 | 144 | 147 | 148 | 149 | 150 | 146 | 140 | 146 | 147 | 147 | 144 | 143 | 143 | 144 | 144 | 143 | 143 | 144 | 145 | 145 | 143 | 142 | 143 | 145 | 144 | 145 | 148 | 148 | 147 | 147 | 147 | 145 | 145 | 147 | 147 | 144 | 144 | 145 | 141 | 142 | 142 | 142 | 142 | 143 | 144 | 145 | 146 | 148 | 149 | 148 | 147 | 147 | 149 | 150 | 149 | 150 | 155 | 157 | 152 | 144 | 141 | 145 | 150 | 152 | 155 | 156 | 155 | 155 | 157 | 160 | 161 | 154 | 163 | 163 | 158 | 159 | 160 | 158 | 156 | 161 | 164 | 165 | 164 | 162 | 162 | 163 | 164 | 165 | 162 | 159 | 159 | . 291 174 | 174 | 171 | 161 | 149 | 142 | 143 | 147 | 151 | 150 | 148 | 145 | 145 | 146 | 146 | 143 | 146 | 148 | 149 | 146 | 144 | 143 | 144 | 143 | 147 | 144 | 143 | 145 | 146 | 145 | 145 | 148 | 143 | 142 | 143 | 146 | 146 | 142 | 142 | 144 | 146 | 145 | 147 | 147 | 144 | 145 | 148 | 146 | 142 | 141 | 141 | 142 | 142 | 142 | 142 | 141 | 148 | 149 | 150 | 149 | 149 | 150 | 149 | 148 | 146 | 147 | 152 | 159 | 158 | 149 | 141 | 139 | 148 | 150 | 152 | 153 | 154 | 156 | 155 | 154 | 160 | 151 | 150 | 164 | 171 | 159 | 152 | 159 | 159 | 158 | 154 | 151 | 156 | 165 | 166 | 162 | 164 | 160 | 158 | 160 | . 292 168 | 170 | 173 | 173 | 169 | 160 | 148 | 140 | 142 | 146 | 149 | 149 | 147 | 147 | 148 | 150 | 144 | 146 | 147 | 145 | 143 | 142 | 142 | 140 | 145 | 142 | 142 | 145 | 147 | 146 | 147 | 149 | 150 | 146 | 144 | 145 | 143 | 141 | 143 | 148 | 146 | 144 | 147 | 148 | 145 | 145 | 147 | 145 | 141 | 142 | 143 | 144 | 144 | 144 | 143 | 143 | 145 | 148 | 150 | 150 | 150 | 150 | 149 | 147 | 145 | 150 | 151 | 149 | 154 | 159 | 153 | 141 | 139 | 146 | 151 | 151 | 149 | 151 | 155 | 157 | 158 | 161 | 155 | 147 | 151 | 161 | 164 | 163 | 165 | 153 | 147 | 153 | 158 | 157 | 158 | 163 | 167 | 164 | 161 | 162 | . 293 168 | 170 | 173 | 176 | 178 | 176 | 169 | 161 | 147 | 144 | 142 | 144 | 149 | 152 | 150 | 146 | 145 | 146 | 146 | 144 | 144 | 144 | 143 | 141 | 146 | 144 | 144 | 146 | 146 | 144 | 140 | 139 | 142 | 143 | 146 | 148 | 148 | 147 | 147 | 149 | 145 | 144 | 148 | 151 | 147 | 145 | 144 | 142 | 139 | 141 | 144 | 144 | 144 | 143 | 144 | 144 | 143 | 145 | 147 | 148 | 149 | 150 | 149 | 147 | 147 | 148 | 148 | 148 | 151 | 156 | 156 | 153 | 144 | 144 | 143 | 142 | 144 | 149 | 151 | 152 | 154 | 154 | 155 | 157 | 154 | 147 | 153 | 169 | 163 | 159 | 158 | 159 | 158 | 154 | 154 | 158 | 166 | 163 | 162 | 164 | . 294 156 | 160 | 162 | 163 | 167 | 174 | 180 | 183 | 181 | 167 | 151 | 143 | 144 | 146 | 146 | 143 | 148 | 147 | 145 | 143 | 144 | 147 | 147 | 145 | 148 | 148 | 147 | 146 | 145 | 144 | 140 | 135 | 132 | 137 | 141 | 143 | 143 | 143 | 144 | 143 | 145 | 143 | 147 | 151 | 148 | 145 | 145 | 143 | 139 | 142 | 144 | 143 | 141 | 140 | 142 | 145 | 143 | 145 | 145 | 145 | 146 | 148 | 149 | 148 | 148 | 145 | 146 | 152 | 153 | 150 | 152 | 157 | 154 | 148 | 141 | 139 | 144 | 149 | 147 | 142 | 143 | 151 | 152 | 149 | 156 | 163 | 156 | 146 | 157 | 162 | 163 | 160 | 158 | 158 | 157 | 154 | 160 | 159 | 159 | 161 | . 295 158 | 159 | 159 | 158 | 160 | 165 | 169 | 170 | 173 | 177 | 179 | 173 | 161 | 150 | 147 | 148 | 149 | 147 | 142 | 140 | 142 | 147 | 148 | 146 | 146 | 147 | 146 | 144 | 146 | 149 | 148 | 144 | 148 | 149 | 145 | 138 | 136 | 140 | 145 | 146 | 145 | 142 | 145 | 148 | 146 | 145 | 148 | 148 | 143 | 146 | 147 | 144 | 140 | 138 | 142 | 145 | 145 | 145 | 145 | 144 | 145 | 148 | 150 | 149 | 147 | 150 | 149 | 145 | 146 | 152 | 154 | 150 | 154 | 154 | 152 | 148 | 147 | 147 | 148 | 147 | 142 | 147 | 146 | 143 | 148 | 153 | 156 | 159 | 158 | 151 | 152 | 161 | 164 | 159 | 157 | 161 | 157 | 156 | 157 | 158 | . 296 154 | 156 | 156 | 156 | 155 | 156 | 158 | 161 | 164 | 166 | 169 | 174 | 179 | 179 | 171 | 162 | 147 | 148 | 150 | 149 | 144 | 140 | 143 | 148 | 146 | 145 | 145 | 147 | 147 | 146 | 143 | 141 | 147 | 146 | 145 | 145 | 143 | 140 | 134 | 129 | 140 | 143 | 146 | 146 | 144 | 144 | 147 | 150 | 143 | 144 | 143 | 141 | 139 | 139 | 137 | 135 | 140 | 145 | 147 | 142 | 139 | 142 | 147 | 149 | 144 | 147 | 150 | 150 | 149 | 148 | 149 | 151 | 149 | 153 | 154 | 152 | 149 | 148 | 147 | 146 | 144 | 144 | 146 | 148 | 148 | 146 | 147 | 150 | 169 | 159 | 149 | 148 | 154 | 161 | 161 | 159 | 161 | 159 | 160 | 163 | . 297 155 | 157 | 158 | 157 | 156 | 157 | 159 | 161 | 164 | 164 | 163 | 164 | 169 | 175 | 178 | 178 | 164 | 152 | 142 | 142 | 148 | 151 | 147 | 143 | 146 | 148 | 146 | 141 | 141 | 145 | 147 | 146 | 146 | 145 | 145 | 146 | 147 | 146 | 145 | 143 | 135 | 138 | 140 | 141 | 142 | 145 | 149 | 153 | 146 | 145 | 142 | 138 | 137 | 139 | 141 | 141 | 144 | 141 | 140 | 141 | 144 | 145 | 145 | 144 | 144 | 145 | 147 | 147 | 147 | 146 | 146 | 147 | 150 | 150 | 149 | 149 | 152 | 154 | 152 | 147 | 146 | 145 | 145 | 147 | 146 | 145 | 147 | 150 | 146 | 152 | 156 | 155 | 151 | 150 | 154 | 158 | 157 | 162 | 163 | 160 | . 298 161 | 162 | 162 | 162 | 161 | 161 | 163 | 164 | 162 | 163 | 163 | 161 | 160 | 163 | 166 | 167 | 180 | 177 | 171 | 160 | 148 | 141 | 144 | 150 | 142 | 143 | 143 | 142 | 140 | 140 | 143 | 146 | 148 | 148 | 147 | 147 | 147 | 147 | 147 | 148 | 141 | 141 | 141 | 141 | 141 | 143 | 146 | 148 | 147 | 146 | 142 | 138 | 137 | 139 | 142 | 142 | 147 | 140 | 138 | 143 | 147 | 145 | 142 | 141 | 145 | 145 | 146 | 146 | 146 | 146 | 146 | 146 | 148 | 148 | 147 | 148 | 152 | 155 | 154 | 151 | 148 | 147 | 147 | 147 | 147 | 147 | 150 | 154 | 145 | 149 | 155 | 157 | 156 | 155 | 155 | 156 | 154 | 158 | 159 | 156 | . 299 157 | 158 | 158 | 158 | 157 | 156 | 157 | 158 | 157 | 161 | 163 | 163 | 162 | 164 | 165 | 165 | 157 | 162 | 168 | 171 | 167 | 158 | 150 | 145 | 137 | 139 | 145 | 149 | 142 | 131 | 133 | 142 | 145 | 146 | 146 | 145 | 144 | 144 | 144 | 144 | 149 | 147 | 145 | 144 | 143 | 143 | 144 | 144 | 147 | 148 | 147 | 144 | 143 | 143 | 142 | 140 | 143 | 143 | 144 | 146 | 144 | 141 | 140 | 141 | 144 | 144 | 144 | 145 | 146 | 147 | 147 | 147 | 145 | 148 | 150 | 149 | 147 | 148 | 151 | 154 | 151 | 151 | 150 | 149 | 148 | 148 | 150 | 152 | 156 | 152 | 150 | 153 | 159 | 163 | 161 | 158 | 155 | 151 | 150 | 155 | . - 결국 이 이미지는 683 $ times$ 1024 개의 숫자의 모임 . - 이 이미지를 벡터로 만든다음 히스토그램을 그려보자. . img.flatten().shape . (699392,) . fig1=plt.hist(img.flatten(),256,[0,256]) . - 히스토그램을 그려보니 120~200 사이에 너무 값들이 모여있음 . - 원래 0~255까지의 색을 표현할 수 있는데 컴퓨터가 표현가능한 색상보다 적은 조합만을 사용하고 있음. . - 아이디어: 좀 더 많은 색상을 표현할 수 없을까? $ to$ 위의 히스토그램은 좀 평평하게 만들면 되지 않을까? . img2=cv.equalizeHist(img) . fig2_1=plt.hist(img2.flatten(),256,[0,256]) # 256개의 구간으로 히스토그램 만들어 . fig2_2=plt.hist(img2.flatten(),10,[0,256]) . plt.imshow(img2,cmap=&#39;gray&#39;,vmin=0,vmax=255) plt.colorbar() . &lt;matplotlib.colorbar.Colorbar at 0x7f6a6e40d1f0&gt; . - 변환전과 변환후를 나란히 보게 되면? . import numpy as np . _img=np.hstack((img,img2)) . plt.imshow(_img,cmap=&#39;gray&#39;) . &lt;matplotlib.image.AxesImage at 0x7f6a6967c760&gt; . &#49689;&#51228;2 . - 아래 이미지를 HE(histogram equalization)로 보정하고 스샷제출 . ref: https://ukdevguy.com/histogram-equalization-in-python/ | . hw_img=cv.imread(&#39;hw_img.png&#39;,0) plt.imshow(hw_img,cmap=&#39;gray&#39;) . &lt;matplotlib.image.AxesImage at 0x7f6a69661df0&gt; . - 이미지는 https://raw.githubusercontent.com/guebin/2021DV/master/_notebooks/hw_img.png 에서 다운받을 수 있다. . hw_img2=cv.equalizeHist(hw_img) . plt.imshow(hw_img2,cmap=&#39;gray&#39;,vmin=0,vmax=255) plt.colorbar() . &lt;matplotlib.colorbar.Colorbar at 0x7f6a69572b20&gt; . _img_hw=np.hstack((hw_img,hw_img2)) . plt.imshow(_img_hw,cmap=&#39;gray&#39;) plt.colorbar() . &lt;matplotlib.colorbar.Colorbar at 0x7f6a694ad280&gt; .",
            "url": "https://seoyeonc.github.io/chch/2021/09/13/%EB%8D%B0%EC%8B%9C_2%EC%A3%BC%EC%B0%A8.html",
            "relUrl": "/2021/09/13/%EB%8D%B0%EC%8B%9C_2%EC%A3%BC%EC%B0%A8.html",
            "date": " • Sep 13, 2021"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . (_pages/about에서 수정) . 학력 . 학사…석사…. . 경력 . 어디..ㅇ디.. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://seoyeonc.github.io/chch/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://seoyeonc.github.io/chch/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}