{
  
    
        "post0": {
            "title": "빅데이터 분석 (2주차) 9월14일, 9월16일",
            "content": "&#54028;&#51060;&#53664;&#52824;&#47484; &#51060;&#50857;&#54616;&#50668; &#54924;&#44480;&#47784;&#54805; &#54617;&#49845;&#54616;&#44592; . - (1/5) 회귀모형 소개, 손실 함수 . - (2/5) 경사하강법, 경사하강법을 이용하여 회귀계수 1회 업데이트 . - (3/5) 회귀계수 반복 업데이트 . - (4/5) 학습률 . - (5/5) 사과영상 . import torch import numpy as np import matplotlib.pyplot as plt . 로드맵 . 회귀분석 $ to$ 로지스틱 $ to$ 심층신경망(DNN) $ to$ 합성곱신경망(CNN) | . - model: $y_i= w_0+w_1 x_i + epsilon_i = 2.5 + 4x_i + epsilon_i, quad i=1,2, dots,n$ . w라는 로테이션을 많이 사용하는 딥러닝 | . - model: ${ bf y}={ bf X}{ bf W} + boldsymbol{ epsilon}$ . ${ bf y}= begin{bmatrix} y_1 y_2 dots y_n end{bmatrix}, quad { bf X}= begin{bmatrix} 1 &amp; x_1 1 &amp; x_2 dots 1 &amp; x_n end{bmatrix}, quad { bf W}= begin{bmatrix} 2.5 4 end{bmatrix}, quad boldsymbol{ epsilon}= begin{bmatrix} epsilon_1 dots epsilon_n end{bmatrix}$ | . torch.manual_seed(202150754) n=100 ones=torch.ones(n) x,_ = torch.randn(n).sort() # 배열하면 tendor,index가 반환됨. 필요한 x만 반환 X = torch.vstack([ones,x]).T W = torch.tensor([2.5,4]) ϵ = torch.randn(n)*0.5 y = X@W + ϵ #@는 벡터를 곱하라는 뜻..! ytrue = X@W # 우리가 알고 싶은 것은 평균 직선 . plt.plot(x,y,&#39;o&#39;) #우리가 관측한 값 plt.plot(x,ytrue,&#39;--&#39;) # 우리가 추론하고 싶은 값 . [&lt;matplotlib.lines.Line2D at 0x7f1443b129a0&gt;] . &#54617;&#49845; . - 파란점만 주어졌을때, 주황색 점선을 추론하는것. . - 좀 더 정확하게 말하면 given data로 $ begin{bmatrix} hat{w}_0 hat{w}_1 end{bmatrix}$를 최대한 $ begin{bmatrix} 2.5 4 end{bmatrix}$와 비슷하게 찾는것. (2.5와 4는 true의 값) . given data : $ big {(x_i,y_i) big }_{i=1}^{n}$ . | parameter: ${ bf W}= begin{bmatrix} w_0 w_1 end{bmatrix}$ . | estimated parameter: ${ bf hat{W}}= begin{bmatrix} hat{w}_0 hat{w}_1 end{bmatrix}$ . | . plt.plot(x,y,&#39;o&#39;) # 그림을 보고 &#39;적당한&#39; 추세를 찾는 과정 . [&lt;matplotlib.lines.Line2D at 0x7f1443a1b9d0&gt;] . - 시도: $( hat{w}_0, hat{w}_1)=(-5,10)$을 선택하여 선을 그려보고 적당한지 판단. . $ hat{y}_i=-5 +10 x_i$ 와 같이 $y_i$의 값을 적합시키겠다는 의미 | . plt.plot(x,y,&#39;o&#39;) plt.plot(x,-5+10*x,&#39;--&#39;) # 그림을 보고 판단해보는 단계 . [&lt;matplotlib.lines.Line2D at 0x7f1443994220&gt;] . - 벡터 표현으로주황색 추세선을 계산 . What = torch.tensor([-5.0,10.0]) # float으로 선언해야 함!!! plt.plot(x,y,&#39;o&#39;) plt.plot(x,X@What,&#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f14438fa310&gt;] . &#54028;&#46972;&#48120;&#53552;&#47484; &#54617;&#49845;&#54616;&#45716; &#48169;&#48277;, &#51593; &#51201;&#45817;&#54620; &#49440;&#50640; &#47582;&#52656;&#44032;&#45716; &#44284;&#51221; . - 이론적으로 추론 (회귀 분석) . - 컴퓨터의 반복계산을 이용하여 추론(경사하강법) . (1) initial value: 임의의 선을 그어봄 . What = torch.tensor([-5.0,10.0],requires_grad=True) What . tensor([-5., 10.], requires_grad=True) . 처음에는 ${ bf hat{W}}= begin{bmatrix} hat{w}_0 hat{w}_1 end{bmatrix}= begin{bmatrix} -5 10 end{bmatrix} $ 를 대입해서 주황색 점선을 적당히 그려보자는 의미 . | 끝에 requires_grad=True는 나중에 미분에 사용되기 위함. . | . yhat=X@What # yhat을 구하면 단지 X(미분X)*What(미분O) = 미분 옵션이 있는 텐션이 되어버린다. yhat.data # 미분 옵션이 사라짐. . tensor([-27.9716, -26.0391, -25.8951, -24.1830, -23.6405, -23.1161, -22.0441, -21.9913, -21.4959, -21.2860, -20.4771, -19.6991, -19.1434, -18.0758, -17.5390, -17.4888, -16.8212, -16.6630, -16.2503, -14.3326, -13.8527, -13.6397, -13.5228, -13.2096, -12.8514, -12.8461, -12.7527, -12.2431, -12.0267, -11.7990, -11.6495, -11.5587, -11.5497, -11.1709, -10.9643, -10.7969, -10.7696, -10.7324, -10.6567, -10.4404, -10.1049, -9.9527, -9.7916, -9.3899, -9.2762, -8.2773, -8.0850, -7.9550, -7.8498, -7.7767, -7.6419, -7.2295, -7.1686, -6.9773, -6.9454, -6.6435, -5.6597, -5.5200, -5.4562, -5.3640, -4.9588, -4.9111, -4.5447, -3.9894, -3.6367, -3.0762, -2.4928, -2.4512, -2.1695, -2.0062, -1.7060, 0.1909, 0.5915, 0.9467, 1.3453, 1.4359, 2.0752, 2.4723, 2.5368, 2.7189, 2.7902, 2.8337, 3.2249, 3.7238, 3.8636, 3.9170, 3.9852, 5.0601, 5.7496, 6.0569, 7.0621, 7.2674, 7.6805, 7.9669, 8.4266, 9.6044, 9.6791, 10.7418, 12.6324, 18.9507]) . plt.plot(x,y,&#39;o&#39;) plt.plot(x,yhat.data,&#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f143d0d54f0&gt;] . (2) 첫 번째 수정: 추세선의 적당한 정도를 판단하여 적당한 선으로 업데이트 . - &#39;적당한 정도&#39;를 판단하기 위하 장치로서 loss function 도입 . $loss= sum_{i=1}^{n}(y_i- hat{y}_i)^2= sum_{i=1}^{n}(y_i-( hat{w}_0+ hat{w}_1x_i))^2$ . $=({ bf y}-{ bf hat{y}})^ top({ bf y}-{ bf hat{y}})=({ bf y}-{ bf X}{ bf hat{W}})^ top({ bf y}-{ bf X}{ bf hat{W}})$ . 구현하기 편하게 하기 위해 벡터로 구현 . - loss 함수의 특징 . $y_i approx hat{y}_i$ 일수록 loss값이 작다. | $y_i approx hat{y}_i$ 이 되도록 $( hat{w}_0, hat{w}_1)$을 잘 찍으면 loss값이 작다. | (중요) 주황색 점선이 적당할수록 loss값이 작다. | . loss = torch.sum((y-yhat)**2) # = (y-yhat)@(y-yhat) loss . tensor(11003.1260, grad_fn=&lt;SumBackward0&gt;) . - $loss(=11003.1260)$을 줄이는, 혹은 없애는 것이 목표 $ to$ 아예 모든 조합 $( hat{w}_0, hat{w}_1)$에 대하여 가장 작은 $loss$ 찾기 . - 문제의 치환 . 적당해 보이는 주황색 선을 찾자 $ to$ $loss(w_0,w_1)$을 최소로 하는 $(w_0,w_1$의 값을 찾기 | . - $loss(w_0,w_1)$를 최소로 하는 $(w_0,w_1)$ 구하는 것으로 수정된 목표 . 단순한 수학문제가 되었다. 마치 $loss(w)=w^2-2w+3$ 을 최소화하는 $w$를 찾으라는 것과 같음. | . - 경사하강법, 벡터미분 사용! . &#44221;&#49324;&#54616;&#44053;&#48277; . 경사하강법 아이디어(1차원) . (step 1) 임의의 점을 찍는다. . (step 2) 그 점에서 순간기울기를 구한다. (접선) &lt;-- 미분 . (step 3) 순간기울기(= 미분계수)의 부호를 살펴보고 부호와 반대방향으로 움직인다. (순간기울기와 같은 방향으로 움직이면 점점 커질테니까.) . (Tip) 기울기의 절대값 크기와 비례하여 보폭(= 움직이는 정도)을 조절한다. . 경사하강법 아이디어(2차원) . (step 1) 임의의 점을 찍는다. . (step 2) 그 점에서 순간기울기를 구한다. (접평면) &lt;-- 편미분 . (step 3) 순간기울기(= 여러개의 미분계수)의 부호를 살펴보고 부호와 반대방향으로 각각 움직인다. (순간기울기와 같은 방향으로 움직이면 점점 커질테니까.) . (Tip) 기울기의 절대값 크기와 비례하여 보폭(= 움직이는 정도)을 각각 조절한다. . loss를 줄이도록 $W$를 개선하는 방법 . - $수정값 leftarrow 원래값 - 기울어진 크기(= 미분계수) times alpha$ . 여기에서 $ alpha$는 전체적인 보폭의 크기를 결정한다. 즉, $ alpha$값이 클수록 한 번의 update에 움직이는 양이 크다. | . - ${ bf W} leftarrow { bf W} - alpha times frac{ partial}{ partial { bf W}}loss(w_0,w_1)$ . 마이너스의 의미 기울기의 부호를 보고 반대방향으로 움직여라 . | $ frac{ partial}{ partial { bf W}}loss(w_0,w_1):$ 기울기의 절대값 크기와 비례하여 움직이는 정도를 조정하라. (속도의 조절) . | $ alpha$의 의미: 전체적인 보폭의 속도를 조절, $ alpha$가 크면 전체적으로 빠르게 움직인다. 다리의 길이로 비유할 수 있다. . | . . - 목표: $loss(=11003.1260)$ 값을 줄이는 것. . - 방법: 경사하강법 . - 경사하강법으로 loss를 줄이기 위해서는 $ frac{ partial}{ partial { bf W}}loss(w_0,w_1)$의 계산이 필요한데, 이를 위해서 벡터미분이 필요하다. . requires_grad=True를 가진 텐서로 미분. | . loss=torch.sum((y-yhat)**2)= torch.sum((y-X@What)**2) # 이었고 What=torch.tensor([-5.0,10.0],requires_grad=True) # 이므로 결국 What으로 미분하라는 의미. # 미분한 식이 나오는 것이 아니고, # 그 식에 (-5.0, 10.0)을 대입한 계수값이 계산됨. . loss.backward() # requires_grad=True를 가진 텐서로 미분하라는 의미 # 단지 미분 계수가 계산되어 있음 # 정확하게 말하면 미분을 활용하여 $(-5,10)$에서의 순간기울기를 구했다는 의미임. . What.grad.data . tensor([-1730.4250, 1485.8135]) . 이것이 의미하는 건 $(-5,10)$에서의 순간기울기가 $([-1730.4250, 1485.8135])$ 이라는 의미 (각각 (양수, 음수)로 움직여야 함) | . - 직접 계산하여 검증 . $loss(w_0,w_1)=(y- hat{y})^ top (y- hat{y})=(y-XW)^ top (y-XW)$ . | $ frac{ partial}{ partial W}loss(w_0,w_1)=-2X^ top y+2X^ top X W$ . | . -2 * X.T @ y + 2 * X.T @ X @ What # = What.grad.data . tensor([-1730.4250, 1485.8135], grad_fn=&lt;AddBackward0&gt;) . alpha=0.001 print(&#39;수정 전: &#39; + str(What.data)) # 미분 옵션 없애기! print(&#39;수정하는 폭: &#39; + str(-alpha*What.grad.data)) print(&#39;수정 후: &#39; + str(What.data-alpha*What.grad.data)) print(&#39;*참값: (2.5,4)&#39;) . 수정 전: tensor([-5., 10.]) 수정하는 폭: tensor([ 1.7304, -1.4858]) 수정 후: tensor([-3.2696, 8.5142]) *참값: (2.5,4) . Wbefore = What.data Wafter = What.data-alpha*What.grad.data Wbefore, Wafter . (tensor([-5., 10.]), tensor([-3.2696, 8.5142])) . plt.plot(x,y,&#39;o&#39;) plt.plot(x,X@Wbefore,&#39;--b&#39;) # 수정 전 파란 점선 plt.plot(x,X@Wafter,&#39;--r&#39;) # 수정 후 빨간 점선 plt.title(&quot;before: blue // after: red&quot;) . Text(0.5, 1.0, &#39;before: blue // after: red&#39;) . (3) Learn (=estimate $ bf hat{W})$: . What= torch.tensor([-5.0,10.0],requires_grad=True) . alpha=0.001 for epoc in range(30): What.grad=None yhat=X@What loss=torch.sum((y-yhat)**2) loss.backward() # What으로 미분하는 과정 What.data = What.data-alpha * What.grad.data # 적정한 선으로 Update! . What.data # true 값은 2.5,4 . tensor([2.5248, 3.9898]) . plt.plot(x,y,&#39;o&#39;) plt.plot(x,(X@What.data),&#39;--&#39;) # 순수 데이터만 뽑기 위해 .data꼭 붙이기 plt.plot(x,(X@np.array([2.5,4])),&#39;-&#39;) # 거의 비슷해서 한 선으로 보임 . [&lt;matplotlib.lines.Line2D at 0x7f1435f96310&gt;] . &#54028;&#46972;&#47700;&#53552;&#51032; &#49688;&#51221; &#44284;&#51221;&#51012; &#44288;&#52272;&#54624; &#49688; &#50630;&#45208;.(&#54617;&#49845;&#44284;&#51221; &#47784;&#45768;&#53552;&#47553;) . - 기록 해보기 . losses=[] # 기록하고 싶은 것 1 yhats = [] # 기록하고 싶은 것 2 Whats = [] # 기록하고 싶은 것 3 . What= torch.tensor([-5.0,10.0],requires_grad=True) alpha=0.001 for epoc in range(30): Whats=Whats+[What.data.tolist()] # What을 list화 해서 저장 What.grad=None yhat=X@What yhats=yhats+[yhat.data.tolist()] loss=torch.sum((y-yhat)**2) losses=losses+[loss.item()] loss.backward() # What으로 미분하는 과정 What.data = What.data-alpha * What.grad.data # 적정한 선으로 Update! . - $ hat{y}$ 관찰 . plt.plot(x,y,&#39;o&#39;) plt.plot(x,yhats[5],&#39;--&#39;) # 5번 업데이트된 추세선 . [&lt;matplotlib.lines.Line2D at 0x7f1435f20490&gt;] . plt.plot(x,y,&#39;o&#39;) plt.plot(x,yhats[10],&#39;--&#39;) # 10번 업데이트된 추세선 . [&lt;matplotlib.lines.Line2D at 0x7f1435f08100&gt;] . - $ hat{ bf{W}}$ . losses . [11003.1259765625, 6417.849609375, 3748.93798828125, 2195.045166015625, 1290.041015625, 762.7489624023438, 455.38189697265625, 276.1114196777344, 171.48153686523438, 110.3656005859375, 74.63228607177734, 53.71556854248047, 41.45503234863281, 34.25670623779297, 30.02236557006836, 27.52593421936035, 26.050209045410156, 25.175155639648438, 24.654428482055664, 24.34327507019043, 24.156478881835938, 24.043743133544922, 23.975299835205078, 23.93347930908203, 23.907733917236328, 23.891769409179688, 23.881786346435547, 23.8754940032959, 23.871488571166992, 23.868919372558594] . plt.plot(losses) . [&lt;matplotlib.lines.Line2D at 0x7f1435e55fd0&gt;] . Animation . plt.rcParams[&#39;figure.figsize&#39;] = (10,4) # 크기 plt.rcParams[&quot;animation.html&quot;] = &quot;jshtml&quot; # 애니메이션 나오게 하는 옵션 . from matplotlib import animation fig = plt.figure() ax1 = fig.add_subplot(1, 2, 1) ax2 = fig.add_subplot(1, 2, 2, projection=&#39;3d&#39;) ## ax1: 왼쪽그림 ax1.plot(x,y,&#39;o&#39;) line, = ax1.plot(x,yhats[0]) ## ax2: 오른쪽그림 _w0 = np.arange(-6, 11, 0.5) ## 파란색곡면을 그리는 코드 (시작) _w1 = np.arange(-6, 11, 0.5) w1,w0 = np.meshgrid(_w1,_w0) l=w0*0 for i in range(len(_w0)): for j in range(len(_w1)): l[i,j]=torch.sum((y-_w0[i]-_w1[j]*x)**2) ax2.plot_surface(w0, w1, l, rstride=1, cstride=1, color=&#39;b&#39;,alpha=0.35) ## 파란색곡면을 그리는 코드(끝) ax2.scatter(2.5,4,torch.sum((y-2.5-4*x)**2),s=200,color=&#39;red&#39;,marker=&#39;*&#39;) ## 최소점을 표시하는 코드 (붉은색 별) ax2.scatter(np.array(Whats)[0,0],np.array(Whats)[0,1],losses[0],color=&#39;b&#39;) ## 업데이트되는 What을 표시하는 점 (파란색 동그라미) ax2.azim = 40 ## 3d plot의 view 조절 ax2.dist = 8 ## 3d plot의 view 조절 ax2.elev = 5 ## 3d plot의 view 조절 def animate(epoc): line.set_ydata(yhats[epoc]) ax2.scatter(np.array(Whats)[epoc,0],np.array(Whats)[epoc,1],losses[epoc],color=&#39;grey&#39;) return line ani = animation.FuncAnimation(fig, animate, frames=30) plt.close() ani . . &lt;/input&gt; Once Loop Reflect $ alpha$&#50640; &#45824;&#54616;&#50668; ($ alpha$&#45716; &#54617;&#49845;&#47456;) . (1) $ alpha$가 너무 작다면?$ to$ 비효율적이다. . losses = [] # 기록하고 싶은것 1 yhats = [] # 기록하고 싶은것 2 Whats = [] # 기록하고 싶은것 3 . . alpha=0.0001 What= torch.tensor([-5.0,10.0],requires_grad=True) for epoc in range(30): Whats=Whats+[What.data.tolist()] What.grad=None yhat=X@What yhats=yhats+[yhat.data.tolist()] loss=torch.sum((y-yhat)**2) losses = losses + [loss.item()] loss.backward() What.data = What.data-alpha * What.grad.data . . fig = plt.figure() ax1 = fig.add_subplot(1, 2, 1) ax2 = fig.add_subplot(1, 2, 2, projection=&#39;3d&#39;) ## ax1: 왼쪽그림 ax1.plot(x,y,&#39;o&#39;) line, = ax1.plot(x,yhats[0]) ## ax2: 오른쪽그림 _w0 = np.arange(-6, 11, 0.5) ## 파란색곡면을 그리는 코드 (시작) _w1 = np.arange(-6, 11, 0.5) w1,w0 = np.meshgrid(_w1,_w0) l=w0*0 for i in range(len(_w0)): for j in range(len(_w1)): l[i,j]=torch.sum((y-_w0[i]-_w1[j]*x)**2) ax2.plot_surface(w0, w1, l, rstride=1, cstride=1, color=&#39;b&#39;,alpha=0.35) ## 파란색곡면을 그리는 코드(끝) ax2.scatter(2.5,4,torch.sum((y-2.5-4*x)**2),s=200,color=&#39;red&#39;,marker=&#39;*&#39;) ## 최소점을 표시하는 코드 (붉은색 별) ax2.scatter(np.array(Whats)[0,0],np.array(Whats)[0,1],losses[0],color=&#39;b&#39;) ## 업데이트되는 What을 표시하는 점 (파란색 동그라미) ax2.azim = 40 ## 3d plot의 view 조절 ax2.dist = 8 ## 3d plot의 view 조절 ax2.elev = 5 ## 3d plot의 view 조절 def animate(epoc): line.set_ydata(yhats[epoc]) ax2.scatter(np.array(Whats)[epoc,0],np.array(Whats)[epoc,1],losses[epoc],color=&#39;grey&#39;) return line ani = animation.FuncAnimation(fig, animate, frames=30) plt.close() ani . . &lt;/input&gt; Once Loop Reflect (1) $ alpha$가 너무 크다면? $ to$ 다른의미에서 비효율적이다 + 위험하다.. . losses = [] # 기록하고 싶은것 1 yhats = [] # 기록하고 싶은것 2 Whats = [] # 기록하고 싶은것 3 . . alpha=0.0083 What= torch.tensor([-5.0,10.0],requires_grad=True) for epoc in range(30): Whats=Whats+[What.data.tolist()] What.grad=None yhat=X@What yhats=yhats+[yhat.data.tolist()] loss=torch.sum((y-yhat)**2) losses = losses + [loss.item()] loss.backward() What.data = What.data-alpha * What.grad.data . . fig = plt.figure() ax1 = fig.add_subplot(1, 2, 1) ax2 = fig.add_subplot(1, 2, 2, projection=&#39;3d&#39;) ## ax1: 왼쪽그림 ax1.plot(x,y,&#39;o&#39;) line, = ax1.plot(x,yhats[0]) ## ax2: 오른쪽그림 _w0 = np.arange(-6, 11, 0.5) ## 파란색곡면을 그리는 코드 (시작) _w1 = np.arange(-6, 11, 0.5) w1,w0 = np.meshgrid(_w1,_w0) l=w0*0 for i in range(len(_w0)): for j in range(len(_w1)): l[i,j]=torch.sum((y-_w0[i]-_w1[j]*x)**2) ax2.plot_surface(w0, w1, l, rstride=1, cstride=1, color=&#39;b&#39;,alpha=0.35) ## 파란색곡면을 그리는 코드(끝) ax2.scatter(2.5,4,torch.sum((y-2.5-4*x)**2),s=200,color=&#39;red&#39;,marker=&#39;*&#39;) ## 최소점을 표시하는 코드 (붉은색 별) ax2.scatter(np.array(Whats)[0,0],np.array(Whats)[0,1],losses[0],color=&#39;b&#39;) ## 업데이트되는 What을 표시하는 점 (파란색 동그라미) ax2.azim = 40 ## 3d plot의 view 조절 ax2.dist = 8 ## 3d plot의 view 조절 ax2.elev = 5 ## 3d plot의 view 조절 def animate(epoc): line.set_ydata(yhats[epoc]) ax2.scatter(np.array(Whats)[epoc,0],np.array(Whats)[epoc,1],losses[epoc],color=&#39;grey&#39;) return line ani = animation.FuncAnimation(fig, animate, frames=30) plt.close() ani . . &lt;/input&gt; Once Loop Reflect (3) $ alpha=0.0085$ 아예 모형을 벗어나버린다. . losses = [] # 기록하고 싶은것 1 yhats = [] # 기록하고 싶은것 2 Whats = [] # 기록하고 싶은것 3 . . alpha=0.0085 What= torch.tensor([-5.0,10.0],requires_grad=True) for epoc in range(30): Whats=Whats+[What.data.tolist()] What.grad=None yhat=X@What yhats=yhats+[yhat.data.tolist()] loss=torch.sum((y-yhat)**2) losses = losses + [loss.item()] loss.backward() What.data = What.data-alpha * What.grad.data . . fig = plt.figure() ax1 = fig.add_subplot(1, 2, 1) ax2 = fig.add_subplot(1, 2, 2, projection=&#39;3d&#39;) ## ax1: 왼쪽그림 ax1.plot(x,y,&#39;o&#39;) line, = ax1.plot(x,yhats[0]) ## ax2: 오른쪽그림 _w0 = np.arange(-6, 11, 0.5) ## 파란색곡면을 그리는 코드 (시작) _w1 = np.arange(-6, 11, 0.5) w1,w0 = np.meshgrid(_w1,_w0) l=w0*0 for i in range(len(_w0)): for j in range(len(_w1)): l[i,j]=torch.sum((y-_w0[i]-_w1[j]*x)**2) ax2.plot_surface(w0, w1, l, rstride=1, cstride=1, color=&#39;b&#39;,alpha=0.35) ## 파란색곡면을 그리는 코드(끝) ax2.scatter(2.5,4,torch.sum((y-2.5-4*x)**2),s=200,color=&#39;red&#39;,marker=&#39;*&#39;) ## 최소점을 표시하는 코드 (붉은색 별) ax2.scatter(np.array(Whats)[0,0],np.array(Whats)[0,1],losses[0],color=&#39;b&#39;) ## 업데이트되는 What을 표시하는 점 (파란색 동그라미) ax2.azim = 40 ## 3d plot의 view 조절 ax2.dist = 8 ## 3d plot의 view 조절 ax2.elev = 5 ## 3d plot의 view 조절 def animate(epoc): line.set_ydata(yhats[epoc]) ax2.scatter(np.array(Whats)[epoc,0],np.array(Whats)[epoc,1],losses[epoc],color=&#39;grey&#39;) return line ani = animation.FuncAnimation(fig, animate, frames=30) plt.close() ani . . &lt;/input&gt; Once Loop Reflect (4) $ alpha=0.01$ . losses = [] # 기록하고 싶은것 1 yhats = [] # 기록하고 싶은것 2 Whats = [] # 기록하고 싶은것 3 . . alpha=0.01 What= torch.tensor([-5.0,10.0],requires_grad=True) for epoc in range(30): Whats=Whats+[What.data.tolist()] What.grad=None yhat=X@What yhats=yhats+[yhat.data.tolist()] loss=torch.sum((y-yhat)**2) losses = losses + [loss.item()] loss.backward() What.data = What.data-alpha * What.grad.data . . fig = plt.figure() ax1 = fig.add_subplot(1, 2, 1) ax2 = fig.add_subplot(1, 2, 2, projection=&#39;3d&#39;) ## ax1: 왼쪽그림 ax1.plot(x,y,&#39;o&#39;) line, = ax1.plot(x,yhats[0]) ## ax2: 오른쪽그림 _w0 = np.arange(-6, 11, 0.5) ## 파란색곡면을 그리는 코드 (시작) _w1 = np.arange(-6, 11, 0.5) w1,w0 = np.meshgrid(_w1,_w0) l=w0*0 for i in range(len(_w0)): for j in range(len(_w1)): l[i,j]=torch.sum((y-_w0[i]-_w1[j]*x)**2) ax2.plot_surface(w0, w1, l, rstride=1, cstride=1, color=&#39;b&#39;,alpha=0.35) ## 파란색곡면을 그리는 코드(끝) ax2.scatter(2.5,4,torch.sum((y-2.5-4*x)**2),s=200,color=&#39;red&#39;,marker=&#39;*&#39;) ## 최소점을 표시하는 코드 (붉은색 별) ax2.scatter(np.array(Whats)[0,0],np.array(Whats)[0,1],losses[0],color=&#39;b&#39;) ## 업데이트되는 What을 표시하는 점 (파란색 동그라미) ax2.azim = 40 ## 3d plot의 view 조절 ax2.dist = 8 ## 3d plot의 view 조절 ax2.elev = 5 ## 3d plot의 view 조절 def animate(epoc): line.set_ydata(yhats[epoc]) ax2.scatter(np.array(Whats)[epoc,0],np.array(Whats)[epoc,1],losses[epoc],color=&#39;grey&#39;) return line ani = animation.FuncAnimation(fig, animate, frames=30) plt.close() ani . . &lt;/input&gt; Once Loop Reflect (5) $ alpha=0.006$ 숙제 . losses = [] # 기록하고 싶은것 1 yhats = [] # 기록하고 싶은것 2 Whats = [] # 기록하고 싶은것 3 . . alpha=0.006 What= torch.tensor([-5.0,10.0],requires_grad=True) for epoc in range(30): Whats=Whats+[What.data.tolist()] What.grad=None yhat=X@What yhats=yhats+[yhat.data.tolist()] loss=torch.sum((y-yhat)**2) losses = losses + [loss.item()] loss.backward() What.data = What.data-alpha * What.grad.data . . fig = plt.figure() ax1 = fig.add_subplot(1, 2, 1) ax2 = fig.add_subplot(1, 2, 2, projection=&#39;3d&#39;) ## ax1: 왼쪽그림 ax1.plot(x,y,&#39;o&#39;) line, = ax1.plot(x,yhats[0]) ## ax2: 오른쪽그림 _w0 = np.arange(-6, 11, 0.5) ## 파란색곡면을 그리는 코드 (시작) _w1 = np.arange(-6, 11, 0.5) w1,w0 = np.meshgrid(_w1,_w0) l=w0*0 for i in range(len(_w0)): for j in range(len(_w1)): l[i,j]=torch.sum((y-_w0[i]-_w1[j]*x)**2) ax2.plot_surface(w0, w1, l, rstride=1, cstride=1, color=&#39;b&#39;,alpha=0.35) ## 파란색곡면을 그리는 코드(끝) ax2.scatter(2.5,4,torch.sum((y-2.5-4*x)**2),s=200,color=&#39;red&#39;,marker=&#39;*&#39;) ## 최소점을 표시하는 코드 (붉은색 별) ax2.scatter(np.array(Whats)[0,0],np.array(Whats)[0,1],losses[0],color=&#39;b&#39;) ## 업데이트되는 What을 표시하는 점 (파란색 동그라미) ax2.azim = 40 ## 3d plot의 view 조절 ax2.dist = 8 ## 3d plot의 view 조절 ax2.elev = 5 ## 3d plot의 view 조절 def animate(epoc): line.set_ydata(yhats[epoc]) ax2.scatter(np.array(Whats)[epoc,0],np.array(Whats)[epoc,1],losses[epoc],color=&#39;grey&#39;) return line ani = animation.FuncAnimation(fig, animate, frames=30) plt.close() ani . . &lt;/input&gt; Once Loop Reflect",
            "url": "https://seoyeonc.github.io/chch/2021/11/13/_bd_2%EC%A3%BC%EC%B0%A8_2.html",
            "relUrl": "/2021/11/13/_bd_2%EC%A3%BC%EC%B0%A8_2.html",
            "date": " • Nov 13, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "빅데이터 분석 (2주차) 9월9일",
            "content": "Path, &#51060;&#48120;&#51648; &#53356;&#47204;&#47553;&#44284; CNN&#47784;&#45944; . - (1/4) Path 설명 . - (2/4) 이미지 크롤링 . - (3/4) 모형학습 및 결과분석 . - (4/4) 테스트 . from fastai.data.all import * from fastai.vision.all import * . path=Path() # 현재 위치 저장 현재폴더=. 상위폴더=.. path . Path(&#39;.&#39;) . path.ls() . (#9) [Path(&#39;bd_1주차.ipynb&#39;),Path(&#39;601f57a1260000bd0c275eca.jpeg&#39;),Path(&#39;2021_09_07_(1주차)_9월7일.ipynb&#39;),Path(&#39;p1065602463397191_754_thum.jpg&#39;),Path(&#39;502104_3008_164.png&#39;),Path(&#39;2021_09_09_(2주차)_9월9일.ipynb&#39;),Path(&#39;.ipynb_checkpoints&#39;),Path(&#39;2021-09-27-(3주차)_9월27일(1).ipynb&#39;),Path(&#39;bd_2주차.ipynb&#39;)] . (path/&#39;폴더 이름 넣어~&#39;).ls() . path=Path() . (path/&#39;asdf&#39;).mkdir() . (path/&#39;asdf&#39;).ls() . (#0) [] . (path/&#39;asdf&#39;).mkdir() # 이미 있는 폴더면 오류 발생 . FileExistsError Traceback (most recent call last) &lt;ipython-input-19-96a686fc4db7&gt; in &lt;module&gt; -&gt; 1 (path/&#39;asdf&#39;).mkdir() # 이미 있는 폴더면 오류 발생 ~/anaconda3/envs/csy/lib/python3.8/pathlib.py in mkdir(self, mode, parents, exist_ok) 1286 self._raise_closed() 1287 try: -&gt; 1288 self._accessor.mkdir(self, mode) 1289 except FileNotFoundError: 1290 if not parents or self.parent == self: FileExistsError: [Errno 17] File exists: &#39;asdf&#39; . (path/&#39;asdf&#39;).mkdir(exist_ok=True) # 이미 존재하면 무시~ . (path/&#39;asdf&#39;).rmdir() # 생성한 폴더 삭제 . &#51060;&#48120;&#51648; &#53356;&#47204;&#47553; . - 이미지 크롤링 . 검색 2. 이미지 주소를 찾음 3. 해당 주소로 이동하여 저장하는 과정 반복 | | . - 다른방법: 덕덕고를 이용한 이미지 크롤링 . ref: https://github.com/fastai/fastbook/blob/master/utils.py | . def search_images_ddg(key,max_n=200): &quot;&quot;&quot;Search for &#39;key&#39; with DuckDuckGo and return a unique urls of &#39;max_n&#39; images (Adopted from https://github.com/deepanprabhu/duckduckgo-images-api) &quot;&quot;&quot; url = &#39;https://duckduckgo.com/&#39; params = {&#39;q&#39;:key} res = requests.post(url,data=params) searchObj = re.search(r&#39;vqd=([ d-]+) &amp;&#39;,res.text) if not searchObj: print(&#39;Token Parsing Failed !&#39;); return requestUrl = url + &#39;i.js&#39; headers = {&#39;User-Agent&#39;: &#39;Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:71.0) Gecko/20100101 Firefox/71.0&#39;} params = ((&#39;l&#39;,&#39;us-en&#39;),(&#39;o&#39;,&#39;json&#39;),(&#39;q&#39;,key),(&#39;vqd&#39;,searchObj.group(1)),(&#39;f&#39;,&#39;,,,&#39;),(&#39;p&#39;,&#39;1&#39;),(&#39;v7exp&#39;,&#39;a&#39;)) urls = [] while True: try: res = requests.get(requestUrl,headers=headers,params=params) data = json.loads(res.text) for obj in data[&#39;results&#39;]: urls.append(obj[&#39;image&#39;]) max_n = max_n - 1 if max_n &lt; 1: return L(set(urls)) # dedupe if &#39;next&#39; not in data: return L(set(urls)) requestUrl = url + data[&#39;next&#39;] except: pass . . search_images_ddg(검색어)를 이용하여 검색어에 해당하는 url 얻기m . search_images_ddg(&#39;Holybang&#39;,max_n=5) . (#5) [&#39;https://i.ytimg.com/vi/fcmDi1DCGDs/maxresdefault.jpg&#39;,&#39;http://one-we.cn/uploads/allimg/191218/1-19121Q35R5G9.jpg&#39;,&#39;https://i.ytimg.com/vi/SBWy4-ZU4qQ/maxresdefault.jpg&#39;,&#39;https://www.kpophighindia.com/wp-content/uploads/2021/07/crews-1.jpg&#39;,&#39;https://t1.daumcdn.net/cfile/tistory/993004335A12CB082C&#39;] . path=Path() . path.ls() . (#7) [Path(&#39;bd_1주차.ipynb&#39;),Path(&#39;2021_09_07_(1주차)_9월7일.ipynb&#39;),Path(&#39;bd_1st&#39;),Path(&#39;2021_09_09_(2주차)_9월9일.ipynb&#39;),Path(&#39;.ipynb_checkpoints&#39;),Path(&#39;2021-09-27-(3주차)_9월27일(1).ipynb&#39;),Path(&#39;bd_2주차.ipynb&#39;)] . download_images(path,urls=search_images_ddg(&#39;Holybang&#39;,max_n=5)) . 현재 working directory에 5개의 이미지가 저장된 모습! | . keywords=&#39;sunmi&#39;, &#39;Hyuna&#39; # 단어 한 개 쓰면 키워드로 입력되어서 알파벳 수대로 폴더 만들어짐.. path=Path(&#39;Singer&#39;) . if not path.exists(): # 현재폴더에 Singer 폴더가 있는지 체크 path.mkdir() # 현재폴더에 Singer 폴더가 만들어짐 for keyword in keywords: # keyword=&#39;sunmi&#39;, keyword=&#39;Hyuna&#39; 일때 아래내용을 반복 lastpath=path/keyword # ./Singer/sunmi or ./Singer/Hyuna lastpath.mkdir(exist_ok=True) # make ./Singer/sunmi or ./Singer/Hyuna urls=search_images_ddg(keyword) # &#39;sunmi&#39; 검색어로 url들의 리스트를 얻음 download_images(lastpath,urls=urls) # 그 url에 해당하는 이미지들을 ./Singer/sunmi or ./Singer/Hyuna 에 저장 . Cleaning Data . 탐색기로 파일들을 살펴보니 조금 이상한 확장자도 있음. . | 조금 이상해보이는 확장자도 열리기는 함. . | . PILImage.create(&#39;./singer/iu/00000015.jpg:large&#39;) . FileNotFoundError Traceback (most recent call last) &lt;ipython-input-44-2622c1a578e7&gt; in &lt;module&gt; -&gt; 1 PILImage.create(&#39;./singer/iu/00000015.jpg:large&#39;) ~/anaconda3/envs/csy/lib/python3.8/site-packages/fastai/vision/core.py in create(cls, fn, **kwargs) 108 if isinstance(fn,ndarray): return cls(Image.fromarray(fn)) 109 if isinstance(fn,bytes): fn = io.BytesIO(fn) --&gt; 110 return cls(load_image(fn, **merge(cls._open_args, kwargs))) 111 112 def show(self, ctx=None, **kwargs): ~/anaconda3/envs/csy/lib/python3.8/site-packages/fastai/vision/core.py in load_image(fn, mode) 83 def load_image(fn, mode=None): 84 &#34;Open and load a `PIL.Image` and convert to `mode`&#34; &gt; 85 im = Image.open(fn) 86 im.load() 87 im = im._new(im.im) ~/anaconda3/envs/csy/lib/python3.8/site-packages/PIL/Image.py in open(fp, mode, formats) 2973 2974 if filename: -&gt; 2975 fp = builtins.open(filename, &#34;rb&#34;) 2976 exclusive_fp = True 2977 FileNotFoundError: [Errno 2] No such file or directory: &#39;./singer/iu/00000015.jpg:large&#39; . verify_images(get_image_files(path)) . (#4) [Path(&#39;Singer/sunmi/00000065.jpg&#39;),Path(&#39;Singer/Hyuna/00000034.jpg&#39;),Path(&#39;Singer/Hyuna/00000039.jpg&#39;),Path(&#39;Singer/Hyuna/00000025.jpeg&#39;)] . 위에 해당하는 이미지를 수동으로 지워줌 | 나중에 지우는 함수 배움(조금 까다로움) | . - fastai 가 지원하는 함수로 분석하기 좋게 dls 만들기 . dls=ImageDataLoaders.from_folder( path, train=&#39;singer&#39;, valid_pct=0.2, item_tfms=Resize(224)) . ImageDataLoaders.from_folder(path, train=&#39;train&#39;, valid=&#39;valid&#39;, valid_pct=None, seed=None, vocab=None, item_tfms=None, batch_tfms=None, bs=64, val_bs=None, shuffle=True, device=None) . dls.show_batch(max_n=16) . learn=cnn_learner(dls,resnet34,metrics=error_rate) learn.fine_tune(7) . epoch train_loss valid_loss error_rate time . 0 | 1.169335 | 1.660869 | 0.470588 | 00:05 | . epoch train_loss valid_loss error_rate time . 0 | 0.718052 | 0.950780 | 0.397059 | 00:04 | . 1 | 0.634088 | 0.537583 | 0.205882 | 00:04 | . 2 | 0.490461 | 0.444096 | 0.205882 | 00:04 | . 3 | 0.389381 | 0.479742 | 0.161765 | 00:04 | . 4 | 0.317441 | 0.513656 | 0.176471 | 00:04 | . 5 | 0.269008 | 0.556920 | 0.191176 | 00:04 | . 6 | 0.234722 | 0.560562 | 0.205882 | 00:04 | . learn.show_results(max_n=16) . &#50724;&#45813;&#48516;&#49437; . interp=Interpretation.from_learner(learn) interp.plot_top_losses(16) . 수동으로 특정 observation에 대한 예측결과를 확인 | . dls.train_ds . (#275) [(PILImage mode=RGB size=1080x1080, TensorCategory(1)),(PILImage mode=RGB size=1038x1557, TensorCategory(1)),(PILImage mode=RGB size=642x858, TensorCategory(1)),(PILImage mode=RGB size=509x509, TensorCategory(0)),(PILImage mode=RGB size=960x1200, TensorCategory(1)),(PILImage mode=RGB size=800x1200, TensorCategory(0)),(PILImage mode=RGB size=3600x2025, TensorCategory(0)),(PILImage mode=RGB size=1100x1716, TensorCategory(1)),(PILImage mode=RGB size=1280x1920, TensorCategory(1)),(PILImage mode=RGB size=768x1024, TensorCategory(1))...] . training test | . dls.train_ds[0] # 첫 번째 observation, 즉, (x1,y1) . (PILImage mode=RGB size=1080x1080, TensorCategory(1)) . $x_1=$PILImage mode=RGB size=960x960 | $y_1=$TensorCategory(1) | . dls.train_ds[100][0] . $x_{100}$=위의 이미지 | . dls.train_ds[100][1] . TensorCategory(1) . $y_{100}=$TensorCategory(1) | . x100=dls.train_ds[100][0] . learn.predict(x100) . (&#39;sunmi&#39;, TensorBase(1), TensorBase([0.0015, 0.9985])) . Test . path=Path() . if not (path/&#39;test&#39;).exists(): (path/&#39;test&#39;).mkdir() . urls=search_images_ddg(&#39;sunmi 선미&#39;,max_n=20) download_images(path/&#39;test&#39;,urls=urls) testset=get_image_files(path/&#39;test&#39;) testset . (#20) [Path(&#39;test/00000010.jpg&#39;),Path(&#39;test/00000005.jpg&#39;),Path(&#39;test/00000013.jpg&#39;),Path(&#39;test/00000011.jpg&#39;),Path(&#39;test/00000003.jpg&#39;),Path(&#39;test/00000000.jpg&#39;),Path(&#39;test/00000004.jpg&#39;),Path(&#39;test/00000016.jpg&#39;),Path(&#39;test/00000012.jpg&#39;),Path(&#39;test/00000006.jpg&#39;)...] . for i in range(len(testset)): print(learn.predict(PILImage.create(testset[i]))) . (&#39;Hyuna&#39;, TensorBase(0), TensorBase([0.5452, 0.4548])) . (&#39;Hyuna&#39;, TensorBase(0), TensorBase([0.5311, 0.4689])) . (&#39;Hyuna&#39;, TensorBase(0), TensorBase([0.9941, 0.0059])) . (&#39;sunmi&#39;, TensorBase(1), TensorBase([0.0239, 0.9761])) . (&#39;sunmi&#39;, TensorBase(1), TensorBase([0.2874, 0.7126])) . (&#39;sunmi&#39;, TensorBase(1), TensorBase([0.2435, 0.7565])) . (&#39;sunmi&#39;, TensorBase(1), TensorBase([4.7129e-04, 9.9953e-01])) . (&#39;sunmi&#39;, TensorBase(1), TensorBase([0.0046, 0.9954])) . (&#39;sunmi&#39;, TensorBase(1), TensorBase([0.2166, 0.7834])) . (&#39;sunmi&#39;, TensorBase(1), TensorBase([0.0633, 0.9367])) . (&#39;Hyuna&#39;, TensorBase(0), TensorBase([0.9806, 0.0194])) . (&#39;Hyuna&#39;, TensorBase(0), TensorBase([9.9916e-01, 8.4005e-04])) . (&#39;Hyuna&#39;, TensorBase(0), TensorBase([0.9590, 0.0410])) . (&#39;sunmi&#39;, TensorBase(1), TensorBase([0.0581, 0.9419])) . (&#39;sunmi&#39;, TensorBase(1), TensorBase([5.8807e-04, 9.9941e-01])) . (&#39;sunmi&#39;, TensorBase(1), TensorBase([0.1369, 0.8631])) . (&#39;sunmi&#39;, TensorBase(1), TensorBase([0.1169, 0.8831])) . (&#39;sunmi&#39;, TensorBase(1), TensorBase([0.0784, 0.9216])) . (&#39;sunmi&#39;, TensorBase(1), TensorBase([7.0567e-07, 1.0000e+00])) . (&#39;Hyuna&#39;, TensorBase(0), TensorBase([0.7406, 0.2594])) . 결과를 보니까 sunmi이 많음 → 어느정도 맞추는것 같긴하다 | . PILImage.create(testset[1]) . 실제로 선미인데 현아로 예측한 사진 | . path=Path() . if not (path/&#39;test2&#39;).exists(): (path/&#39;test2&#39;).mkdir() . urls=search_images_ddg(&#39;hyuna 현아&#39;,max_n=20) download_images(path/&#39;test2&#39;,urls=urls) testset=get_image_files(path/&#39;test2&#39;) testset . (#19) [Path(&#39;test2/00000010.jpg&#39;),Path(&#39;test2/00000000.jpeg&#39;),Path(&#39;test2/00000005.jpg&#39;),Path(&#39;test2/00000013.jpg&#39;),Path(&#39;test2/00000011.jpg&#39;),Path(&#39;test2/00000003.jpg&#39;),Path(&#39;test2/00000018.jpeg&#39;),Path(&#39;test2/00000004.jpg&#39;),Path(&#39;test2/00000016.jpg&#39;),Path(&#39;test2/00000009.jpeg&#39;)...] . for i in range(len(testset)): print(learn.predict(PILImage.create(testset[i]))) . (&#39;Hyuna&#39;, TensorBase(0), TensorBase([1.0000e+00, 3.2445e-06])) . (&#39;sunmi&#39;, TensorBase(1), TensorBase([0.4499, 0.5501])) . (&#39;Hyuna&#39;, TensorBase(0), TensorBase([0.9945, 0.0055])) . (&#39;Hyuna&#39;, TensorBase(0), TensorBase([9.9906e-01, 9.4329e-04])) . (&#39;Hyuna&#39;, TensorBase(0), TensorBase([0.9759, 0.0241])) . (&#39;Hyuna&#39;, TensorBase(0), TensorBase([0.5947, 0.4053])) . (&#39;Hyuna&#39;, TensorBase(0), TensorBase([0.9765, 0.0235])) . (&#39;Hyuna&#39;, TensorBase(0), TensorBase([0.9819, 0.0181])) . (&#39;sunmi&#39;, TensorBase(1), TensorBase([0.3257, 0.6743])) . (&#39;Hyuna&#39;, TensorBase(0), TensorBase([0.9685, 0.0315])) . (&#39;Hyuna&#39;, TensorBase(0), TensorBase([9.9974e-01, 2.6368e-04])) . (&#39;Hyuna&#39;, TensorBase(0), TensorBase([0.9840, 0.0160])) . (&#39;Hyuna&#39;, TensorBase(0), TensorBase([9.9996e-01, 4.0536e-05])) . (&#39;sunmi&#39;, TensorBase(1), TensorBase([0.2522, 0.7478])) . (&#39;Hyuna&#39;, TensorBase(0), TensorBase([9.9949e-01, 5.0994e-04])) . (&#39;Hyuna&#39;, TensorBase(0), TensorBase([0.9084, 0.0916])) . (&#39;Hyuna&#39;, TensorBase(0), TensorBase([0.8650, 0.1350])) . (&#39;Hyuna&#39;, TensorBase(0), TensorBase([0.9987, 0.0013])) . (&#39;Hyuna&#39;, TensorBase(0), TensorBase([0.7162, 0.2838])) . 결과를 보니 Hyuna 역시 잘 맞추는 듯 보인다. | . - 정확률이 아쉽긴 하지만 어느정도 유의미한 결과를 얻었다. . PILImage.create(testset[1]) # 현아인데 선미로 예측한 사진 .",
            "url": "https://seoyeonc.github.io/chch/2021/11/13/_bd_2%EC%A3%BC%EC%B0%A8_1.html",
            "relUrl": "/2021/11/13/_bd_2%EC%A3%BC%EC%B0%A8_1.html",
            "date": " • Nov 13, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "빅데이터분석 (1주차) 21년9월7일",
            "content": "1&#51452;&#52264; 9&#50900; 7&#51068; . https://guebin.github.io/2021BDA/2021/09/07/(1%EC%A3%BC%EC%B0%A8)-9%EC%9B%947%EC%9D%BC.html . - (1/6): 아나콘다 가상환경 만들기, 파이토치 설치, 주피터랩 설치, conda install 과 pip install 의 차이 . - (2/6): 이미지 분석을 위한 데이터셋 준비 및 정리 . - (3/6): 학습 및 예측 . - (4/6): 코랩설명 + 깃허브/블로그 (뒷부분은 화면전환 오류로 설명이 부실함) . - (5/6): 코랩설명 + 깃허브/블로그 . - (6/6): 우리강아지 이미지를 활용한 예측 . from fastai.vision.all import * . fastai 깔기, error 뜬다면 런타임에서 GPU 변경 | !pip install --ungrade fastai | . path=untar_data(URLs.PETS)/&#39;images&#39; # To download model **pretrained** weights: . files=get_image_files(path) # 이미지파일들의 이름을 모두 복붙하여 리스트를 만든뒤에 files.txt로 저장하는 과정으로 비유할 수 있음 . files[2] # txt파일의 3번째 목록 . Path(&#39;/home/cgb4/.fastai/data/oxford-iiit-pet/images/leonberger_5.jpg&#39;) . def label_func(f): if f[0].isupper(): return &#39;cat&#39; else: return &#39;dog&#39; . 만일 f[0]파일 제목의 첫 글자가 대문자면 고양이, 소문자면 강아지로 반환 | 원래 있던 모델 | . label_func(&#39;asdf&#39;) # 소문자로 시작하니까 강아지로 리턴 . &#39;dog&#39; . dls=ImageDataLoaders.from_name_func(path,files,label_func,item_tfms=Resize(224)) . ImageDataLoaders.from_name_func(path, fnames, label_func, valid_pct=0.2, seed=None, item_tfms=None, batch_tfms=None, bs=64, val_bs=None, shuffle=True, device=None) . dls.show_batch(max_n=16) # 16개의 사진들을 보여줘라. . cnn_learner 사용 전 에러뜬다면 설치도 해주고~ . !conda install -c conda-forge jupyterlab_widgets -y . !conda install -c conda-forge ipywidgets -y . !conda install -c conda-forge nodejs -y . learn=cnn_learner(dls,resnet34,metrics=error_rate) . 모형이 만들어진 것. | Resnet34 is a 34 layer convolutional neural network(모형 이름) | metrics=error_rate 평가지표로 삼겠다 | cnn_learner(dls, arch, normalize=True, n_out=None, pretrained=True, config=None, loss_func=None, opt_func=Adam, lr=0.001, splitter=None, cbs=None, metrics=None, path=None, model_dir=&#39;models&#39;, wd=None, wd_bn_bias=False, train_bn=True, moms=(0.95, 0.85, 0.95), cut=None, n_in=3, init=kaimingnormal, custom_head=None, concat_pool=True, lin_ftrs=None, ps=0.5, first_bn=True, bn_final=False, lin_first=False, y_range=None) | . learn.fine_tune(1) . epoch train_loss valid_loss error_rate time . 0 | 0.154754 | 0.033434 | 0.006089 | 00:10 | . epoch train_loss valid_loss error_rate time . 0 | 0.061337 | 0.014634 | 0.004736 | 00:11 | . r과 달리 python은 object(learn) 만들어서 기능 세분화 후 분석 | 학습을 시키라는 뜻. | Learner.fine_tune(epochs, base_lr=0.002, freeze_epochs=1, lr_mult=100, pct_start=0.3, div=5.0, lr_max=None, div_final=100000.0, wd=None, moms=None, cbs=None, reset_opt=False) | . - 예측 . learn.predict(files[0]) # 파일중 첫 번째 사진 가져와라. . (&#39;dog&#39;, TensorBase(1), TensorBase([3.5456e-06, 1.0000e+00])) . output: (&#39;dog&#39;, tensor(1), tensor([6.1421e-07, 1.0000e+00])) | 이 파일은 개이며, tensor(1) 우리가 강아지는 1로 저장해놓놨음 tensor(확신 확률, loss확률) | Learner.predict(item, rm_type_tfms=None, with_input=False) | . learn.show_results() . - 오답분석 . interp = Interpretation.from_learner(learn) # Interpretation . interp.plot_top_losses(16) # 잘 틀리는 거 16개 뽑아서 보여주기 # 한 개 나온 결과는 이상한데..! . 1주차 4번째 . PILImage.create(&#39;502104_3008_164.png&#39;) # 귀여워.. . learn.predict(PILImage.create(&#39;502104_3008_164.png&#39;)) # 고양이 tensor=0 으로 잘 예측한 모습! . (&#39;cat&#39;, TensorBase(0), TensorBase([1.0000e+00, 1.4151e-11])) . PILImage.create(&#39;p1065602463397191_754_thum.jpg&#39;) # 너 누가 귀여우래.. . learn.predict(PILImage.create(&#39;p1065602463397191_754_thum.jpg&#39;)) # 잘 맞춘다! . (&#39;dog&#39;, TensorBase(1), TensorBase([0.0017, 0.9983])) . PILImage.create(&#39;601f57a1260000bd0c275eca.jpeg&#39;) # 귀여운 경태 . learn.predict(PILImage.create(&#39;601f57a1260000bd0c275eca.jpeg&#39;)) . (&#39;dog&#39;, TensorBase(1), TensorBase([2.4683e-04, 9.9975e-01])) .",
            "url": "https://seoyeonc.github.io/chch/2021/11/13/_bd_1%EC%A3%BC%EC%B0%A8.html",
            "relUrl": "/2021/11/13/_bd_1%EC%A3%BC%EC%B0%A8.html",
            "date": " • Nov 13, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "데이터 시각화 특강 (2주차) 9월13일",
            "content": "- (1/8): 박스플랏: 전북고예제 (평균은 좋은 측정값인가?) (숫자 무시~~) . - (2/8): 박스플랏 기본개념 . - (3/8): plotly . - (4/8): 히스토그램 . - (5/8): 히스토그램 2개 겹쳐서 비교하기 . - (7/8): 히스토그램 평활화 . - (8/8): 히스토그램 평활화 . import . import matplotlib.pyplot as plt import numpy as np . boxplot . &#51204;&#48513;&#44256;&#50696;&#51228;: &#54217;&#44512;&#51008; &#44316;&#52270;&#51008; &#52769;&#51221;&#44050;&#51064;&#44032;? . - 전북고등학교에서 통계학을 수업하는 두 선생님이 있다. 편의상 A선생님과 B선생님이라고 하자. A선생님이 강의한 반의 통계학 점수는 79.1점이고, B선생님이 강의한 반의 통계학 점수는 78.3점 이라고 하자. . - 의사결정: A선생님에게 배운 학생들의 실력이 평균적으로 좋을 것이다. . y1=[75,75,76,76,77,77,79,79,79,98] # A선생님에게 통계학을 배운 학생의 점수들 y2=[76,76,77,77,78,78,80,80,80,81] # B선생님에게 통계학을 배운 학생의 점수들 . np.mean(y1),np.mean(y2) . (79.1, 78.3) . - 평균은 A반(=A선생님에게 통계학을 배운 반)이 더 높다. 그런데 98점을 받은 학생때문에 전체평균이 올라간 것이고, 나머지 학생들은 전체적으로 B반 학생들이 점수가 더 높다고 해석할 수 있다. . - 단순한 평균비교보다 분포를 비교해보는 것이 중요하다. 분포를 살펴보는 방법 중 유용한 방법이 박스플랏이다. . plt.boxplot(y1) . {&#39;whiskers&#39;: [&lt;matplotlib.lines.Line2D at 0x7f6a8ef5e430&gt;, &lt;matplotlib.lines.Line2D at 0x7f6a8ef5e7c0&gt;], &#39;caps&#39;: [&lt;matplotlib.lines.Line2D at 0x7f6a8ef5eb50&gt;, &lt;matplotlib.lines.Line2D at 0x7f6a8ef5eee0&gt;], &#39;boxes&#39;: [&lt;matplotlib.lines.Line2D at 0x7f6a8ef5e0a0&gt;], &#39;medians&#39;: [&lt;matplotlib.lines.Line2D at 0x7f6a8ef672b0&gt;], &#39;fliers&#39;: [&lt;matplotlib.lines.Line2D at 0x7f6a8ef67640&gt;], &#39;means&#39;: []} . A반의 boxplot | 뚝 떨어진 하나의 점은 98점 | 붉은 선은 중앙값 (평균이 아니라 중앙값) | 나머지 점들은 7~80점에 분포되어있다. | . plt.boxplot(y2) . {&#39;whiskers&#39;: [&lt;matplotlib.lines.Line2D at 0x7f6a8eec0ac0&gt;, &lt;matplotlib.lines.Line2D at 0x7f6a8eec0e50&gt;], &#39;caps&#39;: [&lt;matplotlib.lines.Line2D at 0x7f6a8eecc220&gt;, &lt;matplotlib.lines.Line2D at 0x7f6a8eecc5b0&gt;], &#39;boxes&#39;: [&lt;matplotlib.lines.Line2D at 0x7f6a8eec0700&gt;], &#39;medians&#39;: [&lt;matplotlib.lines.Line2D at 0x7f6a8eecc940&gt;], &#39;fliers&#39;: [&lt;matplotlib.lines.Line2D at 0x7f6a8eecccd0&gt;], &#39;means&#39;: []} . B반의 boxplot | . - 아래와 같이 하면 박스플랏을 나란히 그릴 수 있다. . plt.boxplot([y1,y2]) # 묶어주는 것 잊지 말기.. . {&#39;whiskers&#39;: [&lt;matplotlib.lines.Line2D at 0x7f6a8eeb07c0&gt;, &lt;matplotlib.lines.Line2D at 0x7f6a8eeb0b50&gt;, &lt;matplotlib.lines.Line2D at 0x7f6a8ee47130&gt;, &lt;matplotlib.lines.Line2D at 0x7f6a8ee474c0&gt;], &#39;caps&#39;: [&lt;matplotlib.lines.Line2D at 0x7f6a8eeb0ee0&gt;, &lt;matplotlib.lines.Line2D at 0x7f6a8ee3c2b0&gt;, &lt;matplotlib.lines.Line2D at 0x7f6a8ee47850&gt;, &lt;matplotlib.lines.Line2D at 0x7f6a8ee47be0&gt;], &#39;boxes&#39;: [&lt;matplotlib.lines.Line2D at 0x7f6a8eeb0430&gt;, &lt;matplotlib.lines.Line2D at 0x7f6a8ee3cd60&gt;], &#39;medians&#39;: [&lt;matplotlib.lines.Line2D at 0x7f6a8ee3c640&gt;, &lt;matplotlib.lines.Line2D at 0x7f6a8ee47f70&gt;], &#39;fliers&#39;: [&lt;matplotlib.lines.Line2D at 0x7f6a8ee3c9d0&gt;, &lt;matplotlib.lines.Line2D at 0x7f6a8ee55340&gt;], &#39;means&#39;: []} . - 미적인 그래프는 아니지만 이정도는 괜찮은것 같다. . boxplot&#51060;&#46976;? . - ref: https://github.com/mGalarnyk/Python_Tutorials/blob/master/Statistics/boxplot/box_plot.ipynb . np.random.seed(916170) # connection path is here: https://stackoverflow.com/questions/6146290/plotting-a-line-over-several-graphs mu, sigma = 0, 1 # mean and standard deviation s = np.random.normal(mu, sigma, 1000) fig, axes = plt.subplots(nrows = 1, ncols = 1, figsize=(10, 5)) # rectangular box plot bplot = axes.boxplot(s, vert=False, patch_artist=True, showfliers=True, # This would show outliers (the remaining .7% of the data) positions = [0], boxprops = dict(linestyle=&#39;--&#39;, linewidth=2, color=&#39;Black&#39;, facecolor = &#39;red&#39;, alpha = .4), medianprops = dict(linestyle=&#39;-&#39;, linewidth=2, color=&#39;Yellow&#39;), whiskerprops = dict(linestyle=&#39;-&#39;, linewidth=2, color=&#39;Blue&#39;, alpha = .4), capprops = dict(linestyle=&#39;-&#39;, linewidth=2, color=&#39;Black&#39;), flierprops = dict(marker=&#39;o&#39;, markerfacecolor=&#39;green&#39;, markersize=10, linestyle=&#39;none&#39;, alpha = .4), widths = .3, zorder = 1) axes.set_xlim(-4, 4) plt.xticks(fontsize = 14) axes.set_yticks([]) axes.annotate(r&#39;&#39;, xy=(-.73, .205), xycoords=&#39;data&#39;, xytext=(.66, .205), textcoords=&#39;data&#39;, arrowprops=dict(arrowstyle=&quot;|-|&quot;, connectionstyle=&quot;arc3&quot;) ); axes.text(0, .25, &quot;Interquartile Range n(IQR)&quot;, horizontalalignment=&#39;center&#39;, fontsize=18) axes.text(0, -.21, r&quot;Median&quot;, horizontalalignment=&#39;center&#39;, fontsize=16); axes.text(2.65, -.15, &quot; &quot;Maximum &quot;&quot;, horizontalalignment=&#39;center&#39;, fontsize=18); axes.text(-2.65, -.15, &quot; &quot;Minimum &quot;&quot;, horizontalalignment=&#39;center&#39;, fontsize=18); axes.text(-.68, -.24, r&quot;Q1&quot;, horizontalalignment=&#39;center&#39;, fontsize=18); axes.text(-2.65, -.21, r&quot;(Q1 - 1.5*IQR)&quot;, horizontalalignment=&#39;center&#39;, fontsize=16); axes.text(.6745, -.24, r&quot;Q3&quot;, horizontalalignment=&#39;center&#39;, fontsize=18); axes.text(.6745, -.30, r&quot;(75th Percentile)&quot;, horizontalalignment=&#39;center&#39;, fontsize=12); axes.text(-.68, -.30, r&quot;(25th Percentile)&quot;, horizontalalignment=&#39;center&#39;, fontsize=12); axes.text(2.65, -.21, r&quot;(Q3 + 1.5*IQR)&quot;, horizontalalignment=&#39;center&#39;, fontsize=16); axes.annotate(&#39;Outliers&#39;, xy=(2.93,0.015), xytext=(2.52,0.20), fontsize = 18, arrowprops={&#39;arrowstyle&#39;: &#39;-&gt;&#39;, &#39;color&#39;: &#39;black&#39;, &#39;lw&#39;: 2}, va=&#39;center&#39;); axes.annotate(&#39;Outliers&#39;, xy=(-3.01,0.015), xytext=(-3.41,0.20), fontsize = 18, arrowprops={&#39;arrowstyle&#39;: &#39;-&gt;&#39;, &#39;color&#39;: &#39;black&#39;, &#39;lw&#39;: 2}, va=&#39;center&#39;); fig.tight_layout() . . 이상점은 동 떨어진 점들 | 1사분위부터 3사분위까지 박스로 나타냄! | 1사분위수 - 1.5IQR부터 3사분위수 + 1.5IQR까지 선으로 나타냄 | . plotly . !pip install plotly !pip install ipywidgets !pip install jupyter-dash !pip install dash !pip install pandas . import plotly.express as px import pandas as pd from IPython.display import HTML . A=pd.DataFrame({&#39;score&#39;:y1,&#39;class&#39;:[&#39;A&#39;]*len(y1)}) # score열에는 y1을 입력, class 열에는 A를 y1의 길이만큼 반복 B=pd.DataFrame({&#39;score&#39;:y2,&#39;class&#39;:[&#39;B&#39;]*len(y2)}) # score열에는 y2를 입력, class 열에는 B를 y2의 길이만큼 반복 . df=pd.concat([A,B],ignore_index=True) # ignore_index는 순서를 이어주는, 즉 각 데이터 셋의 순서 무시하기 df . score class . 0 75 | A | . 1 75 | A | . 2 76 | A | . 3 76 | A | . 4 77 | A | . 5 77 | A | . 6 79 | A | . 7 79 | A | . 8 79 | A | . 9 98 | A | . 10 76 | B | . 11 76 | B | . 12 77 | B | . 13 77 | B | . 14 78 | B | . 15 78 | B | . 16 80 | B | . 17 80 | B | . 18 80 | B | . 19 81 | B | . fig=px.box(data_frame=df, x=&#39;class&#39;,y=&#39;score&#39;) HTML(fig.to_html(include_plotlyjs=&#39;cdn&#39;,include_mathjax=False)) # 이거 해줘야 블로그 같은 곳에 나타남/ . . . histogram . &#55176;&#49828;&#53664;&#44536;&#47016;&#51060;&#46976;? . - X축이 변수의 구간, Y축은 그 구간에 포함된 빈도를 의미하는 그림 . - 예를들면 아래와 같음 . plt.hist(np.random.normal(loc=0, scale=1, size=1000000)) # 평균은 0이고 표준편차는 1인 1000000 사이즈의 랜덤 정규분포 . (array([2.40000e+01, 1.21000e+03, 2.13380e+04, 1.39948e+05, 3.51614e+05, 3.39662e+05, 1.27147e+05, 1.80510e+04, 9.87000e+02, 1.90000e+01]), array([-5.05590169, -4.03792348, -3.01994528, -2.00196708, -0.98398887, 0.03398933, 1.05196753, 2.06994573, 3.08792394, 4.10590214, 5.12388034]), &lt;BarContainer object of 10 artists&gt;) . &#51204;&#48513;&#44256;&#50696;&#51228; . - 중심경향값, 집중경향치 (Measure of central tendency): 분포의 중심성을 나타내기 위한 값, 예시로는 평균, 중앙값. . https://en.wikipedia.org/wiki/Central_tendency | . - &#39;평균이 항상 좋은 중심경향값은 아니다.&#39;라는 사실은 이해했음. . - 하지만 특수한 상황을 가정하면 평균이 좋은 중심경향값임 . np.random.seed(43052) y1=np.random.normal(loc=0,scale=1,size=10000) #전북고 A반의 통계학 성적이라 생각하자. y2=np.random.normal(loc=0.5,scale=1,size=10000) #전북고 B반의 통계학 성적이라 생각하자. . np.mean(y1), np.mean(y2) . (-0.011790879905079434, 0.4979147460611458) . (np.mean(y2)-np.mean(y1)).round(3) . 0.51 . plt.boxplot([y1,y2]) . {&#39;whiskers&#39;: [&lt;matplotlib.lines.Line2D at 0x7f6a86a419d0&gt;, &lt;matplotlib.lines.Line2D at 0x7f6a86a41d60&gt;, &lt;matplotlib.lines.Line2D at 0x7f6a86a59370&gt;, &lt;matplotlib.lines.Line2D at 0x7f6a86a59700&gt;], &#39;caps&#39;: [&lt;matplotlib.lines.Line2D at 0x7f6a86a4f130&gt;, &lt;matplotlib.lines.Line2D at 0x7f6a86a4f4c0&gt;, &lt;matplotlib.lines.Line2D at 0x7f6a86a59a90&gt;, &lt;matplotlib.lines.Line2D at 0x7f6a86a59e20&gt;], &#39;boxes&#39;: [&lt;matplotlib.lines.Line2D at 0x7f6a86a41640&gt;, &lt;matplotlib.lines.Line2D at 0x7f6a86a4ffa0&gt;], &#39;medians&#39;: [&lt;matplotlib.lines.Line2D at 0x7f6a86a4f880&gt;, &lt;matplotlib.lines.Line2D at 0x7f6a86a651f0&gt;], &#39;fliers&#39;: [&lt;matplotlib.lines.Line2D at 0x7f6a86a4fc10&gt;, &lt;matplotlib.lines.Line2D at 0x7f6a86a65580&gt;], &#39;means&#39;: []} . 분포의 모양이 거의 비슷하고, 왼쪽그림을 거의 컨트롤+C,V 오른쪽에 붙인다음 위치조정을 한 느낌 | 이런상황에서는 $B반의 성적 approx A반의 성적 + 0.51$ 라고 주장해도 큰 무리가 없음. | . - 정규분포인것은 어떻게 아는가? $ to$ 히스토그램을 그려보아서 종 모양이 나오는지 살펴보자. . plt.hist(y1,bins=50) # 50개의 구간으로 나누어서 히스토그램을 그릴것 . (array([ 1., 1., 3., 0., 1., 4., 5., 12., 14., 26., 32., 52., 67., 89., 144., 171., 238., 282., 325., 378., 489., 492., 561., 635., 652., 636., 626., 606., 573., 539., 475., 444., 350., 250., 232., 172., 137., 80., 58., 47., 30., 23., 17., 12., 9., 4., 4., 0., 1., 1.]), array([-4.12186916, -3.96068404, -3.79949892, -3.6383138 , -3.47712868, -3.31594356, -3.15475844, -2.99357332, -2.8323882 , -2.67120308, -2.51001796, -2.34883284, -2.18764772, -2.0264626 , -1.86527748, -1.70409236, -1.54290724, -1.38172212, -1.220537 , -1.05935188, -0.89816676, -0.73698164, -0.57579652, -0.4146114 , -0.25342628, -0.09224116, 0.06894396, 0.23012908, 0.3913142 , 0.55249932, 0.71368444, 0.87486956, 1.03605468, 1.1972398 , 1.35842492, 1.51961004, 1.68079516, 1.84198028, 2.0031654 , 2.16435052, 2.32553564, 2.48672076, 2.64790588, 2.809091 , 2.97027612, 3.13146124, 3.29264636, 3.45383148, 3.6150166 , 3.77620172, 3.93738684]), &lt;BarContainer object of 50 artists&gt;) . plt.hist(y2,bins=50) . (array([ 1., 0., 3., 2., 4., 5., 5., 10., 16., 25., 33., 56., 74., 116., 119., 152., 244., 272., 351., 362., 438., 509., 531., 621., 624., 690., 636., 571., 564., 514., 462., 402., 356., 297., 233., 184., 144., 113., 80., 55., 38., 34., 21., 18., 4., 3., 2., 4., 1., 1.]), array([-3.5752867 , -3.4164866 , -3.2576865 , -3.0988864 , -2.9400863 , -2.7812862 , -2.6224861 , -2.463686 , -2.3048859 , -2.1460858 , -1.9872857 , -1.8284856 , -1.6696855 , -1.5108854 , -1.3520853 , -1.1932852 , -1.0344851 , -0.875685 , -0.7168849 , -0.5580848 , -0.3992847 , -0.2404846 , -0.0816845 , 0.0771156 , 0.2359157 , 0.3947158 , 0.5535159 , 0.712316 , 0.87111611, 1.02991621, 1.18871631, 1.34751641, 1.50631651, 1.66511661, 1.82391671, 1.98271681, 2.14151691, 2.30031701, 2.45911711, 2.61791721, 2.77671731, 2.93551741, 3.09431751, 3.25311761, 3.41191771, 3.57071781, 3.72951791, 3.88831801, 4.04711811, 4.20591821, 4.36471831]), &lt;BarContainer object of 50 artists&gt;) . plt.hist([y1,y2],bins=200) # 히스토그램 겹쳐 그리기 . (array([[ 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 2., 1., 0., 1., 1., 3., 4., 4., 2., 2., 6., 4., 1., 4., 7., 8., 9., 11., 5., 9., 9., 14., 12., 16., 11., 9., 18., 25., 30., 22., 18., 28., 29., 39., 40., 41., 37., 42., 48., 56., 58., 49., 80., 62., 62., 91., 78., 75., 82., 89., 81., 106., 85., 89., 126., 125., 106., 142., 141., 121., 121., 135., 154., 166., 146., 125., 169., 160., 170., 172., 162., 161., 161., 193., 146., 186., 170., 166., 197., 152., 149., 167., 173., 158., 155., 156., 153., 152., 137., 151., 147., 126., 141., 125., 139., 117., 116., 135., 118., 93., 115., 99., 78., 91., 77., 63., 81., 52., 83., 53., 61., 49., 46., 46., 47., 45., 26., 48., 31., 27., 27., 20., 17., 22., 15., 15., 14., 14., 15., 10., 8., 13., 7., 5., 8., 6., 6., 6., 2., 4., 9., 3., 3., 6., 2., 1., 4., 2., 2., 2., 2., 0., 1., 1., 2., 2., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [ 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 3., 1., 2., 1., 1., 1., 2., 1., 2., 2., 1., 6., 1., 6., 3., 7., 7., 5., 6., 10., 5., 7., 16., 9., 11., 13., 28., 21., 16., 20., 27., 25., 32., 33., 28., 31., 31., 39., 42., 34., 43., 44., 64., 56., 80., 64., 74., 77., 69., 82., 92., 101., 99., 81., 90., 115., 110., 106., 108., 127., 127., 138., 145., 138., 121., 159., 135., 145., 156., 186., 158., 164., 172., 182., 147., 194., 178., 176., 195., 162., 182., 164., 164., 163., 145., 150., 143., 155., 144., 142., 161., 141., 146., 129., 115., 132., 120., 118., 128., 103., 88., 111., 104., 97., 82., 77., 83., 83., 80., 77., 67., 58., 48., 47., 54., 50., 43., 36., 43., 33., 33., 42., 29., 24., 28., 19., 22., 16., 18., 14., 14., 11., 10., 9., 7., 12., 10., 8., 8., 9., 4., 7., 4., 6., 3., 8., 1., 1., 1., 0., 1., 0., 2., 1., 0., 2., 0., 0., 2., 2., 0., 0., 0., 0., 1., 0., 0., 0., 1.]]), array([-4.12186916, -4.07943623, -4.03700329, -3.99457035, -3.95213741, -3.90970448, -3.86727154, -3.8248386 , -3.78240567, -3.73997273, -3.69753979, -3.65510685, -3.61267392, -3.57024098, -3.52780804, -3.4853751 , -3.44294217, -3.40050923, -3.35807629, -3.31564335, -3.27321042, -3.23077748, -3.18834454, -3.1459116 , -3.10347867, -3.06104573, -3.01861279, -2.97617986, -2.93374692, -2.89131398, -2.84888104, -2.80644811, -2.76401517, -2.72158223, -2.67914929, -2.63671636, -2.59428342, -2.55185048, -2.50941754, -2.46698461, -2.42455167, -2.38211873, -2.33968579, -2.29725286, -2.25481992, -2.21238698, -2.16995405, -2.12752111, -2.08508817, -2.04265523, -2.0002223 , -1.95778936, -1.91535642, -1.87292348, -1.83049055, -1.78805761, -1.74562467, -1.70319173, -1.6607588 , -1.61832586, -1.57589292, -1.53345998, -1.49102705, -1.44859411, -1.40616117, -1.36372824, -1.3212953 , -1.27886236, -1.23642942, -1.19399649, -1.15156355, -1.10913061, -1.06669767, -1.02426474, -0.9818318 , -0.93939886, -0.89696592, -0.85453299, -0.81210005, -0.76966711, -0.72723417, -0.68480124, -0.6423683 , -0.59993536, -0.55750243, -0.51506949, -0.47263655, -0.43020361, -0.38777068, -0.34533774, -0.3029048 , -0.26047186, -0.21803893, -0.17560599, -0.13317305, -0.09074011, -0.04830718, -0.00587424, 0.0365587 , 0.07899164, 0.12142457, 0.16385751, 0.20629045, 0.24872338, 0.29115632, 0.33358926, 0.3760222 , 0.41845513, 0.46088807, 0.50332101, 0.54575395, 0.58818688, 0.63061982, 0.67305276, 0.7154857 , 0.75791863, 0.80035157, 0.84278451, 0.88521744, 0.92765038, 0.97008332, 1.01251626, 1.05494919, 1.09738213, 1.13981507, 1.18224801, 1.22468094, 1.26711388, 1.30954682, 1.35197976, 1.39441269, 1.43684563, 1.47927857, 1.52171151, 1.56414444, 1.60657738, 1.64901032, 1.69144325, 1.73387619, 1.77630913, 1.81874207, 1.861175 , 1.90360794, 1.94604088, 1.98847382, 2.03090675, 2.07333969, 2.11577263, 2.15820557, 2.2006385 , 2.24307144, 2.28550438, 2.32793732, 2.37037025, 2.41280319, 2.45523613, 2.49766906, 2.540102 , 2.58253494, 2.62496788, 2.66740081, 2.70983375, 2.75226669, 2.79469963, 2.83713256, 2.8795655 , 2.92199844, 2.96443138, 3.00686431, 3.04929725, 3.09173019, 3.13416313, 3.17659606, 3.219029 , 3.26146194, 3.30389487, 3.34632781, 3.38876075, 3.43119369, 3.47362662, 3.51605956, 3.5584925 , 3.60092544, 3.64335837, 3.68579131, 3.72822425, 3.77065719, 3.81309012, 3.85552306, 3.897956 , 3.94038894, 3.98282187, 4.02525481, 4.06768775, 4.11012068, 4.15255362, 4.19498656, 4.2374195 , 4.27985243, 4.32228537, 4.36471831]), &lt;a list of 2 BarContainer objects&gt;) . seaborn . import seaborn as sns . A=pd.DataFrame({&#39;score&#39;:y1,&#39;class&#39;:[&#39;A&#39;]*len(y1)}) B=pd.DataFrame({&#39;score&#39;:y2,&#39;class&#39;:[&#39;B&#39;]*len(y2)}) df=pd.concat([A,B],ignore_index=True) . sns.histplot(df,x=&#39;score&#39;,hue=&#39;class&#39;) . &lt;AxesSubplot:xlabel=&#39;score&#39;, ylabel=&#39;Count&#39;&gt; . plotnine . from plotnine import * . ggplot(df)+geom_histogram(aes(x=&#39;score&#39;,fill=&#39;class&#39;),position=&#39;identity&#39;,alpha=0.5) . /home/cgb4/anaconda3/envs/csy/lib/python3.8/site-packages/plotnine/stats/stat_bin.py:95: PlotnineWarning: &#39;stat_bin()&#39; using &#39;bins = 84&#39;. Pick better value with &#39;binwidth&#39;. . &lt;ggplot: (8755886288517)&gt; . plotly . - 인터랙티브 그래프를 위해서 plotly 홈페이지를 방문하여 적당한 코드를 가져온다. . import plotly.figure_factory as ff import numpy as np . hist_data=[y1,y2] group_labels=[&#39;A&#39;,&#39;B&#39;] fig = ff.create_distplot(hist_data, group_labels,bin_size=.2, show_rug=False) HTML(fig.to_html(include_plotlyjs=&#39;cdn&#39;,include_mathjax=False)) . . . [&#49689;&#51228;1] . (1) 자기학번으로 np.random.seed(202043052)를 만들고 . (2) y1, y2 // 10만개의 정규분포를 생성해서 저장 . y1: 평균 0, 표준편차=1 | y2: 평균 1, 표준편차=1 | . (3) plotly 를 활용하여 히스토그램을 겹쳐서 그려보는것. . np.random.seed(202150754) y1=np.random.normal(loc=0,scale=1,size=100000) y2=np.random.normal(loc=1,scale=1,size=100000) plt.hist([y1,y2],bins=200) . (array([[1.000e+00, 0.000e+00, 2.000e+00, 1.000e+00, 0.000e+00, 4.000e+00, 0.000e+00, 1.000e+00, 2.000e+00, 4.000e+00, 2.000e+00, 1.000e+00, 7.000e+00, 1.000e+00, 7.000e+00, 6.000e+00, 7.000e+00, 9.000e+00, 1.200e+01, 4.000e+00, 1.100e+01, 1.500e+01, 1.800e+01, 1.900e+01, 2.900e+01, 3.500e+01, 3.300e+01, 3.700e+01, 5.100e+01, 5.100e+01, 6.800e+01, 6.900e+01, 8.300e+01, 8.400e+01, 8.700e+01, 9.400e+01, 1.140e+02, 1.360e+02, 1.450e+02, 1.580e+02, 1.840e+02, 1.850e+02, 2.180e+02, 2.580e+02, 2.700e+02, 2.850e+02, 2.990e+02, 3.320e+02, 3.800e+02, 4.060e+02, 4.270e+02, 5.110e+02, 4.850e+02, 5.380e+02, 6.160e+02, 6.140e+02, 6.540e+02, 7.110e+02, 8.180e+02, 8.170e+02, 8.610e+02, 9.200e+02, 8.990e+02, 9.870e+02, 1.033e+03, 1.116e+03, 1.152e+03, 1.177e+03, 1.252e+03, 1.302e+03, 1.382e+03, 1.430e+03, 1.494e+03, 1.466e+03, 1.572e+03, 1.596e+03, 1.597e+03, 1.632e+03, 1.671e+03, 1.699e+03, 1.755e+03, 1.820e+03, 1.760e+03, 1.796e+03, 1.834e+03, 1.800e+03, 1.936e+03, 1.901e+03, 1.821e+03, 1.899e+03, 1.803e+03, 1.722e+03, 1.673e+03, 1.756e+03, 1.743e+03, 1.728e+03, 1.697e+03, 1.693e+03, 1.594e+03, 1.506e+03, 1.486e+03, 1.529e+03, 1.438e+03, 1.392e+03, 1.394e+03, 1.304e+03, 1.286e+03, 1.232e+03, 1.129e+03, 1.138e+03, 1.029e+03, 1.005e+03, 9.240e+02, 8.700e+02, 8.540e+02, 8.140e+02, 7.090e+02, 7.270e+02, 6.440e+02, 5.890e+02, 5.790e+02, 5.650e+02, 4.890e+02, 4.300e+02, 4.550e+02, 4.110e+02, 3.190e+02, 3.450e+02, 2.970e+02, 2.880e+02, 2.530e+02, 2.410e+02, 2.000e+02, 1.730e+02, 1.620e+02, 1.540e+02, 1.570e+02, 1.320e+02, 1.120e+02, 9.500e+01, 8.100e+01, 8.600e+01, 8.200e+01, 7.200e+01, 6.700e+01, 4.400e+01, 4.500e+01, 4.500e+01, 2.800e+01, 2.000e+01, 2.400e+01, 2.800e+01, 2.000e+01, 2.500e+01, 8.000e+00, 1.500e+01, 1.000e+01, 7.000e+00, 1.000e+01, 7.000e+00, 3.000e+00, 9.000e+00, 4.000e+00, 3.000e+00, 3.000e+00, 1.000e+00, 4.000e+00, 1.000e+00, 0.000e+00, 1.000e+00, 1.000e+00, 0.000e+00, 1.000e+00, 1.000e+00, 0.000e+00, 2.000e+00, 0.000e+00, 1.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00], [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 1.000e+00, 1.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 1.000e+00, 1.000e+00, 0.000e+00, 2.000e+00, 1.000e+00, 1.000e+00, 2.000e+00, 1.000e+00, 1.000e+00, 3.000e+00, 3.000e+00, 2.000e+00, 3.000e+00, 6.000e+00, 3.000e+00, 9.000e+00, 1.000e+01, 1.100e+01, 6.000e+00, 9.000e+00, 1.300e+01, 1.800e+01, 1.500e+01, 1.600e+01, 3.600e+01, 2.300e+01, 2.800e+01, 3.300e+01, 4.300e+01, 6.500e+01, 6.000e+01, 7.000e+01, 7.600e+01, 7.000e+01, 6.600e+01, 9.400e+01, 1.060e+02, 1.300e+02, 1.440e+02, 1.430e+02, 1.630e+02, 1.900e+02, 1.890e+02, 2.410e+02, 2.540e+02, 2.720e+02, 2.990e+02, 3.860e+02, 3.220e+02, 3.970e+02, 4.100e+02, 4.230e+02, 4.590e+02, 5.070e+02, 5.340e+02, 6.230e+02, 6.520e+02, 7.010e+02, 6.890e+02, 7.730e+02, 7.950e+02, 8.880e+02, 9.260e+02, 9.080e+02, 1.016e+03, 1.065e+03, 1.098e+03, 1.203e+03, 1.194e+03, 1.307e+03, 1.287e+03, 1.367e+03, 1.408e+03, 1.528e+03, 1.516e+03, 1.550e+03, 1.615e+03, 1.593e+03, 1.610e+03, 1.730e+03, 1.784e+03, 1.786e+03, 1.804e+03, 1.800e+03, 1.802e+03, 1.748e+03, 1.817e+03, 1.796e+03, 1.862e+03, 1.837e+03, 1.776e+03, 1.794e+03, 1.798e+03, 1.770e+03, 1.723e+03, 1.779e+03, 1.712e+03, 1.688e+03, 1.694e+03, 1.524e+03, 1.563e+03, 1.566e+03, 1.514e+03, 1.405e+03, 1.329e+03, 1.360e+03, 1.286e+03, 1.271e+03, 1.131e+03, 1.146e+03, 1.054e+03, 1.044e+03, 9.620e+02, 9.050e+02, 9.360e+02, 8.110e+02, 8.290e+02, 7.080e+02, 7.530e+02, 6.310e+02, 6.010e+02, 5.700e+02, 5.130e+02, 5.080e+02, 4.610e+02, 4.150e+02, 3.810e+02, 3.520e+02, 3.380e+02, 3.040e+02, 2.550e+02, 2.550e+02, 2.160e+02, 2.090e+02, 1.810e+02, 1.650e+02, 1.430e+02, 1.410e+02, 1.200e+02, 1.080e+02, 8.400e+01, 9.200e+01, 7.800e+01, 7.500e+01, 7.500e+01, 5.500e+01, 4.300e+01, 4.700e+01, 4.200e+01, 4.300e+01, 3.700e+01, 1.900e+01, 3.000e+01, 2.100e+01, 1.800e+01, 1.400e+01, 8.000e+00, 1.400e+01, 1.100e+01, 7.000e+00, 5.000e+00, 7.000e+00, 4.000e+00, 5.000e+00, 2.000e+00, 2.000e+00, 4.000e+00, 3.000e+00, 1.000e+00, 0.000e+00, 0.000e+00, 1.000e+00, 2.000e+00, 1.000e+00, 0.000e+00, 1.000e+00, 0.000e+00, 0.000e+00, 1.000e+00]]), array([-4.03250572, -3.98635668, -3.94020763, -3.89405858, -3.84790954, -3.80176049, -3.75561144, -3.7094624 , -3.66331335, -3.6171643 , -3.57101526, -3.52486621, -3.47871716, -3.43256812, -3.38641907, -3.34027002, -3.29412098, -3.24797193, -3.20182288, -3.15567384, -3.10952479, -3.06337574, -3.0172267 , -2.97107765, -2.92492861, -2.87877956, -2.83263051, -2.78648147, -2.74033242, -2.69418337, -2.64803433, -2.60188528, -2.55573623, -2.50958719, -2.46343814, -2.41728909, -2.37114005, -2.324991 , -2.27884195, -2.23269291, -2.18654386, -2.14039481, -2.09424577, -2.04809672, -2.00194767, -1.95579863, -1.90964958, -1.86350053, -1.81735149, -1.77120244, -1.7250534 , -1.67890435, -1.6327553 , -1.58660626, -1.54045721, -1.49430816, -1.44815912, -1.40201007, -1.35586102, -1.30971198, -1.26356293, -1.21741388, -1.17126484, -1.12511579, -1.07896674, -1.0328177 , -0.98666865, -0.9405196 , -0.89437056, -0.84822151, -0.80207246, -0.75592342, -0.70977437, -0.66362533, -0.61747628, -0.57132723, -0.52517819, -0.47902914, -0.43288009, -0.38673105, -0.340582 , -0.29443295, -0.24828391, -0.20213486, -0.15598581, -0.10983677, -0.06368772, -0.01753867, 0.02861037, 0.07475942, 0.12090847, 0.16705751, 0.21320656, 0.25935561, 0.30550465, 0.3516537 , 0.39780274, 0.44395179, 0.49010084, 0.53624988, 0.58239893, 0.62854798, 0.67469702, 0.72084607, 0.76699512, 0.81314416, 0.85929321, 0.90544226, 0.9515913 , 0.99774035, 1.0438894 , 1.09003844, 1.13618749, 1.18233654, 1.22848558, 1.27463463, 1.32078368, 1.36693272, 1.41308177, 1.45923081, 1.50537986, 1.55152891, 1.59767795, 1.643827 , 1.68997605, 1.73612509, 1.78227414, 1.82842319, 1.87457223, 1.92072128, 1.96687033, 2.01301937, 2.05916842, 2.10531747, 2.15146651, 2.19761556, 2.24376461, 2.28991365, 2.3360627 , 2.38221175, 2.42836079, 2.47450984, 2.52065889, 2.56680793, 2.61295698, 2.65910602, 2.70525507, 2.75140412, 2.79755316, 2.84370221, 2.88985126, 2.9360003 , 2.98214935, 3.0282984 , 3.07444744, 3.12059649, 3.16674554, 3.21289458, 3.25904363, 3.30519268, 3.35134172, 3.39749077, 3.44363982, 3.48978886, 3.53593791, 3.58208696, 3.628236 , 3.67438505, 3.72053409, 3.76668314, 3.81283219, 3.85898123, 3.90513028, 3.95127933, 3.99742837, 4.04357742, 4.08972647, 4.13587551, 4.18202456, 4.22817361, 4.27432265, 4.3204717 , 4.36662075, 4.41276979, 4.45891884, 4.50506789, 4.55121693, 4.59736598, 4.64351503, 4.68966407, 4.73581312, 4.78196216, 4.82811121, 4.87426026, 4.9204093 , 4.96655835, 5.0127074 , 5.05885644, 5.10500549, 5.15115454, 5.19730358]), &lt;a list of 2 BarContainer objects&gt;) . Histogram Equalization, HE . - ref: https://en.wikipedia.org/wiki/Histogram_equalization . - 히스토그램 평활화: 이미지의 명암대비 개선 . !pip install opencv-python . import cv2 as cv import matplotlib.pyplot as plt import pandas as pd . img = cv.imread(&#39;Unequalized_Hawkes_Bay_NZ.jpg&#39;,0) . plt.imshow(img,cmap=&#39;gray&#39;,vmin=0,vmax=255) plt.colorbar() . &lt;matplotlib.colorbar.Colorbar at 0x7f6a713a2280&gt; . - 이미지자료는 사실 0~255 사이의 어떠한 숫자들이 포함된 매트릭스일 뿐이다. . img . array([[127, 145, 149, ..., 168, 167, 166], [165, 152, 143, ..., 168, 169, 168], [171, 145, 140, ..., 156, 154, 151], ..., [147, 132, 134, ..., 146, 145, 144], [146, 130, 132, ..., 146, 145, 144], [145, 128, 129, ..., 146, 145, 144]], dtype=uint8) . 확인: 이미지가 있다고 믿었던 img는 그냥 넘파이 매트릭스 | 위의 매트릭스에 있는 숫자들을 색깔로 표현하여 값이 클수록 하얗게, 값이 작을수록 검게 그린다. 극단적으로 0은 검은색, 255는 흰색이다. | . - 이미지가 넘파이 매트릭스일 뿐이라는 것을 판다스를 활용하면 더 잘 시각화하여 이해할 수 있다. . plt.imshow(img[200:300,400:500],cmap=&#39;gray&#39;,vmin=0,vmax=255) . &lt;matplotlib.image.AxesImage at 0x7fb294190bb0&gt; . df=pd.DataFrame(img) df.iloc[200:300,400:500].style.set_properties(**{&#39;font-size&#39;:&#39;10pt&#39;}).background_gradient(&#39;gray&#39;,vmin=0,vmax=255) . &nbsp; 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 . 200 155 | 155 | 151 | 149 | 152 | 152 | 151 | 152 | 152 | 152 | 152 | 153 | 154 | 155 | 157 | 158 | 164 | 157 | 150 | 148 | 146 | 143 | 139 | 138 | 138 | 140 | 142 | 140 | 138 | 137 | 137 | 137 | 131 | 142 | 147 | 143 | 143 | 150 | 153 | 151 | 149 | 148 | 146 | 143 | 141 | 141 | 142 | 143 | 143 | 143 | 140 | 138 | 137 | 138 | 136 | 133 | 133 | 134 | 133 | 131 | 128 | 127 | 129 | 131 | 128 | 129 | 132 | 129 | 130 | 129 | 125 | 131 | 128 | 128 | 128 | 130 | 132 | 133 | 132 | 131 | 137 | 136 | 135 | 138 | 140 | 133 | 127 | 129 | 132 | 130 | 130 | 132 | 135 | 135 | 134 | 134 | 137 | 138 | 137 | 134 | . 201 139 | 148 | 152 | 149 | 145 | 142 | 147 | 156 | 150 | 152 | 154 | 154 | 153 | 153 | 155 | 157 | 158 | 159 | 155 | 149 | 144 | 142 | 139 | 136 | 138 | 139 | 140 | 139 | 137 | 136 | 136 | 137 | 141 | 140 | 139 | 141 | 147 | 152 | 152 | 150 | 151 | 150 | 149 | 147 | 145 | 143 | 143 | 143 | 141 | 142 | 142 | 141 | 141 | 141 | 138 | 134 | 133 | 132 | 132 | 131 | 130 | 131 | 133 | 135 | 128 | 128 | 132 | 130 | 132 | 131 | 126 | 132 | 129 | 129 | 128 | 129 | 130 | 132 | 132 | 133 | 137 | 135 | 132 | 133 | 134 | 129 | 126 | 130 | 129 | 129 | 131 | 133 | 134 | 133 | 134 | 136 | 136 | 137 | 137 | 135 | . 202 138 | 145 | 149 | 149 | 149 | 144 | 138 | 139 | 144 | 148 | 153 | 155 | 153 | 152 | 153 | 155 | 153 | 158 | 157 | 147 | 140 | 140 | 139 | 136 | 137 | 135 | 135 | 137 | 137 | 135 | 134 | 136 | 142 | 138 | 139 | 145 | 147 | 144 | 145 | 151 | 150 | 150 | 151 | 150 | 149 | 147 | 145 | 143 | 140 | 140 | 140 | 140 | 140 | 141 | 139 | 135 | 133 | 131 | 129 | 128 | 129 | 130 | 132 | 133 | 128 | 128 | 131 | 131 | 134 | 133 | 128 | 133 | 132 | 132 | 131 | 130 | 129 | 131 | 133 | 135 | 133 | 132 | 129 | 129 | 132 | 131 | 133 | 140 | 135 | 136 | 137 | 137 | 134 | 131 | 131 | 134 | 135 | 136 | 136 | 136 | . 203 152 | 151 | 148 | 150 | 156 | 152 | 141 | 134 | 137 | 141 | 147 | 151 | 152 | 152 | 153 | 154 | 152 | 155 | 153 | 144 | 137 | 138 | 139 | 139 | 134 | 130 | 130 | 134 | 135 | 133 | 133 | 136 | 133 | 132 | 137 | 146 | 147 | 141 | 141 | 147 | 146 | 147 | 148 | 149 | 150 | 149 | 147 | 145 | 143 | 142 | 140 | 137 | 137 | 139 | 139 | 137 | 136 | 133 | 129 | 127 | 127 | 128 | 128 | 128 | 129 | 127 | 130 | 129 | 133 | 134 | 130 | 136 | 136 | 136 | 134 | 132 | 130 | 131 | 133 | 135 | 132 | 133 | 132 | 133 | 137 | 137 | 140 | 147 | 144 | 143 | 142 | 140 | 137 | 133 | 134 | 136 | 136 | 136 | 135 | 135 | . 204 155 | 156 | 153 | 151 | 153 | 153 | 152 | 155 | 141 | 141 | 142 | 144 | 147 | 149 | 151 | 151 | 153 | 152 | 149 | 145 | 140 | 137 | 138 | 140 | 133 | 130 | 129 | 131 | 132 | 131 | 132 | 134 | 130 | 127 | 130 | 139 | 147 | 147 | 144 | 141 | 144 | 144 | 144 | 146 | 147 | 147 | 147 | 146 | 147 | 146 | 143 | 140 | 139 | 140 | 139 | 137 | 138 | 134 | 130 | 127 | 128 | 129 | 129 | 128 | 129 | 127 | 129 | 127 | 131 | 134 | 131 | 139 | 139 | 138 | 136 | 133 | 131 | 130 | 132 | 134 | 137 | 140 | 141 | 141 | 143 | 140 | 139 | 143 | 145 | 141 | 138 | 139 | 140 | 141 | 142 | 144 | 138 | 136 | 134 | 133 | . 205 145 | 151 | 152 | 153 | 154 | 152 | 152 | 156 | 151 | 147 | 141 | 139 | 141 | 144 | 147 | 148 | 151 | 149 | 149 | 148 | 145 | 138 | 135 | 136 | 134 | 133 | 131 | 130 | 130 | 130 | 131 | 132 | 134 | 133 | 134 | 136 | 139 | 142 | 143 | 143 | 145 | 144 | 142 | 143 | 144 | 145 | 144 | 144 | 146 | 146 | 145 | 143 | 141 | 140 | 137 | 133 | 134 | 131 | 127 | 126 | 128 | 129 | 130 | 129 | 129 | 128 | 130 | 127 | 130 | 133 | 132 | 141 | 140 | 138 | 136 | 133 | 130 | 130 | 132 | 133 | 139 | 143 | 143 | 143 | 145 | 141 | 137 | 139 | 144 | 138 | 134 | 136 | 141 | 144 | 145 | 145 | 141 | 137 | 134 | 134 | . 206 143 | 147 | 149 | 151 | 155 | 152 | 146 | 145 | 154 | 151 | 146 | 143 | 142 | 143 | 144 | 145 | 144 | 146 | 147 | 146 | 142 | 138 | 136 | 134 | 133 | 135 | 134 | 130 | 129 | 132 | 134 | 134 | 135 | 136 | 137 | 136 | 133 | 135 | 142 | 150 | 147 | 145 | 143 | 143 | 144 | 145 | 144 | 143 | 145 | 145 | 144 | 142 | 141 | 140 | 136 | 132 | 130 | 128 | 126 | 126 | 127 | 128 | 129 | 129 | 129 | 129 | 131 | 129 | 130 | 133 | 133 | 143 | 143 | 139 | 135 | 132 | 131 | 132 | 134 | 136 | 138 | 141 | 140 | 139 | 142 | 141 | 139 | 140 | 143 | 137 | 133 | 136 | 141 | 143 | 143 | 142 | 143 | 139 | 136 | 136 | . 207 148 | 151 | 150 | 149 | 151 | 150 | 149 | 151 | 150 | 150 | 151 | 150 | 148 | 145 | 144 | 144 | 137 | 144 | 145 | 139 | 135 | 137 | 138 | 135 | 131 | 136 | 136 | 130 | 129 | 135 | 138 | 137 | 134 | 129 | 128 | 132 | 137 | 140 | 146 | 153 | 147 | 145 | 144 | 144 | 145 | 146 | 145 | 143 | 147 | 147 | 144 | 142 | 141 | 141 | 139 | 136 | 132 | 131 | 129 | 128 | 128 | 128 | 128 | 129 | 128 | 130 | 133 | 131 | 131 | 133 | 133 | 144 | 145 | 141 | 135 | 132 | 132 | 135 | 138 | 140 | 141 | 141 | 137 | 135 | 139 | 140 | 139 | 140 | 139 | 135 | 133 | 136 | 141 | 143 | 143 | 143 | 144 | 140 | 137 | 138 | . 208 150 | 148 | 151 | 145 | 143 | 147 | 148 | 153 | 158 | 153 | 150 | 152 | 149 | 143 | 141 | 144 | 145 | 145 | 144 | 142 | 140 | 137 | 133 | 131 | 130 | 133 | 131 | 130 | 137 | 143 | 140 | 135 | 141 | 139 | 130 | 134 | 147 | 142 | 135 | 144 | 147 | 143 | 146 | 148 | 144 | 146 | 149 | 144 | 148 | 144 | 140 | 141 | 143 | 144 | 141 | 137 | 132 | 128 | 126 | 127 | 128 | 127 | 125 | 125 | 128 | 127 | 129 | 135 | 138 | 138 | 138 | 139 | 138 | 133 | 129 | 130 | 133 | 135 | 138 | 140 | 140 | 136 | 135 | 137 | 138 | 136 | 136 | 139 | 139 | 137 | 137 | 138 | 139 | 140 | 141 | 143 | 141 | 144 | 143 | 143 | . 209 153 | 147 | 147 | 143 | 144 | 147 | 144 | 146 | 150 | 149 | 150 | 152 | 153 | 151 | 146 | 143 | 142 | 142 | 141 | 139 | 137 | 135 | 134 | 134 | 133 | 131 | 130 | 129 | 130 | 132 | 134 | 133 | 136 | 139 | 137 | 130 | 132 | 146 | 151 | 142 | 145 | 146 | 153 | 156 | 154 | 156 | 156 | 149 | 145 | 148 | 149 | 148 | 143 | 140 | 139 | 140 | 143 | 137 | 130 | 125 | 122 | 122 | 126 | 129 | 128 | 128 | 129 | 132 | 137 | 139 | 139 | 137 | 133 | 130 | 129 | 133 | 138 | 139 | 137 | 135 | 140 | 136 | 134 | 136 | 136 | 133 | 132 | 135 | 137 | 136 | 136 | 137 | 136 | 136 | 137 | 140 | 137 | 140 | 139 | 139 | . 210 154 | 147 | 147 | 145 | 145 | 145 | 141 | 145 | 143 | 145 | 147 | 149 | 153 | 155 | 151 | 144 | 144 | 143 | 141 | 139 | 137 | 136 | 137 | 137 | 136 | 130 | 132 | 135 | 129 | 129 | 133 | 133 | 137 | 128 | 138 | 144 | 135 | 141 | 149 | 139 | 141 | 142 | 146 | 146 | 145 | 152 | 155 | 150 | 145 | 145 | 144 | 144 | 144 | 143 | 141 | 140 | 142 | 139 | 135 | 132 | 127 | 124 | 125 | 127 | 126 | 126 | 127 | 128 | 133 | 137 | 136 | 133 | 132 | 130 | 131 | 137 | 143 | 142 | 138 | 134 | 138 | 135 | 134 | 136 | 136 | 134 | 134 | 135 | 135 | 135 | 136 | 137 | 135 | 134 | 136 | 140 | 137 | 140 | 139 | 138 | . 211 153 | 149 | 152 | 151 | 148 | 146 | 143 | 150 | 143 | 143 | 143 | 145 | 148 | 150 | 150 | 148 | 149 | 146 | 142 | 140 | 139 | 139 | 138 | 137 | 137 | 131 | 137 | 143 | 137 | 139 | 141 | 134 | 145 | 129 | 145 | 167 | 157 | 144 | 144 | 140 | 139 | 142 | 143 | 140 | 141 | 149 | 153 | 151 | 148 | 145 | 141 | 141 | 142 | 143 | 142 | 141 | 139 | 138 | 139 | 139 | 135 | 129 | 124 | 122 | 125 | 124 | 124 | 127 | 130 | 132 | 133 | 134 | 133 | 131 | 132 | 137 | 140 | 140 | 137 | 135 | 138 | 135 | 133 | 134 | 134 | 133 | 134 | 135 | 133 | 134 | 136 | 136 | 135 | 134 | 136 | 140 | 139 | 141 | 139 | 139 | . 212 156 | 151 | 153 | 151 | 150 | 149 | 145 | 149 | 147 | 144 | 144 | 146 | 146 | 143 | 144 | 149 | 149 | 144 | 139 | 138 | 139 | 139 | 136 | 132 | 136 | 132 | 138 | 142 | 141 | 147 | 147 | 132 | 137 | 136 | 145 | 155 | 154 | 147 | 141 | 135 | 133 | 140 | 142 | 141 | 144 | 148 | 148 | 147 | 149 | 151 | 152 | 149 | 143 | 140 | 141 | 144 | 146 | 142 | 140 | 139 | 137 | 133 | 129 | 127 | 127 | 123 | 124 | 128 | 130 | 127 | 130 | 135 | 130 | 131 | 133 | 136 | 136 | 134 | 134 | 134 | 138 | 135 | 132 | 131 | 131 | 131 | 131 | 133 | 131 | 132 | 134 | 135 | 133 | 131 | 134 | 137 | 135 | 139 | 137 | 136 | . 213 160 | 152 | 151 | 149 | 151 | 153 | 145 | 142 | 148 | 145 | 146 | 150 | 148 | 141 | 141 | 147 | 146 | 142 | 137 | 137 | 139 | 139 | 135 | 131 | 134 | 132 | 134 | 134 | 136 | 144 | 143 | 131 | 128 | 132 | 130 | 129 | 134 | 138 | 137 | 137 | 132 | 138 | 138 | 137 | 141 | 143 | 144 | 147 | 148 | 150 | 151 | 152 | 150 | 148 | 145 | 144 | 145 | 142 | 140 | 142 | 143 | 141 | 139 | 137 | 129 | 125 | 123 | 126 | 127 | 125 | 127 | 131 | 129 | 131 | 135 | 138 | 137 | 134 | 133 | 134 | 135 | 133 | 132 | 132 | 133 | 135 | 136 | 138 | 135 | 135 | 136 | 136 | 134 | 132 | 132 | 135 | 133 | 137 | 136 | 134 | . 214 160 | 157 | 157 | 150 | 150 | 153 | 146 | 143 | 146 | 146 | 147 | 149 | 147 | 144 | 143 | 144 | 144 | 142 | 138 | 137 | 138 | 137 | 136 | 134 | 132 | 133 | 133 | 132 | 132 | 135 | 136 | 133 | 131 | 130 | 129 | 131 | 133 | 135 | 139 | 146 | 140 | 142 | 138 | 137 | 141 | 141 | 142 | 152 | 147 | 144 | 143 | 147 | 153 | 155 | 151 | 147 | 142 | 142 | 143 | 146 | 148 | 146 | 143 | 142 | 134 | 132 | 127 | 124 | 126 | 129 | 128 | 124 | 130 | 131 | 134 | 137 | 137 | 134 | 133 | 134 | 135 | 134 | 134 | 135 | 137 | 140 | 141 | 142 | 138 | 137 | 138 | 138 | 136 | 134 | 133 | 135 | 134 | 140 | 139 | 135 | . 215 157 | 162 | 167 | 156 | 148 | 151 | 149 | 151 | 145 | 145 | 145 | 143 | 144 | 146 | 146 | 143 | 143 | 142 | 139 | 137 | 135 | 134 | 134 | 135 | 130 | 134 | 136 | 136 | 134 | 130 | 131 | 138 | 128 | 130 | 138 | 141 | 136 | 138 | 143 | 140 | 137 | 140 | 138 | 140 | 143 | 137 | 134 | 143 | 147 | 147 | 146 | 147 | 148 | 150 | 153 | 155 | 149 | 147 | 146 | 146 | 143 | 141 | 141 | 143 | 141 | 141 | 133 | 124 | 128 | 137 | 134 | 122 | 129 | 128 | 129 | 131 | 132 | 132 | 132 | 133 | 138 | 138 | 138 | 138 | 138 | 139 | 138 | 137 | 137 | 136 | 136 | 137 | 136 | 134 | 133 | 134 | 136 | 142 | 141 | 136 | . 216 156 | 146 | 149 | 163 | 166 | 153 | 146 | 152 | 145 | 144 | 143 | 144 | 145 | 145 | 143 | 141 | 139 | 141 | 136 | 133 | 138 | 136 | 130 | 131 | 131 | 132 | 136 | 137 | 134 | 130 | 130 | 132 | 132 | 135 | 126 | 136 | 141 | 137 | 146 | 141 | 135 | 137 | 138 | 141 | 143 | 138 | 137 | 143 | 146 | 146 | 146 | 148 | 149 | 145 | 143 | 148 | 147 | 147 | 146 | 144 | 142 | 141 | 140 | 140 | 142 | 143 | 143 | 144 | 144 | 143 | 140 | 138 | 123 | 126 | 137 | 137 | 141 | 131 | 133 | 132 | 138 | 141 | 137 | 135 | 138 | 135 | 132 | 137 | 137 | 135 | 135 | 137 | 136 | 132 | 131 | 134 | 134 | 137 | 139 | 137 | . 217 155 | 156 | 158 | 158 | 159 | 158 | 154 | 148 | 150 | 146 | 142 | 143 | 145 | 145 | 142 | 138 | 136 | 135 | 131 | 132 | 137 | 138 | 135 | 133 | 136 | 131 | 129 | 130 | 132 | 131 | 128 | 127 | 143 | 144 | 130 | 132 | 134 | 132 | 144 | 141 | 134 | 138 | 138 | 136 | 137 | 136 | 135 | 138 | 132 | 144 | 151 | 146 | 144 | 150 | 152 | 147 | 142 | 143 | 143 | 143 | 143 | 142 | 142 | 142 | 144 | 144 | 144 | 145 | 146 | 146 | 146 | 145 | 136 | 133 | 132 | 135 | 136 | 136 | 133 | 133 | 133 | 134 | 133 | 135 | 139 | 138 | 135 | 135 | 134 | 133 | 134 | 136 | 134 | 129 | 129 | 132 | 133 | 134 | 135 | 135 | . 218 153 | 161 | 162 | 156 | 157 | 164 | 164 | 156 | 152 | 150 | 148 | 145 | 142 | 141 | 141 | 141 | 141 | 135 | 132 | 133 | 135 | 136 | 135 | 130 | 135 | 130 | 127 | 128 | 130 | 129 | 127 | 124 | 139 | 145 | 136 | 135 | 134 | 132 | 139 | 132 | 132 | 139 | 137 | 132 | 134 | 136 | 137 | 137 | 135 | 141 | 154 | 158 | 153 | 152 | 151 | 144 | 142 | 142 | 143 | 142 | 142 | 140 | 139 | 138 | 144 | 143 | 142 | 142 | 142 | 143 | 144 | 145 | 144 | 138 | 127 | 134 | 132 | 138 | 129 | 127 | 131 | 127 | 129 | 135 | 138 | 137 | 135 | 130 | 130 | 131 | 132 | 134 | 131 | 127 | 127 | 131 | 134 | 134 | 134 | 135 | . 219 153 | 155 | 157 | 158 | 159 | 161 | 164 | 165 | 157 | 155 | 151 | 147 | 144 | 142 | 142 | 142 | 148 | 139 | 137 | 136 | 132 | 131 | 132 | 126 | 129 | 130 | 131 | 131 | 130 | 128 | 126 | 126 | 127 | 137 | 136 | 136 | 135 | 134 | 136 | 127 | 131 | 136 | 136 | 134 | 137 | 139 | 138 | 140 | 133 | 133 | 146 | 155 | 150 | 150 | 152 | 145 | 143 | 142 | 141 | 140 | 139 | 138 | 136 | 135 | 142 | 141 | 140 | 138 | 137 | 137 | 137 | 138 | 152 | 147 | 139 | 143 | 142 | 144 | 135 | 130 | 131 | 125 | 128 | 135 | 134 | 134 | 134 | 129 | 131 | 132 | 134 | 134 | 131 | 128 | 130 | 135 | 133 | 133 | 134 | 136 | . 220 151 | 151 | 153 | 157 | 157 | 156 | 158 | 162 | 164 | 159 | 153 | 150 | 150 | 148 | 144 | 140 | 145 | 137 | 137 | 137 | 130 | 129 | 131 | 129 | 127 | 129 | 131 | 131 | 130 | 129 | 128 | 128 | 125 | 134 | 133 | 130 | 129 | 132 | 136 | 130 | 130 | 133 | 134 | 137 | 140 | 136 | 134 | 137 | 137 | 146 | 156 | 151 | 140 | 147 | 154 | 144 | 141 | 139 | 138 | 137 | 137 | 137 | 137 | 136 | 138 | 138 | 139 | 138 | 137 | 136 | 136 | 137 | 147 | 146 | 149 | 145 | 148 | 142 | 141 | 136 | 136 | 130 | 133 | 138 | 133 | 131 | 134 | 133 | 133 | 135 | 136 | 136 | 133 | 132 | 135 | 140 | 131 | 132 | 133 | 134 | . 221 147 | 151 | 154 | 154 | 155 | 158 | 160 | 159 | 161 | 164 | 164 | 160 | 152 | 146 | 144 | 145 | 142 | 137 | 137 | 136 | 130 | 127 | 129 | 131 | 131 | 129 | 127 | 126 | 128 | 130 | 130 | 127 | 126 | 132 | 133 | 129 | 128 | 132 | 134 | 130 | 131 | 131 | 131 | 135 | 137 | 131 | 127 | 131 | 136 | 148 | 162 | 161 | 146 | 141 | 144 | 142 | 142 | 140 | 136 | 135 | 135 | 135 | 134 | 134 | 131 | 134 | 137 | 138 | 138 | 138 | 139 | 139 | 139 | 140 | 147 | 140 | 143 | 137 | 142 | 141 | 147 | 143 | 144 | 144 | 136 | 129 | 128 | 131 | 131 | 133 | 135 | 135 | 134 | 134 | 137 | 140 | 134 | 134 | 134 | 132 | . 222 146 | 151 | 153 | 152 | 154 | 159 | 160 | 158 | 156 | 162 | 168 | 166 | 157 | 150 | 148 | 150 | 145 | 142 | 138 | 136 | 133 | 127 | 125 | 129 | 131 | 131 | 129 | 126 | 126 | 128 | 128 | 127 | 125 | 129 | 134 | 132 | 132 | 134 | 130 | 127 | 130 | 132 | 131 | 131 | 133 | 132 | 129 | 131 | 130 | 133 | 144 | 155 | 152 | 140 | 138 | 145 | 143 | 140 | 137 | 135 | 134 | 134 | 132 | 130 | 129 | 132 | 137 | 139 | 139 | 140 | 140 | 141 | 141 | 144 | 147 | 143 | 142 | 142 | 145 | 147 | 149 | 149 | 149 | 148 | 142 | 130 | 124 | 129 | 129 | 132 | 135 | 137 | 138 | 138 | 139 | 140 | 138 | 136 | 133 | 131 | . 223 151 | 149 | 149 | 151 | 152 | 151 | 152 | 153 | 159 | 157 | 157 | 162 | 167 | 165 | 155 | 145 | 147 | 146 | 139 | 136 | 137 | 130 | 124 | 130 | 128 | 134 | 136 | 132 | 126 | 124 | 126 | 127 | 125 | 126 | 131 | 129 | 131 | 134 | 131 | 130 | 129 | 133 | 131 | 128 | 132 | 136 | 136 | 136 | 154 | 150 | 143 | 141 | 145 | 146 | 142 | 140 | 138 | 136 | 135 | 134 | 135 | 136 | 134 | 133 | 133 | 136 | 140 | 142 | 141 | 141 | 142 | 142 | 141 | 146 | 143 | 145 | 138 | 144 | 141 | 143 | 140 | 144 | 145 | 148 | 147 | 135 | 127 | 133 | 131 | 134 | 139 | 142 | 144 | 145 | 144 | 142 | 139 | 135 | 130 | 129 | . 224 152 | 151 | 150 | 150 | 150 | 151 | 152 | 152 | 151 | 155 | 160 | 161 | 161 | 161 | 164 | 167 | 146 | 149 | 145 | 136 | 131 | 132 | 131 | 126 | 128 | 126 | 126 | 128 | 130 | 130 | 127 | 124 | 125 | 126 | 127 | 128 | 130 | 133 | 133 | 131 | 128 | 129 | 130 | 133 | 135 | 132 | 131 | 137 | 144 | 143 | 151 | 151 | 146 | 139 | 133 | 137 | 137 | 135 | 136 | 136 | 132 | 131 | 134 | 133 | 133 | 138 | 140 | 139 | 138 | 134 | 133 | 139 | 141 | 142 | 143 | 144 | 142 | 140 | 139 | 141 | 139 | 146 | 146 | 140 | 139 | 138 | 132 | 127 | 129 | 137 | 145 | 145 | 144 | 145 | 147 | 149 | 141 | 127 | 124 | 130 | . 225 151 | 149 | 147 | 146 | 146 | 147 | 149 | 149 | 151 | 153 | 155 | 156 | 157 | 159 | 161 | 164 | 162 | 151 | 144 | 143 | 140 | 132 | 128 | 129 | 132 | 129 | 127 | 127 | 128 | 129 | 128 | 127 | 126 | 128 | 129 | 130 | 131 | 132 | 130 | 127 | 131 | 131 | 130 | 132 | 134 | 130 | 129 | 134 | 130 | 134 | 146 | 147 | 143 | 138 | 132 | 136 | 133 | 132 | 134 | 135 | 130 | 130 | 132 | 130 | 133 | 136 | 136 | 136 | 138 | 136 | 136 | 142 | 144 | 143 | 143 | 143 | 141 | 139 | 138 | 139 | 142 | 143 | 141 | 141 | 142 | 136 | 128 | 127 | 137 | 145 | 148 | 143 | 141 | 143 | 144 | 140 | 141 | 132 | 128 | 128 | . 226 148 | 147 | 146 | 146 | 148 | 150 | 151 | 151 | 152 | 151 | 150 | 151 | 153 | 156 | 159 | 160 | 164 | 162 | 155 | 147 | 142 | 140 | 135 | 130 | 125 | 125 | 126 | 127 | 129 | 129 | 128 | 127 | 131 | 132 | 131 | 131 | 132 | 132 | 130 | 127 | 132 | 132 | 129 | 129 | 131 | 128 | 127 | 132 | 131 | 138 | 149 | 146 | 140 | 137 | 132 | 133 | 131 | 131 | 134 | 135 | 131 | 131 | 132 | 130 | 131 | 134 | 133 | 133 | 135 | 135 | 139 | 147 | 147 | 144 | 142 | 142 | 141 | 138 | 137 | 138 | 144 | 141 | 138 | 140 | 139 | 130 | 127 | 135 | 139 | 146 | 146 | 139 | 138 | 144 | 143 | 136 | 141 | 137 | 132 | 126 | . 227 148 | 149 | 149 | 150 | 151 | 151 | 150 | 149 | 150 | 150 | 150 | 151 | 153 | 155 | 156 | 157 | 157 | 165 | 166 | 156 | 148 | 146 | 143 | 137 | 126 | 126 | 126 | 126 | 126 | 126 | 127 | 128 | 133 | 133 | 131 | 129 | 130 | 131 | 131 | 129 | 129 | 130 | 128 | 127 | 128 | 126 | 128 | 134 | 144 | 148 | 153 | 145 | 139 | 140 | 136 | 135 | 133 | 132 | 135 | 136 | 132 | 132 | 134 | 132 | 129 | 132 | 133 | 132 | 133 | 133 | 137 | 147 | 147 | 144 | 140 | 140 | 139 | 138 | 136 | 136 | 143 | 141 | 139 | 137 | 132 | 125 | 131 | 147 | 142 | 144 | 142 | 138 | 140 | 145 | 145 | 140 | 141 | 139 | 135 | 130 | . 228 153 | 152 | 150 | 149 | 148 | 146 | 145 | 143 | 147 | 149 | 151 | 153 | 153 | 153 | 154 | 155 | 154 | 157 | 163 | 166 | 160 | 150 | 146 | 148 | 140 | 136 | 130 | 125 | 122 | 124 | 127 | 130 | 130 | 130 | 129 | 129 | 130 | 131 | 130 | 128 | 126 | 129 | 129 | 127 | 127 | 127 | 132 | 140 | 146 | 147 | 150 | 143 | 142 | 147 | 142 | 139 | 134 | 133 | 135 | 135 | 131 | 131 | 133 | 132 | 131 | 131 | 130 | 131 | 136 | 136 | 135 | 138 | 143 | 139 | 137 | 137 | 137 | 136 | 135 | 135 | 140 | 141 | 138 | 134 | 132 | 131 | 138 | 150 | 148 | 144 | 141 | 142 | 144 | 143 | 142 | 142 | 143 | 140 | 141 | 141 | . 229 155 | 152 | 149 | 147 | 146 | 146 | 147 | 147 | 144 | 146 | 149 | 151 | 150 | 150 | 151 | 153 | 153 | 155 | 158 | 162 | 163 | 161 | 154 | 149 | 141 | 138 | 134 | 131 | 129 | 128 | 127 | 127 | 127 | 129 | 131 | 133 | 134 | 135 | 132 | 128 | 127 | 131 | 130 | 128 | 128 | 130 | 134 | 143 | 142 | 144 | 148 | 146 | 148 | 151 | 143 | 137 | 132 | 131 | 132 | 132 | 128 | 128 | 131 | 130 | 135 | 132 | 128 | 132 | 142 | 142 | 134 | 130 | 137 | 135 | 135 | 136 | 136 | 135 | 134 | 135 | 137 | 138 | 134 | 132 | 136 | 140 | 140 | 143 | 145 | 140 | 139 | 143 | 143 | 138 | 137 | 140 | 143 | 141 | 144 | 148 | . 230 154 | 153 | 151 | 149 | 149 | 149 | 149 | 149 | 145 | 145 | 145 | 145 | 147 | 149 | 151 | 152 | 151 | 157 | 157 | 153 | 157 | 166 | 163 | 154 | 141 | 139 | 137 | 136 | 136 | 134 | 131 | 128 | 129 | 131 | 132 | 133 | 134 | 135 | 133 | 129 | 131 | 132 | 129 | 126 | 128 | 130 | 132 | 137 | 139 | 140 | 147 | 147 | 148 | 148 | 138 | 133 | 131 | 130 | 132 | 132 | 128 | 129 | 131 | 129 | 134 | 134 | 134 | 139 | 145 | 142 | 134 | 132 | 135 | 135 | 137 | 139 | 139 | 137 | 137 | 138 | 134 | 136 | 134 | 133 | 137 | 138 | 138 | 140 | 138 | 137 | 139 | 141 | 140 | 136 | 134 | 136 | 138 | 138 | 142 | 144 | . 231 156 | 155 | 155 | 154 | 152 | 148 | 145 | 142 | 148 | 144 | 141 | 141 | 145 | 149 | 152 | 153 | 155 | 153 | 152 | 154 | 156 | 158 | 163 | 168 | 154 | 147 | 139 | 135 | 134 | 136 | 136 | 136 | 130 | 130 | 128 | 127 | 129 | 131 | 131 | 129 | 134 | 133 | 127 | 123 | 127 | 128 | 128 | 130 | 135 | 135 | 143 | 143 | 143 | 142 | 133 | 130 | 131 | 130 | 134 | 135 | 131 | 131 | 133 | 131 | 129 | 137 | 144 | 146 | 144 | 138 | 135 | 140 | 136 | 137 | 141 | 143 | 143 | 140 | 140 | 141 | 131 | 136 | 136 | 135 | 132 | 130 | 133 | 143 | 139 | 143 | 145 | 143 | 139 | 135 | 133 | 131 | 131 | 134 | 138 | 137 | . 232 156 | 156 | 155 | 153 | 153 | 152 | 150 | 146 | 147 | 146 | 146 | 147 | 147 | 147 | 146 | 145 | 150 | 152 | 153 | 153 | 154 | 156 | 159 | 161 | 170 | 158 | 142 | 133 | 134 | 137 | 136 | 132 | 132 | 134 | 135 | 132 | 129 | 127 | 129 | 131 | 136 | 135 | 134 | 132 | 132 | 133 | 134 | 135 | 135 | 135 | 136 | 139 | 141 | 139 | 136 | 135 | 134 | 131 | 129 | 134 | 140 | 136 | 130 | 132 | 132 | 135 | 142 | 144 | 141 | 143 | 146 | 143 | 147 | 138 | 138 | 142 | 140 | 136 | 135 | 135 | 132 | 129 | 129 | 131 | 131 | 130 | 134 | 140 | 143 | 139 | 136 | 137 | 137 | 135 | 132 | 132 | 133 | 134 | 134 | 133 | . 233 153 | 157 | 160 | 158 | 153 | 151 | 150 | 149 | 146 | 148 | 149 | 149 | 147 | 145 | 143 | 142 | 144 | 146 | 148 | 150 | 151 | 154 | 156 | 158 | 163 | 165 | 161 | 150 | 139 | 134 | 136 | 139 | 137 | 136 | 135 | 136 | 135 | 133 | 129 | 126 | 129 | 132 | 135 | 139 | 142 | 143 | 144 | 143 | 144 | 141 | 139 | 137 | 134 | 131 | 131 | 133 | 130 | 137 | 140 | 138 | 132 | 126 | 130 | 142 | 131 | 130 | 134 | 139 | 137 | 137 | 140 | 141 | 140 | 134 | 136 | 141 | 140 | 139 | 138 | 137 | 133 | 130 | 129 | 130 | 129 | 127 | 130 | 135 | 141 | 140 | 141 | 142 | 140 | 136 | 134 | 134 | 129 | 130 | 132 | 133 | . 234 157 | 155 | 154 | 153 | 155 | 156 | 152 | 147 | 144 | 147 | 149 | 148 | 145 | 144 | 144 | 145 | 144 | 145 | 146 | 149 | 152 | 154 | 155 | 155 | 156 | 161 | 166 | 163 | 156 | 148 | 141 | 136 | 137 | 135 | 135 | 136 | 138 | 137 | 134 | 131 | 128 | 128 | 129 | 130 | 133 | 135 | 138 | 140 | 146 | 146 | 148 | 148 | 145 | 141 | 140 | 141 | 131 | 137 | 139 | 137 | 134 | 130 | 130 | 136 | 137 | 131 | 134 | 140 | 139 | 136 | 140 | 144 | 143 | 139 | 139 | 138 | 135 | 135 | 134 | 130 | 132 | 130 | 129 | 131 | 130 | 129 | 131 | 135 | 135 | 138 | 141 | 142 | 138 | 133 | 132 | 134 | 132 | 133 | 133 | 133 | . 235 159 | 156 | 151 | 151 | 155 | 158 | 155 | 150 | 148 | 149 | 148 | 146 | 144 | 144 | 145 | 147 | 147 | 147 | 146 | 148 | 151 | 153 | 153 | 153 | 154 | 155 | 157 | 161 | 165 | 163 | 153 | 143 | 140 | 139 | 137 | 136 | 135 | 136 | 138 | 139 | 137 | 135 | 132 | 130 | 130 | 131 | 133 | 135 | 135 | 136 | 139 | 142 | 143 | 141 | 141 | 142 | 137 | 136 | 131 | 129 | 135 | 136 | 132 | 129 | 134 | 129 | 130 | 135 | 133 | 132 | 135 | 137 | 140 | 138 | 138 | 135 | 133 | 138 | 141 | 137 | 131 | 129 | 129 | 130 | 130 | 129 | 130 | 132 | 132 | 135 | 138 | 137 | 133 | 130 | 131 | 133 | 137 | 137 | 135 | 134 | . 236 155 | 159 | 161 | 159 | 155 | 156 | 158 | 160 | 156 | 155 | 153 | 150 | 148 | 147 | 145 | 144 | 144 | 143 | 142 | 143 | 145 | 148 | 150 | 150 | 155 | 156 | 156 | 155 | 157 | 160 | 163 | 164 | 154 | 149 | 143 | 139 | 139 | 140 | 141 | 141 | 138 | 139 | 139 | 139 | 137 | 135 | 133 | 132 | 134 | 129 | 125 | 126 | 128 | 130 | 132 | 134 | 137 | 137 | 131 | 126 | 128 | 131 | 133 | 136 | 130 | 129 | 132 | 132 | 129 | 130 | 132 | 129 | 139 | 139 | 139 | 137 | 135 | 140 | 142 | 137 | 131 | 129 | 128 | 128 | 127 | 125 | 125 | 125 | 136 | 137 | 135 | 133 | 131 | 131 | 132 | 133 | 133 | 134 | 135 | 136 | . 237 154 | 158 | 162 | 161 | 160 | 159 | 158 | 157 | 157 | 157 | 156 | 156 | 156 | 154 | 150 | 147 | 141 | 140 | 139 | 140 | 143 | 146 | 149 | 150 | 151 | 154 | 155 | 153 | 153 | 156 | 160 | 162 | 162 | 154 | 147 | 146 | 149 | 151 | 148 | 143 | 140 | 140 | 139 | 138 | 136 | 134 | 132 | 131 | 137 | 131 | 126 | 127 | 129 | 130 | 130 | 130 | 133 | 135 | 132 | 131 | 133 | 133 | 131 | 134 | 131 | 134 | 138 | 137 | 133 | 134 | 135 | 131 | 137 | 137 | 139 | 138 | 134 | 135 | 134 | 128 | 131 | 129 | 128 | 128 | 128 | 129 | 129 | 129 | 139 | 138 | 135 | 131 | 130 | 132 | 133 | 132 | 128 | 132 | 135 | 138 | . 238 160 | 158 | 157 | 157 | 161 | 162 | 158 | 153 | 154 | 155 | 156 | 157 | 157 | 157 | 156 | 156 | 146 | 146 | 145 | 144 | 144 | 146 | 148 | 149 | 148 | 150 | 152 | 153 | 155 | 156 | 154 | 151 | 159 | 156 | 152 | 151 | 151 | 152 | 151 | 150 | 150 | 148 | 145 | 142 | 140 | 138 | 138 | 138 | 132 | 130 | 130 | 132 | 134 | 133 | 131 | 130 | 132 | 130 | 129 | 134 | 139 | 135 | 129 | 128 | 128 | 130 | 136 | 137 | 132 | 129 | 131 | 130 | 130 | 130 | 134 | 136 | 135 | 136 | 137 | 134 | 130 | 130 | 129 | 130 | 133 | 135 | 136 | 136 | 139 | 139 | 136 | 132 | 131 | 131 | 131 | 130 | 129 | 132 | 135 | 136 | . 239 163 | 163 | 161 | 158 | 157 | 158 | 159 | 159 | 155 | 156 | 156 | 154 | 153 | 154 | 157 | 161 | 153 | 153 | 152 | 149 | 146 | 144 | 144 | 145 | 149 | 152 | 153 | 151 | 150 | 152 | 155 | 157 | 156 | 159 | 159 | 152 | 145 | 142 | 147 | 153 | 147 | 148 | 150 | 150 | 149 | 146 | 142 | 140 | 137 | 135 | 133 | 134 | 135 | 135 | 136 | 138 | 135 | 131 | 127 | 129 | 132 | 128 | 128 | 134 | 128 | 127 | 134 | 139 | 133 | 126 | 129 | 133 | 140 | 137 | 138 | 138 | 135 | 135 | 137 | 137 | 132 | 131 | 130 | 131 | 133 | 136 | 137 | 137 | 139 | 140 | 139 | 135 | 133 | 132 | 131 | 129 | 129 | 130 | 131 | 132 | . 240 158 | 159 | 162 | 165 | 165 | 163 | 158 | 155 | 166 | 156 | 150 | 153 | 155 | 153 | 153 | 157 | 156 | 153 | 150 | 149 | 150 | 150 | 148 | 146 | 144 | 148 | 151 | 151 | 150 | 150 | 153 | 157 | 162 | 154 | 153 | 158 | 156 | 146 | 141 | 143 | 148 | 147 | 148 | 150 | 150 | 147 | 145 | 146 | 140 | 134 | 131 | 133 | 136 | 136 | 135 | 135 | 141 | 133 | 128 | 129 | 130 | 129 | 128 | 129 | 124 | 132 | 136 | 140 | 132 | 123 | 132 | 140 | 142 | 135 | 140 | 142 | 145 | 131 | 134 | 139 | 133 | 132 | 130 | 129 | 130 | 132 | 133 | 133 | 141 | 140 | 139 | 137 | 135 | 133 | 131 | 130 | 126 | 130 | 131 | 129 | . 241 156 | 157 | 159 | 161 | 163 | 163 | 161 | 160 | 158 | 162 | 161 | 154 | 151 | 155 | 157 | 156 | 152 | 155 | 157 | 154 | 149 | 147 | 148 | 150 | 147 | 146 | 146 | 148 | 152 | 155 | 156 | 156 | 152 | 160 | 162 | 157 | 157 | 159 | 152 | 141 | 135 | 143 | 146 | 142 | 144 | 149 | 146 | 136 | 140 | 134 | 130 | 130 | 131 | 131 | 132 | 133 | 136 | 130 | 127 | 130 | 133 | 131 | 130 | 130 | 130 | 129 | 126 | 133 | 135 | 132 | 137 | 139 | 127 | 135 | 142 | 137 | 135 | 132 | 134 | 132 | 130 | 130 | 129 | 130 | 132 | 133 | 132 | 132 | 136 | 135 | 134 | 133 | 131 | 130 | 129 | 128 | 131 | 131 | 129 | 128 | . 242 155 | 155 | 155 | 157 | 160 | 162 | 164 | 164 | 160 | 160 | 161 | 161 | 157 | 152 | 154 | 158 | 155 | 155 | 154 | 154 | 154 | 152 | 150 | 148 | 148 | 146 | 145 | 147 | 151 | 155 | 155 | 153 | 155 | 156 | 156 | 155 | 156 | 157 | 155 | 151 | 135 | 133 | 131 | 131 | 133 | 137 | 140 | 141 | 145 | 140 | 135 | 132 | 131 | 131 | 133 | 135 | 135 | 131 | 130 | 133 | 135 | 132 | 128 | 127 | 130 | 130 | 127 | 130 | 130 | 128 | 137 | 140 | 137 | 135 | 133 | 137 | 135 | 134 | 129 | 127 | 131 | 130 | 129 | 129 | 130 | 130 | 130 | 130 | 135 | 135 | 133 | 132 | 130 | 130 | 129 | 129 | 128 | 129 | 128 | 127 | . 243 155 | 154 | 153 | 154 | 157 | 160 | 162 | 164 | 164 | 157 | 157 | 162 | 162 | 155 | 153 | 156 | 156 | 153 | 152 | 153 | 156 | 156 | 153 | 150 | 149 | 149 | 149 | 148 | 147 | 147 | 149 | 151 | 157 | 153 | 151 | 154 | 156 | 155 | 157 | 161 | 161 | 152 | 143 | 138 | 134 | 131 | 135 | 142 | 145 | 143 | 140 | 136 | 134 | 132 | 133 | 134 | 134 | 132 | 131 | 134 | 135 | 132 | 128 | 127 | 130 | 133 | 130 | 129 | 126 | 123 | 132 | 135 | 147 | 139 | 130 | 136 | 133 | 135 | 127 | 128 | 131 | 129 | 127 | 126 | 127 | 128 | 130 | 131 | 135 | 135 | 134 | 133 | 132 | 131 | 130 | 130 | 125 | 130 | 131 | 129 | . 244 155 | 154 | 153 | 154 | 155 | 157 | 159 | 159 | 159 | 163 | 162 | 158 | 158 | 163 | 160 | 153 | 151 | 153 | 155 | 154 | 152 | 151 | 155 | 158 | 153 | 152 | 151 | 149 | 147 | 146 | 147 | 148 | 148 | 152 | 153 | 153 | 156 | 161 | 161 | 159 | 159 | 164 | 161 | 149 | 142 | 143 | 142 | 136 | 140 | 141 | 140 | 138 | 135 | 132 | 131 | 131 | 130 | 128 | 128 | 130 | 132 | 131 | 130 | 129 | 132 | 133 | 128 | 128 | 129 | 128 | 132 | 128 | 134 | 143 | 139 | 133 | 123 | 132 | 132 | 131 | 129 | 128 | 128 | 127 | 127 | 128 | 130 | 131 | 130 | 130 | 130 | 130 | 130 | 129 | 128 | 128 | 129 | 133 | 134 | 130 | . 245 154 | 153 | 153 | 153 | 154 | 155 | 155 | 155 | 158 | 162 | 164 | 162 | 160 | 161 | 161 | 160 | 154 | 154 | 153 | 152 | 152 | 153 | 155 | 157 | 157 | 154 | 150 | 150 | 151 | 152 | 150 | 148 | 146 | 143 | 143 | 146 | 149 | 150 | 154 | 159 | 152 | 157 | 160 | 157 | 152 | 149 | 146 | 142 | 141 | 143 | 144 | 143 | 141 | 139 | 136 | 134 | 133 | 130 | 128 | 127 | 127 | 127 | 127 | 126 | 126 | 132 | 131 | 131 | 131 | 131 | 137 | 136 | 135 | 139 | 137 | 136 | 130 | 130 | 130 | 131 | 133 | 133 | 133 | 131 | 129 | 127 | 126 | 125 | 127 | 128 | 128 | 128 | 128 | 128 | 128 | 128 | 131 | 131 | 130 | 130 | . 246 152 | 152 | 152 | 153 | 154 | 154 | 154 | 154 | 159 | 156 | 158 | 164 | 165 | 160 | 159 | 162 | 161 | 156 | 151 | 151 | 154 | 156 | 155 | 152 | 156 | 154 | 152 | 152 | 153 | 154 | 152 | 151 | 152 | 143 | 138 | 141 | 142 | 140 | 146 | 157 | 163 | 159 | 159 | 163 | 160 | 152 | 147 | 149 | 148 | 149 | 149 | 147 | 146 | 145 | 143 | 141 | 140 | 137 | 132 | 128 | 126 | 126 | 125 | 124 | 121 | 132 | 133 | 132 | 129 | 131 | 142 | 144 | 143 | 132 | 131 | 136 | 139 | 129 | 129 | 134 | 138 | 137 | 136 | 133 | 129 | 128 | 127 | 128 | 134 | 133 | 131 | 129 | 128 | 128 | 128 | 128 | 128 | 128 | 129 | 132 | . 247 150 | 150 | 150 | 152 | 153 | 155 | 155 | 155 | 154 | 156 | 156 | 156 | 162 | 168 | 163 | 152 | 159 | 159 | 158 | 155 | 151 | 150 | 152 | 154 | 152 | 155 | 157 | 155 | 151 | 149 | 152 | 155 | 152 | 156 | 153 | 144 | 142 | 149 | 151 | 147 | 145 | 151 | 154 | 156 | 160 | 164 | 159 | 150 | 149 | 149 | 147 | 145 | 144 | 145 | 144 | 142 | 142 | 139 | 135 | 131 | 129 | 129 | 128 | 128 | 127 | 131 | 127 | 127 | 131 | 137 | 145 | 141 | 133 | 131 | 135 | 129 | 133 | 128 | 136 | 139 | 136 | 135 | 132 | 130 | 129 | 131 | 136 | 140 | 141 | 138 | 134 | 131 | 128 | 127 | 127 | 128 | 127 | 130 | 134 | 135 | . 248 150 | 151 | 150 | 149 | 150 | 152 | 154 | 153 | 154 | 152 | 152 | 154 | 157 | 160 | 164 | 168 | 159 | 159 | 163 | 164 | 157 | 148 | 147 | 151 | 152 | 154 | 155 | 157 | 157 | 156 | 154 | 153 | 155 | 153 | 153 | 155 | 154 | 149 | 146 | 144 | 147 | 154 | 156 | 154 | 155 | 162 | 166 | 165 | 158 | 152 | 147 | 147 | 149 | 148 | 146 | 145 | 146 | 145 | 141 | 136 | 135 | 135 | 132 | 128 | 130 | 128 | 126 | 126 | 129 | 132 | 132 | 129 | 132 | 133 | 132 | 134 | 136 | 133 | 134 | 140 | 138 | 130 | 128 | 137 | 144 | 142 | 137 | 136 | 133 | 131 | 130 | 129 | 128 | 126 | 127 | 129 | 129 | 130 | 130 | 129 | . 249 149 | 150 | 150 | 149 | 149 | 151 | 153 | 152 | 154 | 152 | 152 | 153 | 154 | 155 | 158 | 161 | 162 | 161 | 162 | 164 | 166 | 164 | 157 | 150 | 153 | 153 | 153 | 153 | 153 | 153 | 153 | 152 | 155 | 154 | 154 | 154 | 152 | 149 | 151 | 154 | 152 | 144 | 142 | 148 | 151 | 151 | 157 | 165 | 165 | 161 | 157 | 153 | 151 | 150 | 147 | 145 | 146 | 145 | 143 | 141 | 140 | 139 | 136 | 131 | 133 | 132 | 129 | 127 | 129 | 132 | 133 | 132 | 134 | 133 | 131 | 131 | 132 | 130 | 130 | 137 | 138 | 134 | 131 | 133 | 137 | 141 | 144 | 146 | 146 | 137 | 131 | 133 | 135 | 132 | 129 | 129 | 129 | 128 | 128 | 128 | . 250 147 | 148 | 149 | 148 | 148 | 151 | 151 | 151 | 155 | 154 | 153 | 155 | 155 | 154 | 155 | 156 | 156 | 160 | 160 | 157 | 159 | 164 | 166 | 163 | 155 | 155 | 153 | 152 | 151 | 151 | 151 | 151 | 147 | 152 | 158 | 160 | 157 | 154 | 154 | 156 | 146 | 137 | 135 | 140 | 139 | 135 | 143 | 158 | 161 | 163 | 163 | 159 | 157 | 156 | 154 | 151 | 149 | 150 | 149 | 148 | 147 | 144 | 139 | 135 | 137 | 136 | 134 | 130 | 130 | 132 | 133 | 133 | 133 | 132 | 128 | 128 | 129 | 127 | 128 | 135 | 135 | 135 | 132 | 126 | 126 | 135 | 145 | 150 | 143 | 135 | 129 | 131 | 134 | 131 | 129 | 129 | 129 | 127 | 125 | 126 | . 251 144 | 146 | 147 | 146 | 148 | 150 | 150 | 150 | 153 | 152 | 153 | 155 | 155 | 154 | 154 | 156 | 153 | 157 | 157 | 153 | 152 | 158 | 164 | 166 | 157 | 158 | 158 | 156 | 152 | 150 | 151 | 152 | 151 | 152 | 153 | 154 | 154 | 155 | 158 | 161 | 154 | 149 | 143 | 141 | 146 | 151 | 150 | 145 | 150 | 158 | 162 | 160 | 159 | 160 | 159 | 155 | 153 | 153 | 154 | 154 | 153 | 150 | 146 | 142 | 139 | 140 | 139 | 136 | 133 | 133 | 133 | 133 | 131 | 130 | 126 | 127 | 129 | 127 | 128 | 135 | 133 | 134 | 132 | 126 | 125 | 131 | 140 | 146 | 138 | 138 | 135 | 133 | 130 | 129 | 129 | 129 | 130 | 128 | 126 | 125 | . 252 143 | 145 | 145 | 145 | 146 | 149 | 149 | 149 | 149 | 148 | 150 | 152 | 154 | 153 | 153 | 154 | 157 | 156 | 156 | 157 | 159 | 159 | 157 | 156 | 155 | 159 | 162 | 160 | 156 | 153 | 153 | 154 | 149 | 149 | 151 | 154 | 158 | 159 | 156 | 152 | 148 | 158 | 162 | 156 | 152 | 155 | 153 | 148 | 147 | 154 | 157 | 154 | 153 | 156 | 157 | 155 | 153 | 154 | 155 | 157 | 157 | 155 | 153 | 152 | 140 | 143 | 144 | 142 | 138 | 136 | 134 | 132 | 131 | 130 | 127 | 128 | 131 | 129 | 129 | 134 | 133 | 132 | 133 | 135 | 136 | 137 | 141 | 145 | 144 | 148 | 145 | 137 | 133 | 135 | 133 | 128 | 128 | 129 | 129 | 128 | . 253 143 | 145 | 145 | 144 | 145 | 147 | 148 | 147 | 149 | 148 | 149 | 151 | 152 | 152 | 152 | 154 | 155 | 155 | 156 | 157 | 157 | 155 | 157 | 160 | 153 | 156 | 160 | 160 | 159 | 157 | 156 | 157 | 150 | 150 | 150 | 153 | 156 | 157 | 153 | 147 | 142 | 152 | 161 | 160 | 153 | 148 | 149 | 151 | 148 | 150 | 150 | 147 | 148 | 153 | 156 | 156 | 157 | 156 | 156 | 157 | 156 | 154 | 153 | 153 | 143 | 146 | 148 | 146 | 143 | 140 | 136 | 133 | 133 | 132 | 129 | 131 | 133 | 130 | 127 | 132 | 130 | 128 | 131 | 139 | 145 | 145 | 143 | 143 | 140 | 141 | 137 | 131 | 133 | 139 | 134 | 125 | 126 | 129 | 132 | 132 | . 254 145 | 146 | 145 | 144 | 144 | 145 | 146 | 146 | 150 | 148 | 148 | 150 | 151 | 151 | 152 | 154 | 150 | 155 | 156 | 152 | 149 | 153 | 160 | 165 | 156 | 155 | 155 | 157 | 160 | 160 | 159 | 157 | 159 | 156 | 150 | 143 | 142 | 148 | 154 | 158 | 160 | 152 | 148 | 153 | 160 | 161 | 156 | 150 | 151 | 149 | 147 | 148 | 151 | 154 | 156 | 156 | 157 | 156 | 156 | 156 | 154 | 151 | 150 | 151 | 148 | 150 | 150 | 148 | 145 | 143 | 140 | 138 | 135 | 133 | 130 | 131 | 133 | 129 | 126 | 130 | 128 | 127 | 129 | 135 | 143 | 146 | 142 | 136 | 132 | 129 | 125 | 125 | 130 | 134 | 133 | 129 | 130 | 131 | 131 | 131 | . 255 147 | 147 | 146 | 143 | 143 | 144 | 145 | 144 | 147 | 146 | 145 | 147 | 148 | 148 | 150 | 153 | 153 | 156 | 154 | 150 | 153 | 161 | 159 | 151 | 162 | 157 | 153 | 154 | 160 | 163 | 160 | 156 | 147 | 154 | 159 | 156 | 150 | 148 | 148 | 149 | 158 | 160 | 159 | 153 | 150 | 154 | 160 | 163 | 155 | 151 | 150 | 154 | 157 | 155 | 152 | 150 | 151 | 151 | 152 | 154 | 154 | 152 | 151 | 153 | 152 | 152 | 151 | 148 | 146 | 145 | 144 | 142 | 135 | 133 | 129 | 130 | 132 | 129 | 126 | 130 | 129 | 131 | 130 | 130 | 137 | 143 | 139 | 129 | 133 | 129 | 127 | 131 | 131 | 130 | 133 | 140 | 137 | 133 | 128 | 126 | . 256 146 | 147 | 148 | 147 | 146 | 146 | 148 | 151 | 143 | 146 | 147 | 147 | 147 | 148 | 149 | 148 | 149 | 151 | 149 | 146 | 146 | 149 | 151 | 149 | 157 | 157 | 158 | 156 | 149 | 145 | 156 | 171 | 161 | 151 | 150 | 157 | 161 | 160 | 155 | 148 | 154 | 150 | 151 | 154 | 153 | 150 | 155 | 163 | 163 | 158 | 156 | 159 | 158 | 153 | 150 | 151 | 151 | 152 | 151 | 150 | 152 | 156 | 156 | 154 | 152 | 152 | 152 | 151 | 150 | 148 | 147 | 146 | 138 | 139 | 137 | 132 | 128 | 127 | 127 | 126 | 130 | 130 | 132 | 136 | 138 | 138 | 141 | 144 | 142 | 138 | 133 | 130 | 129 | 129 | 129 | 129 | 140 | 127 | 127 | 128 | . 257 144 | 145 | 146 | 146 | 145 | 145 | 146 | 148 | 149 | 148 | 146 | 142 | 141 | 143 | 146 | 146 | 146 | 147 | 146 | 145 | 146 | 148 | 150 | 150 | 148 | 153 | 157 | 156 | 151 | 150 | 153 | 156 | 166 | 163 | 159 | 150 | 145 | 152 | 159 | 159 | 143 | 142 | 145 | 152 | 158 | 159 | 154 | 150 | 157 | 161 | 163 | 160 | 160 | 163 | 162 | 158 | 150 | 152 | 153 | 152 | 153 | 153 | 151 | 147 | 154 | 153 | 152 | 150 | 149 | 148 | 148 | 148 | 145 | 143 | 138 | 133 | 130 | 130 | 129 | 128 | 131 | 129 | 129 | 131 | 134 | 136 | 141 | 146 | 144 | 141 | 137 | 133 | 131 | 130 | 129 | 128 | 131 | 124 | 129 | 131 | . 258 143 | 144 | 146 | 146 | 145 | 145 | 146 | 147 | 149 | 148 | 144 | 139 | 138 | 140 | 142 | 143 | 146 | 144 | 144 | 146 | 147 | 147 | 149 | 151 | 146 | 154 | 157 | 153 | 153 | 158 | 156 | 150 | 158 | 160 | 162 | 158 | 150 | 151 | 155 | 156 | 169 | 157 | 142 | 135 | 143 | 155 | 159 | 156 | 156 | 161 | 162 | 158 | 157 | 160 | 162 | 161 | 162 | 160 | 155 | 149 | 146 | 148 | 151 | 152 | 153 | 153 | 152 | 152 | 151 | 151 | 150 | 150 | 147 | 144 | 138 | 132 | 131 | 132 | 131 | 129 | 130 | 128 | 128 | 129 | 131 | 133 | 138 | 142 | 139 | 137 | 134 | 132 | 130 | 128 | 126 | 124 | 128 | 123 | 132 | 136 | . 259 143 | 145 | 146 | 146 | 145 | 145 | 145 | 144 | 145 | 146 | 145 | 143 | 142 | 143 | 144 | 143 | 147 | 145 | 145 | 148 | 149 | 147 | 149 | 152 | 151 | 155 | 153 | 148 | 151 | 159 | 161 | 156 | 151 | 146 | 153 | 166 | 165 | 156 | 150 | 149 | 149 | 161 | 170 | 165 | 154 | 148 | 148 | 151 | 154 | 153 | 155 | 160 | 159 | 154 | 153 | 156 | 157 | 159 | 161 | 160 | 158 | 155 | 154 | 153 | 150 | 151 | 153 | 154 | 154 | 153 | 151 | 150 | 144 | 143 | 139 | 135 | 133 | 133 | 132 | 130 | 128 | 128 | 129 | 130 | 130 | 130 | 131 | 133 | 130 | 129 | 128 | 127 | 126 | 125 | 124 | 123 | 128 | 124 | 131 | 139 | . 260 143 | 146 | 146 | 145 | 144 | 145 | 144 | 142 | 145 | 147 | 149 | 148 | 147 | 148 | 148 | 147 | 149 | 146 | 147 | 149 | 150 | 147 | 147 | 150 | 153 | 153 | 150 | 147 | 149 | 154 | 158 | 158 | 156 | 145 | 145 | 155 | 158 | 157 | 157 | 157 | 159 | 153 | 149 | 155 | 163 | 163 | 157 | 151 | 149 | 148 | 152 | 160 | 162 | 158 | 154 | 154 | 153 | 155 | 159 | 161 | 161 | 160 | 160 | 161 | 152 | 153 | 153 | 154 | 153 | 153 | 152 | 151 | 145 | 147 | 146 | 142 | 138 | 135 | 133 | 131 | 128 | 129 | 130 | 130 | 129 | 128 | 128 | 127 | 127 | 127 | 126 | 125 | 125 | 125 | 126 | 126 | 127 | 123 | 128 | 134 | . 261 147 | 149 | 148 | 145 | 145 | 147 | 147 | 145 | 146 | 148 | 148 | 146 | 146 | 147 | 148 | 148 | 147 | 147 | 147 | 148 | 148 | 147 | 147 | 147 | 149 | 150 | 152 | 153 | 153 | 152 | 153 | 155 | 159 | 155 | 150 | 144 | 144 | 155 | 163 | 162 | 155 | 154 | 156 | 158 | 156 | 153 | 156 | 161 | 154 | 156 | 153 | 150 | 152 | 158 | 160 | 156 | 161 | 158 | 154 | 153 | 153 | 155 | 160 | 164 | 158 | 157 | 155 | 153 | 151 | 151 | 152 | 153 | 151 | 154 | 155 | 151 | 145 | 141 | 137 | 134 | 134 | 134 | 133 | 130 | 128 | 129 | 130 | 130 | 128 | 128 | 127 | 125 | 124 | 124 | 126 | 127 | 127 | 128 | 129 | 127 | . 262 147 | 149 | 148 | 144 | 144 | 148 | 149 | 147 | 145 | 146 | 146 | 145 | 144 | 145 | 146 | 145 | 144 | 146 | 147 | 147 | 147 | 148 | 148 | 147 | 146 | 149 | 152 | 155 | 155 | 153 | 153 | 154 | 154 | 159 | 160 | 153 | 148 | 154 | 158 | 152 | 162 | 162 | 159 | 155 | 154 | 155 | 157 | 158 | 161 | 161 | 156 | 148 | 148 | 154 | 157 | 156 | 156 | 155 | 156 | 159 | 159 | 156 | 154 | 154 | 160 | 159 | 157 | 155 | 154 | 153 | 153 | 153 | 153 | 155 | 155 | 152 | 149 | 147 | 144 | 142 | 141 | 141 | 138 | 133 | 130 | 131 | 132 | 132 | 130 | 130 | 129 | 127 | 125 | 124 | 125 | 126 | 128 | 131 | 130 | 124 | . 263 144 | 145 | 143 | 140 | 141 | 146 | 147 | 145 | 143 | 146 | 148 | 148 | 147 | 147 | 147 | 145 | 142 | 146 | 147 | 146 | 147 | 150 | 150 | 147 | 144 | 148 | 150 | 150 | 151 | 154 | 156 | 156 | 150 | 154 | 162 | 165 | 160 | 154 | 149 | 141 | 148 | 160 | 166 | 162 | 157 | 158 | 159 | 156 | 155 | 155 | 158 | 163 | 160 | 153 | 151 | 153 | 156 | 154 | 153 | 156 | 159 | 159 | 160 | 161 | 157 | 158 | 159 | 159 | 159 | 157 | 154 | 152 | 150 | 150 | 149 | 149 | 150 | 152 | 151 | 149 | 147 | 147 | 144 | 138 | 134 | 134 | 133 | 132 | 132 | 133 | 132 | 131 | 128 | 127 | 127 | 127 | 125 | 128 | 128 | 125 | . 264 149 | 142 | 139 | 143 | 147 | 147 | 146 | 146 | 146 | 147 | 147 | 146 | 145 | 145 | 147 | 148 | 148 | 146 | 146 | 146 | 146 | 146 | 148 | 151 | 149 | 148 | 148 | 149 | 149 | 149 | 151 | 155 | 155 | 155 | 156 | 159 | 163 | 161 | 152 | 142 | 149 | 150 | 159 | 167 | 163 | 156 | 156 | 158 | 157 | 160 | 159 | 156 | 158 | 162 | 160 | 153 | 155 | 155 | 156 | 156 | 156 | 156 | 156 | 155 | 162 | 160 | 158 | 157 | 158 | 159 | 159 | 158 | 152 | 151 | 151 | 152 | 153 | 154 | 153 | 152 | 150 | 150 | 148 | 144 | 140 | 138 | 137 | 138 | 135 | 135 | 135 | 134 | 131 | 129 | 127 | 127 | 128 | 129 | 130 | 131 | . 265 145 | 145 | 146 | 146 | 144 | 142 | 144 | 146 | 143 | 144 | 146 | 147 | 146 | 145 | 145 | 145 | 149 | 147 | 146 | 146 | 145 | 144 | 145 | 148 | 148 | 148 | 149 | 151 | 151 | 150 | 151 | 154 | 153 | 153 | 155 | 158 | 163 | 165 | 161 | 155 | 152 | 143 | 144 | 154 | 163 | 165 | 162 | 156 | 156 | 157 | 158 | 158 | 158 | 159 | 159 | 158 | 155 | 155 | 154 | 154 | 154 | 155 | 155 | 155 | 158 | 158 | 158 | 157 | 157 | 157 | 158 | 158 | 162 | 160 | 157 | 154 | 152 | 153 | 155 | 157 | 151 | 152 | 152 | 150 | 146 | 143 | 141 | 141 | 138 | 137 | 137 | 137 | 137 | 134 | 130 | 127 | 129 | 132 | 133 | 131 | . 266 141 | 144 | 144 | 140 | 137 | 137 | 140 | 142 | 144 | 145 | 146 | 147 | 146 | 146 | 146 | 147 | 148 | 146 | 146 | 145 | 144 | 143 | 144 | 146 | 147 | 147 | 149 | 152 | 152 | 150 | 150 | 152 | 150 | 151 | 151 | 153 | 158 | 163 | 164 | 162 | 160 | 152 | 147 | 146 | 150 | 158 | 165 | 165 | 160 | 157 | 155 | 157 | 158 | 157 | 158 | 162 | 158 | 157 | 156 | 155 | 155 | 154 | 154 | 154 | 156 | 157 | 159 | 158 | 157 | 156 | 157 | 159 | 159 | 157 | 154 | 150 | 146 | 146 | 149 | 152 | 151 | 153 | 154 | 153 | 151 | 148 | 146 | 145 | 145 | 142 | 139 | 139 | 141 | 140 | 135 | 131 | 131 | 130 | 133 | 142 | . 267 151 | 151 | 147 | 142 | 142 | 146 | 147 | 145 | 146 | 146 | 144 | 143 | 144 | 145 | 147 | 149 | 145 | 144 | 144 | 145 | 145 | 144 | 145 | 148 | 146 | 147 | 149 | 150 | 151 | 150 | 150 | 150 | 150 | 151 | 150 | 149 | 152 | 156 | 159 | 160 | 166 | 166 | 163 | 153 | 144 | 148 | 159 | 163 | 166 | 160 | 155 | 155 | 157 | 158 | 159 | 160 | 161 | 160 | 159 | 158 | 156 | 154 | 152 | 151 | 154 | 156 | 157 | 158 | 158 | 157 | 158 | 159 | 155 | 156 | 156 | 154 | 152 | 150 | 150 | 150 | 150 | 151 | 152 | 152 | 152 | 150 | 149 | 149 | 151 | 147 | 142 | 140 | 141 | 141 | 139 | 137 | 131 | 132 | 132 | 134 | . 268 146 | 147 | 144 | 139 | 139 | 142 | 141 | 138 | 144 | 143 | 142 | 141 | 142 | 143 | 145 | 145 | 144 | 143 | 143 | 145 | 145 | 145 | 146 | 148 | 146 | 147 | 147 | 147 | 148 | 149 | 149 | 148 | 151 | 152 | 151 | 150 | 150 | 154 | 157 | 158 | 163 | 165 | 168 | 164 | 157 | 155 | 153 | 147 | 161 | 162 | 161 | 157 | 156 | 157 | 158 | 158 | 160 | 160 | 160 | 159 | 157 | 155 | 152 | 150 | 152 | 152 | 153 | 155 | 158 | 159 | 159 | 159 | 155 | 155 | 157 | 158 | 159 | 157 | 154 | 151 | 151 | 150 | 149 | 149 | 150 | 151 | 152 | 152 | 152 | 150 | 146 | 144 | 142 | 142 | 141 | 141 | 140 | 137 | 133 | 128 | . 269 145 | 149 | 152 | 150 | 146 | 143 | 142 | 141 | 141 | 142 | 143 | 145 | 146 | 145 | 143 | 141 | 144 | 143 | 143 | 145 | 145 | 144 | 145 | 147 | 146 | 147 | 146 | 145 | 146 | 148 | 148 | 147 | 147 | 149 | 149 | 149 | 150 | 153 | 156 | 156 | 156 | 159 | 166 | 168 | 165 | 164 | 160 | 152 | 151 | 160 | 165 | 162 | 157 | 156 | 156 | 157 | 159 | 160 | 161 | 161 | 161 | 159 | 157 | 156 | 151 | 150 | 150 | 152 | 156 | 158 | 159 | 158 | 155 | 155 | 154 | 156 | 157 | 157 | 154 | 152 | 154 | 152 | 150 | 149 | 150 | 152 | 153 | 154 | 149 | 150 | 151 | 150 | 147 | 144 | 143 | 142 | 146 | 143 | 140 | 139 | . 270 140 | 143 | 146 | 148 | 146 | 141 | 139 | 139 | 143 | 144 | 146 | 148 | 149 | 147 | 143 | 140 | 143 | 142 | 143 | 144 | 144 | 143 | 144 | 146 | 146 | 147 | 146 | 145 | 146 | 148 | 148 | 146 | 145 | 146 | 147 | 147 | 148 | 152 | 154 | 154 | 154 | 156 | 162 | 165 | 162 | 164 | 167 | 166 | 154 | 155 | 157 | 159 | 160 | 157 | 155 | 154 | 159 | 159 | 160 | 160 | 161 | 161 | 161 | 161 | 156 | 155 | 153 | 153 | 153 | 155 | 156 | 157 | 159 | 158 | 158 | 157 | 158 | 158 | 157 | 157 | 157 | 155 | 153 | 152 | 153 | 153 | 153 | 152 | 149 | 151 | 153 | 153 | 151 | 148 | 147 | 146 | 145 | 148 | 149 | 143 | . 271 147 | 142 | 141 | 146 | 150 | 149 | 145 | 144 | 144 | 144 | 145 | 146 | 147 | 146 | 143 | 140 | 141 | 141 | 142 | 143 | 143 | 143 | 143 | 145 | 146 | 147 | 146 | 145 | 146 | 149 | 148 | 145 | 146 | 147 | 147 | 147 | 148 | 151 | 152 | 151 | 154 | 151 | 155 | 161 | 162 | 164 | 165 | 162 | 166 | 152 | 144 | 152 | 162 | 161 | 155 | 151 | 157 | 157 | 156 | 156 | 156 | 157 | 158 | 159 | 162 | 161 | 159 | 155 | 152 | 151 | 153 | 155 | 154 | 156 | 157 | 156 | 155 | 155 | 156 | 157 | 158 | 157 | 156 | 155 | 155 | 153 | 151 | 149 | 151 | 152 | 152 | 153 | 152 | 151 | 151 | 151 | 151 | 149 | 148 | 148 | . 272 148 | 147 | 145 | 144 | 145 | 146 | 148 | 149 | 146 | 144 | 142 | 142 | 143 | 145 | 146 | 146 | 143 | 144 | 145 | 145 | 148 | 149 | 147 | 143 | 146 | 145 | 146 | 146 | 143 | 141 | 143 | 147 | 148 | 147 | 147 | 148 | 149 | 150 | 150 | 150 | 152 | 152 | 154 | 158 | 160 | 160 | 161 | 162 | 168 | 167 | 157 | 150 | 155 | 157 | 155 | 158 | 150 | 154 | 157 | 157 | 157 | 157 | 157 | 155 | 159 | 159 | 161 | 162 | 161 | 158 | 155 | 152 | 153 | 154 | 155 | 155 | 154 | 154 | 155 | 155 | 154 | 155 | 155 | 154 | 153 | 153 | 155 | 156 | 153 | 152 | 151 | 151 | 151 | 151 | 151 | 151 | 151 | 150 | 148 | 147 | . 273 147 | 147 | 146 | 145 | 145 | 146 | 147 | 148 | 144 | 143 | 143 | 144 | 145 | 146 | 145 | 145 | 143 | 144 | 144 | 144 | 145 | 146 | 144 | 141 | 144 | 142 | 141 | 142 | 142 | 141 | 141 | 143 | 144 | 144 | 145 | 147 | 149 | 151 | 152 | 152 | 152 | 151 | 152 | 156 | 159 | 159 | 159 | 159 | 157 | 166 | 170 | 164 | 157 | 152 | 153 | 158 | 151 | 153 | 155 | 156 | 156 | 155 | 156 | 157 | 156 | 156 | 157 | 158 | 159 | 158 | 157 | 156 | 156 | 156 | 156 | 155 | 154 | 154 | 156 | 157 | 155 | 155 | 156 | 156 | 155 | 154 | 155 | 156 | 154 | 153 | 151 | 150 | 149 | 148 | 147 | 145 | 151 | 150 | 149 | 149 | . 274 145 | 146 | 146 | 146 | 146 | 145 | 145 | 145 | 146 | 145 | 144 | 144 | 143 | 142 | 141 | 140 | 143 | 144 | 143 | 142 | 143 | 144 | 143 | 140 | 146 | 143 | 141 | 143 | 145 | 145 | 144 | 143 | 144 | 144 | 145 | 147 | 147 | 148 | 148 | 148 | 151 | 150 | 151 | 155 | 157 | 158 | 157 | 158 | 160 | 164 | 169 | 169 | 164 | 160 | 157 | 152 | 153 | 151 | 152 | 154 | 155 | 153 | 155 | 158 | 155 | 155 | 154 | 155 | 157 | 158 | 159 | 160 | 157 | 157 | 157 | 156 | 155 | 155 | 155 | 156 | 154 | 154 | 155 | 155 | 154 | 154 | 154 | 154 | 154 | 152 | 151 | 151 | 153 | 153 | 151 | 150 | 150 | 150 | 149 | 149 | . 275 143 | 144 | 145 | 145 | 145 | 144 | 143 | 143 | 148 | 147 | 145 | 143 | 142 | 142 | 142 | 142 | 143 | 144 | 143 | 142 | 142 | 144 | 143 | 141 | 147 | 145 | 144 | 146 | 148 | 148 | 147 | 146 | 145 | 146 | 147 | 148 | 147 | 147 | 146 | 146 | 150 | 150 | 151 | 154 | 156 | 156 | 157 | 159 | 164 | 157 | 159 | 163 | 166 | 171 | 168 | 157 | 160 | 153 | 150 | 154 | 155 | 153 | 154 | 157 | 157 | 156 | 155 | 156 | 157 | 159 | 160 | 160 | 156 | 158 | 159 | 159 | 158 | 156 | 154 | 154 | 154 | 154 | 154 | 154 | 154 | 154 | 155 | 155 | 152 | 151 | 150 | 152 | 155 | 156 | 154 | 152 | 151 | 151 | 151 | 150 | . 276 143 | 144 | 145 | 146 | 146 | 145 | 144 | 143 | 145 | 145 | 146 | 146 | 145 | 145 | 145 | 146 | 143 | 144 | 144 | 142 | 143 | 145 | 145 | 144 | 143 | 144 | 144 | 144 | 144 | 144 | 145 | 145 | 142 | 144 | 146 | 148 | 149 | 149 | 150 | 151 | 147 | 148 | 151 | 153 | 153 | 153 | 155 | 159 | 157 | 154 | 158 | 160 | 159 | 166 | 174 | 172 | 167 | 159 | 153 | 156 | 159 | 156 | 155 | 157 | 158 | 157 | 156 | 157 | 158 | 158 | 159 | 159 | 159 | 159 | 160 | 160 | 159 | 157 | 157 | 156 | 157 | 156 | 155 | 155 | 155 | 156 | 157 | 157 | 154 | 152 | 151 | 152 | 153 | 152 | 150 | 148 | 151 | 151 | 152 | 153 | . 277 144 | 145 | 146 | 147 | 147 | 146 | 146 | 145 | 143 | 145 | 147 | 148 | 146 | 144 | 141 | 140 | 142 | 144 | 144 | 143 | 144 | 146 | 147 | 146 | 140 | 143 | 144 | 143 | 140 | 141 | 142 | 144 | 140 | 142 | 144 | 146 | 146 | 146 | 147 | 149 | 145 | 146 | 149 | 151 | 150 | 150 | 152 | 156 | 156 | 158 | 160 | 159 | 156 | 159 | 166 | 168 | 170 | 164 | 160 | 161 | 162 | 160 | 158 | 158 | 157 | 156 | 156 | 157 | 158 | 158 | 158 | 157 | 162 | 162 | 161 | 159 | 159 | 159 | 160 | 162 | 158 | 156 | 155 | 155 | 155 | 155 | 155 | 155 | 157 | 156 | 155 | 155 | 155 | 154 | 153 | 152 | 153 | 152 | 151 | 151 | . 278 144 | 145 | 145 | 145 | 146 | 146 | 146 | 146 | 146 | 147 | 148 | 147 | 144 | 141 | 139 | 138 | 141 | 143 | 144 | 143 | 143 | 145 | 146 | 145 | 141 | 145 | 146 | 143 | 140 | 141 | 143 | 144 | 143 | 144 | 145 | 144 | 141 | 140 | 141 | 142 | 147 | 146 | 146 | 149 | 150 | 150 | 150 | 152 | 157 | 159 | 157 | 155 | 157 | 158 | 158 | 158 | 165 | 165 | 164 | 163 | 161 | 159 | 159 | 160 | 158 | 158 | 158 | 158 | 158 | 158 | 157 | 156 | 160 | 160 | 160 | 160 | 160 | 160 | 161 | 162 | 159 | 158 | 157 | 157 | 157 | 156 | 153 | 152 | 155 | 156 | 157 | 157 | 156 | 157 | 158 | 159 | 156 | 154 | 152 | 151 | . 279 143 | 143 | 143 | 143 | 144 | 145 | 146 | 146 | 149 | 149 | 148 | 146 | 144 | 144 | 146 | 148 | 140 | 142 | 143 | 143 | 143 | 144 | 145 | 144 | 143 | 146 | 146 | 143 | 141 | 143 | 144 | 144 | 146 | 146 | 147 | 145 | 142 | 140 | 141 | 142 | 151 | 147 | 145 | 148 | 151 | 151 | 150 | 149 | 148 | 155 | 154 | 152 | 157 | 158 | 157 | 163 | 158 | 163 | 166 | 163 | 159 | 157 | 159 | 160 | 162 | 161 | 160 | 159 | 159 | 158 | 157 | 156 | 154 | 157 | 160 | 162 | 162 | 160 | 159 | 158 | 164 | 163 | 163 | 162 | 162 | 159 | 155 | 152 | 152 | 153 | 154 | 153 | 151 | 151 | 153 | 155 | 159 | 158 | 157 | 156 | . 280 148 | 145 | 140 | 138 | 140 | 143 | 143 | 141 | 142 | 143 | 144 | 146 | 147 | 147 | 147 | 146 | 143 | 141 | 142 | 145 | 146 | 145 | 146 | 147 | 143 | 145 | 146 | 145 | 145 | 146 | 144 | 142 | 140 | 142 | 145 | 146 | 146 | 146 | 146 | 146 | 146 | 147 | 148 | 148 | 147 | 148 | 150 | 152 | 152 | 150 | 152 | 156 | 156 | 154 | 155 | 158 | 162 | 158 | 162 | 166 | 164 | 165 | 160 | 146 | 152 | 159 | 162 | 159 | 160 | 164 | 161 | 153 | 151 | 157 | 159 | 159 | 160 | 157 | 155 | 157 | 161 | 159 | 157 | 158 | 160 | 161 | 160 | 159 | 156 | 154 | 152 | 152 | 153 | 155 | 154 | 152 | 154 | 154 | 153 | 154 | . 281 144 | 144 | 142 | 139 | 138 | 141 | 143 | 144 | 141 | 143 | 144 | 145 | 146 | 146 | 147 | 148 | 147 | 145 | 145 | 146 | 147 | 145 | 146 | 147 | 143 | 144 | 145 | 144 | 144 | 146 | 145 | 144 | 140 | 141 | 142 | 142 | 144 | 145 | 147 | 148 | 144 | 146 | 149 | 149 | 148 | 147 | 147 | 148 | 145 | 146 | 148 | 150 | 152 | 152 | 154 | 156 | 159 | 158 | 162 | 163 | 160 | 165 | 171 | 168 | 145 | 147 | 151 | 155 | 158 | 158 | 158 | 158 | 160 | 158 | 153 | 152 | 158 | 161 | 161 | 162 | 158 | 158 | 158 | 159 | 161 | 161 | 161 | 161 | 161 | 159 | 156 | 154 | 153 | 153 | 154 | 154 | 155 | 153 | 152 | 152 | . 282 143 | 146 | 146 | 142 | 138 | 139 | 143 | 145 | 143 | 144 | 145 | 146 | 145 | 146 | 147 | 148 | 148 | 147 | 146 | 146 | 145 | 144 | 143 | 144 | 143 | 144 | 144 | 143 | 143 | 145 | 147 | 146 | 146 | 145 | 143 | 143 | 143 | 143 | 143 | 143 | 142 | 144 | 147 | 149 | 148 | 147 | 146 | 146 | 144 | 146 | 148 | 148 | 150 | 153 | 155 | 155 | 153 | 155 | 161 | 163 | 160 | 163 | 167 | 166 | 175 | 158 | 148 | 152 | 154 | 150 | 152 | 160 | 162 | 164 | 161 | 158 | 157 | 156 | 157 | 162 | 159 | 160 | 160 | 160 | 159 | 158 | 158 | 158 | 162 | 162 | 161 | 157 | 153 | 151 | 150 | 150 | 155 | 153 | 152 | 152 | . 283 148 | 150 | 150 | 146 | 142 | 141 | 142 | 142 | 143 | 145 | 147 | 147 | 145 | 145 | 145 | 147 | 146 | 146 | 147 | 146 | 145 | 144 | 143 | 143 | 144 | 144 | 143 | 142 | 142 | 145 | 147 | 147 | 149 | 148 | 147 | 147 | 146 | 144 | 141 | 139 | 141 | 143 | 145 | 147 | 147 | 147 | 147 | 148 | 147 | 151 | 151 | 149 | 149 | 153 | 154 | 153 | 151 | 153 | 157 | 161 | 162 | 161 | 158 | 154 | 167 | 171 | 159 | 137 | 132 | 147 | 154 | 148 | 154 | 159 | 162 | 163 | 162 | 158 | 156 | 160 | 159 | 160 | 161 | 159 | 157 | 156 | 156 | 157 | 158 | 159 | 160 | 160 | 158 | 155 | 152 | 151 | 152 | 152 | 153 | 153 | . 284 149 | 149 | 148 | 146 | 147 | 147 | 143 | 139 | 141 | 143 | 145 | 145 | 145 | 144 | 144 | 144 | 144 | 146 | 148 | 149 | 148 | 147 | 146 | 145 | 145 | 146 | 144 | 142 | 142 | 145 | 146 | 147 | 146 | 147 | 147 | 148 | 149 | 148 | 147 | 146 | 144 | 144 | 144 | 144 | 145 | 146 | 148 | 149 | 148 | 151 | 151 | 148 | 147 | 150 | 151 | 150 | 154 | 154 | 154 | 155 | 159 | 160 | 160 | 161 | 155 | 162 | 165 | 155 | 142 | 138 | 143 | 149 | 150 | 148 | 145 | 152 | 163 | 166 | 163 | 164 | 159 | 160 | 161 | 160 | 158 | 157 | 159 | 162 | 156 | 156 | 157 | 159 | 162 | 162 | 161 | 159 | 153 | 154 | 154 | 154 | . 285 147 | 146 | 144 | 145 | 148 | 149 | 146 | 141 | 139 | 139 | 141 | 142 | 143 | 144 | 143 | 143 | 140 | 144 | 147 | 148 | 147 | 147 | 146 | 145 | 146 | 147 | 145 | 143 | 143 | 145 | 146 | 146 | 146 | 147 | 146 | 146 | 146 | 148 | 150 | 152 | 148 | 146 | 145 | 143 | 143 | 145 | 147 | 148 | 147 | 148 | 149 | 148 | 148 | 149 | 150 | 150 | 150 | 155 | 156 | 156 | 157 | 156 | 158 | 166 | 164 | 156 | 161 | 173 | 168 | 151 | 148 | 161 | 159 | 152 | 144 | 143 | 151 | 155 | 159 | 166 | 163 | 164 | 164 | 163 | 160 | 159 | 160 | 161 | 163 | 160 | 157 | 157 | 159 | 160 | 160 | 158 | 158 | 159 | 158 | 156 | . 286 147 | 147 | 146 | 145 | 145 | 147 | 146 | 144 | 142 | 141 | 140 | 141 | 143 | 144 | 144 | 143 | 140 | 143 | 146 | 145 | 144 | 145 | 146 | 145 | 146 | 147 | 146 | 144 | 144 | 146 | 146 | 145 | 145 | 146 | 147 | 145 | 143 | 144 | 147 | 150 | 147 | 146 | 145 | 144 | 144 | 145 | 145 | 145 | 145 | 146 | 147 | 149 | 149 | 149 | 150 | 152 | 147 | 154 | 155 | 157 | 160 | 155 | 153 | 159 | 150 | 156 | 158 | 155 | 161 | 171 | 170 | 160 | 165 | 163 | 157 | 152 | 148 | 144 | 148 | 159 | 164 | 165 | 166 | 165 | 163 | 161 | 160 | 160 | 166 | 163 | 160 | 158 | 157 | 156 | 154 | 153 | 160 | 159 | 158 | 158 | . 287 150 | 152 | 152 | 147 | 142 | 142 | 144 | 146 | 149 | 145 | 142 | 141 | 143 | 145 | 145 | 143 | 142 | 146 | 147 | 145 | 144 | 145 | 147 | 147 | 146 | 147 | 147 | 145 | 145 | 147 | 147 | 145 | 140 | 143 | 146 | 146 | 143 | 143 | 145 | 148 | 144 | 144 | 145 | 145 | 146 | 145 | 144 | 144 | 144 | 142 | 144 | 148 | 149 | 147 | 147 | 151 | 150 | 152 | 149 | 152 | 160 | 158 | 153 | 157 | 152 | 153 | 159 | 162 | 158 | 152 | 155 | 163 | 161 | 162 | 161 | 162 | 161 | 152 | 147 | 150 | 157 | 159 | 162 | 164 | 165 | 164 | 163 | 163 | 161 | 162 | 164 | 163 | 161 | 158 | 156 | 155 | 156 | 154 | 154 | 157 | . 288 144 | 147 | 151 | 151 | 147 | 143 | 145 | 150 | 144 | 148 | 148 | 144 | 142 | 144 | 144 | 142 | 144 | 144 | 144 | 143 | 143 | 145 | 145 | 144 | 146 | 148 | 147 | 144 | 143 | 147 | 148 | 147 | 144 | 147 | 147 | 145 | 146 | 148 | 147 | 144 | 145 | 144 | 143 | 140 | 137 | 140 | 144 | 141 | 142 | 144 | 146 | 146 | 146 | 146 | 147 | 149 | 148 | 149 | 149 | 149 | 150 | 154 | 156 | 156 | 158 | 152 | 148 | 151 | 155 | 156 | 155 | 155 | 163 | 159 | 155 | 157 | 163 | 165 | 159 | 151 | 149 | 158 | 161 | 161 | 164 | 165 | 164 | 164 | 161 | 164 | 162 | 158 | 159 | 164 | 165 | 161 | 159 | 157 | 156 | 157 | . 289 148 | 141 | 136 | 140 | 147 | 150 | 148 | 146 | 146 | 150 | 151 | 145 | 140 | 141 | 144 | 144 | 143 | 145 | 144 | 142 | 141 | 143 | 144 | 143 | 141 | 143 | 145 | 144 | 144 | 145 | 145 | 144 | 146 | 146 | 144 | 142 | 143 | 145 | 146 | 145 | 144 | 144 | 146 | 145 | 141 | 142 | 143 | 140 | 143 | 144 | 145 | 145 | 145 | 146 | 148 | 150 | 148 | 149 | 148 | 147 | 148 | 151 | 152 | 152 | 155 | 160 | 156 | 143 | 138 | 147 | 156 | 156 | 154 | 157 | 159 | 158 | 157 | 160 | 163 | 165 | 169 | 159 | 149 | 153 | 162 | 162 | 160 | 163 | 165 | 163 | 165 | 169 | 166 | 158 | 159 | 166 | 165 | 162 | 159 | 158 | . 290 173 | 165 | 155 | 148 | 145 | 145 | 146 | 148 | 140 | 144 | 147 | 148 | 149 | 150 | 146 | 140 | 146 | 147 | 147 | 144 | 143 | 143 | 144 | 144 | 143 | 143 | 144 | 145 | 145 | 143 | 142 | 143 | 145 | 144 | 145 | 148 | 148 | 147 | 147 | 147 | 145 | 145 | 147 | 147 | 144 | 144 | 145 | 141 | 142 | 142 | 142 | 142 | 143 | 144 | 145 | 146 | 148 | 149 | 148 | 147 | 147 | 149 | 150 | 149 | 150 | 155 | 157 | 152 | 144 | 141 | 145 | 150 | 152 | 155 | 156 | 155 | 155 | 157 | 160 | 161 | 154 | 163 | 163 | 158 | 159 | 160 | 158 | 156 | 161 | 164 | 165 | 164 | 162 | 162 | 163 | 164 | 165 | 162 | 159 | 159 | . 291 174 | 174 | 171 | 161 | 149 | 142 | 143 | 147 | 151 | 150 | 148 | 145 | 145 | 146 | 146 | 143 | 146 | 148 | 149 | 146 | 144 | 143 | 144 | 143 | 147 | 144 | 143 | 145 | 146 | 145 | 145 | 148 | 143 | 142 | 143 | 146 | 146 | 142 | 142 | 144 | 146 | 145 | 147 | 147 | 144 | 145 | 148 | 146 | 142 | 141 | 141 | 142 | 142 | 142 | 142 | 141 | 148 | 149 | 150 | 149 | 149 | 150 | 149 | 148 | 146 | 147 | 152 | 159 | 158 | 149 | 141 | 139 | 148 | 150 | 152 | 153 | 154 | 156 | 155 | 154 | 160 | 151 | 150 | 164 | 171 | 159 | 152 | 159 | 159 | 158 | 154 | 151 | 156 | 165 | 166 | 162 | 164 | 160 | 158 | 160 | . 292 168 | 170 | 173 | 173 | 169 | 160 | 148 | 140 | 142 | 146 | 149 | 149 | 147 | 147 | 148 | 150 | 144 | 146 | 147 | 145 | 143 | 142 | 142 | 140 | 145 | 142 | 142 | 145 | 147 | 146 | 147 | 149 | 150 | 146 | 144 | 145 | 143 | 141 | 143 | 148 | 146 | 144 | 147 | 148 | 145 | 145 | 147 | 145 | 141 | 142 | 143 | 144 | 144 | 144 | 143 | 143 | 145 | 148 | 150 | 150 | 150 | 150 | 149 | 147 | 145 | 150 | 151 | 149 | 154 | 159 | 153 | 141 | 139 | 146 | 151 | 151 | 149 | 151 | 155 | 157 | 158 | 161 | 155 | 147 | 151 | 161 | 164 | 163 | 165 | 153 | 147 | 153 | 158 | 157 | 158 | 163 | 167 | 164 | 161 | 162 | . 293 168 | 170 | 173 | 176 | 178 | 176 | 169 | 161 | 147 | 144 | 142 | 144 | 149 | 152 | 150 | 146 | 145 | 146 | 146 | 144 | 144 | 144 | 143 | 141 | 146 | 144 | 144 | 146 | 146 | 144 | 140 | 139 | 142 | 143 | 146 | 148 | 148 | 147 | 147 | 149 | 145 | 144 | 148 | 151 | 147 | 145 | 144 | 142 | 139 | 141 | 144 | 144 | 144 | 143 | 144 | 144 | 143 | 145 | 147 | 148 | 149 | 150 | 149 | 147 | 147 | 148 | 148 | 148 | 151 | 156 | 156 | 153 | 144 | 144 | 143 | 142 | 144 | 149 | 151 | 152 | 154 | 154 | 155 | 157 | 154 | 147 | 153 | 169 | 163 | 159 | 158 | 159 | 158 | 154 | 154 | 158 | 166 | 163 | 162 | 164 | . 294 156 | 160 | 162 | 163 | 167 | 174 | 180 | 183 | 181 | 167 | 151 | 143 | 144 | 146 | 146 | 143 | 148 | 147 | 145 | 143 | 144 | 147 | 147 | 145 | 148 | 148 | 147 | 146 | 145 | 144 | 140 | 135 | 132 | 137 | 141 | 143 | 143 | 143 | 144 | 143 | 145 | 143 | 147 | 151 | 148 | 145 | 145 | 143 | 139 | 142 | 144 | 143 | 141 | 140 | 142 | 145 | 143 | 145 | 145 | 145 | 146 | 148 | 149 | 148 | 148 | 145 | 146 | 152 | 153 | 150 | 152 | 157 | 154 | 148 | 141 | 139 | 144 | 149 | 147 | 142 | 143 | 151 | 152 | 149 | 156 | 163 | 156 | 146 | 157 | 162 | 163 | 160 | 158 | 158 | 157 | 154 | 160 | 159 | 159 | 161 | . 295 158 | 159 | 159 | 158 | 160 | 165 | 169 | 170 | 173 | 177 | 179 | 173 | 161 | 150 | 147 | 148 | 149 | 147 | 142 | 140 | 142 | 147 | 148 | 146 | 146 | 147 | 146 | 144 | 146 | 149 | 148 | 144 | 148 | 149 | 145 | 138 | 136 | 140 | 145 | 146 | 145 | 142 | 145 | 148 | 146 | 145 | 148 | 148 | 143 | 146 | 147 | 144 | 140 | 138 | 142 | 145 | 145 | 145 | 145 | 144 | 145 | 148 | 150 | 149 | 147 | 150 | 149 | 145 | 146 | 152 | 154 | 150 | 154 | 154 | 152 | 148 | 147 | 147 | 148 | 147 | 142 | 147 | 146 | 143 | 148 | 153 | 156 | 159 | 158 | 151 | 152 | 161 | 164 | 159 | 157 | 161 | 157 | 156 | 157 | 158 | . 296 154 | 156 | 156 | 156 | 155 | 156 | 158 | 161 | 164 | 166 | 169 | 174 | 179 | 179 | 171 | 162 | 147 | 148 | 150 | 149 | 144 | 140 | 143 | 148 | 146 | 145 | 145 | 147 | 147 | 146 | 143 | 141 | 147 | 146 | 145 | 145 | 143 | 140 | 134 | 129 | 140 | 143 | 146 | 146 | 144 | 144 | 147 | 150 | 143 | 144 | 143 | 141 | 139 | 139 | 137 | 135 | 140 | 145 | 147 | 142 | 139 | 142 | 147 | 149 | 144 | 147 | 150 | 150 | 149 | 148 | 149 | 151 | 149 | 153 | 154 | 152 | 149 | 148 | 147 | 146 | 144 | 144 | 146 | 148 | 148 | 146 | 147 | 150 | 169 | 159 | 149 | 148 | 154 | 161 | 161 | 159 | 161 | 159 | 160 | 163 | . 297 155 | 157 | 158 | 157 | 156 | 157 | 159 | 161 | 164 | 164 | 163 | 164 | 169 | 175 | 178 | 178 | 164 | 152 | 142 | 142 | 148 | 151 | 147 | 143 | 146 | 148 | 146 | 141 | 141 | 145 | 147 | 146 | 146 | 145 | 145 | 146 | 147 | 146 | 145 | 143 | 135 | 138 | 140 | 141 | 142 | 145 | 149 | 153 | 146 | 145 | 142 | 138 | 137 | 139 | 141 | 141 | 144 | 141 | 140 | 141 | 144 | 145 | 145 | 144 | 144 | 145 | 147 | 147 | 147 | 146 | 146 | 147 | 150 | 150 | 149 | 149 | 152 | 154 | 152 | 147 | 146 | 145 | 145 | 147 | 146 | 145 | 147 | 150 | 146 | 152 | 156 | 155 | 151 | 150 | 154 | 158 | 157 | 162 | 163 | 160 | . 298 161 | 162 | 162 | 162 | 161 | 161 | 163 | 164 | 162 | 163 | 163 | 161 | 160 | 163 | 166 | 167 | 180 | 177 | 171 | 160 | 148 | 141 | 144 | 150 | 142 | 143 | 143 | 142 | 140 | 140 | 143 | 146 | 148 | 148 | 147 | 147 | 147 | 147 | 147 | 148 | 141 | 141 | 141 | 141 | 141 | 143 | 146 | 148 | 147 | 146 | 142 | 138 | 137 | 139 | 142 | 142 | 147 | 140 | 138 | 143 | 147 | 145 | 142 | 141 | 145 | 145 | 146 | 146 | 146 | 146 | 146 | 146 | 148 | 148 | 147 | 148 | 152 | 155 | 154 | 151 | 148 | 147 | 147 | 147 | 147 | 147 | 150 | 154 | 145 | 149 | 155 | 157 | 156 | 155 | 155 | 156 | 154 | 158 | 159 | 156 | . 299 157 | 158 | 158 | 158 | 157 | 156 | 157 | 158 | 157 | 161 | 163 | 163 | 162 | 164 | 165 | 165 | 157 | 162 | 168 | 171 | 167 | 158 | 150 | 145 | 137 | 139 | 145 | 149 | 142 | 131 | 133 | 142 | 145 | 146 | 146 | 145 | 144 | 144 | 144 | 144 | 149 | 147 | 145 | 144 | 143 | 143 | 144 | 144 | 147 | 148 | 147 | 144 | 143 | 143 | 142 | 140 | 143 | 143 | 144 | 146 | 144 | 141 | 140 | 141 | 144 | 144 | 144 | 145 | 146 | 147 | 147 | 147 | 145 | 148 | 150 | 149 | 147 | 148 | 151 | 154 | 151 | 151 | 150 | 149 | 148 | 148 | 150 | 152 | 156 | 152 | 150 | 153 | 159 | 163 | 161 | 158 | 155 | 151 | 150 | 155 | . - 결국 이 이미지는 683 $ times$ 1024 개의 숫자의 모임 . - 이 이미지를 벡터로 만든다음 히스토그램을 그려보자. . img.flatten().shape . (699392,) . fig1=plt.hist(img.flatten(),256,[0,256]) . - 히스토그램을 그려보니 120~200 사이에 너무 값들이 모여있음 . - 원래 0~255까지의 색을 표현할 수 있는데 컴퓨터가 표현가능한 색상보다 적은 조합만을 사용하고 있음. . - 아이디어: 좀 더 많은 색상을 표현할 수 없을까? $ to$ 위의 히스토그램은 좀 평평하게 만들면 되지 않을까? . img2=cv.equalizeHist(img) . fig2_1=plt.hist(img2.flatten(),256,[0,256]) # 256개의 구간으로 히스토그램 만들어 . fig2_2=plt.hist(img2.flatten(),10,[0,256]) . plt.imshow(img2,cmap=&#39;gray&#39;,vmin=0,vmax=255) plt.colorbar() . &lt;matplotlib.colorbar.Colorbar at 0x7f6a6e40d1f0&gt; . - 변환전과 변환후를 나란히 보게 되면? . import numpy as np . _img=np.hstack((img,img2)) . plt.imshow(_img,cmap=&#39;gray&#39;) . &lt;matplotlib.image.AxesImage at 0x7f6a6967c760&gt; . &#49689;&#51228;2 . - 아래 이미지를 HE(histogram equalization)로 보정하고 스샷제출 . ref: https://ukdevguy.com/histogram-equalization-in-python/ | . hw_img=cv.imread(&#39;hw_img.png&#39;,0) plt.imshow(hw_img,cmap=&#39;gray&#39;) . &lt;matplotlib.image.AxesImage at 0x7f6a69661df0&gt; . - 이미지는 https://raw.githubusercontent.com/guebin/2021DV/master/_notebooks/hw_img.png 에서 다운받을 수 있다. . hw_img2=cv.equalizeHist(hw_img) . plt.imshow(hw_img2,cmap=&#39;gray&#39;,vmin=0,vmax=255) plt.colorbar() . &lt;matplotlib.colorbar.Colorbar at 0x7f6a69572b20&gt; . _img_hw=np.hstack((hw_img,hw_img2)) . plt.imshow(_img_hw,cmap=&#39;gray&#39;) plt.colorbar() . &lt;matplotlib.colorbar.Colorbar at 0x7f6a694ad280&gt; .",
            "url": "https://seoyeonc.github.io/chch/2021/09/13/%EB%8D%B0%EC%8B%9C_2%EC%A3%BC%EC%B0%A8.html",
            "relUrl": "/2021/09/13/%EB%8D%B0%EC%8B%9C_2%EC%A3%BC%EC%B0%A8.html",
            "date": " • Sep 13, 2021"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . (_pages/about에서 수정) . 학력 . 학사…석사…. . 경력 . 어디..ㅇ디.. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://seoyeonc.github.io/chch/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://seoyeonc.github.io/chch/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}