{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# TensorFlow Category 5\n",
    "> `Individual House Hold Electric Power Consumption Dataset`을 활용한 예측\n",
    "\n",
    "- toc:true\n",
    "- branch: master\n",
    "- badges: true\n",
    "- comments: false\n",
    "- author: 최서연\n",
    "- categories: [TensorFlow]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4odN9vGLL5vF"
   },
   "source": [
    "## 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zPhkbbfCL6T9"
   },
   "source": [
    "1. GPU 옵션 켜져 있는지 확인할 것!!! (수정 - 노트설정 - 하드웨어설정 (GPU))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xaFSq4s3L8ht"
   },
   "source": [
    "## 순서"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-kXOCqfL8eF"
   },
   "source": [
    "1. **import**: 필요한 모듈 import\n",
    "2. **전처리**: 학습에 필요한 데이터 전처리를 수행합니다.\n",
    "3. **모델링(model)**: 모델을 정의합니다.\n",
    "4. **컴파일(compile)**: 모델을 생성합니다.\n",
    "5. **학습 (fit)**: 모델을 학습시킵니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kqk9o1bTL8ZF"
   },
   "source": [
    "## 문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XvgGPciAL8QW"
   },
   "source": [
    "ABOUT THE DATASET\n",
    "\n",
    "Original Source:\n",
    "https://archive.ics.uci.edu/ml/datasets/individual+household+electric+power+consumption\n",
    "\n",
    "The original 'Individual House Hold Electric Power Consumption Dataset'\n",
    "has Measurements of electric power consumption in one household with\n",
    "a one-minute sampling rate over a period of almost 4 years.\n",
    "\n",
    "Different electrical quantities and some sub-metering values are available.\n",
    "\n",
    "For the purpose of the examination we have provided a subset containing\n",
    "the data for the first 60 days in the dataset. We have also cleaned the\n",
    "dataset beforehand to remove missing values. The dataset is provided as a\n",
    "csv file in the project.\n",
    "\n",
    "The dataset has a total of 7 features ordered by time.\n",
    "==============================================================================\n",
    "\n",
    "INSTRUCTIONS\n",
    "\n",
    "Complete the code in following functions:\n",
    "1. windowed_dataset()\n",
    "2. solution_model()\n",
    "\n",
    "The model input and output shapes must match the following\n",
    "specifications.\n",
    "\n",
    "1. Model input_shape must be (BATCH_SIZE, N_PAST = 24, N_FEATURES = 7),\n",
    "   since the testing infrastructure expects a window of past N_PAST = 24\n",
    "   observations of the 7 features to predict the next 24 observations of\n",
    "   the same features.\n",
    "\n",
    "2. Model output_shape must be (BATCH_SIZE, N_FUTURE = 24, N_FEATURES = 7)\n",
    "\n",
    "3. DON'T change the values of the following constants\n",
    "   N_PAST, N_FUTURE, SHIFT in the windowed_dataset()\n",
    "   BATCH_SIZE in solution_model() (See code for additional note on\n",
    "   BATCH_SIZE).\n",
    "4. Code for normalizing the data is provided - DON't change it.\n",
    "   Changing the normalizing code will affect your score.\n",
    "\n",
    "HINT: Your neural network must have a **validation MAE of approximately 0.055** or\n",
    "less on the normalized validation dataset for top marks.\n",
    "\n",
    "WARNING: Do not use lambda layers in your model, they are not supported\n",
    "on the grading infrastructure.\n",
    "\n",
    "WARNING: If you are using the GRU layer, it is advised not to use the\n",
    "'recurrent_dropout' argument (you can alternatively set it to 0),\n",
    "since it has not been implemented in the cuDNN kernel and may\n",
    "result in much longer training times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w7I4VwtsON9H"
   },
   "source": [
    "## 필요한 모듈 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KPbpBIlJ_I4U"
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Conv1D, LSTM, Bidirectional\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TpZw2qNyORZO",
    "tags": []
   },
   "source": [
    "## 데이터셋 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OTErfPA2OU92"
   },
   "outputs": [],
   "source": [
    "def download_and_extract_data():\n",
    "    url = 'https://storage.googleapis.com/download.tensorflow.org/data/certificate/household_power.zip'\n",
    "    urllib.request.urlretrieve(url, 'household_power.zip')\n",
    "    with zipfile.ZipFile('household_power.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "84yYH8yhOVbG"
   },
   "outputs": [],
   "source": [
    "download_and_extract_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "D6-31N10OW2u",
    "outputId": "015cdb42-8ce9-4d13-e2f3-9c2527ec9907"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('household_power_consumption.csv', sep=',', infer_datetime_format=True, index_col='datetime', header=0)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "24개 학습해서 24개 맞출 예정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W8T_IULIOaTu"
   },
   "source": [
    "## 데이터 정규화\n",
    "\n",
    "데이터의 스케일(Scale)을 0 ~ 1 사이로 정규화 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ujr6nyzkOZem"
   },
   "outputs": [],
   "source": [
    "def normalize_series(data, min, max):\n",
    "    data = data - min\n",
    "    data = data / max\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에는 문제에서 건들지 마라고 언급될걸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C6DSkBjMOsOc",
    "outputId": "f4c19292-0b4d-460b-b339-e2ff3c93a324"
   },
   "outputs": [],
   "source": [
    "# FEATURES에 데이터프레임의 Column 개수 대입\n",
    "N_FEATURES = len(df.columns)\n",
    "\n",
    "# 데이터프레임을 numpy array으로 가져와 data에 대입\n",
    "data = df.values\n",
    "\n",
    "# 데이터 정규화\n",
    "data = normalize_series(data, data.min(axis=0), data.max(axis=0))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "1eOHSnw5Sgr1",
    "outputId": "00ce4d41-4c56-44cb-c6ef-2cc77fc7dd4e"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(data).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vDlrFALf87hk"
   },
   "source": [
    "## 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tb_FY89o9OIk"
   },
   "outputs": [],
   "source": [
    "# 데이터셋 분할 (0.8). \n",
    "# 기존 0.5 -> 0.8로 변경 // 다른 비율로 변경 가능\n",
    "split_time = int(len(data) * 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "81keVjW29AXD"
   },
   "outputs": [],
   "source": [
    "x_train = data[:split_time]\n",
    "x_valid = data[split_time:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_crFBEHu89mR"
   },
   "source": [
    "## Windowed Dataset 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jH_QOZ0p00hO"
   },
   "source": [
    "This line converts the dataset into a windowed dataset where a\n",
    "window consists of both the observations to be included as features and the targets.\n",
    "\n",
    "Don't change the shift parameter. The test windows are\n",
    "created with the specified shift and hence it might affect your\n",
    "scores. Calculate the window size so that based on the **past 24 observations (observations at time steps t=1,t=2,...t=24) of the 7 variables**\n",
    "\n",
    "in the dataset, you predict the **next 24 observations\n",
    "(observations at time steps t=25,t=26....t=48) of the 7 variables of the dataset.**\n",
    "\n",
    "Hint: Each window should include both the past observations and\n",
    "the future observations which are to be predicted. Calculate the\n",
    "window size based on n_past and n_future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "frxkiKXxLbJu"
   },
   "outputs": [],
   "source": [
    "def windowed_dataset(series, batch_size, n_past=24, n_future=24, shift=1):\n",
    "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
    "    ds = ds.window(size=(n_past + n_future), shift = shift, drop_remainder = True)\n",
    "    ds = ds.flat_map(lambda w: w.batch(n_past + n_future))\n",
    "    ds = ds.shuffle(len(series))\n",
    "    ds = ds.map(\n",
    "        lambda w: (w[:n_past], w[n_past:])\n",
    "    )\n",
    "    return ds.batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c-hBQxDf4s6c"
   },
   "source": [
    "`train_set`과 `valid_set`을 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wVFQ99wf9YO8"
   },
   "outputs": [],
   "source": [
    "# 다음 4개의 옵션은 주어 집니다.\n",
    "BATCH_SIZE = 32 # 변경 가능하나 더 올리는 것은 비추 (내리는 것은 가능하나 시간 오래 걸림)\n",
    "N_PAST = 24 # 변경 불가.\n",
    "N_FUTURE = 24 # 변경 불가.\n",
    "SHIFT = 1 # 변경 불가."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SJbUkp1W4n-z"
   },
   "outputs": [],
   "source": [
    "train_set = windowed_dataset(series=x_train, \n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             n_past=N_PAST, \n",
    "                             n_future=N_FUTURE,\n",
    "                             shift=SHIFT)\n",
    "\n",
    "valid_set = windowed_dataset(series=x_valid, \n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             n_past=N_PAST, \n",
    "                             n_future=N_FUTURE,\n",
    "                             shift=SHIFT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_1yVBgfz5AK8"
   },
   "source": [
    "## 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "94dEuVdH5Cpk"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    Conv1D(filters=32, \n",
    "            kernel_size=3,\n",
    "            padding=\"causal\",\n",
    "            activation=\"relu\",\n",
    "            input_shape=[N_PAST, 7],\n",
    "            ),\n",
    "    Bidirectional(LSTM(32, return_sequences=True)),\n",
    "    Dense(32, activation=\"relu\"),\n",
    "    Dense(16, activation=\"relu\"),\n",
    "    Dense(N_FEATURES)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filter_size나 kernal_size등 바꿔보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kBuqPmBF5GP6"
   },
   "source": [
    "## 체크포인트 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Arm5-TF5Jh7"
   },
   "outputs": [],
   "source": [
    "checkpoint_path='model/my_checkpoint.ckpt'\n",
    "\n",
    "checkpoint = ModelCheckpoint(checkpoint_path,\n",
    "                             save_weights_only=True,\n",
    "                             save_best_only=True,\n",
    "                             monitor='val_loss',\n",
    "                             verbose=1,\n",
    "                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aVt2b6lq5QiU"
   },
   "source": [
    "## 모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yr5PxcHR5MUp"
   },
   "outputs": [],
   "source": [
    "# learning_rate=0.0005, Adam 옵치마이저\n",
    "optimizer =  tf.keras.optimizers.Adam(learning_rate=0.0005)\n",
    "\n",
    "model.compile(loss='mae',\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"mae\"]\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W_zhL1eL5akg"
   },
   "source": [
    "## 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "56MfdhKe5Zr1",
    "outputId": "3d40217e-b4fa-41a0-fe1e-a567ac669948"
   },
   "outputs": [],
   "source": [
    "model.fit(train_set, \n",
    "        validation_data=(valid_set), \n",
    "        epochs=20, \n",
    "        callbacks=[checkpoint], \n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "paeq-Xus5eI8"
   },
   "source": [
    "`load_weights` 로 저장한 모델 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rJTuV1s-5cB8",
    "outputId": "e770a211-11e4-47e0-eee3-39e1a3801699"
   },
   "outputs": [],
   "source": [
    "model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E_OWIGHV5lNs"
   },
   "source": [
    "## 모델 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ardw40zS53CV"
   },
   "outputs": [],
   "source": [
    "# HINT: Your neural network must have a validation MAE of approximately 0.055 or\n",
    "# less on the normalized validation dataset for top marks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mE6m1sRE5ih8",
    "outputId": "ae66dacd-17df-4f49-82d5-08c60a3cdd4c"
   },
   "outputs": [],
   "source": [
    "model.evaluate(valid_set)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
