{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c44061c-9d43-4d23-8d5e-606a6b206802",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 빅데이터 분석 특강 (midterm 대비)\n",
    "\n",
    "- toc:true\n",
    "- branch: master\n",
    "- badges: true\n",
    "- comments: false\n",
    "- author: 최서연\n",
    "- categories: [Special Topics in Big Data Analysis]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02425a4-7a5a-4f8a-8b19-35832c037835",
   "metadata": {
    "id": "e3c11be6-bdd2-42ea-8a4e-b18d54851532"
   },
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edfad276-b67d-4036-8671-a5e640aea97d",
   "metadata": {
    "id": "4205a323-41bd-447a-a737-4a77a15d4be8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf \n",
    "import tensorflow.experimental.numpy as tnp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e7523b9-7ce8-4d8b-8f6b-9d12ce1e66d8",
   "metadata": {
    "id": "b9491bb4-1f1a-4763-b0b6-977b47413732"
   },
   "outputs": [],
   "source": [
    "tnp.experimental_enable_numpy_behavior()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070cd3b7-2c17-4e4a-aa45-a1d1e89c2363",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130f50fa-39d9-49ad-94b3-e7f25326284a",
   "metadata": {
    "id": "9419b5c9-92c2-4c9a-9248-8567c3d9ad83"
   },
   "source": [
    "### `1`. 인지할 것"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3036e1d8-1d2b-4caa-9e6b-bfcda3f4b81e",
   "metadata": {},
   "source": [
    "- 계산은 같은 자료형끼리, keras는 소수점 맞춰서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4b2bc38-fd5f-48b6-a3fd-39ea9a69723e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-23 08:13:19.821724: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-23 08:13:20.277096: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22288 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:65:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=4.140000000000001>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(1.0,dtype=tf.float64) + tf.constant(3.14,dtype=tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9d4bfc5-af22-40cf-9503-3fe9bb234024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=4.140000000000001>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.add(tf.constant(1.0,dtype=tf.float64), tf.constant(3.14,dtype=tf.float64)) # 덧셈 = +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "870766db-0dfd-4da1-8bfa-c48c6a09c64d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[ 5, 12],\n",
       "       [21, 32]], dtype=int32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.multiply(tf.constant([[1,2],[3,4]]),tf.constant([[5,6],[7,8]])) # 요소의 곱 = *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10be7d3a-18f9-4461-9a4b-750dbb45cf78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[19, 22],\n",
       "       [43, 50]], dtype=int32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.matmul(tf.constant([[1,2],[3,4]]),tf.constant([[5,6],[7,8]])) # 행렬의 곱 = @"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "598654ba-3a6e-4a99-b69d-bb72f1129093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=int64, numpy=\n",
       "array([[1, 0, 0, 0],\n",
       "       [0, 2, 0, 0],\n",
       "       [0, 0, 3, 0],\n",
       "       [0, 0, 0, 4]])>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(np.diag([1,2,3,4])) # 텐서로 대각행렬 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51710c85-0cd7-4643-8ca0-84df21a45c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[0., 0.],\n",
       "       [0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.zeros([2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc0e6d56-c68d-47bc-87a8-a11dca4c4828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[1., 1.],\n",
       "       [1., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.ones([2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eeedee97-e19b-4b41-a105-7579837c5811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float64, numpy=\n",
       "array([0.        , 0.11111111, 0.22222222, 0.33333333, 0.44444444,\n",
       "       0.55555556, 0.66666667, 0.77777778, 0.88888889, 1.        ])>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.linspace(0,1,10) # 0에서 1 사이의 10개 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f40d0d-9e89-4a07-a32d-d9af57a5b0e1",
   "metadata": {},
   "source": [
    "- 차원 확장 없이 변경만 원할 때 `tf.concat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26260bcc-051b-457a-8f37-ddea9a40ed60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[1, 2],\n",
       "       [3, 4]], dtype=int32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.concat([tf.constant([[1,2]]), tf.constant([[3,4]])],axis=0) # 원하는 차원의 수 axis 입력 첫번째 = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172c832e-41f6-4d38-a158-d96a81103c81",
   "metadata": {},
   "source": [
    "- 차원을 확장하면서 변경을 원할 때 `tf.stack`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99f63e6a-7bbf-40fc-b1c8-7e143eb0f089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 2), dtype=int32, numpy=\n",
       "array([[1, 1],\n",
       "       [2, 2],\n",
       "       [3, 3],\n",
       "       [4, 4]], dtype=int32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.stack([tf.constant([1,2,3,4]),tf.constant([1,2,3,4])],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24635e78-ca38-4f7c-b352-83438b3ccb54",
   "metadata": {},
   "source": [
    "- 자료형 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0780b8a-fdc7-4135-88e4-d5be6771dbab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensorflow.python.ops.resource_variable_ops.ResourceVariable,\n",
       " tensorflow.python.framework.ops.EagerTensor)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.Variable([1,2,3,4])\n",
    "b = -a\n",
    "type(a),type(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e2fe5b5-8b98-402b-9245-8eda263ba294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensorflow.python.ops.resource_variable_ops.ResourceVariable,\n",
       " tensorflow.python.ops.resource_variable_ops.ResourceVariable)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.Variable([1,2,3,4])\n",
    "b = tf.Variable([-1,-2,-3,-4])\n",
    "type(a),type(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ffb53e7-6418-4aa3-9989-c98582ed6d2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 2], dtype=int32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:2] # 불러온 수의 전 위치까지만 불러온다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5041c0-5486-4846-bfe1-54882f315129",
   "metadata": {
    "id": "9419b5c9-92c2-4c9a-9248-8567c3d9ad83"
   },
   "source": [
    "### `2`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d3ead71-47f3-4f90-bb21-309a4cbfedf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tnp.array([11.0,12.0,13.0,14.0,15.0])\n",
    "y = tnp.array([17.7,18.5,21.2,23.6,24.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd57be45-a143-4fdf-ad6b-8b357f1787a8",
   "metadata": {},
   "source": [
    "(a) 모형 $y_i=\\beta_0+\\beta_1 x_i$ 에 해당하는 네트워크를 keras를 이용하여 설계하고 손실함수를 정의하라. $(\\beta_0,\\beta_1)=(3,3)$ 일 경우의 loss를 계산하라.\n",
    "- 손실함수는 MSELoss를 활용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c2606f5-db43-4c29-8a3a-02af891f46d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.concat([tf.ones(5,dtype=tf.float64).reshape(5,1),x.reshape(5,1)],axis=1)\n",
    "y = y.reshape(5,1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5e17a2a-b23b-4dec-812b-a536adebf8f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 2), dtype=float64, numpy=\n",
       "array([[ 1., 11.],\n",
       "       [ 1., 12.],\n",
       "       [ 1., 13.],\n",
       "       [ 1., 14.],\n",
       "       [ 1., 15.]])>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "403ebde1-e196-4267-a860-cc198430fa2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 5), dtype=float64, numpy=\n",
       "array([[ 1.,  1.,  1.,  1.,  1.],\n",
       "       [11., 12., 13., 14., 15.]])>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bbee7d36-8749-4959-9789-6c1a3b7a86ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-23 08:13:21.281547: I tensorflow/core/util/cuda_solvers.cc:179] Creating GpuSolver handles for stream 0x5631fd34e110\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float64, numpy=\n",
       "array([[-2.49],\n",
       "       [ 1.81]])>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta = tf.linalg.inv(X.T @ X) @ X.T @ y\n",
    "beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60d65d64-2333-4e44-b315-7fcc03d4af0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float64, numpy=\n",
       "array([[-7.67386155e-13],\n",
       "       [-1.00044417e-11]])>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = -2*X.T @ y + 2*X.T@X@beta \n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "360cb997-e456-47be-893c-e3b729ecd3f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 1) dtype=float64, numpy=\n",
       "array([[3.],\n",
       "       [3.]])>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta = tf.Variable(tnp.array([3.0,3.0]).reshape(2,1))\n",
    "beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4e8aa92-9d26-4d6e-b725-686ef903a286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float64, numpy=\n",
       "array([[ 209.6],\n",
       "       [2748.6]])>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = -2*X.T @ y + 2*X.T@X@beta \n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d434cdc-cabd-4fd5-b45f-8dfd8363c29e",
   "metadata": {},
   "source": [
    "(b) $(\\beta_0,\\beta_1)=(3,3)$ 에서 손실함수의 미분계수를 계산하라."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3652e491-bde8-4ff7-b7b6-4830c204158e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(beta)\n",
    "    yhat = X @ beta\n",
    "    loss = (y-yhat).T@(y - yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3c552d9-656b-4817-b3c8-dd75d37f61e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float64, numpy=\n",
       "array([[ 209.6],\n",
       "       [2748.6]])>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tape.gradient(loss, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ae084327-9dbc-4d31-8c5b-45939977bf64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float64, numpy=array([[2212.18]])>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y-X @ beta).T@(y - X @ beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21655cd-ee04-40ad-9fb0-1148f4a865a0",
   "metadata": {},
   "source": [
    "(c) 경사하강법을 통하여 $(\\beta_0,\\beta_1)=(3,3)$ 의 값을 1회 update하라. 여기에서 학습률은 0.01로 설정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "241f15ab-7b60-44b4-ba57-c77db3cebb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.SGD(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8984307f-7bf3-4d4c-a79c-b0c6ced2edd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=() dtype=int64, numpy=1>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.GradientTape(persistent=False) as tape:\n",
    "    tape.watch(beta)\n",
    "    yhat = X @ beta\n",
    "    loss = (y-yhat).T@(y-yhat)/5\n",
    "slope = tape.gradient(loss,beta)\n",
    "opt.apply_gradients([(slope,beta)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d879f00e-10b9-4793-a336-9dd7d142927e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 1) dtype=float64, numpy=\n",
       "array([[ 2.58080001],\n",
       "       [-2.49719988]])>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cfaecf-f1d0-4649-bad1-e6b7772244ff",
   "metadata": {},
   "source": [
    "### `3.` 아래와 같은 모형에서 시뮬레이션 된 자료가 있다고 하자.\n",
    "$$y_i= \\beta_0 + \\beta_1 \\exp(-x_i)+ \\epsilon_i$$\n",
    "\n",
    "여기에서 $\\epsilon_i \\overset{iid}\\sim N(0,0.1^2)$ 이다. 시뮬레이션된 자료는 아래의 코드를 통하여 얻을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f667b3a9-120d-45c8-8caf-ba41acf2d720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.962202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>4.889815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2</td>\n",
       "      <td>4.605782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.3</td>\n",
       "      <td>4.491711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4</td>\n",
       "      <td>4.344537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     x         y\n",
       "0  0.0  4.962202\n",
       "1  0.1  4.889815\n",
       "2  0.2  4.605782\n",
       "3  0.3  4.491711\n",
       "4  0.4  4.344537"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df=pd.read_csv('https://raw.githubusercontent.com/guebin/2021BDA/master/_notebooks/2021-11-06-prob3.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ddc7f2-8b70-4404-ac36-28ef6363849f",
   "metadata": {},
   "source": [
    "자료를 시각화 하면 아래와 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "68517064-bcd2-4ac5-adb2-965b85547e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2fe05015d0>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(df.x,df.y,'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132f1882-bb47-4543-b4dd-7fd0cc55d5e0",
   "metadata": {},
   "source": [
    "keras를 이용하여 적절한 $\\beta_0, \\beta_1$ 의 값을 구하여라. (손실함수는 MSEloss를 사용한다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "50911183-bf02-4b75-ad98-b258d5e175a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= np.array(df.x)\n",
    "y= np.array(df.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1bf98d64-905b-48a4-b26a-a5ece656c9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "_x = x.reshape(100,1)\n",
    "_y = y.reshape(100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a9c61cb0-6a5f-4221-bb3e-7c979377cd18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2f7803a020>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = tf.keras.Sequential()\n",
    "net.add(tf.keras.layers.Dense(1)) \n",
    "net.compile(optimizer='SGD',loss='mse')\n",
    "net.fit(_x,_y,batch_size=100,epochs=1000,verbose=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "314e9719-1cb1-4424-9fad-f194e7955eb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense/kernel:0' shape=(1, 1) dtype=float32, numpy=array([[-0.09727863]], dtype=float32)>,\n",
       " <tf.Variable 'dense/bias:0' shape=(1,) dtype=float32, numpy=array([3.6987545], dtype=float32)>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6956ff8-aea0-43c8-802a-b41f55059f2d",
   "metadata": {
    "id": "9419b5c9-92c2-4c9a-9248-8567c3d9ad83"
   },
   "source": [
    "### `4`. 다음을 잘 읽고 물음에 O/X로 답하라. (25점)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c1859d-6572-4ffd-a051-a317466c8939",
   "metadata": {
    "id": "5882816b-2bfa-476c-a5bb-99fbf4db0691"
   },
   "source": [
    "`(1)` 경사하강법은 손실함수와 상관없이 언제나 전역최소해를 찾을 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932ca300-39ab-48e3-83cc-d2fb524125d4",
   "metadata": {},
   "source": [
    "X\n",
    "- 손실함수 모양이 convex인 경우에만"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d667a8-e30a-46a5-bf34-7e37b9d3666c",
   "metadata": {
    "id": "6a3f52db-34aa-40aa-81f6-aa279e1a7a57"
   },
   "source": [
    "`(2)` 확률적경사하강법은 손실함수와 상관없이 언제 전역최소해를 찾을 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e36789-2741-4e5d-a5df-9ee69650283e",
   "metadata": {},
   "source": [
    "X\n",
    "- 손실함수 모양이 convex인 경우에만"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d453666-0d50-4e13-9d00-94872ae9d1c0",
   "metadata": {
    "id": "604e99bd-3dca-4a96-8a68-012d43bcc10a"
   },
   "source": [
    "`(3)` 일반근사정리(universal approximation theorem)는 충분히 깊은 신경망이 어떠한 함수든 표현할 수 있다는 내용의 이론이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e95bd08-47f2-4a8d-91df-1b3f56c67e6c",
   "metadata": {},
   "source": [
    "X\n",
    "- 넓은 신경망에 대한 이론, 모든 함수 표현 가능, 특정 함수는 아님"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc9e80d-719d-40c2-bacb-42cd77950598",
   "metadata": {
    "id": "14b1fbd7-1f53-4b9d-adc8-b5de6b885a0c"
   },
   "source": [
    "`(4)` $y_i=\\beta_0+\\beta_1 x_i+\\epsilon_i$ 와 같은 형태의 단순회귀모형은 학습해야할 파라메터가 2개이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e2a72f-095e-48e1-ac2c-649e4fa90ea2",
   "metadata": {},
   "source": [
    "O\n",
    "- $\\beta_0$, $\\beta_1 $ 2개"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49deedd-3f87-4dc8-b098-c65fa24ee0ec",
   "metadata": {
    "id": "61ba04f4-882a-4d88-ae7a-b74c38096a08"
   },
   "source": [
    "`(5)` 참모형(true model)이 단순회귀모형일 경우, 비선형 활성화 함수를 사용한 깊은신경망으로 모형을 적합시키면 오히려 적합력이 떨어진다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b914294-e063-4d76-a9ad-f410bcac376d",
   "metadata": {},
   "source": [
    "X\n",
    "- x,y가 일반화되어있을떄는 비선형 활성화 함수(sigmoid, relu 등 MLP) 적합력은 올라가지만 overfitting issue가 생긴다.\n",
    "- 파라메터 수, 즉 모형의 표현력이 증가하면 적합력이 올라감"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c76375-6769-4398-a38c-bac6938b504c",
   "metadata": {
    "id": "eb09a0cf-aa51-45b3-855d-9e36ca7b7ffc"
   },
   "source": [
    "`(6)` 확률적 경사하강법은 관측자료에 임의의 오차항을 더하여 학습시키는 방법이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a496b437-ab63-4eaa-beca-5c7dd72cc971",
   "metadata": {},
   "source": [
    "x\n",
    "- 전체에서 미니배치로 나눠서 미니배치를 순서대로 학습하는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd039a0-813f-4066-8841-8035555783f7",
   "metadata": {
    "id": "18a237ff-0552-4d60-8406-c31406b97b29"
   },
   "source": [
    "`(7)` 경사하강법은 손실함수가 convex일 경우 언제나 전역최소해를 찾을 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0143ebf-2af0-4412-845e-edbcb3deac29",
   "metadata": {},
   "source": [
    "O"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081ef663-4ffb-4bc9-b6a3-a281349dcfbc",
   "metadata": {
    "id": "7dada2ae-eeee-40e3-881c-87fbd9b5ea0e"
   },
   "source": [
    "`(8)` 로지스틱 모형에서 MSEloss를 사용하더라도 전역최소해를 찾는 경우가 있다. 즉 시그모이드 활성화 함수와 MSEloss를 사용한다고 하여도 항상 전역최소해를 찾지 못하는 것은 아니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3165c3-1f58-4fe4-baae-f3cfb80c41ad",
   "metadata": {},
   "source": [
    "O\n",
    "- sigmoid가 적절한"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862a12e2-84bb-4b2c-ad2c-b4f73210e278",
   "metadata": {
    "id": "63275fcb-20b8-404f-b715-44f02cda7ba9"
   },
   "source": [
    "`(9)` 로지스틱 모형에서 MSELoss를 사용하면 옵티마이저를 Adam으로 선택하고 BCELoss를 사용하면 확률적 경사하강법을 사용한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2308c4e5-e385-417c-b3ba-d540a94be555",
   "metadata": {},
   "source": [
    "X\n",
    "- Adam은 확률적 경사하강법을 개량시킨 것이기 떄문에 Adam을 쓰면 수렴이 잘 되고 optimizer 선택해야하는 rule은 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2c368e-bb6e-4784-811b-1baa413ead0b",
   "metadata": {
    "id": "b60e2a6e-cf58-4cd5-b930-103d2166f8cd"
   },
   "source": [
    "`(10)` 확률적 경사하강법은 컴퓨터의 자원을 효율적으로 활용할 수 있도록 도와준다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9b22da-6df4-47be-8bfb-f3e06e0a3475",
   "metadata": {},
   "source": [
    "O\n",
    "- 우리가 주로 쓰는 gpu, memory가 중요\n",
    "- observation만 바꿔서 학습하는 방법 뭐지, 미니배치를 활용한 확률적 경사하강법\n",
    "- 컴퓨터 자원을 효율적으로 활용할 수 있기 위해 나온 건 아니고 도와준다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bfb109-6c74-4c01-9098-99c6963422d9",
   "metadata": {
    "id": "35e374ad-fe1c-4634-ade0-199d13f4ac0b"
   },
   "source": [
    "`(11)` 학습할 파라메터가 많을수록 GPU의 학습속도가 CPU의 학습속도 보다 빠르다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cd4689-5851-437b-bd85-e3de44048231",
   "metadata": {},
   "source": [
    "O"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5aa991-f5d2-4e55-b27e-b9a8f45f6a49",
   "metadata": {
    "id": "7201e47d-5360-44ff-bae9-ad4b4fe11511"
   },
   "source": [
    "`(12)` GPU는 언제나 CPU보다 빠르게 모형을 학습한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98bad41-e02c-4d0c-a6eb-314ea9e175ea",
   "metadata": {},
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd277d6-2272-444c-b55f-57570b620659",
   "metadata": {
    "id": "15b3b551-8860-4b00-ac35-4a102fe150a6"
   },
   "source": [
    "`(13)` CNN 모형에서 에서 2D콘볼루션은 비선형 변환이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031682b8-f2ac-4238-8aed-3a1e299373d6",
   "metadata": {},
   "source": [
    "X\n",
    "- 선형 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e0a9d8-3f79-436d-aaa5-b3b92ed621a5",
   "metadata": {
    "id": "b7b79354-ba2f-450a-964d-373cb595e12d"
   },
   "source": [
    "`(14)` 드랍아웃은 결측치를 제거하는 기법이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429c7ffe-9a0f-4150-8e56-51d9057d0323",
   "metadata": {},
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae214226-1a5a-49ae-b385-9adb5aa561d4",
   "metadata": {
    "id": "d2ff1851-e112-4c00-a011-326285425c1c"
   },
   "source": [
    "`(15)` 모든 관측치를 활용하지 않고 일부의 관측치만 활용하여 학습하는 기법을 드랍아웃이라 한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21edc9c0-24c4-4203-b0cc-500b8e21192d",
   "metadata": {},
   "source": [
    "X\n",
    "- 디자인 매트릭스 n * p 중 n에 일부를 버리진 않음.\n",
    "- 오히려 이 문항은 미니배치와 적절>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d994a58-c5d0-46d1-aa09-7dcbe5d351db",
   "metadata": {
    "id": "8cbc1b9a-50ef-4b47-935c-154e117f7a2d"
   },
   "source": [
    "`(16)` 확률적 경사하강법은 드랍아웃과 같이 사용할 수 없다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7efa0c9-ca99-41df-9ba7-f06f547f1f19",
   "metadata": {},
   "source": [
    "X\n",
    "- 경사하강법은 optimizer에 사용, dropout은 아키텍쳐 단계."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a745bb44-f599-45a5-aa07-2cc87725845e",
   "metadata": {
    "id": "eacc29bb-0675-4f4f-bb66-314afc3d83a5"
   },
   "source": [
    "`(17)` MLP의 모든 활성화 함수가 선형이라면 은닉층(Hidden Layer)을 아무리 추가하여도 모형의 표현력이 향상되지 않는다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd1b1a0-37fe-45b8-9658-d248c1cfb663",
   "metadata": {},
   "source": [
    "O"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311bab99-4a39-4634-aa37-8b62b32bf6bb",
   "metadata": {
    "id": "0b028d7a-e9f3-49b4-a371-4ce4025d4cb4"
   },
   "source": [
    "`(18)` 학습할 파라메터수가 증가하면 언더피팅의 위험이 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e487f6fc-0c41-475e-8508-0179edd1644f",
   "metadata": {},
   "source": [
    "X\n",
    "- overfitting의 위험"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1bdb82-4c11-4b70-9c71-2c3e3a58d043",
   "metadata": {
    "id": "06b520bc-6a58-4811-9aa3-358d4ec65551"
   },
   "source": [
    "`(19)` CAM은 CNN의 모든층에서 사용가능하다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5361e33f-418e-4a34-8771-56c3b4904b75",
   "metadata": {},
   "source": [
    "X\n",
    "- 최종 아웃풋에서만 시각화할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039fcf4a-e58d-44cd-83dc-c381a1e23abb",
   "metadata": {
    "id": "539b98e8-7d95-4575-b759-189f47821481"
   },
   "source": [
    "`(20)` CAM은 CNN모형의 일부를 수정해야 한다는 점에서 단점이 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e18e1d-e138-4947-828b-4394140fdf6d",
   "metadata": {},
   "source": [
    "O"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68557740-50c9-4491-83bd-0de77acf18c2",
   "metadata": {
    "id": "e419d33f-06f1-4b72-92ca-7e8ea4416309"
   },
   "source": [
    "`(21)` CNN은 이미지 자료만 분석할 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ff523d-10d5-47bf-8ec0-e8bfe8af40fc",
   "metadata": {},
   "source": [
    "X\n",
    "- array 형태로 저장할 수 있는 자료에 특화되어 있음, 2d형태에 사용 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e9b609-7b74-412b-b582-ebaebd4bb0b0",
   "metadata": {
    "id": "f3987fb2-848b-4ba3-936b-5a86917b413c"
   },
   "source": [
    "`(22)` 드랍아웃은 과적합을 방지하는 효과가 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055008b0-04ce-4464-9b96-abccedc1d893",
   "metadata": {},
   "source": [
    "O"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33d56ad-9a1a-4bec-91a0-bf92514d2bdc",
   "metadata": {
    "id": "49c9720f-c49f-4ea9-b2ec-324acf5957dc"
   },
   "source": [
    "`(23)` 예측 및 적합을 할때는 네트워크에서 드랍아웃층을 제거해야 한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845cb3a5-024f-4a85-afb9-518dbeb199b6",
   "metadata": {},
   "source": [
    "O"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46805734-8230-4952-8af7-03e99dddb1da",
   "metadata": {
    "id": "8f00ead7-8400-4b56-81ec-72b4ea005d8d"
   },
   "source": [
    "`(24)` BCELoss는 Softmax 활성화 함수와 잘 어울린다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a5085d-24b6-41d3-8d33-25109e1ebb4f",
   "metadata": {},
   "source": [
    "X\n",
    "- Sigmoid\n",
    "- Softmax는 Cross Entropy Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6848dc69-8ca1-4a58-9437-aa074e4fbee0",
   "metadata": {
    "id": "0cb33575-80b3-4d3b-b9fc-a41f27c365db"
   },
   "source": [
    "`(25)` 파이토치에서 미분을 수행하는 메소드는 backward() 이다. keras는 tf.gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552c6a76-5337-4b67-a072-565df0a2d79a",
   "metadata": {},
   "source": [
    "O"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb18da5-6a75-4c92-a55b-1df1a1283944",
   "metadata": {
    "id": "77a4415a-b109-4a24-a4df-93165d411d61"
   },
   "source": [
    "#### 그리드서치의 문제점 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1a2778-ea28-448d-9af6-caedfd0e2d9b",
   "metadata": {
    "id": "98ce2838-514c-4df2-bb70-1444deb88e7b"
   },
   "source": [
    "`-` 비판1: [-10,10]이외에 해가 존재하면? \n",
    "- 이 예제의 경우는 운좋게 [-10,10]에서 해가 존재했음\n",
    "- 하지만 임의의 고정된 $x,y$에 대하여 $loss(\\beta)=(x\\beta-y)^2$ 의 형태의 해가 항상 [-10,10]에서 존재한다는 보장은 없음\n",
    "- 해결책: 더 넓게 많은 범위를 탐색하자?\n",
    "    - -100 ~ 100으로 범위 잡던가~ but, 완전한 해결은 하지 못해.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbf8824-6978-46eb-bc2a-52d36eaa2d94",
   "metadata": {
    "id": "aafe2234-aab7-4d4e-961c-ad8751bd1ee5"
   },
   "source": [
    "`-` 비판2: 효율적이지 않음\n",
    "- 알고리즘을 요약하면 결국 -10부터 10까지 작은 간격으로 조금씩 이동하며 loss를 조사하는 것이 grid search의 아이디어 \n",
    "- $\\to$ 생각해보니까 $\\beta=2$인 순간 $loss=(\\frac{1}{2}\\beta-1)^2=0$이 되어서 이것보다 작은 최소값은 존재하지 않는다(제곱은 항상 양수이어야 하므로)\n",
    "- $\\to$ 따라서 $\\beta=2$ 이후로는 탐색할 필요가 없다 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909dbddf-b870-40d2-85b4-57c9ad672f0d",
   "metadata": {
    "id": "72b7efab-6333-43e7-954d-e1a1e8029bec"
   },
   "source": [
    "> Note: 이처럼 손실함수의 기울기(=경사)를 계산하여 점차적으로 가중치를 업데이트 하는 방식을 경사하강법이라고 부른다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e94326-df03-4c24-8ab9-624826fc4aeb",
   "metadata": {
    "id": "2cc8d193-d0d1-4441-94c7-03cf3c461b45"
   },
   "source": [
    "#### 왼쪽/오른쪽중에 어디로 갈지 어떻게 판단하는 과정을 수식화?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c26163-6020-4670-97b1-286d16fe8430",
   "metadata": {},
   "source": [
    "`-` 아래와 같이 해석 가능\n",
    "- 오른쪽으로 0.01 간다 = $\\beta_{old}$에 0.01을 더함. (if, 미분계수가 음수)\n",
    "- 왼쪽으로 0.01 간다 = $\\beta_{old}$에 0.01을 뺌. (if, 미분계수가 양수)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2dde8e-b71b-4315-9312-eb53d69ec0df",
   "metadata": {},
   "source": [
    "`-` 수식화\n",
    "\n",
    "$\\beta_{new} = \\begin{cases} \\beta_{old} + 0.01, & loss'(\\beta_{old}) <0 \\\\ \\beta_{old} - 0.01,& loss'(\\beta_{old})>0 \\end{cases}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64a049b-c323-4cb5-9eb6-10af2ecbb870",
   "metadata": {
    "id": "9419b5c9-92c2-4c9a-9248-8567c3d9ad83"
   },
   "source": [
    "### `5`. 식 정리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122cb306-0225-4288-9a0e-4b25368857cb",
   "metadata": {},
   "source": [
    "$$\\hat{\\beta}_0= \\bar{y}-\\hat{\\beta}_1 \\bar{x}$$\n",
    "\n",
    "$$\\hat{\\beta}_1= \\frac{S_{xy}}{S_{xx}}=\\frac{\\sum_{i=1}^{n}(x_i-\\bar{x})(y_i-\\bar{y})}{\\sum_{i=1}^{n}(x_i-\\bar{x})^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a096a0aa-5ede-4f57-9730-c72039178a30",
   "metadata": {},
   "source": [
    "- x가 스칼라일떼"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b26a35-157c-4d0a-914e-d5e6fbc42b71",
   "metadata": {},
   "source": [
    "```python\n",
    "Sxx= sum((x-sum(x)/10)**2\n",
    "Sxy=  sum((x-sum(x)/10)*(y-sum(y)/10))\n",
    "beta1_estimated = Sxy/Sxx\n",
    "beta0_estimated = sum(y)/10 - beta1_estimated * sum(x)/10 \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40887ba-f5ef-465c-a897-136f58b42ccd",
   "metadata": {},
   "source": [
    "- x가 벡터일 때 loss 함수 정의 및 loss 미분 후 beta hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec60018-020b-4465-bb94-3f31a1bbcbef",
   "metadata": {},
   "source": [
    "$loss=({\\bf y}-{\\bf X}{\\boldsymbol \\beta})^\\top({\\bf y}-{\\bf X}{\\boldsymbol \\beta})={\\bf y}^\\top {\\bf y} - {\\bf y}^\\top {\\bf X}{\\boldsymbol\\beta} - {\\boldsymbol\\beta}^\\top {\\bf X}^\\top {\\bf y} + {\\boldsymbol\\beta}^\\top {\\bf X}^\\top {\\bf X} {\\boldsymbol\\beta}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d2a436-97c2-40e7-9218-ce50da228721",
   "metadata": {},
   "source": [
    "```python\n",
    "loss = (y-X@beta).T @ (y-X@beta)\n",
    "# 어떻게 정의하느냐에 따라\n",
    "yhat = X@beta\n",
    "loss = (y-yhat).T @ (y-yhat)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a741d7-e850-4f47-8d5d-7403fa9d49a1",
   "metadata": {},
   "source": [
    "$\\boldsymbol{\\hat\\beta}= ({\\bf X}^\\top {\\bf X})^{-1}{\\bf X}^\\top {\\bf y} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0e688e-5855-42ce-ba13-89a5a7188ea2",
   "metadata": {},
   "source": [
    "```python\n",
    "beta_optim = tf.linalg.inv(X.T @ X) @ X.T @ y\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83191749-f724-4ab2-b849-ea5d20d747b0",
   "metadata": {
    "id": "9419b5c9-92c2-4c9a-9248-8567c3d9ad83"
   },
   "source": [
    "### `7`. tf.GradientTape 에 관하여"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20d6651-7d8e-4130-bb98-5cd25d8c80be",
   "metadata": {},
   "source": [
    "```python\n",
    "x = tf.Variable(2.0) \n",
    "\n",
    "with tf.GradientTape(persistent=True(미분 계속 안 되게 해),watch_accessed_variables=False(관찰하지마)) as myname: # 자동으로 감시되는 모드를 꺼라\n",
    "    myname.watch(x) # 감시하는 옵션 사용\n",
    "    a = x/2*3\n",
    "    y = a*x**2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2084a49c-5e71-4616-8350-999b43dac42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(43052)\n",
    "epsilon=tf.random.normal([10])\n",
    "X = tnp.array([1]*10 +[20.1, 22.2, 22.7, 23.3, 24.4, 25.1, 26.2, 27.3, 28.4, 30.4]).reshape(2,10).T\n",
    "beta = tnp.array([9.0,2.0]).reshape(2,1)\n",
    "beta_true= tnp.array([10.2,2.2]).reshape(2,1)\n",
    "y= X@beta_true+epsilon.reshape(10,1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "de6cdcd6-b054-4f61-9333-20f97412b055",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape(persistent=True) as tape: \n",
    "    tape.watch(beta)\n",
    "    yhat= X@beta\n",
    "    loss= (y-yhat).T @(y-yhat) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9577ac23-cbf6-446f-91fb-41cc2b282f4e",
   "metadata": {},
   "source": [
    "변수가 Variable로 생성되면 자동적으로 관찰되지만 constant로 생성되면 관찰되지 않으니 보고 싶다면 watch 추가하거나 variable로 생성하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b78d306e-22c4-4c23-9bdb-f41a18dad061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float64, numpy=\n",
       "array([[ -126.78690968],\n",
       "       [-3208.83947922]])>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tape.gradient(loss,beta) # tf 기울기 미분한 계산값"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164ae4f5-38d4-42eb-8f96-27c8fb28640e",
   "metadata": {},
   "source": [
    "loss 함수 정의 $\\to$$loss = -2\\bf{X}^\\top \\bf{y} + 2\\bf{X}^\\top \\bf{XB}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "39f30476-5440-4805-888b-62fc36aa954e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float64, numpy=\n",
       "array([[ -126.78690968],\n",
       "       [-3208.83947922]])>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-2*X.T @ y + 2*X.T@X@beta  # 이론적 loss 계산값"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4183f4d5-051d-489f-89c0-e30871a0e43b",
   "metadata": {},
   "source": [
    "이론적인 베타의 최적값 $\\hat{\\bf{B}} = (\\bf{X}^\\top \\bf{X})^{-1}\\bf{X}^\\top \\bf{y}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2820c08-698a-4891-ad8c-4db4cf010b68",
   "metadata": {},
   "source": [
    "> important: 시험 예상"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75c0188-abd5-4470-90fb-a45706844e37",
   "metadata": {},
   "source": [
    "`-`  이론적인 𝜷의 최적값을 찾아보고 (즉 𝜷̂ 을 찾고) 그 지점에서 loss의 미분값(=접선의 기울기)를 구하라. 결과가 0인지 확인하라. (단 0은 길이가 2이고 각 원소가 0인 벡터)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7396b81a-4c9c-4f7a-96d6-379803814ad1",
   "metadata": {},
   "source": [
    "y를 최소화하는 x를 구해라 = loss를 최소화하는 beta를 구해라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e7522b1f-0caf-448e-adc2-d530336b9f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_optimal = tf.linalg.inv(X.T @ X) @ X.T  @y  # 이보다 loss를 작게 만드는 beta는 없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "45a0289b-617d-41cb-a598-38f807fe9aca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float64, numpy=\n",
       "array([[-6.67910172e-12],\n",
       "       [-1.67774636e-10]])>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.GradientTape(persistent=True) as tape: \n",
    "    tape.watch(beta_optimal)\n",
    "    yhat= X@beta_optimal\n",
    "    loss= (y-yhat).T @(y-yhat) \n",
    "tape.gradient(loss,beta_optimal) # 베타 최적값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "806c7e20-6af0-4dca-9b90-5ce0ca02d62c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float64, numpy=\n",
       "array([[ -2.74690968],\n",
       "       [-71.45947922]])>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.GradientTape(persistent=True) as tape: \n",
    "    tape.watch(beta_true)\n",
    "    yhat= X@beta_true\n",
    "    loss= (y-yhat).T @(y-yhat) \n",
    "tape.gradient(loss,beta_true) #베타 true 값"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb7e9b1-ac33-43a8-a468-1b3fc8bd5f1a",
   "metadata": {},
   "source": [
    "```python\n",
    "beta = tf.Variable(-10.0)\n",
    "alpha=0.01/6\n",
    "opt = tf.keras.optimizers.SGD(alpha)\n",
    "# tf.keras.optimizers.SGD.apply_gradients 이용\n",
    "for epoc in range(10000):\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(beta)\n",
    "        loss = (beta/2-1)**2\n",
    "    slope = tape.gradient(loss,beta)\n",
    "    opt.apply_gradients([(slope,beta)])\n",
    "beta\n",
    "# tf.keras.optimizer.SGD.minimize 이용\n",
    "loss_fn = lambda: (beta/2-1)**2\n",
    "for epoc in range(10000):\n",
    "    opt.minimize(loss_fn,beta)\n",
    "beta\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6f06d1-b8e0-40fd-87f3-57a5f5c6332f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
