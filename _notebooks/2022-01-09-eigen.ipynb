{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09b8286a-05ec-45c7-b21c-df69751aad18",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Introduction to Linear Algebra\n",
    "> Gilbert Strang\n",
    "\n",
    "- toc:true\n",
    "- branch: master\n",
    "- badges: true\n",
    "- comments: false\n",
    "- author: 최서연\n",
    "- categories: [Linear Algebra]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df53c0f-861a-4d61-9683-8d2fd6b5408f",
   "metadata": {},
   "source": [
    "## Chapter 6 Eilgenvalues and Eigenvectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da08b65-4787-4b02-b14b-f2024d321d1b",
   "metadata": {},
   "source": [
    "### 6.1 Introduction to Eigencalues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc19aace-c8b5-4d4c-9e97-2dfb89ce81b1",
   "metadata": {},
   "source": [
    "This chapter enters a new part of linear algebra, based on $Ax = AX.$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff11e0c-53a9-4f7d-9132-e2bffafd2e39",
   "metadata": {},
   "source": [
    "Certain exceptional vectors x are in the same direction as Ax. Those are the \"eigenvectors\". Multiply an eigenvector by A, and the vector Ax is a number A times the original x. \n",
    "\n",
    "`+` 선형변환 A에 의한 변환 결과가 자기 자신의 상수배가 되는 0이 아닌 벡터"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb04f8a8-efe6-44a5-b7a6-7e58c24d4e03",
   "metadata": {},
   "source": [
    "**The basic equation is $Ax = Ax$. The number $A$ is an eigenvalue of $A$.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ecf559-9dc7-4f78-bfc0-f246321bad97",
   "metadata": {},
   "source": [
    "- 고유값 $\\lambda$는 A의 고유값이며, 0이 될 수 있다.\n",
    "- $Ax=0x$는 이 고유벡터 x가 **nullspace** 안에 있다는 것을 의미한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f5f754-ede7-496f-9c42-7be3f85c7917",
   "metadata": {},
   "source": [
    "- A가 identity matrix라면 모든 벡터는 Ax=x를 가지고 있음.\n",
    "- 모든 벡터들이 I의 고유벡터이고, 모든 고유값 lambda는 1임"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b835a6d-8830-4f6b-bec1-9805890e7e77",
   "metadata": {},
   "source": [
    "##### ex1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554d0fb1-833e-4a0b-b343-ad32b735a883",
   "metadata": {},
   "source": [
    "$A= \\begin{bmatrix}{.8}&{.3}\\\\{.2}&{.7} \\end{bmatrix} det\\begin{bmatrix}{.8-\\lambda}&{.3}\\\\{.2}&{.7-\\lambda} \\end{bmatrix} = \\lambda^{2}-\\frac{3}{2} \\lambda + \\frac{1}{2} = (\\lambda-1)(\\lambda-\\frac{1}{2})$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46f44c9-d1a5-4b44-aaa7-30acf0e4704b",
   "metadata": {},
   "source": [
    "nullspace에 있는\n",
    "- $(A-I)x_1=0, Ax_1=x_1$, 고유벡터$(.6,.4) \\rightarrow Ax_1=\\begin{bmatrix}{.8}&{.3}\\\\{.2}&{.7}\\end{bmatrix}\\begin{bmatrix}{.6}\\\\{.4} \\end{bmatrix}=x_1$\n",
    "- $(A-\\frac{1}{2}I)x_2=0, Ax_2=x_2$, 고유벡터$(1,-1) \\rightarrow Ax_2=\\begin{bmatrix}{.8}&{.3}\\\\{1}&{-1}\\end{bmatrix}\\begin{bmatrix}{.5}\\\\{-.5} \\end{bmatrix}=x_2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45bc25a-dc60-4483-b66e-099806e0216d",
   "metadata": {},
   "source": [
    "**When A is squared, the eigenvectors stay the same. The eigenvalues are squared.**\n",
    "- 여기서 고유벡터들이 절대 섞이지 않고 자신의 방향에 머물기 때문에 패턴이 유지된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b3305f-521d-4224-a4cb-5c9455dfa068",
   "metadata": {},
   "source": [
    "Other vectors do change direction. But all other vectors are combinations of the two eigenvectors. \n",
    "- 방향이 변하는 다른 벡터들의 경우.\n",
    "- A의 첫번째 열은 $x_1+(.2)x_2$ 임.\n",
    "- 예제에서는 $\\begin{bmatrix}{.8}\\\\{-.2} \\end{bmatrix}=x_1+(.2)x_2=\\begin{bmatrix}{.6}\\\\{-.4} \\end{bmatrix}+\\begin{bmatrix}{.2}\\\\{-.2} \\end{bmatrix}$\n",
    "- A에 곱해질때 각 고유벡터는 고유값에 곱해짐\n",
    "- At every step $x_1$ is unchanged and $x_2$ is multiplied by ($\\frac{1}{2}$), so we have ($\\frac{1}{2})^{99}$\n",
    "- $x^{99}\\begin{bmatrix}{.8}\\\\{-.2} \\end{bmatrix} isreally_1+(.2)\\frac{1}{2}^{99}x_2=\\begin{bmatrix}{.6}\\\\{-.4} \\end{bmatrix}+\\begin{bmatrix}{very}\\\\{small}\\\\{vector} \\end{bmatrix}$\n",
    "- This is the first column of A 100. $\\rightarrow$ 여기서(.8,.2)를 의미함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d6ee1f-75a1-45b8-bbda-7fefca88ccd6",
   "metadata": {},
   "source": [
    "**A is a Markov matrix(각 열 벡터들을 더하면 1이 되는 행렬).**\n",
    "- Its eigenvector $x_l = (.6,.4)$ is the steady state-which all columns of Ak will approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9145a60d-9c2e-4378-9bb5-cc5a5d052039",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6585e669-01fe-40f5-86fb-07ba659577c8",
   "metadata": {},
   "source": [
    "##### ex2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c3a2bd-86e5-4946-9072-07bf42b6917f",
   "metadata": {},
   "source": [
    "**The projection matrix $P=\\begin{bmatrix}{.5}&{.5}\\\\{.5}&{.5} \\end{bmatrix}$ has eigencalues $\\lambda=1$ and $\\lambda=0$**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0573ab-f988-4639-9232-193bacd9df05",
   "metadata": {},
   "source": [
    "위 예는 markov matrices, singular matrices, 그리고 symmetric matrices를 설명한다.\n",
    "- All have special A's and x 's: \n",
    "    - $P=\\begin{bmatrix}{.5}&{.5}\\\\{.5}&{.5} \\end{bmatrix}$의 각 열은 1을 추가해서 람다=1이 고유값\n",
    "    - P는 singular여서 람다=0이 고유값\n",
    "    - P는 대칭이어서 고유벡터(1,1)과 (1,-1)이 직각"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ef27ab-0e53-45d7-a2ff-72ee3ba02368",
   "metadata": {},
   "source": [
    "- 영공간nullspace는 0에 투영되어있음\n",
    "- 열 공간은 그 스스로를 투영함\n",
    "- Project each aprt $v=\\begin{bmatrix}{1}&{-1}\\\\{2}&{2} \\end{bmatrix}$ projects onto $P_v=\\begin{bmatrix}{0}&{0}\\\\{2}&{2} \\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8eff78f-00c7-49b8-9314-017104d68a7d",
   "metadata": {},
   "source": [
    "- Projections have $\\lambda = 0$ and $1$. Permutations have all $|A| = 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93293487-ed27-4852-bf01-a77dc7daa1f1",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761e7a1d-4840-46bc-9044-0e540b215800",
   "metadata": {},
   "source": [
    "##### ex3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96412ed9-f939-4cc0-af6f-1094882176df",
   "metadata": {},
   "source": [
    "**The reflection matrix $R=\\begin{bmatrix}{0}&{1}\\\\{1}&{0} \\end{bmatrix}$ has eigenvalues 1 snd -1**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acc3e95-fe59-4316-a8fc-c6cbc9253a54",
   "metadata": {},
   "source": [
    "- 고유벡터(1,1)은 R에 의해 변하지 않음!\n",
    "- $reflection = 2(projection)-I$ 때문에 R에서 고유벡터은 P에서와 같다.\n",
    "- $R=2P-I, \\begin{bmatrix}{0}&{1}\\\\{1}&{0} \\end{bmatrix}=2\\begin{bmatrix}{.5}&{.5}\\\\{.5}&{.5} \\end{bmatrix}-\\begin{bmatrix}{1}&{0}\\\\{0}&{1} \\end{bmatrix}.\\dots (2)$\n",
    "- $2Px=2\\lambda x$처럼 행렬이 두 배가 되면 고유값이 2배가 된다.\n",
    "- 그 결과가 $(2p-i)X=(2\\lambda-1)x$!!\n",
    "- 행렬이 I에 의해 변하면 각 $\\lambda$는 1에 의해 바뀐다. 고유벡터 내에서는 변화 없음!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c295b2-8755-494e-91cf-710fb32a814c",
   "metadata": {},
   "source": [
    "Key idea: The eigenvalues of Rand P are related exactly as the matrices are related:\n",
    "- The eigenvalues of $R = 2P - I$ are 2(1) - 1 = 1 and 2(0) - 1 = -1. \n",
    "- The eigenvalues of $R^2$ are $\\lambda^2$. In this case $R^2 = I$. Check $(I)^2$ = 1 and $(-1)^2$ = 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d93ff3-5f27-49b3-a7b3-5a58a908cbd4",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc7c2ed-ba5f-4c36-8455-c74c0f00c983",
   "metadata": {},
   "source": [
    "#### The Equation for the Eigenvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec3091f-2ca7-4080-9f38-38027db9fc38",
   "metadata": {},
   "source": [
    "The Equation for the Eigenvalues: $P x = x, P x = 0, Rx = -x$ is the key caculation almost every application starts by solving $Ax = \\lambda x$. \n",
    "- 일단 $\\lambda x$를 왼쪽으로 넘기면 $(A-\\lambda I)x=0$을 쓸 수 있고\n",
    "- 행렬 $(A-\\lambda I)$매를 한 고유벡터 x는 0 벡터임.\n",
    "- **The eigenvectors make up the nullspace of $A - \\lambda I$**\n",
    "- 고유값 람다를 알때, $(A-\\lambda I)x=0$을 풀어서 고유벡터를 찾을 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acaa4e25-d5b3-4930-a4df-812de7e75fba",
   "metadata": {},
   "source": [
    "If $(A - \\lambda I)X = 0$ has a nonzero solution, $A - \\lambda I$ is not invertible. The determinant of $A -\\lambda I$ must be zero. \n",
    "- 고유값 람다 알아내는 법\n",
    "    - **The number $\\lambda$ is an eignvalue of A if and only if $A-\\lambda I$ is singular:**\n",
    "    - Equtation for the eigenvalues $\\rightarrow det(A-\\lambda I)=0$\n",
    "        - $det(A-\\lambda I)=0$ 여기에는 x가 아닌 람다만 들어있음\n",
    "        - A가 N $\\times$ N 행렬일때 $det(A-\\lambda I)=0$는 degree N을 가지게 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cff8c3d-4ad4-431f-b92e-39651ee84b65",
   "metadata": {},
   "source": [
    "> For each elgenvalue $\\lambda$ solve $(A - \\lambda I)x = 0$ or $A_x=\\lambda x$ to find an eigenvector x."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1a901a-f051-42bd-976f-2761e346d6dd",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d2e6fa-dfe3-4ea0-abcb-010f3b0b6641",
   "metadata": {},
   "source": [
    "##### ex4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9541b5f-cfe9-4e28-b652-71cc2160e837",
   "metadata": {},
   "source": [
    "$A=\\begin{bmatrix}{1}&{2}\\\\{2}&{4} \\end{bmatrix}$ is already singular (zero determinant). Find its $\\lambda$'s and $x$'s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cbdc8a-3b5a-4b9a-b662-009fc91356c1",
   "metadata": {},
   "source": [
    "- A가 singular일때 $\\lambda=0$은 고유값들 중 하나이다.\n",
    "- $Ax=0x$가 solution을 가짐! 이는 $\\lambda=0$에 대한 고유 벡터임\n",
    "- 하지만 $det(A-\\lambda I)=0$은 모든 람다들과 x들을 찾는 방법임\n",
    "- **Subtract $\\lambda$ from the diagonal to find $a-\\lambda i =\\begin{bmatrix}{1-\\lambda}&{2}\\\\{2}&{4-\\lambda} \\end{bmatrix}$**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2c6f55-0757-4de8-a264-d03e73e90354",
   "metadata": {},
   "source": [
    "**Take the determinant \"ad - bc\" of this 2 by 2 matrix.**\n",
    "- $det\\begin{bmatrix}{1-\\lambda}&{2}\\\\{2}&{4-\\lambda} \\end{bmatrix}=(1-\\lambda)(4-\\lambda)-(2)(2)=\\lambda^{2}-5\\lambda$\n",
    "- $\\lambda^{2}-5\\lambda$를 0으로 놓으면 근은 람다가 0 또는 5\n",
    "- One solution is $\\lambda = 0$ (as expected, since A is singular). Factoring into $\\lambda$ times $\\lambda - 5$, the other root is $\\lambda = 5$.:\n",
    "- $det(A-\\lambda I)=\\lambda^2-5\\lambda =0$ yields the eigenvalues $\\lambda_1=0$ and $\\lambda_2=5$\n",
    "- 고유벡터를 찾아보자\n",
    "- $(A-0I)x=\\begin{bmatrix}{1}&{2}\\\\{2}&{4} \\end{bmatrix}\\begin{bmatrix}{y}\\\\{z} \\end{bmatrix}=\\begin{bmatrix}{0}\\\\{0} \\end{bmatrix}$ yields the eigenvector $\\begin{bmatrix}{y}\\\\{z} \\end{bmatrix}=\\begin{bmatrix}{2}\\\\{-1} \\end{bmatrix}$ for $\\lambda_1=0$\n",
    "- $(A-5I)x=\\begin{bmatrix}{-4}&{2}\\\\{2}&{-1} \\end{bmatrix}\\begin{bmatrix}{y}\\\\{z} \\end{bmatrix}=\\begin{bmatrix}{0}\\\\{0} \\end{bmatrix}$ yields the eigenvector $\\begin{bmatrix}{y}\\\\{z} \\end{bmatrix}=\\begin{bmatrix}{1}\\\\{2} \\end{bmatrix}$ for $\\lambda_2=5$.\n",
    "    - 0과 5가 고유값이기 때문에 $A-0I$, $A-5I$는 singular이다.\n",
    "    - 고유벡터 (2,-1)과 (1,2)은 영공간nullspace에 있다.: $(A-\\lambda I)x=0$ is $Ax=\\lambda x$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d300315-c521-425a-be06-1e08b0eb416b",
   "metadata": {},
   "source": [
    "> warning: There is nothing exceptional about A = O. Like every other number, zero might be an eigenvalue and it might not. If A is singular, it is. The eigenvectors fill the nullspace: Ax = Ox = O. **If A is invertible, zero is not an eigenvalue. We shift A by a multiple of I to make it singular.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab0c079-eadd-482f-a494-1b3caa5cb590",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21994773-83ce-464e-a968-1511bb66d758",
   "metadata": {},
   "source": [
    "summary: n matrix에 의한 고유값 문제를 해결하기 위해 밟을 step!\n",
    "1. Compute the determinant of $A-\\lambda I$.\n",
    "2. Find the roots of this polynomial\n",
    "3. solve $(A-\\lambda I)x=0$ to find an eigenvector $x$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e473e68d-f1e5-42d3-9797-4d3c48d6d07b",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c074269c-7030-4191-ac24-e963f5cf3fcb",
   "metadata": {},
   "source": [
    "> warning: Some 2 by 2 matrices have only one line of eigenvectors. This can only happen when two eigenvalues are equal. *Similarly some n by n matrices don't have n independent eigenvectors. Without n eigenvectors, we don't have a basis. We can't write every v as a combination of eigenvectors.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6ff7b9-72e0-4007-9855-f4b1b9cade4f",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8029e1f1-c297-4794-8ad0-e1b6f5ae5a1f",
   "metadata": {},
   "source": [
    "#### Good News, Bad News"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3c808e-c2b6-4bb9-bed4-b5c3fb65d2c7",
   "metadata": {},
   "source": [
    "Bad news: A 행에 또다른 열을 추가하거나 행을 바꾼다면 고유값들은 항상 변할 것임!\n",
    "- Elimination does not preserve the A'S. The triangular U has its eigenvalues sitting along the diagonal-they are the pivots. But they are not the eigenvalues of A!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01368500-a26a-4c93-b8b6-5e87f201ac60",
   "metadata": {},
   "source": [
    "Good news: The product $\\lambda_1$ times $\\lambda_2$ and the sum $\\lambda_1$ + $\\lambda_2$ can be found quickly from the matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c87014-9350-4039-8acb-bd985dc5bd79",
   "metadata": {},
   "source": [
    "**The product of the n eigenvalues equals the determinant. The sum of the n eigenvalues equals the sum of the n diagonal entries.**\n",
    "- The sum of the entries on the main diagonal is called the trace of A:\n",
    "    - $\\lambda_1+\\lambda_2+\\dots+\\lambda_n=trace=a_{11}+a_{22}+\\dots+a_{nn}$\n",
    "    - 계산을 잘못했는지 알 수 있음! 잘못되었다면? go back to $det(A-\\lambda I)=0$\n",
    "- The determinant test makes the product of the A'S equal to the product of the pivots (assuming no row exchanges). But the sum of the A'S is not the sum of the pivots-as the example showed. The individual A's have almost nothing to do with the pivots. In this new part of linear algebra, the key equation is really nonlinear: A multiplies x."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0db0d0-bca9-4161-9385-34b94e4f5f88",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2775e1-7def-4581-b755-17123a236cce",
   "metadata": {},
   "source": [
    "#### Imaginary Eigenvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb07d3d4-ecb3-4f51-823b-57f77c738d66",
   "metadata": {},
   "source": [
    " The eigenvalues might not be real numbers.?!?!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbb7210-4f1e-480a-919f-d6b90d62cfe5",
   "metadata": {},
   "source": [
    "##### ex5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791f44de-e9ad-499c-93f7-217cf71e04a7",
   "metadata": {},
   "source": [
    "**The $90^o$ rotation $Q=\\begin{bmatrix}{0}&{-1}\\\\{1}&{0} \\end{bmatrix}$ has no real eigenvectors. Its eigenvalues are $\\lambda=i$ and $\\lambda=-i$. Sum of $\\lambda$'s= trace=0, Product=determinany=1.**\n",
    "- rotation 후 $Q_x$ 어느 벡터도 x와 같은 방향에 있지 않음 x=0일때 빼고.\n",
    "- 그러면 고유벡터가 될 수 없는데 그래도 우리는 허수imaginary numbers로 보겠다.\n",
    "- $-I$인 $Q^2$을 봐봐. 만약 Q가 90도 회전하면 $Q^2$은 180도 회전하겠지? 그건 고유값들이 -1과 -1이라는 거고.(확실히 $-IX=-1X$인 건 아니까.) $Q^2$이니까 각 $\\lambda ^2$이 될거고. 우리는 $\\lambda ^2=-1$을 얻게될거야. 그러면 근은 $i,-i$가 나오겠지. 우리는 허수 i가 고유벡터에 있다는 것을 알 수 있어.\n",
    "    - $\\begin{matrix}  complex \\\\  eigenvectors \\end{matrix}$   $\\begin{bmatrix}{0}&{-1}\\\\{1}&{0} \\end{bmatrix}\\begin{bmatrix}{1}\\\\{i} \\end{bmatrix}=-i\\begin{bmatrix}{1}\\\\{i} \\end{bmatrix}$ and $\\begin{bmatrix}{0}&{-1}\\\\{1}&{0} \\end{bmatrix}\\begin{bmatrix}{i}\\\\{1} \\end{bmatrix}=i\\begin{bmatrix}{i}\\\\{1} \\end{bmatrix}$\n",
    "    - 여기서 복소수벡터complex vector $x_1=(1,i),x_2=(i,1)$는 회전한 방향을 유지하지. \n",
    "    - 이 예제들은 실제 행렬이 복소수 고유치들과 고유값들을 쉽게 가질 수 있는 모든 중요한 포인트를 만들지.\n",
    "    - 특히 고유치 i와 -i는 Q의 two special properties을 말해.\n",
    "    1. Q is an otrhogonal matrix so the absolute value of each $\\lambda$ is $|\\lambda|=1$\n",
    "    2. Q is a skew-wymmetric matrix so each $\\lambda$ is pure imaginary.\n",
    "    - A symmetric matrix $(^AT=A)$ can be compared to a real number. A skew-symmetric matrix $(A^T = -A)$ can be compared to an imaginary number. An orthogonal matrix $(A^T A = 1)$ can be compared to a complex number with $|\\lambda| = 1$.\n",
    "    - The eigenvectors for all these special matrices are perpendicular. Somehow (i, I) and (1, i) are perpendicular"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc60d03-956b-4f8c-858b-ddbf0e810935",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e544238-a5a4-4adb-8917-d25648be0f6d",
   "metadata": {},
   "source": [
    "#### Eigshow in MATLAB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eae13c7-b2af-40be-89d8-faaade715f4d",
   "metadata": {},
   "source": [
    "The eigenvalue A is the length of $Ax$ , when the unit eigenvector x lines up. The built-in \n",
    "choices for A illustrate three possibilities: 0,1, or 2 directions where $A_x$ crosses x. \n",
    "- **0**: 실제 고유벡터가 없음. $Ax$가 x의 뒤 혹은 앞에 있음. 이건 고유값과 고유벡터들이 rotation Q에서 복소수라는 것을 의미함.\n",
    "- **1**: 고유벡터들의 오직 한 line만이 존재. Ax와 x는 움직이는 방향에서 만나긴 하는데 교차하진 않음.(2$\\times$2행렬에서)\n",
    "- **2**: 두 독립적인 방향의 고유벡터가 있음. This is typica! Ax는 x와 첫번째 고유벡터 $x_1$에서 교차하고, 두번째 고유벡터 $x_2$에서 다시 돌아옴(cross back). 그러면 Ax와 x는 $-x_1$과 $-x_2$에서 다시 교차함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b20b282-2ab9-43e5-9c2f-47a5dc350158",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4d97fa-d4ca-4bf0-872f-4487451f590c",
   "metadata": {},
   "source": [
    "***REVIEW OF THE KEY IDEAS***\n",
    "1. $Ax = \\lambda x$ says that **eigenvectors x keep the same direction** when multiplied by A. \n",
    "2. $Ax = \\lambda x$ also says that **$det(A - \\lambda I) = 0$**. This determines **n eigenvalues**. \n",
    "3. **The eigenvalues of $A^2$ and $A^{-1}$ are $\\lambda^2$ and $\\lambda^{-1}$**, with the **same eigenvectors**. \n",
    "4. **The sum of the A'S equals the sum down the main diagonal of A (the trace). The product of the A'S equals the determinant**. \n",
    "5. **Projections $P$, reflections $R$, $90^o$ rotations $Q$** have special eigenvalues $1,0, -1, i, -i$. **Singular matrices** have $\\lambda = O$. **Triangular matrices** have A'S on their diagonal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8227dc67-d077-4bd6-a99a-548d62f6d933",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c724c7-e97b-4afd-9f39-68a6a920180d",
   "metadata": {},
   "source": [
    "***WORKED EXAMPLES***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf507732-aef3-408d-b3ce-998f20388e5c",
   "metadata": {},
   "source": [
    "6.1.A 다 끝내고 시간 나면 할 것,,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd40e46-9a7a-464a-a85b-b7362fc9082f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a32c5ed-5398-4a57-b1b4-169b8733397f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "adc62263-1376-4f68-8ae9-915fffc7c606",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe8f483-bca2-4317-aa7a-6c59d2ccac20",
   "metadata": {},
   "source": [
    "### 6.2 Diagonalizing a Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e083e79f-77d6-4c4d-bb0f-20ef9f5e77a1",
   "metadata": {},
   "source": [
    "**Does the matrix A turn into a diagonal matrix A when we use the eigenvectors properly?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dae704-0612-4883-9f24-32bc0b07e52b",
   "metadata": {},
   "source": [
    "Diagonalization: Suppose the n by n matrix A has n linearly independent eigervectors $x_1,\\dots,x_n$. Put them into the columns of an eigenvectors matrix S. Then $S^{-1}AS$ is tje eigenvalue matrix $\\Lambda$\n",
    "- Eigenvector matrix S, Eigenvalue matrix $\\Lambda$, $S^{-1}AS=\\Lambda=\\begin{bmatrix}{\\lambda_1}&{}&{}\\\\{}&{\\ddots}&{}\\\\{}&{}&{\\lambda_n}\\end{bmatrix}$\n",
    "- i.e. $AS=S\\Lambda$ is $S^{-1}AS=\\Lambda$ or $A=SAS^{-1}$\n",
    "- 행렬 S는 역을 취할 수 있기 때문에 그 열들은 선형적으로 독립이 될 수 있다. n개의 독립적인 고유벡터 없이 대각선화 할 수 없다.\n",
    "- $A$와 $\\Lambda$는 같은 고유값 $\\lambda_1,\\dots\\lambda_n$을 가지고 있다.\n",
    "- 이 고유 벡터들은 다르다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03de0857-1a5a-4b06-9c38-51ff8957235e",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f123d65-d6a1-4d12-bb08-2a038a583af4",
   "metadata": {},
   "source": [
    "##### ex1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294792b4-4f64-423a-8939-76db3ce0ed09",
   "metadata": {},
   "source": [
    "$$\\text{Eigenvectors }\\begin{bmatrix}{1}\\\\{0}\\end{bmatrix}\\begin{bmatrix}{1}\\\\{1}\\end{bmatrix} \\begin{matrix}\\begin{bmatrix}{1}&{-1}\\\\{0}&{1}\\end{bmatrix}\\\\S^{-1}\\end{matrix}\\begin{matrix}\\begin{bmatrix}{1}&{5}\\\\{0}&{6}\\end{bmatrix}\\\\A\\end{matrix}\\begin{matrix}\\begin{bmatrix}{1}&{1}\\\\{0}&{1}\\end{bmatrix}\\\\S\\end{matrix}$ = $\\begin{matrix}\\begin{bmatrix}{1}&{0}\\\\{0}&{6}\\end{bmatrix}\\\\ \\Lambda\\end{matrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f020e6b-f27f-421c-8df7-0d3a34173768",
   "metadata": {},
   "source": [
    "$A=S\\Lambda S^{-1} \\rightarrow A^2=S \\Lambda S^{-1}S \\Lambda S^{-1} \\rightarrow \\text{ remove } S^{-1}S=I \\rightarrow S \\Lambda^2S^{-1}$\n",
    "- The $k^{th}$ power will be $A^k = S \\Lambda^k S^{-1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc56a8da-a9ed-4ce3-a1f0-d3d6a19ec66b",
   "metadata": {},
   "source": [
    "**Remark**\n",
    "1. 고유값 $\\lambda_1,\\dots\\lambda_n$는 다 달라서 자동으로 고유벡터 $x_1,\\dots,x_n$도 독립적이다. 반복죄지 않는 고유값을 가진 어느 행렬도 대각성화 할 수 없다.\n",
    "2.어느 nonzero constats를 고유벡터에 곱할 수 있다.$Ax=\\lambda x$는 true로 남아있다.\n",
    "3. S에서 고유벡터는 $\\Lambda$의 고유값에 따라 같은 정렬에 있다.(The eigenvectors in $S$ come in the same order as the eigenvalues in $\\Lambda$)\n",
    "4.어떤 행렬이 너무 적은 고유벡터를 가지고 있으면 그 행렬은 대각선화할 수 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747712fd-620b-4c4c-ba1f-2b4bff86ee5d",
   "metadata": {},
   "source": [
    "> note: Remember that there is no connection between invertibility and diagonalizability; 1. Invertibility is concerened with the eigenvalues($\\lambda=0 \\text{ or } \\lambda \\neq 0$) 2. Diagonalizability is concerend with the eigenvectors(too few or enough for S)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30cf7e2-00e8-42b1-a69a-469173a113b8",
   "metadata": {},
   "source": [
    "> warning: Each eigenvalue has at least one eigenvector! $A - \\lambda I$ is singular. If $(A - \\lambda I)x = 0$ leads you to $x = 0$, $\\lambda$ is not an eigenvalue. Look for a mistake in solving $det(A - \\lambda I) = O$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8d4f7d-77ff-488d-adeb-3d4be3d04dcd",
   "metadata": {},
   "source": [
    "**n개의 람다들에 대해 고유벡터들은 독립적이다. 그러면 우리는 A를 대각화할 수 있다.**\n",
    "\n",
    "**Independent $x$ from differentt $\\lambda$**\n",
    "- 구별되는 고유값들에 관련된 고유벡터 $x_1,\\dots,x_n$는 선형적으로 독립이다.\n",
    "- n개의 다른 고유값들을(반복되지 않은 람다들) 가진 n by n 행렬은 대각화되어야만 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b39a80-22ad-4614-8c9c-2297030e7e53",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55e4bf4-ef10-4c23-94e4-55c10224cf88",
   "metadata": {},
   "source": [
    "##### ex2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6b8d0f-7911-4cbe-a525-cbbf4463bf6d",
   "metadata": {},
   "source": [
    "**Powers of A**\n",
    "- A가 Markov matrix이면?\n",
    "    - $A=S\\Lambda S^{-1}$에서 구한 고유벡터들은 $S$의 열 안에 있고, $A^2$의 고유벡터이기도 함.\n",
    "- $A^2$은 $S$와 같고, $A^2$ 고유벡터 행렬은 $\\Lambda^2$임을 보여보자.\n",
    "    - SAME $S$ for $A^2$\n",
    "        - $A^2 = S\\Lambda S^{-1}S\\Lambda S^{-1} = S\\Lambda^2 S^{-1}$\n",
    "    - Powers of A\n",
    "        - $A^k = S\\Lambda^k S^{-1}$\n",
    "    - Limit $k \\rightarrow \\infty$\n",
    "        - $A^{100}=S\\Lambda S^{-1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a61c7c-7dad-403d-b52f-61eafd902f61",
   "metadata": {},
   "source": [
    "> note: Q: When does $A^k \\rightarrow zero$ matrix? A: All $|\\lambda|<1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782d94b7-8014-48c4-bffe-7ed614667e1c",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fcf6c1-fe53-4d93-bb94-1d856b6e0312",
   "metadata": {},
   "source": [
    "### Fibonacci Numbers "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01366bca-b13c-44e6-9f80-c3eb826d17a2",
   "metadata": {},
   "source": [
    "**Every new Fibonacci number is the sum of the two previous F's:**\n",
    "- The sequence 0,1,1,2,3,5,8,13,... comes from $F_{k+2}=F_{k+1}+F_{k}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4025249-89a0-4028-b127-7b793e2a911c",
   "metadata": {},
   "source": [
    "**step 1**: 일단 matrix equation $u_{k+1}=Au_k$으로 시작!\n",
    "- Let $u_k=\\begin{bmatrix}{F_{k+1}}\\\\{F_k}\\end{bmatrix} $. The rule $\\begin{matrix}{F_{k+2}=F_{k+1}+F_k}\\\\{F_{k+1}=F_{k+1}}\\end{matrix}$ is $u_{k+1} = \\begin{bmatrix}{1}&{1}\\\\{1}&{0}\\end{bmatrix}u_k$\n",
    "\n",
    "\n",
    "Every step multiples by $A= \\begin{bmatrix}{1}&{1}\\\\{1}&{0}\\end{bmatrix}$.\n",
    "- 100번하면 $u_{100}=A^{100}u_k$가 된다.\n",
    "- Subtract $\\lambda$ from the diagonal of A:\n",
    "    - $A-\\lambda I =  \\begin{bmatrix}{1-\\lambda}&{1}\\\\{1}&{-\\lambda}\\end{bmatrix}$ leads to $det(A-\\lambda I)=\\lambda^2 - \\lambda - 1$\n",
    "    - $-b\\pm sqrt(b^2-4ac)/2a$ 으로 해를 구할 수 있지\n",
    "    - Eigenvalues $\\lambda_1=\\frac{1+\\sqrt{5}}{2} \\approx 1.618$ and $\\lambda_2=\\frac{1-\\sqrt{5}}{2} \\approx -.618$\n",
    "    - Eigenvalues로 Eigenvectors를 구해보자. $x_1=(\\lambda_1,1)$ and $x_2=(\\lambda_2,1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be67a8f9-22a5-4029-80cc-2013a84ac0c7",
   "metadata": {},
   "source": [
    "**step 2**: Find the combination of those eigenvectors that gives $u_0=(1,0)$\n",
    "- $\\begin{bmatrix} {1}\\\\{0} \\end{bmatrix} = \\frac{1}{\\lambda_1-\\lambda_2} \\bigg( \\begin{bmatrix}{\\lambda_1}\\\\{1} \\end{bmatrix} - \\begin{bmatrix}{\\lambda_2}\\\\{1} \\end{bmatrix} \\bigg)$  or $u_0=\\frac{x_1-x_2}{\\lambda_1-\\lambda_2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f143b78-afb9-4ed4-99d7-b7db5c5c4e9a",
   "metadata": {},
   "source": [
    "**step 3**: multiplies $u_0$ by $A^{100}$ to find $u_{100}$\n",
    "- 100 steps from $u_0$ $u_{100}=\\frac{(\\lambda_1)^{100}x_1-(\\lambda_2)^{100}x_2}{\\lambda_1-\\lambda_2}$\n",
    "- 우리는 $F_{100}= \\text{ second componets of } u_{100}$ 를 원해\n",
    "- $x_1$과 $x_2$의 second component는 1이야\n",
    "- ${\\lambda_1-\\lambda_2}$은 $\\sqrt{5}$\n",
    "- 결국 $F_{100}=\\frac{1}{\\sqrt{5}}\\bigg[\\bigg(\\frac{1+\\sqrt{5}}{2} \\bigg)^{100} - \\bigg(\\frac{1-\\sqrt{5}}{2} \\bigg)^{100}\\bigg] \\approx 3.54\\cdot10^{20}$\n",
    "- The fractions and square roots must disappear, because Fibonacci's rule $F_{k+2} = F_{k+l} + F_k$ stays with integers\n",
    "- k번째 피보나치 수=$\\frac{\\lambda_{1}^{k}-\\lambda_{2}^{k}}{\\lambda_1-\\lambda_2}$ = 가장 가까운 상수는 $\\frac{1}{\\sqrt{5}}\\bigg(\\frac{1+\\sqrt{5}}{2} \\bigg)^{k}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49bfffd-5c2e-4d44-8850-057bf4cd6d24",
   "metadata": {},
   "source": [
    "**The ratio FlOd F100 must be very close to the limiting ratio (I + 0) /2. The Greeks called this number the \"golden mean\".**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be98b440-daae-46b4-8f82-4dd2f327d9c6",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb893f53-128c-4159-ba35-44283d9d24f0",
   "metadata": {},
   "source": [
    "### Matrix Powers $A^k$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e355437-c9c6-47ee-ac82-9b48c2ba8ca3",
   "metadata": {},
   "source": [
    "Power of A: $A^KU_0 = (S\\Lambda  S^{-1})\\dots(S\\Lambda  S^{-1})u_0=S\\Lambda^k  S^{-1}u_0$\n",
    "1. **Write $u_0$ as a combination $c_1x_1+\\dots+c_nx_n$ of the eigenvectors.**\n",
    "2. **Multuply eaxh eigenvector $x_i$ by $(\\lambda_i)^k$**\n",
    "3. **Add up the pieces $c_i(\\lambda_i)^kx_i$ to find the solution $u_k=A^ku_0$**\n",
    "\n",
    "- Solution for $u_{k+1}=Au_k$ $u_k=A^ku_0=c_1(\\lambda_1)^kx_1+\\dots+c_n(\\lambda_n)^kx_n$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d1e913-446f-45df-ae7e-3b57129e75a4",
   "metadata": {},
   "source": [
    "the eigenvectors in S lead to the c's in the combination $u_0=c_1x_1+\\dots+c_nx_n$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f97a433-209b-48dd-9bf2-43c3126d37c7",
   "metadata": {},
   "source": [
    "**step 1**\n",
    "- $u_0= \\begin{bmatrix}{}\\\\ {x_1} & {\\dots} & {x_n}\\\\{} \\end{bmatrix}\\begin{bmatrix}{c_1}\\\\{\\vdots}\\\\{c_n} \\end{bmatrix}$. This says that $u_0=Sc$\n",
    "- 상관계수는 $c=S^{-1}U_0$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f69c129-8efa-4526-91ae-46fc90dd6fb0",
   "metadata": {},
   "source": [
    "**step 2**\n",
    "- Multiply by $\\Lambda^k$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ba76a1-b1ae-41da-96a3-b42678ee81b8",
   "metadata": {},
   "source": [
    "**step 3**\n",
    "- the final result $u_k=\\sum c_i(\\lambda_i)^kx_i$is the product of S and $\\Lambda^k$ and $S^{-1}u_0$\n",
    "- $A^ku_0 = S\\Lambda^kS^{-1}u_0 = S\\Lambda^kc = \\begin{bmatrix}{}&{}&{}\\\\{x_1} & {\\dots}&{x_n}\\\\{}&{}&{}\\end{bmatrix} \\begin{bmatrix}{(\\lambda_1)^k}&{}&{}\\\\{}&{\\ddots}&{}\\\\{}&{}&{(\\lambda_n)^k}\\end{bmatrix} \\begin{bmatrix}{c_1}\\\\{\\vdots}\\\\{c_n}\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e11bc4-81d1-4695-a115-1030a4f631c1",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73929a27-2e36-44e2-acfa-302e2c0651d9",
   "metadata": {},
   "source": [
    "##### ex 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4572de88-1946-463b-b482-9fe574eed3d8",
   "metadata": {},
   "source": [
    "고유벡터와 고유값을 가진 S와 람다집합일때, $A^Ku_0$를 계산해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50a9516-09f9-44ac-93c4-70fb1b66360e",
   "metadata": {},
   "source": [
    "- $u_0=(1,0)$\n",
    "- $A=\\begin{bmatrix}{1}&{2}\\\\{1}&{0}\\end{bmatrix} \\text{ has } \\lambda_1=2 \\text{ and } x_1=\\begin{bmatrix}{2}\\\\{1}\\end{bmatrix}$\n",
    "- $\\lambda_2=-1 \\text{ and } x_2=\\begin{bmatrix}{1}\\\\{-1}\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4c376c-20f4-4a19-9db4-da0a48868e96",
   "metadata": {},
   "source": [
    "Solution in three steps: $u_0=c_1x_1+c_2x_2$를 찾고 $u_k=c_1(\\lambda_1)^kx_1+c_2(\\lambda_2)^kx_2$도 찾자\n",
    "- **step 1** $u_0=\\begin{bmatrix}{1}\\\\{0}\\end{bmatrix} = \\frac{1}{3}\\begin{bmatrix}{2}\\\\{1}\\end{bmatrix} + \\frac{1}{3}\\begin{bmatrix}{1}\\\\{-1}\\end{bmatrix} \\text{ so } c_1 = c_2=\\frac{1}{3}$\n",
    "- **step 2** Multiply the two parts by $(\\lambda_1)^k=2^k \\text{ and } (\\lambda_2)^k=(-1)^k$\n",
    "- **step 3** Combine eigenvectors $c_1(\\lambda_1)^kx_1 \\text{ and }c_2(\\lambda_2)^kx_2 \\text{ into } u_k $\n",
    "    - $u_k=A^ku_0$ $u_k=\\frac{1}{3}2^k\\begin{bmatrix}{2}\\\\{1}\\end{bmatrix}+\\frac{1}{3}(-1)^k\\begin{bmatrix}{1}\\\\{-1}\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a014852-baff-4dcb-9e5d-698da4815807",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed74039b-7549-43be-98f6-03d4a63ead5d",
   "metadata": {},
   "source": [
    "#### Nondiagonalizable Matrices (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39518b50-f285-488a-a8bb-83ba9098bc8e",
   "metadata": {},
   "source": [
    "람다가 A의 고유값일때 우리는 두가지를 알아냈지\n",
    "1. 기하학적으로 고유벡터; 0이 아닌nonzero 해결책은 $Ax=\\lambda x$\n",
    "2. 대수로 고유값; $A-\\lambda I $의 determinant는 0이야."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ca656d-f7e4-4680-a88a-b1728fade5aa",
   "metadata": {},
   "source": [
    "For exceptional matrices, an eigenvalue can be repeated. Then there are two different ways to count its multiplicity. Always OM < AM for each A: 고유값들이 반복되는 예외적인 경우에 중복도(?)를 세는 두가지 다른 방법이 있다.\n",
    "1. 기하학적 중복도 Geomatric Multiplicity=GM\n",
    "    - $\\lambda$에서 독립적인 고유벡터를 센다.이건 $A-\\lambda I$의 nullspace의 차원이다.\n",
    "2. 대수적 중복도 Algebraic Multiplicity=AM\n",
    "    - 고유값을 사용한 $\\lambda$의 반복을 센다. $det(A-\\lambda I)=0$의 n개의 근을 본다.\n",
    "\n",
    "\n",
    "$\\lambda=4,4,4$이면 GM은 3이고 AM은 1 또는 2 또는 3임!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3941619a-892d-4a69-ae18-14d9d8cea205",
   "metadata": {},
   "source": [
    "> warning: AM=2, GM=1 일때, 고유값은 2개인데 고유벡터가 1개인 경우가 있다. 이는 A가 대각선화 할 수 없은AM평균 아래에 있을때 고유벡터의 단점이다.(?)When repeats = [1 1. .. 1] we know that the n eigenvalues are \n",
    "all different and A is diagonalizable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c75f79b-f2bf-4b15-97ec-03957ce90347",
   "metadata": {},
   "source": [
    "- When repeats = [1 1. .. 1] we know that the n eigenvalues are all different and A is diagonalizable.\n",
    "    - The sum of all components in \"repeats\" is always n, because every nth degree equation $det(A - \\lambda I) = 0$ has n roots (counting repetitions). The sum of all components in \"repeats\" is always $n$, because every $n^{th}$ degree equation $det(A - \\lambda I) = 0$ has $n$ roots (counting repetitions). \n",
    "- The total number of independent eigenvectors might be less than n. Then A is not diagonalizable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55600fcd-d9ea-48cd-836d-0c0f5afae879",
   "metadata": {},
   "source": [
    "#### Eigenvalues of A B and A + B "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337e699a-7fcf-4222-ae21-c097d813a06e",
   "metadata": {},
   "source": [
    "An eigenvalue $\\lambda$ of A times an eigenvalue $\\beta$ of B usually does not give an eigenvalue of AB: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c4f740-d258-4757-bd94-2c87ec989547",
   "metadata": {},
   "source": [
    "**False proof**: $ABx = A\\beta x = \\beta A x = \\beta \\lambda x$.\n",
    "- 이건 베타를 곱한 람다가 고유값처럼 보인다.\n",
    "- x가 A,B의 고유벡터일때 이는 옳은 증명이다.\n",
    "- 하지만 항상 그렇지는 않지!\n",
    "- A의 고유벡터들은 일반적으로 B의 고유벡터들이 아니다.\n",
    "- 1이 AB의 고유값일때, A,B는 모두 0 고유값을 가질 수 있다.\n",
    "- 이 때문에 A+B의 고유값은 일반적으로 $\\lambda+\\beta$가 아니다.\n",
    "- 이 잘못된 증명은 위 사실을 보인다.\n",
    "- x가 진짜 A,B 모두의 고유벡터라면, $ABx=\\lambda \\beta x$와 $BAx= \\beta \\lambda x$가 나와야 한다.\n",
    "- n개의 고유벡터가 공유된다면 고유값들을 곱할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddb8da2-a067-4180-929b-f070b75d816d",
   "metadata": {},
   "source": [
    "> note: Commuting matrics share eigenvectpors: A와 B가 대각화할 수 있다고 가정할떄 $AB=BA$일 경우에만 같은 고유벡터 행렬 S가 공유된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf029d1a-6405-46e4-a980-48c4319cfc63",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f384f2aa-09a5-41bf-b90c-e970581ed6e2",
   "metadata": {},
   "source": [
    "***REVIEW OF THE KEY IDEAS***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32cf236-f523-4060-9553-67920188dd67",
   "metadata": {},
   "source": [
    "1. If $A$ has $n$ independent eigenvectors $x_1 \\dots x_n$, they go into the columns of $S$. \n",
    "- **$A$ is diagonalized by $S$** $S^{-1}AS = \\Lambda$ and $A = S\\Lambda S^{-1}$.\n",
    "2. The powers of $A$ are $A^k = S\\Lambda^kS^{-1}$. The eigenvectors in $S$ are unchanged.\n",
    "3. The eigenvalues of $A^k$ are $(\\lambda_1)^k, ... , (\\lambda_n)^k$ in the matrix $\\Lambda^k$. \n",
    "4. The solution to $u_{k+l} = Au_k$ starting from $u_0$ is $u_k = A^ku_0 = S\\Lambda^kS^{-1}u_0$:\n",
    "- $u_k=c_1(\\lambda_1)^kx_1+\\dots+c_n(\\lambda_n)^kx_n$ provided $u_0 = c_1x_1 + c_nx_n$\n",
    "- That shows Steps 1,2,3 ($c$'s from $S^{-1} u_O , \\lambda^k$ from $\\Lambda^k$, and $x$'s from $S$)\n",
    "5. A is diagonalizable if every eigenvalue has enough eigenvectors (GM = AM). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4524cb60-cd85-4bd4-8d41-1efb3468cd83",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6f0448-dd60-478d-bfd6-c0cc08d9588b",
   "metadata": {},
   "source": [
    "*** WORKED EXAMPLES***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99af73ad-91f7-4af2-9b65-23e80a0f39bf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e04c780-58a7-4963-8e59-2a882a4db961",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "816f9fb6-53f5-4ce9-8abf-d06142a34906",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8643c7-36f6-4239-b0bd-ed5ed2d3a3a4",
   "metadata": {},
   "source": [
    "***Problem Set 6.2 ***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f69025-aea9-4c6d-a427-f345efeda3d3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b7014f6-43fa-44f2-9a98-ece791523b93",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "344b4518-a7be-45f3-9543-d2b34d563e9c",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b06706-4ae2-485e-bdb6-944118db5b58",
   "metadata": {},
   "source": [
    "### 6.3 Applications to Differential Equations "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8009bfe2-bfc3-4a8b-841f-451f58f60949",
   "metadata": {},
   "source": [
    "**The whole point of the section is this: To convert constant-coefficient differential equations into linear algebra.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a08258-74b1-4073-b879-e1d4def80fb8",
   "metadata": {},
   "source": [
    "*One equation* $\\frac{du}{dt}=\\lambda u$ has the solutions $u(t) = Ce^{\\lambda t}$.\n",
    "- Linear algebra moves to n by n. The unknown is  a vector u (now boldface).\n",
    "- 우리는 n exponentials $e^{\\lambda t}x$ in $u(t)$를 expect하지.\n",
    "\n",
    "*n equations* $\\frac{du}{dt}=Au$ starting from the vector $u(0)$ at t=0\n",
    "- These differential equations are linear. If u(t) and vet) are solutions, so is $C u(t) + Dv(t)$.\n",
    "- 우리가 가장 먼저 할 일: \"pure exponential solutions\" $Ax=\\lambda x$를 사용하여 $u=e^{\\lambda t}x$ 를찾는 것\n",
    "- Notice that A is a constant matrix. \n",
    "- $\\frac{du}{dt} = Au$ is \"linear with constant coefficients\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93d077e-6adc-4870-8cea-6817a2f86ba3",
   "metadata": {},
   "source": [
    "> The main point will be: Solve linear constant coefficient equations by exponentials $e^{\\lambda t}x$, when $Ax = \\lambda X$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67c11be-fdda-4a12-a0f8-75ac84f73779",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30abe539-f66c-4351-8103-fdf5f8fe192c",
   "metadata": {},
   "source": [
    "#### Solution of du/dt = Au "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260f287b-4d1a-48f2-ad92-75c787cec543",
   "metadata": {},
   "source": [
    "**Use $u=e^{\\lambda t}x$ when $Ax=\\lambda x$ $\\frac{du}{dt}=\\lambda e^{\\lambda t}x$ agrees with $Au=Ae^{\\lambda t}x$**\n",
    "- All components of this special solution $u = e^{\\lambda t}x$ share the same $e^{\\lambda t}$. The solution grows when $\\lambda > O$. It decays when $\\lambda < O$. If $\\lambda$ is a complex number, its real part decides growth or decay. The imaginary part $w$ gives oscillation ei wt like a sine wave."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5a1664-bd60-458a-9456-6621feffa0ba",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e7516f-cfb0-4c12-a451-6d38d5f473f8",
   "metadata": {},
   "source": [
    "##### ex1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96830b3-06b4-46d3-a355-77299246ccf0",
   "metadata": {},
   "source": [
    "Solve $\\frac{du}{dt}=Au=\\begin{bmatrix}{0}&{1}\\\\{1}&{0}\\end{bmatrix}u$ starting from $u(0)=\\begin{bmatrix}{4}\\\\{2}\\end{bmatrix}$\n",
    "- u에 대한 벡터방정식\n",
    "- y,z라는 스칼라를 포함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c861e9-863d-4f1d-b881-2cf8e7faaf1d",
   "metadata": {},
   "source": [
    "$\\frac{du}{dt}=Au$, $frac{d}{dt}\\begin{bmatrix}{y}\\\\{z}\\end{bmatrix} = \\begin{bmatrix}{1}&{1}\\\\{1}&{0}\\end{bmatrix} \\begin{bmatrix}{y}\\\\{z}\\end{bmatrix}$ means that $\\frac{dy}{dt}=z$ and $\\frac{dz}{dt}=y$\n",
    "- This matrix A has eigenvalues 1 and -1. The eigenvectors are (1, 1) and (1, -1). \n",
    "- $u_1(t)=e^{\\lambda_1 t}x_1=e^t \\begin{bmatrix} {1}\\\\{1}\\end{bmatrix}$ and $u_2(t)=e^{\\lambda_2 t}x_2=e^{-t} \\begin{bmatrix} {1}\\\\{-1}\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d148a47c-fade-472d-b3db-d28c7455c2b0",
   "metadata": {},
   "source": [
    "> note: 위의 u는 고유벡터임!, $e^t,e^{-t}$들은 시간에 따라 변함!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57de8479-d4b5-4225-bf5b-b0b86de5fca6",
   "metadata": {},
   "source": [
    "To find all other solutions, multiply those special solutions by any C and D and add:\n",
    "- Complete solution\n",
    "    - $u(t) = Ce^t\\begin{bmatrix}{1}\\\\{1}\\end{bmatrix}+De^{-t}\\begin{bmatrix}{1}\\\\{-1}\\end{bmatrix} = \\begin{bmatrix}{4}\\\\{2}\\end{bmatrix}$ yields $C=3$ and $D=1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fadb97f-c482-420b-a329-59c1219f5d47",
   "metadata": {},
   "source": [
    "The same three steps that solved Uk+l = AUk now solve $\\frac{du}{dt} = Au:$ \n",
    "1. Write $u (0)$ as a combination $c_1 x_1 + ... + c_n x_n$ of the eigenvectors of $A$. \n",
    "2. Multiply each eigenvector $x_i$ by $e^{\\lambda_i t}$ . \n",
    "3. The solution is the combination of pure solutions $e^{\\lambda t}x$: \n",
    "    - $u(t)=c_1e^{\\lambda_1 t}x_1+\\dots+c_ne^{\\lambda_n t}x_n$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea3a096-3c5b-4684-b9b5-a84e765d8ffb",
   "metadata": {},
   "source": [
    "> warning: Not included: If two $\\lambda$'S are equal, with only one eigenvector, another solution is needed. (It will be $te^{\\lambda t} x$). Step 1 needs $A = S\\Lambda S^{-1}$ to be diagonalizable: a basis of eigenvectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be11a78-e2a7-42a6-9bf0-1f800e45b0d0",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b6859f-628d-4041-9e54-e31552d6ff5a",
   "metadata": {},
   "source": [
    "##### ex2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28abba83-4004-4bd9-88e2-95e809be907c",
   "metadata": {},
   "source": [
    "Solve $\\frac{du}{dt}=Au$ knowing tjhe eigenvalues $\\lambda=1,2,3$ of A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6190037e-23af-4f15-9fba-faf277b3879b",
   "metadata": {},
   "source": [
    "$$\\frac{du}{dt}=\\begin{bmatrix}{1}&{1}&{1}\\\\{0}&{2}&{2}\\\\{0}&{0}&{3} \\end{bmatrix}u \\text{ starting from } u(0)=\\begin{bmatrix}{9}\\\\{7}\\\\{4} \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac647c3-ecd3-44dd-abab-1cd0e169cdc0",
   "metadata": {},
   "source": [
    "The eigenvectors are $x_1 = (1,0,0)$ and $x_2 = (1,1,0)$ and $x_3 = (1,1,1)$. \n",
    "- Step 1 The vector $u(0) = (9,7,4)$ is $2x_1 + 3x_2 + 4x_3$. Thus ($c_1, c_2, c_3) = (2,3,4)$. \n",
    "- Step 2 The pure exponential solutions are $e^t x_1$ and $e^{2t} x_2$ and $e^{3t} x_3$. \n",
    "- Step 3 The combination that starts from $u(0)$ is $u(t) = 2e^{t}x_1 + 3e^{2t} x_2 + 4e^{3t} x_3$. \n",
    "\n",
    "The coefficients 2, 3, 4 came from solving the linear equation $c_1x_1 + c_2x_2 + c_3x_3 = u(0)$: \n",
    "\n",
    "$$\\begin{bmatrix}{}&{}&{}\\\\{x_1}&{x_2}&{x_3}\\\\{}&{}&{} \\end{bmatrix}\\begin{bmatrix}{c_1}\\\\{c_2}\\\\{c_3} \\end{bmatrix}=\\begin{bmatrix}{1}&{1}&{1}\\\\{0}&{1}&{1}\\\\{0}&{0}{1} \\end{bmatrix}\\begin{bmatrix}{2}\\\\{3}\\\\{4} \\end{bmatrix}=\\begin{bmatrix}{9}\\\\{7}\\\\{4} \\end{bmatrix} \\text{ which is } Sc=u(0)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef0e27d-d007-4922-b361-f57e2b686ff1",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa68689d-bb94-44f9-b5f9-d880c2ff1852",
   "metadata": {},
   "source": [
    "#### Second Order Equations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab6e74e-e77e-4584-85ed-fbf2409b98d2",
   "metadata": {},
   "source": [
    "The most important equation in mechanics is $my\" +by' +ky = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bcef46-a0f4-44f6-8265-f7535371d182",
   "metadata": {},
   "source": [
    "?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda72759-7548-4b84-90aa-bdaa2e54faf4",
   "metadata": {},
   "source": [
    "$$m\\frac{d^2 y}{dt^2}+b\\frac{dy}{dt} + ky = 0 \\text{ becomes } (m\\lambda^2 + b\\lambda + k) e^{\\lambda t}=0$$\n",
    "\n",
    "Everything depends on $m\\lambda^2 + b\\lambda + k = 0$. This equation for $\\lambda$ has two roots $\\lambda_1$ and $\\lambda_2$. Then the equation for $y$ has two pure solutions $y_1 = e^{\\lambda_1 t}$ and $y_2 = e^{\\lambda_2 t}$ . Their combinations $c_1 y_1 + c_2y_2$ give the complete solution unless $\\lambda_1 = \\lambda_2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc737f3-e85c-4ffd-92ac-1d24b363ef0a",
   "metadata": {},
   "source": [
    "$$u(t)=c_1e^{\\lambda_1 t}\\begin{bmatrix}{1}\\\\{\\lambda_1} \\end{bmatrix}+c_we^{\\lambda_2 t}\\begin{bmatrix}{1}\\\\{\\lambda_2} \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200557ae-aa43-4a14-93f9-c6f478b22a05",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485a70a9-2aa4-42f3-a88e-f4624a24a031",
   "metadata": {},
   "source": [
    "##### ex3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab01735b-9dc3-47df-b464-13e62e5851e2",
   "metadata": {},
   "source": [
    "Motion around a circle with $y\" + y = 0$ and $y = cos t$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd9a55f-cee9-4091-b4f5-39924e63ff0c",
   "metadata": {},
   "source": [
    "$$\\begin{matrix}{\\text{Forward from }n-1}\\\\{\\text{ Centeren at }n}\\\\{\\text{ Backward from }n+1} \\end{matrix}\\frac{Y_{n+1}-2Y_n +Y_{n-1}}{(\\Delta t)^2}=\\begin{matrix}{-Y_{n-1}}\\\\{-Y_n}\\\\{-Y_{n+1}} \\end{matrix}$$\n",
    "- 이 세가지 방법은 완전한 원을 구성하진 않아, $\\Delta t = \\frac{2\\pi}{32}$ 길이의 32단계에서"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf94cea-ab2b-406f-a03c-cd16fca8f820",
   "metadata": {},
   "source": [
    "$$\\text{Foward }|\\lambda|>1\\text{  (spiral out) Centered} |\\lambda|=1\\text{(best) Backward } |\\lambda|<1 \\text{ (spiral in)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743ff554-d737-4d4f-95fe-ebfd4da4061d",
   "metadata": {},
   "source": [
    "$$\\text{Forward }\\begin{matrix}{Y_{n+1}=Y_n+\\Delta tZ_n}\\\\{Z_{n+1}=Z_n-\\Delta tY_n}\\end{matrix}\\text{ becomes } U_{n+1}=\\begin{bmatrix}{1}&{\\Delta t}\\\\{-\\Delta t}&{1} \\end{bmatrix}\\begin{bmatrix}{Y_n}\\\\{A_n} \\end{bmatrix}=AU_n$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedb5810-2d7b-487d-8e16-881606a88b06",
   "metadata": {},
   "source": [
    "$$\\text{Eigenvalues of A } \\lambda = 1 \\pm i\\Delta t \\text{  } |\\lambda | >1 \\text{ and } (Y_n, Z_n) \\text{ spirals out}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5623c92-236f-4a64-a354-01546f81a8b0",
   "metadata": {},
   "source": [
    "$$\\text{Backward }\\begin{matrix} {Y_{n+1}=Y_n+\\Delta t Z_{n+1}}\\\\{Z_{n+1}=Z_n-\\Delta t T_{n+1}}\\end{matrix} \\text{ is } \\begin{bmatrix}{1} &{-\\Delta t}\\\\{\\Delta}&{1}\\end{bmatrix}\\begin{bmatrix}{Y_{n+1}\\\\{Z_{n+1}}}\\end{bmatrix}=\\begin{bmatrix}{Y_n}\\\\{Z_n}\\end{bmatrix}=U_n$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0240ca4-f534-4c34-bb5e-cb4b6dc5aef5",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e530ae-9a64-4832-ae46-ba2472591fa5",
   "metadata": {},
   "source": [
    "#### Stability of 2 by 2 Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88371708-6885-449b-b745-77393f08b2ca",
   "metadata": {},
   "source": [
    "- complete solution $u(t)$ 는 $e^{\\lambda t}$로 만들어짐!\n",
    "- 만약 고유값 람다가 있다면, $e^{\\lambda t}$가 0에 가까워지면 그땐 정확하게 람다가 음수여야 한다는 것을 알지.\n",
    "- 만약 고유값이 복소수 $\\lambda = r+is$라면 실제 부분 r은 음수여야 하지."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10473aa4-a05d-4554-bc6b-8b4f573aa6ff",
   "metadata": {},
   "source": [
    "$$e^{ist} =\\cos st + i \\sin st \\text{ has }|e^{ist}|^2=\\cos ^2 st+\\sin ^2 st =1 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4088505b-f4b1-4e30-9e00-d8fcfab5f4ed",
   "metadata": {},
   "source": [
    "**Which matrices have negative eigenvalues? More accurately, when are the real parts of the $\\lambda$'s all negative?**\n",
    "\n",
    "$$\\text{Stability; a is stable and } u(t)\\rightarrow 0 \\text{ when all eigenvalues have negative real parts.}$$\n",
    "\n",
    "$$\\text{The 2 by 2 matrix } A=\\begin{bmatrix}{a}&{b}\\\\{c}&{d}\\end{bmatrix} \\text{must pass two tests:}$$\n",
    "\n",
    "$$\\begin{matrix}{\\lambda_1+\\lambda_2<0}\\\\{\\lambda_1\\lambda_2 >0}\\end{matrix} \\begin{matrix}{\\text{The trace } T=a+d \\text{must be negative}}\\\\{\\text{The determinant } D=ad-bc \\text{ must be positive}}\\end{matrix}$$\n",
    "\n",
    "- 람다들이 음수로 존재하면 합은 음수일테니까, 그 합이 trace T이고. 그럼 곱은 양수가 되겠지. 이게 determinant D야.\n",
    "- 람다들이 복소수라면 $r\\pm is$로부터 얻을 수 있겠지, 그렇지 않으면 T,D는 얻을 수 없어"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a5fa9f-b4a8-4beb-8df2-a4c612f562db",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b39bfc4-761d-4683-b863-231884adf9b6",
   "metadata": {},
   "source": [
    "#### The Exponential of a Matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce38fa66-6215-4c0f-b637-faf0ce07bb70",
   "metadata": {},
   "source": [
    "We want to write the solution $u(t)$ in a new form $e^{At} u(0)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d023c34b-798d-49f5-949c-d2717abf1e81",
   "metadata": {},
   "source": [
    "$$\\text{Matrix exponentil }e^{At} \\text{    } e^{At} = I At +\\frac{1}{2}(At)^2 + \\frac{1}{6}(At)^3+\\dots$$\n",
    "\n",
    "$$\\text{Its derivative is } Ae^{At} \\text{     }A+A^2+\\frac{1}{2}A^3t^2+\\dots = Ae^{At}$$\n",
    "\n",
    "$$\\text{Its eigenvalues are } e^{\\lambda r}\\text{   }(I+At +\\frac{1}{2}(At)^2)x=(1+\\lambda t +\\frac{1}{2}(\\lambda t)^2+\\dots)x$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70e5537-ac25-45ee-98bc-c967e7b86a19",
   "metadata": {},
   "source": [
    "This chapter emphasizes how to find$ u(t) = e^{At} u(0)$ by diagonalization. Assume A does have $n$ independent eigenvectors, so it is diagonalizable. Substitute $A = S\\Lambda S^{-1}$ into the series for $e^{At}$. Whenever $\\Lambda S^{-1} S\\Lambda S^{-1}$ appears, cancel $S^{-1} S$ in the middle:\n",
    "\n",
    "$$\\text{Use the series  } e^{At}=I+S\\Lambda S^{-1}t +\\frac{1}{2}(S\\Lambda S^{-1}t)(S\\Lambda S^{-1}t)+\\dots$$\n",
    "\n",
    "$$\\text{Factor out } S \\text{ and } S^{-1} \\text{   } = S[I+\\Lambda t +\\frac{1}{2}(\\Lambda t)^2+\\dots]S^{-1}$$\n",
    "\n",
    "$$\\text{Diagonalize } e^{At} \\text{  } = Se^{\\Lambda t}S^{-1}$$\n",
    "\n",
    "$$e^{At}u(0) = Se^{\\Lambda t}S^{-1}u(0)=\\begin{bmatrix}{}\\\\{x_1}&{\\dots}&{x_n}\\\\{}\\end{bmatrix}\\begin{bmatrix}{e^{\\lambda_1t}}&{}&{}\\\\{}&{\\ddots}&{}\\\\{}&{}&{e^{\\lambda)n t}}\\end{bmatrix}\\begin{bmatrix}{c_1}\\\\{\\vdots}\\\\{c_n}\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c1f95d-f504-4dd6-a479-a76e8f2f276a",
   "metadata": {
    "tags": []
   },
   "source": [
    "$e^{At}u(0)$의 solution\n",
    "\n",
    "1. $u(0)=c_1x_1+\\dots+c_nx_n$을 쓰자, n개의 독립적인 고유벡터가 필요하다.\n",
    "2. $e^{\\lambda_i t}$에 각 $x_i$를 곱하자\n",
    "3. $e^{At}u(0)$의 best form은 $u(t)=c_1e^{\\lambda_1 t}x_1+\\dots+c_ne^{\\lambda_n t}x_n$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c1bddd-8648-4f3a-a235-03a97736fa20",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e76cda2-ca59-42d3-83cf-f03f42215bdb",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### ex4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317eddbb-58c4-4b8a-a107-59fe1152adf1",
   "metadata": {},
   "source": [
    "When you substitute $y = e^{\\lambda t}$ into $y\" - 2y' + y = 0$, you get an equation with repeated roots: $\\lambda^2 - 2\\lambda + 1 = 0 = (\\lambda-1)$.\n",
    "\n",
    "$$\\text{Short series  }e^{At}=e^{It}e^P-I{t=e^t[I+(A-I)t}$$\n",
    "\n",
    "$$u(t)=e^t\\begin{bmatrix}I+\\begin{bmatrix}{-1}&{1}\\\\{-1}&{1}\\end{bmatrix} t \\end{bmatrix}u(0)$$\n",
    "\n",
    "$$y(t) = e^ty(0) -te^ty(0) +te^t y[0]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123855ab-187f-477f-8847-651eb4781dbf",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7aba56a-38a0-4937-915e-241dd5db9935",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### ex5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7fcfd4-886e-4a85-92ea-5da65386987a",
   "metadata": {},
   "source": [
    "Use the infinite series to find $e^{At}$ for $A=\\begin{bmatrix}{0}&{1}\\\\{-1}&{1}\\end{bmatrix}$. Notice that $A^4=I$\n",
    "\n",
    "$$A=\\begin{bmatrix}{0}&{1}\\\\{-1}&{1}\\end{bmatrix}$$\n",
    "\n",
    "$$e^{At}=\\begin{bmatrix}{\\cos t}&{\\sin t}\\\\{\\sin t}&{\\cos t}\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f88163-1b12-4f74-aa13-68f74ebbb48a",
   "metadata": {},
   "source": [
    "The eigenvalues of eAt are e it and e-it . Three rules: \n",
    "1. $e^{At}$ always has the inverse $e^{-A}$t . \n",
    "2. The eigenvalues of $e^{At}$ are always $e^{\\lambda t}$. \n",
    "3. When A is skew-symmetric, $e^{At}$ is orthogonal. Inverse = transpose = $e^{-At}. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827d6e55-0971-44b7-987c-8df594730ceb",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f985b8-7bf1-482e-a81e-5ef16a040b09",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### ex6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4ef915-2dde-4fb4-94dc-a229aa0e7de8",
   "metadata": {},
   "source": [
    "Solve\n",
    "\n",
    "$\\frac{du}{dt}=Au=\\begin{bmatrix}{1}&{1}\\\\{0}&{2}\\end{bmatrix}u$ starting from $u(0)=\\begin{bmatrix}{2}\\\\{1}\\end{bmatrix}$ at t=0\n",
    "\n",
    "Solution\n",
    "\n",
    "$u(t)=e^t\\begin{bmatrix}{1}\\\\{0}\\end{bmatrix}+e^{2t}\\begin{bmatrix}{1}\\\\{1}\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507a7b7e-99e7-40b3-a2c0-13e8212f2d06",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f48ac6-3b40-4d8d-ae8c-57640ce7e129",
   "metadata": {},
   "source": [
    "**REVIEW OF THE KEY IDEAS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc70e7e-c88f-473b-97c5-b1a17bf96076",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43212dee-477a-4e50-9fd0-87fa5b57feda",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a4f398b-7e1b-4d4f-bb3b-bf811f940cf1",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e419ab2-8152-42e0-8296-9755603a59d0",
   "metadata": {},
   "source": [
    "**WORKED EXAMPLES**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f95858d-9b24-48f8-a68e-a062367634b1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a816192a-dd1c-469d-b5b2-c0293bd1422d",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4fe394-1f9f-46fb-98fc-5edc29c14ec2",
   "metadata": {},
   "source": [
    "**Problem Set 6.3**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ba48fb-005d-41ba-896b-bf1e1e4b9782",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "671cad3c-0bd8-44d0-a2b7-5715c7b0c595",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515839fd-f874-4102-830e-c5a876a746a2",
   "metadata": {},
   "source": [
    "### 6.4 Symmetric Matrices "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75009bc-f0e3-4209-9026-091942359355",
   "metadata": {},
   "source": [
    "**I have to write \"can be chosen\" because the two in the plane are not automatically perpendicular.**\n",
    "\n",
    "**This section makes that best possible choice for symmetric matrices: The eigenvectors of $P = P^T$ are perpendicular unit vectors.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87739b13-6261-4ae2-9790-3b065cee5056",
   "metadata": {},
   "source": [
    "What is special about $A x = \\lambda x$ when A is symmetric?\n",
    "- A와 trsnspose한 A가 같을 때 고유값 람다와 고유벡터 엑스의 특징을 볼거야"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c61c87-6ab8-4361-a01c-58c58cab79bc",
   "metadata": {},
   "source": [
    "diagonalization $A=S\\Lambda S^{-1}$는 A의 대칭을 반영할걸, $A^T=(S^{-1})^T \\Lambda S^{T}$에서 힌트를 얻어볼까!\n",
    "- A와 trsnpose A가 같다 했으니까.\n",
    "- $S = S^{-1}$ 겠네?\n",
    "     - That makes each eigenvector in S orthogonal to the other eigenvectors.\n",
    "     - S의 각 고유 벡터를 다르 고유벡터와 직교하게 만듦!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3687db83-5c16-4d4b-9345-85deddefe318",
   "metadata": {},
   "source": [
    "**key fact**\n",
    "1. Asymmetric matrix has only real eigenvalues.\n",
    "2. The eigenvectors can be chosen orthonormal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfeb166-27f7-4fbf-8465-2bbeb6202f8a",
   "metadata": {},
   "source": [
    "Its eigenvector matrix $S$ becomes an orthogonal matrix $Q$. Orthogonal matrices have $Q^{-l} = Q^T$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe7ea9f-01fc-4385-94c0-b20ec52ba86a",
   "metadata": {},
   "source": [
    "> note: 직교한 고유벡터를 선택할 떄 S = Q 라 쓴다는 것을 기억하자"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73d3bf6-8c4d-4ba0-b83a-61c315b4feaa",
   "metadata": {},
   "source": [
    "Why do we use the word \"choose\"? Because the eigenvectors do not have to be unit vectors.\n",
    "\n",
    "Their lengths are at our disposal. We will choose unit vectors-eigenvectors of length one, which are orthnormal and not just orthogonal.\n",
    "\n",
    "Then $S\\Lambda S^{-1}$ is in its special and particular form $Q\\Lambda Q^T$ for symmetric matrices:\n",
    "\n",
    "**(Special Theorem) 모든 대칭 행렬은 람다 행렬의 고유값들과 $S=Q$ 인 직교 고유벡터와 같이 factorization $A=Q\\Lambda Q^T$을 가지고 있음**\n",
    "\n",
    "$$\\text{Symmetric diagonalixation } A=Q\\Lambda Q^{-1}=Q\\Lambda Q^T \\text{ with } Q^{-1} = Q^T$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20664c1c-a8f4-41a8-8b26-ab0ad496aae6",
   "metadata": {},
   "source": [
    "This is the \"spectral theorem\" in mathematics and the \"principal axis theorem\" in geometry and physics. \n",
    "1. By an example, showing real $\\Lambda$'s in A and orthonormal $x$'s in $Q$. \n",
    "2. By a proof of those facts when no eigenvalues are repeated. \n",
    "3. By a proof that allows repeated eigenvalues (at the end of this section). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb9179d-6847-4dcb-8a49-b6c452f19b27",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630136a6-de86-42c5-936b-d54ce3504feb",
   "metadata": {},
   "source": [
    "##### ex1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e7d45f-28df-453b-9dea-5eb3773325fb",
   "metadata": {},
   "source": [
    "Find the $\\lambda$'s and $x$'s when $A=\\begin{bmatrix}{1}&{2}\\\\{2}&{4}\\end{bmatrix}$ and $A-\\lambda I = \\begin{bmatrix}{1-\\lambda}&{2}\\\\{2}&{4-\\lambda}\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8915be-e753-438c-97aa-dfd17bd32fec",
   "metadata": {},
   "source": [
    "*Solution*\n",
    "\n",
    "- determinant of $A-\\lambda I$인 $\\lambda^2-5\\lambda$로 고유값 0,5를 찾을 수 있지\n",
    "- 두 고유 벡터는 (2,-1),(1,2)야.(orthogonal but not yet orthonormal.)\n",
    "- 람다가 0일때 고유벡터는 A의 nullspace안에 있어.\n",
    "- 람다가 5일때 고유벡터는 열공간column space 안에 있어.\n",
    "- why are the nullspace and column space perpendicular? \n",
    "    - The Fundamental Theorem says that the nullspace is perpendicular to the row space-not the column space.\n",
    "- 하지만 우리가 보는 행령은 대칭이잖아!\n",
    "- 그래서 행과 열 공간은 같지."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c4e7c3-6478-49ec-a491-07fbe193175a",
   "metadata": {},
   "source": [
    "These eigenvectors have length $\\sqrt{5}$. Divide them by $\\sqrt{5}$ to get unit vectors.\n",
    "\n",
    "Put those into the columns of $S$ (which is $Q$). Then $Q^{-1} AQ$ is $\\Lambda$ and $Q^{-1} = Q^T$:\n",
    "\n",
    "$$Q^{-1}AQ = \\frac{1}{\\sqrt{5}}\\begin{bmatrix}{2}&{-1}\\\\{1}&{2}\\end{bmatrix} \\begin{bmatrix} {1}&{2}\\\\{2}&{4} \\end{bmatrix} \\frac{1}{\\sqrt{5}} \\begin{bmatrix} {2}&{1}\\\\{-1}&{2} \\end{bmatrix}=\\begin{bmatrix}{0}&{0}\\\\{0}&{5}\\end{bmatrix}=\\Lambda$$\n",
    "\n",
    "Now comes the $n$ by $n$ case. The $\\lambda$'s are real when $A = A^T$ and $Ax = \\lambda x$ . "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be09432c-d2d0-4b69-b84e-93e2c2f1530a",
   "metadata": {},
   "source": [
    "**Real Eigenvalues; All the eigen values of a real symmetric matrix are real**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31541f6f-49e1-4580-876e-324b5978e136",
   "metadata": {},
   "source": [
    "**Orthogonal Eigenvectors; Eigenvectors of a real symmetic matrix (when they correspond to different $\\lambda|'s)are always perpendeicular.**\n",
    "\n",
    "$$(\\lambda_1x)^Ty = (Ax)^Ty=x^TA^Ty = x^TAy=x^T\\lambda_2y$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63e3f80-652d-4191-9a05-e9216400642f",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb113822-0646-4904-8f5a-62199ad81c53",
   "metadata": {},
   "source": [
    "##### ex2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01b0702-18c6-4b34-b757-71f4fb40a1e2",
   "metadata": {},
   "source": [
    "The eigenvectors of a 2 by 2 symmetric matrix have a special form:\n",
    "\n",
    "Not widely known $A=\\begin{bmatrix}{a}&{b}\\\\{b}&{c}\\end{bmatrix}$ has $x_1=\\begin{bmatrix}{b}\\\\{\\lambda_1-a}\\end{bmatrix}$ and $x_2=\\begin{bmatrix}{\\lambda_2-c}\\\\{b}\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42e09f0-6eb6-4026-8f29-3bcb28584a7c",
   "metadata": {},
   "source": [
    "$$x_{1}^{T}x_2=b(\\lambda_2-c)+(\\lambda_1-a)b=b(\\lambda_1+\\lambda_2-a-c)=0$$\n",
    "- $\\lambda_1+\\lambda_2$가 trace a+c와 같기 떄문에 0이다~\n",
    "- $x_{1}^{T}x_2=0$이 되겠지?\n",
    "- $x_1=x_2=0$일때, a=c,b=0\n",
    "    - 이 경우 A=I에서 고유값이 반복됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27deca8-0f49-4fbb-a369-ee3ac871f5f3",
   "metadata": {},
   "source": [
    "**This example shows the main goal of this section-to diagonalize symmetric matrices A by orthogonal eigenvector matrices $S = Q$. Look again at the result:**\n",
    "$$\\text{Symmetry } A=S\\Lambda S^{-1} \\text{ becomes } A=Q\\Lambda Q^T \\text{ with } Q^TQ=I$$\n",
    "\n",
    "이는 모든 2 by 2 행렬이 이렇게 생겼다는 것을 의미\n",
    "$$A=Q\\Lambda Q^T = \\begin{bmatrix}{}\\\\{x_1}&{x_2}\\\\{}\\end{bmatrix} \\begin{bmatrix} {\\lambda_1}&{}\\\\{}&{\\lambda_2}\\end{bmatrix} \\begin{bmatrix}{}&{x^{T}_{1}}&{}\\\\{}&{x_{2}^{T}}&{} \\end{bmatrix}$$\n",
    "\n",
    "$$\\text{Sum of ranl-one matrics }A=\\lambda_1x_1x_{1}^{T}+\\lambda_2x_2x_{2}^{T}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5081bfa2-18b2-4aff-9cdf-3316972bddd8",
   "metadata": {},
   "source": [
    "- $x_ix_{i}^{T}$를 n번 곱하면 projection matrices임.\n",
    "-  Including the A's, the spectral theorem A = QAQT for symmetric matrices says that A is a combination of projection matrices:\n",
    "$$A=\\lambda_1P_1+\\dots+\\lambda_nP_n \\text{  } \\lambda_i=\\text{ eigenvalue, } P_i=\\text{projection onto eigenspace}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b5b941-0ef9-4b1b-9594-b2a25f405668",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7f8f6f-6eac-4b0f-a2fc-9e2a740d90ed",
   "metadata": {},
   "source": [
    "#### Complex Eigenvalues of Real Matrices "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a217d277-6389-430a-8ca0-5b7b9fb8f18d",
   "metadata": {},
   "source": [
    "**For real matrices, complex $\\lambda$'s and $x$'s come in \"conjugate pairs.\"**\n",
    "$$\\text{If }Ax=\\lambda x \\text{ then } A\\bar{x}=\\bar{\\lambda}\\bar{x}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4f0608-0f39-4877-9253-b8851a6802c3",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcff78f7-fff2-4161-afb1-f60d71ad8888",
   "metadata": {},
   "source": [
    "##### ex3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d782ab-4838-4ab8-9831-a2aed7c61ff3",
   "metadata": {},
   "source": [
    "$$A=\\begin{bmatrix}{\\cos \\theta} &{-\\sin \\theta}\\\\{\\sin \\theta} &{\\cos \\theta} \\end{bmatrix} \\text{ has } \\lambda_1=\\cos \\theta + i \\sin \\theta \\text{ and } \\lambda_2 \\cos \\theta -i\\sin \\theta$$\n",
    "\n",
    "$$\\text{This is } \\lambda x \\text{   } Ax=\\begin{bmatrix} {\\cos \\theta}&{-\\sin \\theta}\\\\{\\sin \\theta}&{\\cos \\theta}\\end{bmatrix}\\begin{bmatrix}{1}\\\\{-i}\\end{bmatrix}=(\\cos \\theta + i \\sin \\theta) \\begin{bmatrix}{1}\\\\{-i}\\end{bmatrix})$$\n",
    "\n",
    "$$\\text{This is } \\bar{\\lambda}\\bar{x} \\text{   } A\\bar{x}=\\begin{bmatrix} {\\cos \\theta}&{-\\sin \\theta}\\\\{\\sin \\theta}&{\\cos \\theta}\\end{bmatrix}\\begin{bmatrix}{1}\\\\{i}\\end{bmatrix}=(\\cos \\theta - i \\sin \\theta) \\begin{bmatrix}{1}\\\\{i}\\end{bmatrix})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a98b5c-7eb6-418f-925c-4d8a8f31485d",
   "metadata": {},
   "source": [
    "**For this rotation matrix the absolute value is $|\\lambda|=1$, because $|cos^2 \\theta + \\sin^2 \\theta = 1$. This fact $|\\lambda| = 1$ holds for the eigenvalues of every orthogonal matrix.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd41d574-d5e6-4487-8523-ed90aba1f6e9",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a88c39-00e0-4363-b9c9-9e499f40b990",
   "metadata": {},
   "source": [
    "#### Eigenvalues versus Pivots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85b2510-6083-442c-a6d8-437806e12088",
   "metadata": {},
   "source": [
    "$$product of pivots = determinant = product of eigenvalues.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e53ffc-f37c-4847-a1cb-bf84c847c0ed",
   "metadata": {},
   "source": [
    "We are assuming a full set of pivots d 1, ... , dn. There are n real eigenvalues AI, ... , An. The d's and A'S are not the same, but they come from the same matrix. This paragraph is about a hidden relation. For symmetric matrices the pivots and the eigenvalues have the same signs: \n",
    "- **The number of positive eigenvalues of $A = A^T$ equals the number of positive pivots. Special case: $A$ has all $\\lambda_i > 0$ if and only if all pivots are positive.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039ba89b-d6f1-4be7-900a-baab27ced688",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c25268-5080-4ed3-8311-1b37c4ebf820",
   "metadata": {},
   "source": [
    "##### ex4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad9ab06-b4eb-40ba-acfe-6e4594f3ae4d",
   "metadata": {},
   "source": [
    "The signs of the pivots match the signs of the eigenvalues, one plus and one minus. This could be false when the matrix is not symmetric.\n",
    "- 대칭 행렬에서 pivot이 둘 중 한 개만 양수라면 고유값도 둘 중 한 개만 양수\n",
    "- 비대칭행렬에서는 pivot이 둘 다 양수여도 고유값은 아닐 수 있으니 주의!\n",
    "- *the pivots and eigenvalues have matching signs,*\n",
    "- *But to change sign, a real eigenvalue would have to cross zero.*\n",
    "- *The matrix would at that moment be singular*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7da28aa-6259-46ad-9d65-f6c1b75f4b01",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a70918-ef08-4fcd-a693-8375ae268b0f",
   "metadata": {},
   "source": [
    "#### All Symmetric Matrices are Diagonalizable "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9021972e-1d7e-48fd-92f7-3dfe42717014",
   "metadata": {},
   "source": [
    "- 어느 A의 고유값도 반복되지 않을 때, 고유벡터는 독립이 확실하다.\n",
    "- 그러면 A는 대각화될 수 있다.\n",
    "- 하지만 반복된 고유값은 고유벡터의 단점을 가질 수 있음\n",
    "- 이건 비대칭 행렬에대해 일어나곤 함.\n",
    "- 대칭 행렬에서는 절대 안 일어나는 일\n",
    "- **There are always enough eigenvectors to diagonalize $A = A^T$.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454cf992-9d58-4668-9ba4-d3d7d489fa2b",
   "metadata": {},
   "source": [
    "Here is one idea for a proof. Change A slightly by a diagonal matrix $diag( c , 2c, ... , n c)$. If c is very small, the new symmetric matrix will have no repeated eigenvalues. Then we know it has a full set of orthonormal eigenvectors. As $c \\rightarrow 0$ we obtain n orthonormal eigenvectors of the original A-even if some eigenvalues of that A are repeated. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2142e7f-3c1a-48cc-bb78-77e7e5cbdffd",
   "metadata": {},
   "source": [
    "**Schur's Theorem**\n",
    "- **Every square matrixfactors into $A=QTQ^{-1}$ where $T$ is upper triangular and $\\bar{Q}^{T} =Q-^{l.}$ If A has real eigenvalues then $Q$ and $T$ can be chosen real: $Q^T Q = I$**\n",
    "- 임의의 복소수 정사각 행렬을 상삼각 행렬로 나타내는 행렬 분해\n",
    "- ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05389c6f-c4e3-4c20-8da7-bd4a0ee20b65",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613c1568-f864-4928-af9a-13affb33d270",
   "metadata": {},
   "source": [
    "**REVIEW OF THE KEY IDEAS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0e4589-c8b4-4582-b3a4-1af0f85d430c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8cd0f7f7-ed4e-42b4-a108-cb11d123bfe4",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e24938-6722-4f3f-87aa-1a1303404c4d",
   "metadata": {},
   "source": [
    "**WORKED EXAMPLES**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87a3bab-e9df-4b62-bb40-e87ba026cb95",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "561398e1-92ed-4507-8469-b1a997633777",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e19643-fc0e-456b-8cbc-2cd6765c41a6",
   "metadata": {},
   "source": [
    "**Problem Set 6.4**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46213f64-652d-4ff1-a9ca-4034b083ca4a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93f45934-5c24-441e-ae1a-c9363568ef92",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12622678-e5ef-4f77-86ad-dbb235a248ea",
   "metadata": {},
   "source": [
    "**Challenge Problems**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bb80bb-f84b-423a-bbc9-91bedaf53db5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4de9cfa0-3ba7-4e40-a59c-6742064e4bfd",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf62df6d-5c98-4f30-9bdb-eaa2f75cae4d",
   "metadata": {},
   "source": [
    "### 6.5 Positive Definite Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e69ad47-6e04-4b41-a40e-651ae2b0b3d6",
   "metadata": {},
   "source": [
    "*This section concentrates on symmetric matrices that have positive eigenvalues.*\n",
    "\n",
    "*Symmetric matrices with positive eigenvalues are at the center of all kinds of applications. They are called **positive definite.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d893379b-81ac-4e77-8b9f-95a997d1e216",
   "metadata": {},
   "source": [
    "Here are two goals of this section: \n",
    "- To find quick tests on a symmetric matrix that guarantee positive eigenvalues. \n",
    "- To explain important applications of positive definiteness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9af6f3-4269-4236-a160-37ec249f1c0e",
   "metadata": {},
   "source": [
    "$$\\text{Start with 2 by 2 When does } A=\\begin{bmatrix}{a}&{b}\\\\{b}&{c}\\end{bmatrix} \\text{ have } \\lambda_1>0 \\text{ and } \\lambda_2>0?$$\n",
    "\n",
    "$$\\text{The eigenvalues of A are positive if and only if } a>0 \\text{ and } ac-b^2>0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ef5210-aa38-4478-a6d6-71b628bb7ced",
   "metadata": {},
   "source": [
    "Proof that the 2 by itest is passed when $\\lambda_l > 0$ and $|lambda_2 > O$. Their product $\\lambda_1 \\lambda_2$ is the determinant so $ac - b^2 > O$. Their sum is the trace so $a + c > O$. Then $a$ and $c$ are both positive (if one of them is not positive, $ac - b^2 > 0$ will fail)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48386682-0936-4d4a-a166-f58c68fb1f53",
   "metadata": {},
   "source": [
    "$$\\text{The eigenvalues of } A = A^T \\text{ are positive if and only if the pivots are positive:  } a>0 \\text{ and } \\frac{ac-b^2}{a}>0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbae124-1fe0-4526-a88d-be69fd664ea4",
   "metadata": {},
   "source": [
    "- $a > 0$은 위 두 test에서 모두 요구하는 조건!!\n",
    "- 그래서 $ac>b^2$도 요구됨!\n",
    "\n",
    "$$\\begin{bmatrix}{1}&{b}\\\\{b}&{c}\\end{bmatrix} \\begin{matrix}{\\text{The first pivot is a}}\\\\{\\longrightarrow}\\\\{\\text{The multiplier is b/a}}\\end{matrix}\\begin{bmatrix}{a}&{b}\\\\{0}&{c-\\frac{b}{a}b}\\end{bmatrix}\\begin{matrix}{\\text{The second pivot is}}\\\\{c-\\frac{b^2}{a}=\\frac{ac-b^2}{a}}\\end{matrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e650b571-643d-4f45-ad76-a32faa243a1f",
   "metadata": {},
   "source": [
    "**Positive eigenvalues mean positive pivots and vice versa. 양수인 고유겂은 양수인 피벗을 의미하고 그 반대도 마찬가지!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61921c32-59e1-4c44-a00a-30b27145a5ab",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93dd237-883d-4cf1-9704-467a45f9a393",
   "metadata": {},
   "source": [
    "#### Energy-based Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca86f5c-e7c6-47ce-8047-976ebb6c9edb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d730cb0-1317-4148-a048-4a7e87f77882",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6dfc104-f2ca-4974-b696-071d3547e91b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73530a11-a553-4fbf-bfb3-39973afcdf41",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b910905-8301-45e0-a3e2-879094b1fd4d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd10c826-519b-4937-9f78-efab6d30a34d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb288a4f-d9da-44ab-8a62-9184f53bb4c0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12d7e835-10cb-4c87-adee-e217e280bbd1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f4f640e-7002-49d3-a708-e7a929626030",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "807adf36-fa9b-46cd-a513-e0389a8bf331",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69120212-563d-40f5-a089-5e7a145234ee",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53f6fa09-0787-4b74-b395-5a683d9c5f51",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ab67f52-3496-4f1b-bb7a-3b7f2370d637",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd0b759a-55c7-4c58-a23b-1e646ee9e067",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71d663dd-53cd-4afe-87f6-c2436c7f2679",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9112e465-7cb9-485a-b41e-bb3b2fd3a2a1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d061382-4ba4-4d77-98d3-edc29f0971af",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22faf0c3-551e-4033-9407-8bd5d3ed3984",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a0ecc8d-3bfd-4983-9198-a0d34cc1d06b",
   "metadata": {},
   "source": [
    "### Gilbert Strang 강의영상...!."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed1205d-3b7c-4eb8-bdeb-6c89182ca9aa",
   "metadata": {},
   "source": [
    "> youtube: https://www.youtube.com/watch?v=ZK3O402wf1c&list=PL49CF3715CB9EF31D&index=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
